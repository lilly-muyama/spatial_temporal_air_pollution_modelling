{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e5c435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 19:05:01.816723: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 19:05:01.882487: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-10 19:05:01.884795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-10 19:05:01.884807: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-10 19:05:02.210594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-10 19:05:02.210623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-10 19:05:02.210626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from math import sqrt\n",
    "sys.path.append('../..')\n",
    "from modules import utils\n",
    "import gpflow\n",
    "from gpflow import set_trainable\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3788d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "# random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "# os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# gpflow.config.set_default_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4044e37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>930434</td>\n",
       "      <td>0.360209</td>\n",
       "      <td>32.610756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718028</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>32.620600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>912224</td>\n",
       "      <td>0.346460</td>\n",
       "      <td>32.703280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930426</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>32.646800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>930427</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>32.588000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       lat       long\n",
       "0  930434  0.360209  32.610756\n",
       "1  718028  0.307500  32.620600\n",
       "2  912224  0.346460  32.703280\n",
       "3  930426  0.365500  32.646800\n",
       "4  930427  0.268900  32.588000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kampala_devices = pd.read_csv('../data/kampala_devices.csv', usecols=['lat', 'long', 'id'])\n",
    "kampala_devices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0370166c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pm2_5_calibrated_value</th>\n",
       "      <th>pm2_5_raw_value</th>\n",
       "      <th>pm10_raw_value</th>\n",
       "      <th>pm10_calibrated_value</th>\n",
       "      <th>site_id</th>\n",
       "      <th>device_number</th>\n",
       "      <th>device_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Civic Centre, Kampala Central</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>32.592509</td>\n",
       "      <td>Kampala</td>\n",
       "      <td>2021-09-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6145</td>\n",
       "      <td>689761</td>\n",
       "      <td>aq_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civic Centre, Kampala Central</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>32.592509</td>\n",
       "      <td>Kampala</td>\n",
       "      <td>2021-09-01 01:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6145</td>\n",
       "      <td>689761</td>\n",
       "      <td>aq_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Civic Centre, Kampala Central</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>32.592509</td>\n",
       "      <td>Kampala</td>\n",
       "      <td>2021-09-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6145</td>\n",
       "      <td>689761</td>\n",
       "      <td>aq_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Civic Centre, Kampala Central</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>32.592509</td>\n",
       "      <td>Kampala</td>\n",
       "      <td>2021-09-01 03:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6145</td>\n",
       "      <td>689761</td>\n",
       "      <td>aq_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civic Centre, Kampala Central</td>\n",
       "      <td>0.317725</td>\n",
       "      <td>32.592509</td>\n",
       "      <td>Kampala</td>\n",
       "      <td>2021-09-01 04:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6145</td>\n",
       "      <td>689761</td>\n",
       "      <td>aq_26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       site_name  latitude  longitude     city  \\\n",
       "0  Civic Centre, Kampala Central  0.317725  32.592509  Kampala   \n",
       "1  Civic Centre, Kampala Central  0.317725  32.592509  Kampala   \n",
       "2  Civic Centre, Kampala Central  0.317725  32.592509  Kampala   \n",
       "3  Civic Centre, Kampala Central  0.317725  32.592509  Kampala   \n",
       "4  Civic Centre, Kampala Central  0.317725  32.592509  Kampala   \n",
       "\n",
       "                  timestamp  pm2_5_calibrated_value  pm2_5_raw_value  \\\n",
       "0 2021-09-01 00:00:00+00:00                     NaN              NaN   \n",
       "1 2021-09-01 01:00:00+00:00                     NaN              NaN   \n",
       "2 2021-09-01 02:00:00+00:00                     NaN              NaN   \n",
       "3 2021-09-01 03:00:00+00:00                     NaN              NaN   \n",
       "4 2021-09-01 04:00:00+00:00                     NaN              NaN   \n",
       "\n",
       "   pm10_raw_value  pm10_calibrated_value                   site_id  \\\n",
       "0             NaN                    NaN  60d058c8048305120d2d6145   \n",
       "1             NaN                    NaN  60d058c8048305120d2d6145   \n",
       "2             NaN                    NaN  60d058c8048305120d2d6145   \n",
       "3             NaN                    NaN  60d058c8048305120d2d6145   \n",
       "4             NaN                    NaN  60d058c8048305120d2d6145   \n",
       "\n",
       "   device_number device_name  \n",
       "0         689761       aq_26  \n",
       "1         689761       aq_26  \n",
       "2         689761       aq_26  \n",
       "3         689761       aq_26  \n",
       "4         689761       aq_26  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kampala_df = pd.read_csv('../data/kampala_data.csv', parse_dates=['timestamp'])\n",
    "kampala_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d3adbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 52, 57)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitudes = kampala_df['latitude'].unique()\n",
    "longitudes = kampala_df['longitude'].unique()\n",
    "device_ids = kampala_df['device_number'].unique()\n",
    "len(latitudes), len(longitudes), len(device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4527b5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>453031.0</td>\n",
       "      <td>0.356989</td>\n",
       "      <td>32.613888</td>\n",
       "      <td>10.5477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453032.0</td>\n",
       "      <td>0.356989</td>\n",
       "      <td>32.613888</td>\n",
       "      <td>16.4250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>453033.0</td>\n",
       "      <td>0.356989</td>\n",
       "      <td>32.613888</td>\n",
       "      <td>17.7239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>453034.0</td>\n",
       "      <td>0.356989</td>\n",
       "      <td>32.613888</td>\n",
       "      <td>16.1533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>453035.0</td>\n",
       "      <td>0.356989</td>\n",
       "      <td>32.613888</td>\n",
       "      <td>18.0123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  latitude  longitude    pm2_5\n",
       "0  453031.0  0.356989  32.613888  10.5477\n",
       "1  453032.0  0.356989  32.613888  16.4250\n",
       "2  453033.0  0.356989  32.613888  17.7239\n",
       "3  453034.0  0.356989  32.613888  16.1533\n",
       "4  453035.0  0.356989  32.613888  18.0123"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "cols = ['timestamp', 'latitude', 'longitude', 'pm2_5_calibrated_value']\n",
    "# for i, device_id in enumerate(device_ids):\n",
    "for i, device_id in kampala_devices.id.iteritems():\n",
    "    device_df = utils.get_device_data(kampala_df, device_id, cols)\n",
    "    processed_df = utils.preprocessing(device_df)\n",
    "#     print(f'{device_id}: {len(processed_df)}')\n",
    "    final_df = pd.concat([final_df, processed_df])\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501c41db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48112, 35, 35)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df), len(final_df.latitude.unique()), len(final_df.longitude.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be929aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(final_df, idx, kernel_variance, lengthscales, likelihood_variance, trainable_kernel, \n",
    "                     trainable_variance, trainable_lengthscales):\n",
    "    device_indices = final_df[final_df.latitude==latitudes[idx]].index\n",
    "    device_df = kampala_df[kampala_df.device_number == device_ids[idx]]\n",
    "#     assert(len(device_indices) == len(device_df)-device_df.pm2_5_calibrated_value.isna().sum())\n",
    "    \n",
    "    test_df = final_df.loc[device_indices]\n",
    "#     assert(len(test_df.longitude.unique()) == 1)\n",
    "    \n",
    "    train_df = pd.concat([final_df, test_df]).drop_duplicates(keep=False)\n",
    "#     assert(len(train_df.longitude.unique()) == len(longitudes)-1)\n",
    "#     assert len(final_df) == len(test_df) + len(train_df)\n",
    "    \n",
    "    X_train = train_df.iloc[:, 0:-1]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train).reshape(-1, 1)\n",
    "    if X_train.shape[0] > 39999:\n",
    "        X_train = X_train[::6, :]\n",
    "        y_train = y_train[::6, :]\n",
    "#     print('printing x_train')\n",
    "    print(f'X_train shape:{X_train.shape}')\n",
    "    \n",
    "    X_test = test_df.iloc[:, 0:-1]\n",
    "    y_test = test_df.iloc[:, -1]\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test).reshape(-1, 1)\n",
    "    #to delete\n",
    "    #X_train, y_train, X_test, y_test = X_train[:100, :], y_train[:100, :], X_test[:100, :], y_test[:100, :]\n",
    "    \n",
    "    if lengthscales == 'train_shape':\n",
    "        lengthscales = np.ones(X_train.shape[1])\n",
    "    \n",
    "    if (lengthscales is None) & (kernel_variance is None):\n",
    "        k = gpflow.kernels.RBF() + gpflow.kernels.Bias()\n",
    "    elif lengthscales is None:\n",
    "        k = gpflow.kernels.RBF(variance=kernel_variance) + gpflow.kernels.Bias()\n",
    "    elif kernel_variance is None:\n",
    "        k = gpflow.kernels.RBF(lengthscales=lengthscales) + gpflow.kernels.Bias()\n",
    "    else:\n",
    "        k = gpflow.kernels.RBF(lengthscales=lengthscales, variance=kernel_variance) + gpflow.kernels.Bias()\n",
    "    print('Training model .....................')    \n",
    "    m = gpflow.models.GPR(data=(X_train, y_train), kernel=k, mean_function=None)\n",
    "    if likelihood_variance is None:\n",
    "        pass\n",
    "    else:\n",
    "        m.likelihood.variance.assign(likelihood_variance)\n",
    "    set_trainable(m.kernel.kernels[0].variance, trainable_kernel)\n",
    "    set_trainable(m.likelihood.variance, trainable_variance)\n",
    "    set_trainable(m.kernel.kernels[0].lengthscales, trainable_lengthscales)\n",
    "    \n",
    "    #optimization\n",
    "    print('Optimizing model ...........................')\n",
    "    opt = gpflow.optimizers.Scipy()\n",
    "    def objective_closure():\n",
    "        return - m.log_marginal_likelihood()\n",
    "    \n",
    "    opt_logs = opt.minimize(objective_closure,\n",
    "                            m.trainable_variables,\n",
    "                            options=dict(maxiter=100))\n",
    "\n",
    "    #prediction\n",
    "    mean, var = m.predict_f(X_test)\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_test, mean.numpy()))\n",
    "    mape = mean_absolute_percentage_error(y_test, mean.numpy())\n",
    "    return rmse, mape\n",
    "    \n",
    "#     return mean.numpy(), var.numpy(), Xtest, Ytest, round(rmse, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928bfce",
   "metadata": {},
   "source": [
    "#### The real work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f270d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lengthscales = [[0.08, 0.08, 1], None, 'train_shape']\n",
    "lengthscales = [[0.08, 0.08, 1]]\n",
    "# likelihood_variances = [400, 625, None]\n",
    "likelihood_variances = [400]\n",
    "# kernel_variances = [625, 400, None]\n",
    "kernel_variances  = [625]\n",
    "# trainable_kernels = [True, False]\n",
    "trainable_kernels = [True]\n",
    "# trainable_variances = [True, False]\n",
    "trainable_variances = [True]\n",
    "# trainable_lengthscales = [False, True]\n",
    "trainable_lengthscales = [False] #only changed this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "146de88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 1\n",
      "689761 starting ...\n",
      "X_train shape:(7664, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 19:05:13.027442: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-10 19:05:13.027471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: PL1207-PRO.paris.inria.fr\n",
      "2023-07-10 19:05:13.027473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: PL1207-PRO.paris.inria.fr\n",
      "2023-07-10 19:05:13.027568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.125.6\n",
      "2023-07-10 19:05:13.027593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  525.125.06  Release Build  (dvs-builder@U16-A23-14-1)  Tue May 30 05:12:48 UTC 2023\n",
      "GCC version:  gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) \n",
      "\"\n",
      "2023-07-10 19:05:13.028342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "WARNING:tensorflow:From /home/lmuyama/anaconda3/envs/gp_env/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "689761 successful\n",
      "718028 starting ...\n",
      "X_train shape:(7770, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "718028 successful\n",
      "718029 starting ...\n",
      "X_train shape:(7926, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "718029 successful\n",
      "737273 starting ...\n",
      "X_train shape:(7924, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "737273 successful\n",
      "737276 starting ...\n",
      "X_train shape:(7944, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "737276 successful\n",
      "755612 starting ...\n",
      "X_train shape:(7745, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "755612 successful\n",
      "755614 starting ...\n",
      "X_train shape:(7663, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "755614 successful\n",
      "782718 starting ...\n",
      "X_train shape:(7747, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "782718 successful\n",
      "782719 starting ...\n",
      "X_train shape:(7785, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "782719 successful\n",
      "782720 starting ...\n",
      "X_train shape:(7796, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "782720 successful\n",
      "782721 starting ...\n",
      "X_train shape:(7787, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "782721 successful\n",
      "782722 starting ...\n",
      "X_train shape:(7655, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "782722 successful\n",
      "832251 starting ...\n",
      "X_train shape:(7780, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "832251 successful\n",
      "832252 starting ...\n",
      "X_train shape:(7787, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "832252 successful\n",
      "832253 starting ...\n",
      "X_train shape:(7738, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "832253 successful\n",
      "832254 starting ...\n",
      "X_train shape:(7788, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "832254 successful\n",
      "832255 starting ...\n",
      "X_train shape:(7669, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "832255 successful\n",
      "870142 starting ...\n",
      "X_train shape:(7938, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "870142 successful\n",
      "870143 starting ...\n",
      "X_train shape:(7868, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "870143 successful\n",
      "870144 starting ...\n",
      "X_train shape:(7780, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "870144 successful\n",
      "870145 starting ...\n",
      "X_train shape:(7812, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "870145 successful\n",
      "870146 starting ...\n",
      "X_train shape:(7755, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "870146 successful\n",
      "870147 starting ...\n",
      "X_train shape:(7693, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "870147 successful\n",
      "912219 starting ...\n",
      "X_train shape:(7825, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "912219 successful\n",
      "912220 starting ...\n",
      "X_train shape:(7811, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "912220 successful\n",
      "912221 starting ...\n",
      "X_train shape:(7920, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "912221 successful\n",
      "912222 starting ...\n",
      "X_train shape:(7780, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "912222 successful\n",
      "912223 starting ...\n",
      "X_train shape:(7691, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "912223 successful\n",
      "912224 starting ...\n",
      "X_train shape:(7861, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "912224 successful\n",
      "912225 starting ...\n",
      "X_train shape:(8007, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "912225 successful\n",
      "930426 starting ...\n",
      "X_train shape:(7661, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "930426 successful\n",
      "930427 starting ...\n",
      "X_train shape:(7807, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "930427 successful\n",
      "930429 starting ...\n",
      "X_train shape:(7745, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "930429 successful\n",
      "930431 starting ...\n",
      "X_train shape:(7832, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "930431 successful\n",
      "930434 starting ...\n",
      "X_train shape:(8019, 3)\n",
      "Training model .....................\n",
      "Optimizing model ...........................\n",
      "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required.\n",
      "930434 failed\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_mape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_90667/264219889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                        \u001b[0;34m'kernel_variance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkernel_variance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trainable_kernel'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrainable_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                        \u001b[0;34m'trainable_variance'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrainable_variance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'trainable_lengthscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrainable_lengthscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                                        'avg_rmse':mean_rmse, 'rmse_list':rmse_list, 'avg_mape':mean_mape, 'mape_list':mape_list}\n\u001b[0m\u001b[1;32m     32\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mean_mape' is not defined"
     ]
    }
   ],
   "source": [
    "# results_df = pd.DataFrame()\n",
    "count = 0\n",
    "results_df = pd.DataFrame()\n",
    "for lengthscale in lengthscales:\n",
    "    for likelihood_variance in likelihood_variances:\n",
    "        for kernel_variance in kernel_variances:\n",
    "            for trainable_kernel in trainable_kernels:\n",
    "                for trainable_variance in trainable_variances:\n",
    "                    for trainable_lengthscale in trainable_lengthscales:\n",
    "                        count+=1\n",
    "                        rmse_list = []\n",
    "                        mape_list = []\n",
    "                        print(f'EXPERIMENT {count}')\n",
    "                        for i in range(len(latitudes)):\n",
    "                            try:\n",
    "                                print(f'{device_ids[i]} starting ...')\n",
    "                                rmse, mape = cross_validation(final_df, i, kernel_variance, lengthscale, likelihood_variance, \n",
    "                                                        trainable_kernel, trainable_variance, trainable_lengthscale)\n",
    "                                rmse_list.append(rmse)\n",
    "                                mape_list.append(mape)\n",
    "                                print(f'{device_ids[i]} successful')\n",
    "                            except Exception as e:\n",
    "                                print(e)\n",
    "                                print(f'{device_ids[i]} failed')\n",
    "                                break\n",
    "                            \n",
    "                        mean_rmse = np.mean(rmse_list)\n",
    "                        mean_mape = np.mean(mape_list)\n",
    "                        results_dict= {'lengthscale':lengthscale, 'likelihood_variance':likelihood_variance, \n",
    "                                       'kernel_variance':kernel_variance, 'trainable_kernel':trainable_kernel, \n",
    "                                       'trainable_variance':trainable_variance, 'trainable_lengthscale':trainable_lengthscale, \n",
    "                                       'avg_rmse':mean_rmse, 'rmse_list':rmse_list, 'avg_mape':mean_mape, 'mape_list':mape_list}\n",
    "                        print(results_dict)\n",
    "                        results_df = results_df.append(results_dict, ignore_index=True)\n",
    "                        results_df.to_csv(f'../results/basic_results_mape_{count}.csv', index=False)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78d074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd712a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
