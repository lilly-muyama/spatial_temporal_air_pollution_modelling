{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148a9670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:50:48.416038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 21:50:48.485158: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-06 21:50:48.487163: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:50:48.487172: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-06 21:50:48.827077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:50:48.827106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:50:48.827109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from math import sqrt\n",
    "sys.path.append('../..')\n",
    "from modules import utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86911a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0afe661",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c1406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pm2_5_calibrated_value</th>\n",
       "      <th>pm2_5_raw_value</th>\n",
       "      <th>pm10_raw_value</th>\n",
       "      <th>pm10_calibrated_value</th>\n",
       "      <th>site_id</th>\n",
       "      <th>device_number</th>\n",
       "      <th>device_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 01:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 03:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 04:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  site_name  latitude  longitude   city  \\\n",
       "0  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "1  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "2  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "3  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "4  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "\n",
       "                  timestamp  pm2_5_calibrated_value  pm2_5_raw_value  \\\n",
       "0 2021-09-01 00:00:00+00:00                     NaN              NaN   \n",
       "1 2021-09-01 01:00:00+00:00                     NaN              NaN   \n",
       "2 2021-09-01 02:00:00+00:00                     NaN              NaN   \n",
       "3 2021-09-01 03:00:00+00:00                     NaN              NaN   \n",
       "4 2021-09-01 04:00:00+00:00                     NaN              NaN   \n",
       "\n",
       "   pm10_raw_value  pm10_calibrated_value                   site_id  \\\n",
       "0             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "1             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "2             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "3             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "4             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "\n",
       "   device_number device_name  \n",
       "0         689753       aq_23  \n",
       "1         689753       aq_23  \n",
       "2         689753       aq_23  \n",
       "3         689753       aq_23  \n",
       "4         689753       aq_23  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jinja_df = pd.read_csv('../data/jinja_data.csv', parse_dates=['timestamp'])\n",
    "jinja_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8a2954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitudes = jinja_df['latitude'].unique()\n",
    "longitudes = jinja_df['longitude'].unique()\n",
    "device_ids = jinja_df['device_number'].unique()\n",
    "len(latitudes), len(longitudes), len(device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07dea145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452909.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>12.2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452910.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>11.6507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452911.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>22.3980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>452912.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>17.4937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452913.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>25.1622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  latitude  longitude    pm2_5\n",
       "0  452909.0  0.437337  33.211051  12.2844\n",
       "1  452910.0  0.437337  33.211051  11.6507\n",
       "2  452911.0  0.437337  33.211051  22.3980\n",
       "3  452912.0  0.437337  33.211051  17.4937\n",
       "4  452913.0  0.437337  33.211051  25.1622"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "cols = ['timestamp', 'latitude', 'longitude', 'pm2_5_calibrated_value']\n",
    "for i, device_id in enumerate(device_ids):\n",
    "    device_df = utils.get_device_data(jinja_df, device_id, cols)\n",
    "    processed_df = utils.preprocessing(device_df)\n",
    "    final_df = pd.concat([final_df, processed_df])\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593969e",
   "metadata": {},
   "source": [
    "#### Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbae94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffnn(X_train, y_train, epochs=1000, optimizer='RMSProp', dropout=0.2):\n",
    "    model = tf.keras.Sequential() \n",
    "    model.add(Input(shape=(X_train.shape[1],), name='Input-Layer')) \n",
    "#     model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(128, activation='relu', name='Hidden-Layer1'))\n",
    "#     model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(32, activation='relu', name='Hidden-Layer2'))\n",
    "#     model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(1, activation='linear', name='Output-Layer')) \n",
    "\n",
    "    model.compile(optimizer=optimizer, # default='rmsprop', an algorithm to be used in backpropagation\n",
    "                  loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 )\n",
    "    model.fit(X_train, \n",
    "          y_train,\n",
    "          batch_size=32,\n",
    "          epochs=epochs, # default=1, Number of epochs to train the model\n",
    "          callbacks=None,\n",
    "          validation_split=0.2, \n",
    "         )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484a957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_data(X):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     X_scaled = X.copy()\n",
    "#     X_scaled[:, 0] = scaler.fit_transform(X[:, 0].reshape(-1, 1)).flatten()\n",
    "#     return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2795c0b",
   "metadata": {},
   "source": [
    "#### delete from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b246fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# device_indices = final_df[final_df.latitude==latitudes[idx]].index\n",
    "# device_df = jinja_df[jinja_df.device_number == device_ids[idx]]\n",
    "# assert(len(device_indices) == len(device_df)-device_df.pm2_5_calibrated_value.isna().sum())\n",
    "# test_df = final_df.loc[device_indices]\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113bbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([final_df, test_df]).drop_duplicates(keep=False)\n",
    "# assert(len(train_df.longitude.unique()) == len(longitudes)-1)\n",
    "# assert len(final_df) == len(test_df) + len(train_df)\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c4dae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train_df.iloc[:, 0:-1]\n",
    "# y_train = train_df.iloc[:, -1]\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)#.reshape(-1, 1)\n",
    "\n",
    "# X_test = test_df.iloc[:, 0:-1]\n",
    "# y_test = test_df.iloc[:, -1]\n",
    "# X_test, y_test = np.array(X_test), np.array(y_test)#.reshape(-1, 1)\n",
    "# X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b81083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98e539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = scale_data(X_train)\n",
    "# X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c01784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ffnn(X_train, y_train, 500, 'RMSProp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38805ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test) \n",
    "# y_pred.shape, y_test.reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46a83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(y_pred), np.mean(y_pred), np.max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0aaefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b5965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = model.predict(X_train)\n",
    "# mean_squared_error(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03798db5",
   "metadata": {},
   "source": [
    "#### end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d0392e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(final_df, idx):\n",
    "    device_indices = final_df[final_df.latitude==latitudes[idx]].index\n",
    "    device_df = jinja_df[jinja_df.device_number == device_ids[idx]]\n",
    "    assert(len(device_indices) == len(device_df)-device_df.pm2_5_calibrated_value.isna().sum())\n",
    "    \n",
    "    test_df = final_df.loc[device_indices]\n",
    "    assert(len(test_df.longitude.unique()) == 1)\n",
    "    \n",
    "    train_df = pd.concat([final_df, test_df]).drop_duplicates(keep=False)\n",
    "    assert(len(train_df.longitude.unique()) == len(longitudes)-1)\n",
    "    assert len(final_df) == len(test_df) + len(train_df)\n",
    "    \n",
    "    X_train = train_df.iloc[:, 0:-1]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)#.reshape(-1, 1)\n",
    "#     X_train_scaled = scale_data(X_train)\n",
    "    \n",
    "    X_test = test_df.iloc[:, 0:-1]\n",
    "    y_test = test_df.iloc[:, -1]\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)#.reshape(-1, 1)\n",
    "#     X_test_scaled = scale_data(X_test)\n",
    "    \n",
    "    model = ffnn(X_train, y_train, optimizer='Adam', dropout=0.8)\n",
    "    y_pred = model.predict(X_test) \n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    return rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fe7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:50:50.523981: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-06 21:50:50.524003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: PL1207-PRO.paris.inria.fr\n",
      "2023-07-06 21:50:50.524006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: PL1207-PRO.paris.inria.fr\n",
      "2023-07-06 21:50:50.524087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.125.6\n",
      "2023-07-06 21:50:50.524099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  525.116.04  Release Build  (dvs-builder@U16-I3-A16-3-3)  Thu Apr 27 18:11:06 UTC 2023\n",
      "GCC version:  gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) \n",
      "\"\n",
      "2023-07-06 21:50:50.524307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 1ms/step - loss: 14429381.0000 - val_loss: 695.1968\n",
      "Epoch 2/1000\n",
      "289/289 [==============================] - 0s 934us/step - loss: 440.1732 - val_loss: 630.7939\n",
      "Epoch 3/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 448.7069 - val_loss: 714.0650\n",
      "Epoch 4/1000\n",
      "289/289 [==============================] - 0s 837us/step - loss: 488.5003 - val_loss: 635.2147\n",
      "Epoch 5/1000\n",
      "289/289 [==============================] - 0s 710us/step - loss: 472.7919 - val_loss: 844.3975\n",
      "Epoch 6/1000\n",
      "289/289 [==============================] - 0s 750us/step - loss: 530.0157 - val_loss: 988.3795\n",
      "Epoch 7/1000\n",
      "289/289 [==============================] - 0s 806us/step - loss: 563.4109 - val_loss: 709.6088\n",
      "Epoch 8/1000\n",
      "289/289 [==============================] - 0s 752us/step - loss: 611.3159 - val_loss: 692.2584\n",
      "Epoch 9/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 601.9983 - val_loss: 868.5683\n",
      "Epoch 10/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 705.1030 - val_loss: 981.1019\n",
      "Epoch 11/1000\n",
      "289/289 [==============================] - 0s 915us/step - loss: 808.4721 - val_loss: 697.9484\n",
      "Epoch 12/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 1144.2581 - val_loss: 1022.1990\n",
      "Epoch 13/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 2490.0598 - val_loss: 808.0933\n",
      "Epoch 14/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 74505.6953 - val_loss: 11405.3447\n",
      "Epoch 15/1000\n",
      "289/289 [==============================] - 0s 894us/step - loss: 47751.2852 - val_loss: 117543.3125\n",
      "Epoch 16/1000\n",
      "289/289 [==============================] - 0s 801us/step - loss: 76324.4766 - val_loss: 1310.5264\n",
      "Epoch 17/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 70443.5000 - val_loss: 113783.6328\n",
      "Epoch 18/1000\n",
      "289/289 [==============================] - 0s 864us/step - loss: 80953.0547 - val_loss: 500102.0938\n",
      "Epoch 19/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 71139.7969 - val_loss: 75553.6172\n",
      "Epoch 20/1000\n",
      "289/289 [==============================] - 0s 722us/step - loss: 90546.3594 - val_loss: 4641.3789\n",
      "Epoch 21/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 54724.6953 - val_loss: 5784.8301\n",
      "Epoch 22/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 72941.5625 - val_loss: 111178.1953\n",
      "Epoch 23/1000\n",
      "289/289 [==============================] - 0s 897us/step - loss: 62827.7656 - val_loss: 67516.3750\n",
      "Epoch 24/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 61900.6836 - val_loss: 42756.0430\n",
      "Epoch 25/1000\n",
      "289/289 [==============================] - 0s 826us/step - loss: 79563.5547 - val_loss: 20054.3418\n",
      "Epoch 26/1000\n",
      "289/289 [==============================] - 0s 774us/step - loss: 49606.1602 - val_loss: 61311.2305\n",
      "Epoch 27/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 66096.2891 - val_loss: 12731.3359\n",
      "Epoch 28/1000\n",
      "289/289 [==============================] - 0s 714us/step - loss: 56882.0117 - val_loss: 13783.2480\n",
      "Epoch 29/1000\n",
      "289/289 [==============================] - 0s 718us/step - loss: 61552.6133 - val_loss: 2308.1270\n",
      "Epoch 30/1000\n",
      "289/289 [==============================] - 0s 833us/step - loss: 57075.8984 - val_loss: 64459.0820\n",
      "Epoch 31/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 54958.4688 - val_loss: 2845.2720\n",
      "Epoch 32/1000\n",
      "289/289 [==============================] - 0s 753us/step - loss: 58808.4922 - val_loss: 9741.8008\n",
      "Epoch 33/1000\n",
      "289/289 [==============================] - 0s 822us/step - loss: 57395.2930 - val_loss: 76011.7969\n",
      "Epoch 34/1000\n",
      "289/289 [==============================] - 0s 909us/step - loss: 52567.5430 - val_loss: 108511.1875\n",
      "Epoch 35/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 47095.0430 - val_loss: 354744.7188\n",
      "Epoch 36/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 52989.9766 - val_loss: 8545.5010\n",
      "Epoch 37/1000\n",
      "289/289 [==============================] - 0s 908us/step - loss: 49882.7266 - val_loss: 6441.6079\n",
      "Epoch 38/1000\n",
      "289/289 [==============================] - 0s 754us/step - loss: 63054.7812 - val_loss: 22087.3047\n",
      "Epoch 39/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 43396.4141 - val_loss: 8534.8389\n",
      "Epoch 40/1000\n",
      "289/289 [==============================] - 0s 868us/step - loss: 41881.6602 - val_loss: 25334.4570\n",
      "Epoch 41/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 47077.5508 - val_loss: 3260.0962\n",
      "Epoch 42/1000\n",
      "289/289 [==============================] - 0s 868us/step - loss: 42653.2109 - val_loss: 20690.6113\n",
      "Epoch 43/1000\n",
      "289/289 [==============================] - 0s 902us/step - loss: 47697.0547 - val_loss: 346152.2188\n",
      "Epoch 44/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 41923.2188 - val_loss: 3254.2708\n",
      "Epoch 45/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 46498.2461 - val_loss: 2663.4854\n",
      "Epoch 46/1000\n",
      "289/289 [==============================] - 0s 834us/step - loss: 48771.7734 - val_loss: 5141.3281\n",
      "Epoch 47/1000\n",
      "289/289 [==============================] - 0s 763us/step - loss: 38141.8750 - val_loss: 6778.6655\n",
      "Epoch 48/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 42505.3555 - val_loss: 13931.0830\n",
      "Epoch 49/1000\n",
      "289/289 [==============================] - 0s 768us/step - loss: 39894.1133 - val_loss: 629.4484\n",
      "Epoch 50/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 43764.2578 - val_loss: 116547.9453\n",
      "Epoch 51/1000\n",
      "289/289 [==============================] - 0s 928us/step - loss: 35626.6172 - val_loss: 786.7567\n",
      "Epoch 52/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 39673.8516 - val_loss: 10213.2041\n",
      "Epoch 53/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 46590.2969 - val_loss: 120400.5547\n",
      "Epoch 54/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 26357.2539 - val_loss: 24916.4414\n",
      "Epoch 55/1000\n",
      "289/289 [==============================] - 0s 728us/step - loss: 36485.2188 - val_loss: 5713.6343\n",
      "Epoch 56/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 37228.9219 - val_loss: 22822.1953\n",
      "Epoch 57/1000\n",
      "289/289 [==============================] - 0s 730us/step - loss: 32850.2344 - val_loss: 8399.8643\n",
      "Epoch 58/1000\n",
      "289/289 [==============================] - 0s 806us/step - loss: 37318.2461 - val_loss: 4092.3789\n",
      "Epoch 59/1000\n",
      "289/289 [==============================] - 0s 857us/step - loss: 36345.2656 - val_loss: 857.6076\n",
      "Epoch 60/1000\n",
      "289/289 [==============================] - 0s 872us/step - loss: 29007.9688 - val_loss: 1099.2152\n",
      "Epoch 61/1000\n",
      "289/289 [==============================] - 0s 742us/step - loss: 29352.6934 - val_loss: 18364.3281\n",
      "Epoch 62/1000\n",
      "289/289 [==============================] - 0s 918us/step - loss: 35835.1953 - val_loss: 13292.7627\n",
      "Epoch 63/1000\n",
      "289/289 [==============================] - 0s 868us/step - loss: 33978.9805 - val_loss: 18122.8320\n",
      "Epoch 64/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 27152.2148 - val_loss: 19118.4766\n",
      "Epoch 65/1000\n",
      "289/289 [==============================] - 0s 806us/step - loss: 30068.7910 - val_loss: 5682.9067\n",
      "Epoch 66/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 29515.3184 - val_loss: 30463.4668\n",
      "Epoch 67/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 28131.9004 - val_loss: 10897.0195\n",
      "Epoch 68/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 24979.8496 - val_loss: 17022.5762\n",
      "Epoch 69/1000\n",
      "289/289 [==============================] - 0s 892us/step - loss: 28325.3965 - val_loss: 6316.6279\n",
      "Epoch 70/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 36345.1250 - val_loss: 5356.5703\n",
      "Epoch 71/1000\n",
      "289/289 [==============================] - 0s 819us/step - loss: 16493.0840 - val_loss: 21999.4727\n",
      "Epoch 72/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 24698.9141 - val_loss: 3406.2654\n",
      "Epoch 73/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 25065.3672 - val_loss: 7819.0483\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 743us/step - loss: 27155.5254 - val_loss: 637.7709\n",
      "Epoch 75/1000\n",
      "289/289 [==============================] - 0s 798us/step - loss: 21555.9746 - val_loss: 15788.6992\n",
      "Epoch 76/1000\n",
      "289/289 [==============================] - 0s 724us/step - loss: 23540.2852 - val_loss: 2550.6472\n",
      "Epoch 77/1000\n",
      "289/289 [==============================] - 0s 916us/step - loss: 22780.8262 - val_loss: 31565.1992\n",
      "Epoch 78/1000\n",
      "289/289 [==============================] - 0s 747us/step - loss: 19399.4590 - val_loss: 18866.4238\n",
      "Epoch 79/1000\n",
      "289/289 [==============================] - 0s 720us/step - loss: 17685.8828 - val_loss: 89440.0781\n",
      "Epoch 80/1000\n",
      "289/289 [==============================] - 0s 716us/step - loss: 21029.6035 - val_loss: 6868.3315\n",
      "Epoch 81/1000\n",
      "289/289 [==============================] - 0s 777us/step - loss: 19354.2363 - val_loss: 22005.6074\n",
      "Epoch 82/1000\n",
      "289/289 [==============================] - 0s 939us/step - loss: 24778.8652 - val_loss: 9825.4619\n",
      "Epoch 83/1000\n",
      "289/289 [==============================] - 0s 812us/step - loss: 19229.8477 - val_loss: 1214.1903\n",
      "Epoch 84/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 16838.9902 - val_loss: 5804.4404\n",
      "Epoch 85/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 13456.3418 - val_loss: 1889.8245\n",
      "Epoch 86/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 19290.1973 - val_loss: 667.0338\n",
      "Epoch 87/1000\n",
      "289/289 [==============================] - 0s 847us/step - loss: 19740.2637 - val_loss: 925.1835\n",
      "Epoch 88/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 13800.5049 - val_loss: 18091.7344\n",
      "Epoch 89/1000\n",
      "289/289 [==============================] - 0s 956us/step - loss: 18569.2480 - val_loss: 1534.2593\n",
      "Epoch 90/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 14522.0205 - val_loss: 3397.7046\n",
      "Epoch 91/1000\n",
      "289/289 [==============================] - 0s 850us/step - loss: 15979.5479 - val_loss: 6669.3872\n",
      "Epoch 92/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 14755.2109 - val_loss: 1661.5638\n",
      "Epoch 93/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 16454.9609 - val_loss: 22579.3398\n",
      "Epoch 94/1000\n",
      "289/289 [==============================] - 0s 822us/step - loss: 15608.4404 - val_loss: 632.0159\n",
      "Epoch 95/1000\n",
      "289/289 [==============================] - 0s 874us/step - loss: 12956.2070 - val_loss: 13116.0566\n",
      "Epoch 96/1000\n",
      "289/289 [==============================] - 0s 900us/step - loss: 18400.3672 - val_loss: 16840.5801\n",
      "Epoch 97/1000\n",
      "289/289 [==============================] - 0s 779us/step - loss: 10848.3154 - val_loss: 3554.2395\n",
      "Epoch 98/1000\n",
      "289/289 [==============================] - 0s 873us/step - loss: 14963.9160 - val_loss: 16544.3340\n",
      "Epoch 99/1000\n",
      "289/289 [==============================] - 0s 874us/step - loss: 12446.3242 - val_loss: 8580.5068\n",
      "Epoch 100/1000\n",
      "289/289 [==============================] - 0s 823us/step - loss: 15531.3828 - val_loss: 32120.1250\n",
      "Epoch 101/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 12347.2627 - val_loss: 12053.9199\n",
      "Epoch 102/1000\n",
      "289/289 [==============================] - 0s 919us/step - loss: 13504.0049 - val_loss: 686.4132\n",
      "Epoch 103/1000\n",
      "289/289 [==============================] - 0s 781us/step - loss: 12822.9570 - val_loss: 13112.1562\n",
      "Epoch 104/1000\n",
      "289/289 [==============================] - 0s 844us/step - loss: 13366.5107 - val_loss: 5802.1216\n",
      "Epoch 105/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 11351.2363 - val_loss: 8522.1797\n",
      "Epoch 106/1000\n",
      "289/289 [==============================] - 0s 882us/step - loss: 12374.2871 - val_loss: 7569.2104\n",
      "Epoch 107/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 11801.4092 - val_loss: 1097.1799\n",
      "Epoch 108/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 11005.7871 - val_loss: 634.6411\n",
      "Epoch 109/1000\n",
      "289/289 [==============================] - 0s 811us/step - loss: 11666.7852 - val_loss: 9427.8760\n",
      "Epoch 110/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 10352.2695 - val_loss: 7755.4067\n",
      "Epoch 111/1000\n",
      "289/289 [==============================] - 0s 774us/step - loss: 8501.0098 - val_loss: 1162.0011\n",
      "Epoch 112/1000\n",
      "289/289 [==============================] - 0s 846us/step - loss: 9965.0430 - val_loss: 2985.7300\n",
      "Epoch 113/1000\n",
      "289/289 [==============================] - 0s 950us/step - loss: 10763.8408 - val_loss: 27251.4941\n",
      "Epoch 114/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 9976.5850 - val_loss: 9203.4951\n",
      "Epoch 115/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 205802.2344 - val_loss: 659.8383\n",
      "Epoch 116/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 526.6123 - val_loss: 782.1684\n",
      "Epoch 117/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 659.3121 - val_loss: 955.7882\n",
      "Epoch 118/1000\n",
      "289/289 [==============================] - 0s 768us/step - loss: 768.3956 - val_loss: 1011.3933\n",
      "Epoch 119/1000\n",
      "289/289 [==============================] - 0s 672us/step - loss: 738.2620 - val_loss: 764.6636\n",
      "Epoch 120/1000\n",
      "289/289 [==============================] - 0s 755us/step - loss: 1007.4005 - val_loss: 687.3673\n",
      "Epoch 121/1000\n",
      "289/289 [==============================] - 0s 925us/step - loss: 1177.5083 - val_loss: 723.0703\n",
      "Epoch 122/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 1801.5879 - val_loss: 1108.0465\n",
      "Epoch 123/1000\n",
      "289/289 [==============================] - 0s 805us/step - loss: 5966.6616 - val_loss: 29604.4355\n",
      "Epoch 124/1000\n",
      "289/289 [==============================] - 0s 930us/step - loss: 8858.5918 - val_loss: 1966.4344\n",
      "Epoch 125/1000\n",
      "289/289 [==============================] - 0s 737us/step - loss: 9408.1240 - val_loss: 12415.9492\n",
      "Epoch 126/1000\n",
      "289/289 [==============================] - 0s 869us/step - loss: 6766.6177 - val_loss: 61249.7656\n",
      "Epoch 127/1000\n",
      "289/289 [==============================] - 0s 983us/step - loss: 8001.3926 - val_loss: 24715.9473\n",
      "Epoch 128/1000\n",
      "289/289 [==============================] - 0s 726us/step - loss: 6449.3140 - val_loss: 851.1068\n",
      "Epoch 129/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 9729.3701 - val_loss: 4266.0332\n",
      "Epoch 130/1000\n",
      "289/289 [==============================] - 0s 848us/step - loss: 5263.5361 - val_loss: 4491.6245\n",
      "Epoch 131/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 8479.2256 - val_loss: 1066.4250\n",
      "Epoch 132/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 6634.7100 - val_loss: 7581.9482\n",
      "Epoch 133/1000\n",
      "289/289 [==============================] - 0s 856us/step - loss: 7908.7563 - val_loss: 5808.6562\n",
      "Epoch 134/1000\n",
      "289/289 [==============================] - 0s 711us/step - loss: 5960.8052 - val_loss: 1700.6864\n",
      "Epoch 135/1000\n",
      "289/289 [==============================] - 0s 852us/step - loss: 7799.7974 - val_loss: 1837.8749\n",
      "Epoch 136/1000\n",
      "289/289 [==============================] - 0s 641us/step - loss: 6958.9604 - val_loss: 2789.8167\n",
      "Epoch 137/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 5796.7812 - val_loss: 2276.7036\n",
      "Epoch 138/1000\n",
      "289/289 [==============================] - 0s 787us/step - loss: 7163.6787 - val_loss: 635.1801\n",
      "Epoch 139/1000\n",
      "289/289 [==============================] - 0s 899us/step - loss: 5381.9761 - val_loss: 833.0428\n",
      "Epoch 140/1000\n",
      "289/289 [==============================] - 0s 781us/step - loss: 6521.8477 - val_loss: 12816.9736\n",
      "Epoch 141/1000\n",
      "289/289 [==============================] - 0s 853us/step - loss: 6974.7246 - val_loss: 1764.3971\n",
      "Epoch 142/1000\n",
      "289/289 [==============================] - 0s 838us/step - loss: 5318.8086 - val_loss: 1802.9662\n",
      "Epoch 143/1000\n",
      "289/289 [==============================] - 0s 747us/step - loss: 6340.3345 - val_loss: 1847.8029\n",
      "Epoch 144/1000\n",
      "289/289 [==============================] - 0s 658us/step - loss: 5888.7026 - val_loss: 2199.2083\n",
      "Epoch 145/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 5517.2026 - val_loss: 3810.1360\n",
      "Epoch 146/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 7121.8442 - val_loss: 974.3615\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 699us/step - loss: 4607.2720 - val_loss: 6634.4575\n",
      "Epoch 148/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 5595.3608 - val_loss: 5961.6587\n",
      "Epoch 149/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 27815.9180 - val_loss: 2171.8884\n",
      "Epoch 150/1000\n",
      "289/289 [==============================] - 0s 908us/step - loss: 839.6008 - val_loss: 649.4758\n",
      "Epoch 151/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 1331.8673 - val_loss: 626.0139\n",
      "Epoch 152/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 1933.7330 - val_loss: 15161.0801\n",
      "Epoch 153/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 5215.1392 - val_loss: 759.6946\n",
      "Epoch 154/1000\n",
      "289/289 [==============================] - 0s 734us/step - loss: 3638.9631 - val_loss: 25198.9844\n",
      "Epoch 155/1000\n",
      "289/289 [==============================] - 0s 725us/step - loss: 5058.0923 - val_loss: 7355.1499\n",
      "Epoch 156/1000\n",
      "289/289 [==============================] - 0s 950us/step - loss: 5500.6260 - val_loss: 13223.8018\n",
      "Epoch 157/1000\n",
      "289/289 [==============================] - 0s 835us/step - loss: 3822.2932 - val_loss: 11422.1523\n",
      "Epoch 158/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 5734.4897 - val_loss: 13565.1875\n",
      "Epoch 159/1000\n",
      "289/289 [==============================] - 0s 855us/step - loss: 3890.5271 - val_loss: 7782.5933\n",
      "Epoch 160/1000\n",
      "289/289 [==============================] - 0s 780us/step - loss: 3833.1265 - val_loss: 968.7737\n",
      "Epoch 161/1000\n",
      "289/289 [==============================] - 0s 715us/step - loss: 4258.2983 - val_loss: 3439.8135\n",
      "Epoch 162/1000\n",
      "289/289 [==============================] - 0s 742us/step - loss: 4717.7119 - val_loss: 7388.3262\n",
      "Epoch 163/1000\n",
      "289/289 [==============================] - 0s 808us/step - loss: 3201.7993 - val_loss: 723.6771\n",
      "Epoch 164/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 319432.1250 - val_loss: 662.0074\n",
      "Epoch 165/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 486.6591 - val_loss: 856.8799\n",
      "Epoch 166/1000\n",
      "289/289 [==============================] - 0s 682us/step - loss: 454.0922 - val_loss: 715.4400\n",
      "Epoch 167/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 484.9881 - val_loss: 626.3362\n",
      "Epoch 168/1000\n",
      "289/289 [==============================] - 0s 688us/step - loss: 494.8929 - val_loss: 727.5046\n",
      "Epoch 169/1000\n",
      "289/289 [==============================] - 0s 711us/step - loss: 510.0639 - val_loss: 647.9034\n",
      "Epoch 170/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 567.0624 - val_loss: 987.8080\n",
      "Epoch 171/1000\n",
      "289/289 [==============================] - 0s 725us/step - loss: 640.7410 - val_loss: 637.3008\n",
      "Epoch 172/1000\n",
      "289/289 [==============================] - 0s 652us/step - loss: 647.9424 - val_loss: 1081.8591\n",
      "Epoch 173/1000\n",
      "289/289 [==============================] - 0s 707us/step - loss: 717.8513 - val_loss: 1027.8352\n",
      "Epoch 174/1000\n",
      "289/289 [==============================] - 0s 783us/step - loss: 729.6785 - val_loss: 2109.3105\n",
      "Epoch 175/1000\n",
      "289/289 [==============================] - 0s 764us/step - loss: 1046.4950 - val_loss: 641.6901\n",
      "Epoch 176/1000\n",
      "289/289 [==============================] - 0s 721us/step - loss: 1306.7750 - val_loss: 2736.7793\n",
      "Epoch 177/1000\n",
      "289/289 [==============================] - 0s 704us/step - loss: 2422.7402 - val_loss: 12184.5625\n",
      "Epoch 178/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 2789.6692 - val_loss: 1401.9751\n",
      "Epoch 179/1000\n",
      "289/289 [==============================] - 0s 856us/step - loss: 3081.2991 - val_loss: 16128.1035\n",
      "Epoch 180/1000\n",
      "289/289 [==============================] - 0s 933us/step - loss: 2782.6672 - val_loss: 2336.3420\n",
      "Epoch 181/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 3029.5330 - val_loss: 789.5815\n",
      "Epoch 182/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 2758.0022 - val_loss: 4595.3052\n",
      "Epoch 183/1000\n",
      "289/289 [==============================] - 0s 953us/step - loss: 3287.2996 - val_loss: 1170.6085\n",
      "Epoch 184/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 2466.3440 - val_loss: 918.4912\n",
      "Epoch 185/1000\n",
      "289/289 [==============================] - 0s 1000us/step - loss: 2382.6750 - val_loss: 11088.9199\n",
      "Epoch 186/1000\n",
      "289/289 [==============================] - 0s 688us/step - loss: 3075.1511 - val_loss: 628.1213\n",
      "Epoch 187/1000\n",
      "289/289 [==============================] - 0s 670us/step - loss: 2249.0886 - val_loss: 729.5115\n",
      "Epoch 188/1000\n",
      "289/289 [==============================] - 0s 658us/step - loss: 2262.7891 - val_loss: 2691.2214\n",
      "Epoch 189/1000\n",
      "289/289 [==============================] - 0s 950us/step - loss: 3154.5134 - val_loss: 3239.0242\n",
      "Epoch 190/1000\n",
      "289/289 [==============================] - 0s 754us/step - loss: 2024.5139 - val_loss: 2450.3860\n",
      "Epoch 191/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 2085.7241 - val_loss: 6169.8560\n",
      "Epoch 192/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 2626.7334 - val_loss: 1037.4155\n",
      "Epoch 193/1000\n",
      "289/289 [==============================] - 0s 712us/step - loss: 3424.0081 - val_loss: 1963.6089\n",
      "Epoch 194/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 1422.6210 - val_loss: 671.5779\n",
      "Epoch 195/1000\n",
      "289/289 [==============================] - 0s 883us/step - loss: 2072.5027 - val_loss: 663.9141\n",
      "Epoch 196/1000\n",
      "289/289 [==============================] - 0s 765us/step - loss: 1791.4026 - val_loss: 3372.6021\n",
      "Epoch 197/1000\n",
      "289/289 [==============================] - 0s 674us/step - loss: 2814.0461 - val_loss: 9269.4023\n",
      "Epoch 198/1000\n",
      "289/289 [==============================] - 0s 752us/step - loss: 1440.1306 - val_loss: 1095.5104\n",
      "Epoch 199/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 1989.1941 - val_loss: 6599.1094\n",
      "Epoch 200/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 2584.7402 - val_loss: 743.7076\n",
      "Epoch 201/1000\n",
      "289/289 [==============================] - 0s 943us/step - loss: 2209.3242 - val_loss: 682.1219\n",
      "Epoch 202/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 2148.8347 - val_loss: 750.8138\n",
      "Epoch 203/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 1356.2491 - val_loss: 693.8826\n",
      "Epoch 204/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 2193.7817 - val_loss: 5956.0605\n",
      "Epoch 205/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 1691.9762 - val_loss: 814.1996\n",
      "Epoch 206/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 2310.0303 - val_loss: 1677.8016\n",
      "Epoch 207/1000\n",
      "289/289 [==============================] - 0s 822us/step - loss: 1572.9890 - val_loss: 4363.8511\n",
      "Epoch 208/1000\n",
      "289/289 [==============================] - 0s 677us/step - loss: 2265.9888 - val_loss: 2598.6096\n",
      "Epoch 209/1000\n",
      "289/289 [==============================] - 0s 666us/step - loss: 1127.4602 - val_loss: 1328.5835\n",
      "Epoch 210/1000\n",
      "289/289 [==============================] - 0s 684us/step - loss: 1480.2236 - val_loss: 1049.8015\n",
      "Epoch 211/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 90262.2109 - val_loss: 730.3693\n",
      "Epoch 212/1000\n",
      "289/289 [==============================] - 0s 684us/step - loss: 463.7682 - val_loss: 628.5188\n",
      "Epoch 213/1000\n",
      "289/289 [==============================] - 0s 650us/step - loss: 515.5731 - val_loss: 627.4954\n",
      "Epoch 214/1000\n",
      "289/289 [==============================] - 0s 642us/step - loss: 501.5655 - val_loss: 714.9620\n",
      "Epoch 215/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 482.8663 - val_loss: 764.7521\n",
      "Epoch 216/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 554.0499 - val_loss: 712.6649\n",
      "Epoch 217/1000\n",
      "289/289 [==============================] - 0s 798us/step - loss: 536.1084 - val_loss: 936.6159\n",
      "Epoch 218/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 581.5566 - val_loss: 946.0728\n",
      "Epoch 219/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 697.6838 - val_loss: 1046.1262\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 704us/step - loss: 797.3736 - val_loss: 653.6112\n",
      "Epoch 221/1000\n",
      "289/289 [==============================] - 0s 710us/step - loss: 826.3627 - val_loss: 722.7275\n",
      "Epoch 222/1000\n",
      "289/289 [==============================] - 0s 833us/step - loss: 921.1188 - val_loss: 628.2672\n",
      "Epoch 223/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 1260.9399 - val_loss: 816.9923\n",
      "Epoch 224/1000\n",
      "289/289 [==============================] - 0s 726us/step - loss: 1004.6031 - val_loss: 691.4389\n",
      "Epoch 225/1000\n",
      "289/289 [==============================] - 0s 839us/step - loss: 1516.5729 - val_loss: 1369.9880\n",
      "Epoch 226/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 1474.6846 - val_loss: 2639.3694\n",
      "Epoch 227/1000\n",
      "289/289 [==============================] - 0s 854us/step - loss: 1296.6978 - val_loss: 1385.8105\n",
      "Epoch 228/1000\n",
      "289/289 [==============================] - 0s 714us/step - loss: 1455.3848 - val_loss: 848.1095\n",
      "Epoch 229/1000\n",
      "289/289 [==============================] - 0s 746us/step - loss: 1445.4028 - val_loss: 3342.3835\n",
      "Epoch 230/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 1110.9386 - val_loss: 804.9417\n",
      "Epoch 231/1000\n",
      "289/289 [==============================] - 0s 698us/step - loss: 1590.5616 - val_loss: 970.9254\n",
      "Epoch 232/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 1220.9230 - val_loss: 630.1780\n",
      "Epoch 233/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 993.7370 - val_loss: 698.1259\n",
      "Epoch 234/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 19415.4355 - val_loss: 751.4908\n",
      "Epoch 235/1000\n",
      "289/289 [==============================] - 0s 991us/step - loss: 538.3055 - val_loss: 627.1092\n",
      "Epoch 236/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 489.0285 - val_loss: 625.9850\n",
      "Epoch 237/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 580.5547 - val_loss: 936.7304\n",
      "Epoch 238/1000\n",
      "289/289 [==============================] - 0s 731us/step - loss: 576.5883 - val_loss: 639.2263\n",
      "Epoch 239/1000\n",
      "289/289 [==============================] - 0s 712us/step - loss: 606.5898 - val_loss: 651.0336\n",
      "Epoch 240/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 764.3332 - val_loss: 1072.5043\n",
      "Epoch 241/1000\n",
      "289/289 [==============================] - 0s 903us/step - loss: 928.3985 - val_loss: 1455.1682\n",
      "Epoch 242/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 1303.5258 - val_loss: 2023.7212\n",
      "Epoch 243/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 930.8627 - val_loss: 630.5566\n",
      "Epoch 244/1000\n",
      "289/289 [==============================] - 0s 665us/step - loss: 1209.6506 - val_loss: 626.3677\n",
      "Epoch 245/1000\n",
      "289/289 [==============================] - 0s 684us/step - loss: 1065.8179 - val_loss: 647.7884\n",
      "Epoch 246/1000\n",
      "289/289 [==============================] - 0s 791us/step - loss: 873.9150 - val_loss: 1453.0632\n",
      "Epoch 247/1000\n",
      "289/289 [==============================] - 0s 845us/step - loss: 1250.0240 - val_loss: 703.0228\n",
      "Epoch 248/1000\n",
      "289/289 [==============================] - 0s 723us/step - loss: 1027.1035 - val_loss: 1051.8665\n",
      "Epoch 249/1000\n",
      "289/289 [==============================] - 0s 719us/step - loss: 1180.2604 - val_loss: 2087.1594\n",
      "Epoch 250/1000\n",
      "289/289 [==============================] - 0s 765us/step - loss: 925.0219 - val_loss: 1396.1322\n",
      "Epoch 251/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 1150.6279 - val_loss: 882.3874\n",
      "Epoch 252/1000\n",
      "289/289 [==============================] - 0s 921us/step - loss: 946.8242 - val_loss: 937.5350\n",
      "Epoch 253/1000\n",
      "289/289 [==============================] - 0s 852us/step - loss: 933.8223 - val_loss: 1349.0618\n",
      "Epoch 254/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 1026.5598 - val_loss: 766.4175\n",
      "Epoch 255/1000\n",
      "289/289 [==============================] - 0s 786us/step - loss: 1070.5458 - val_loss: 635.8525\n",
      "Epoch 256/1000\n",
      "289/289 [==============================] - 0s 790us/step - loss: 841.2557 - val_loss: 1611.0062\n",
      "Epoch 257/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 11947.2158 - val_loss: 1048.5710\n",
      "Epoch 258/1000\n",
      "289/289 [==============================] - 0s 923us/step - loss: 523.7990 - val_loss: 635.1567\n",
      "Epoch 259/1000\n",
      "289/289 [==============================] - 0s 884us/step - loss: 562.2890 - val_loss: 1467.8320\n",
      "Epoch 260/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 569.3179 - val_loss: 699.0903\n",
      "Epoch 261/1000\n",
      "289/289 [==============================] - 0s 834us/step - loss: 627.6619 - val_loss: 793.6158\n",
      "Epoch 262/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 561.8879 - val_loss: 701.9414\n",
      "Epoch 263/1000\n",
      "289/289 [==============================] - 0s 819us/step - loss: 579.1851 - val_loss: 1096.3195\n",
      "Epoch 264/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 728.4243 - val_loss: 637.6469\n",
      "Epoch 265/1000\n",
      "289/289 [==============================] - 0s 825us/step - loss: 686.6098 - val_loss: 751.2037\n",
      "Epoch 266/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 613.9811 - val_loss: 734.7488\n",
      "Epoch 267/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 763.9233 - val_loss: 1373.5946\n",
      "Epoch 268/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 1056.2992 - val_loss: 1031.4291\n",
      "Epoch 269/1000\n",
      "289/289 [==============================] - 0s 888us/step - loss: 832.7785 - val_loss: 2155.7961\n",
      "Epoch 270/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 741.3344 - val_loss: 1459.2554\n",
      "Epoch 271/1000\n",
      "289/289 [==============================] - 0s 723us/step - loss: 678.6208 - val_loss: 627.2473\n",
      "Epoch 272/1000\n",
      "289/289 [==============================] - 0s 708us/step - loss: 882.6956 - val_loss: 628.4012\n",
      "Epoch 273/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 672.1538 - val_loss: 655.5146\n",
      "Epoch 274/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 808.7679 - val_loss: 1265.4246\n",
      "Epoch 275/1000\n",
      "289/289 [==============================] - 0s 714us/step - loss: 665.7128 - val_loss: 2134.9622\n",
      "Epoch 276/1000\n",
      "289/289 [==============================] - 0s 780us/step - loss: 772.8752 - val_loss: 626.5994\n",
      "Epoch 277/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 660.1489 - val_loss: 648.3877\n",
      "Epoch 278/1000\n",
      "289/289 [==============================] - 0s 753us/step - loss: 723.5007 - val_loss: 2128.4775\n",
      "Epoch 279/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 704.1440 - val_loss: 995.6459\n",
      "Epoch 280/1000\n",
      "289/289 [==============================] - 0s 896us/step - loss: 749.4648 - val_loss: 692.4886\n",
      "Epoch 281/1000\n",
      "289/289 [==============================] - 0s 711us/step - loss: 674.7089 - val_loss: 698.4285\n",
      "Epoch 282/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 747.7440 - val_loss: 676.6039\n",
      "Epoch 283/1000\n",
      "289/289 [==============================] - 0s 823us/step - loss: 695.2889 - val_loss: 628.4849\n",
      "Epoch 284/1000\n",
      "289/289 [==============================] - 0s 799us/step - loss: 643.8119 - val_loss: 794.2885\n",
      "Epoch 285/1000\n",
      "289/289 [==============================] - 0s 718us/step - loss: 620.1610 - val_loss: 949.3607\n",
      "Epoch 286/1000\n",
      "289/289 [==============================] - 0s 778us/step - loss: 590.6560 - val_loss: 644.7144\n",
      "Epoch 287/1000\n",
      "289/289 [==============================] - 0s 763us/step - loss: 567.2565 - val_loss: 665.0885\n",
      "Epoch 288/1000\n",
      "289/289 [==============================] - 0s 737us/step - loss: 610.5109 - val_loss: 637.0743\n",
      "Epoch 289/1000\n",
      "289/289 [==============================] - 0s 694us/step - loss: 598.8334 - val_loss: 663.2125\n",
      "Epoch 290/1000\n",
      "289/289 [==============================] - 0s 931us/step - loss: 609.8301 - val_loss: 1094.1990\n",
      "Epoch 291/1000\n",
      "289/289 [==============================] - 0s 859us/step - loss: 655.9387 - val_loss: 1977.1400\n",
      "Epoch 292/1000\n",
      "289/289 [==============================] - 0s 840us/step - loss: 592.7953 - val_loss: 1196.2814\n",
      "Epoch 293/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 566.0752 - val_loss: 633.8699\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 999us/step - loss: 584.2621 - val_loss: 763.5949\n",
      "Epoch 295/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 601.5676 - val_loss: 827.7820\n",
      "Epoch 296/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 540.7006 - val_loss: 900.6365\n",
      "Epoch 297/1000\n",
      "289/289 [==============================] - 0s 663us/step - loss: 535.7651 - val_loss: 695.6960\n",
      "Epoch 298/1000\n",
      "289/289 [==============================] - 0s 744us/step - loss: 572.5806 - val_loss: 666.0480\n",
      "Epoch 299/1000\n",
      "289/289 [==============================] - 0s 801us/step - loss: 541.1354 - val_loss: 914.0098\n",
      "Epoch 300/1000\n",
      "289/289 [==============================] - 0s 750us/step - loss: 572.5159 - val_loss: 1093.4408\n",
      "Epoch 301/1000\n",
      "289/289 [==============================] - 0s 929us/step - loss: 502.4918 - val_loss: 633.9722\n",
      "Epoch 302/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 528.7831 - val_loss: 692.1944\n",
      "Epoch 303/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 543.3134 - val_loss: 897.0604\n",
      "Epoch 304/1000\n",
      "289/289 [==============================] - 0s 900us/step - loss: 528.5704 - val_loss: 646.5724\n",
      "Epoch 305/1000\n",
      "289/289 [==============================] - 0s 846us/step - loss: 510.6233 - val_loss: 629.6414\n",
      "Epoch 306/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 483.6013 - val_loss: 1112.0542\n",
      "Epoch 307/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 480.2064 - val_loss: 646.9201\n",
      "Epoch 308/1000\n",
      "289/289 [==============================] - 0s 786us/step - loss: 486.2819 - val_loss: 671.2645\n",
      "Epoch 309/1000\n",
      "289/289 [==============================] - 0s 691us/step - loss: 442.7406 - val_loss: 625.9915\n",
      "Epoch 310/1000\n",
      "289/289 [==============================] - 0s 878us/step - loss: 427.7765 - val_loss: 710.5262\n",
      "Epoch 311/1000\n",
      "289/289 [==============================] - 0s 953us/step - loss: 424.2244 - val_loss: 636.9248\n",
      "Epoch 312/1000\n",
      "289/289 [==============================] - 0s 914us/step - loss: 422.1671 - val_loss: 659.7159\n",
      "Epoch 313/1000\n",
      "289/289 [==============================] - 0s 808us/step - loss: 420.1449 - val_loss: 684.1742\n",
      "Epoch 314/1000\n",
      "289/289 [==============================] - 0s 734us/step - loss: 415.4941 - val_loss: 655.7723\n",
      "Epoch 315/1000\n",
      "289/289 [==============================] - 0s 886us/step - loss: 416.8199 - val_loss: 734.8694\n",
      "Epoch 316/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 419.9964 - val_loss: 657.9692\n",
      "Epoch 317/1000\n",
      "289/289 [==============================] - 0s 880us/step - loss: 420.2707 - val_loss: 650.3890\n",
      "Epoch 318/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 417.0378 - val_loss: 697.0886\n",
      "Epoch 319/1000\n",
      "289/289 [==============================] - 0s 717us/step - loss: 415.5810 - val_loss: 677.5389\n",
      "Epoch 320/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 417.5772 - val_loss: 663.2696\n",
      "Epoch 321/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 419.2898 - val_loss: 635.2271\n",
      "Epoch 322/1000\n",
      "289/289 [==============================] - 0s 696us/step - loss: 421.7946 - val_loss: 748.9282\n",
      "Epoch 323/1000\n",
      "289/289 [==============================] - 0s 898us/step - loss: 420.8654 - val_loss: 632.5295\n",
      "Epoch 324/1000\n",
      "289/289 [==============================] - 0s 808us/step - loss: 418.6751 - val_loss: 685.3156\n",
      "Epoch 325/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 426.1541 - val_loss: 722.3234\n",
      "Epoch 326/1000\n",
      "289/289 [==============================] - 0s 904us/step - loss: 423.3481 - val_loss: 728.6723\n",
      "Epoch 327/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 420.7589 - val_loss: 686.1328\n",
      "Epoch 328/1000\n",
      "289/289 [==============================] - 0s 683us/step - loss: 422.2628 - val_loss: 633.7113\n",
      "Epoch 329/1000\n",
      "289/289 [==============================] - 0s 749us/step - loss: 421.6031 - val_loss: 754.4042\n",
      "Epoch 330/1000\n",
      "289/289 [==============================] - 0s 685us/step - loss: 423.9356 - val_loss: 693.6908\n",
      "Epoch 331/1000\n",
      "289/289 [==============================] - 0s 889us/step - loss: 418.6871 - val_loss: 632.3323\n",
      "Epoch 332/1000\n",
      "289/289 [==============================] - 0s 713us/step - loss: 424.5051 - val_loss: 651.7319\n",
      "Epoch 333/1000\n",
      "289/289 [==============================] - 0s 810us/step - loss: 423.8818 - val_loss: 638.1367\n",
      "Epoch 334/1000\n",
      "289/289 [==============================] - 0s 786us/step - loss: 427.7045 - val_loss: 635.3998\n",
      "Epoch 335/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 421.8907 - val_loss: 695.5735\n",
      "Epoch 336/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 422.0265 - val_loss: 677.8118\n",
      "Epoch 337/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 429.0346 - val_loss: 793.9335\n",
      "Epoch 338/1000\n",
      "289/289 [==============================] - 0s 869us/step - loss: 422.1884 - val_loss: 733.7055\n",
      "Epoch 339/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 427.6880 - val_loss: 712.7523\n",
      "Epoch 340/1000\n",
      "289/289 [==============================] - 0s 682us/step - loss: 426.3867 - val_loss: 705.3251\n",
      "Epoch 341/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 426.9856 - val_loss: 642.4064\n",
      "Epoch 342/1000\n",
      "289/289 [==============================] - 0s 730us/step - loss: 421.8125 - val_loss: 669.8204\n",
      "Epoch 343/1000\n",
      "289/289 [==============================] - 0s 835us/step - loss: 420.1212 - val_loss: 635.7054\n",
      "Epoch 344/1000\n",
      "289/289 [==============================] - 0s 864us/step - loss: 423.8971 - val_loss: 685.8328\n",
      "Epoch 345/1000\n",
      "289/289 [==============================] - 0s 746us/step - loss: 422.0726 - val_loss: 796.3979\n",
      "Epoch 346/1000\n",
      "289/289 [==============================] - 0s 783us/step - loss: 428.6273 - val_loss: 713.5790\n",
      "Epoch 347/1000\n",
      "289/289 [==============================] - 0s 691us/step - loss: 424.4275 - val_loss: 674.9881\n",
      "Epoch 348/1000\n",
      "289/289 [==============================] - 0s 876us/step - loss: 423.3898 - val_loss: 727.4349\n",
      "Epoch 349/1000\n",
      "289/289 [==============================] - 0s 731us/step - loss: 426.4102 - val_loss: 724.7068\n",
      "Epoch 350/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 418.6174 - val_loss: 735.1177\n",
      "Epoch 351/1000\n",
      "289/289 [==============================] - 0s 720us/step - loss: 419.7708 - val_loss: 689.8670\n",
      "Epoch 352/1000\n",
      "289/289 [==============================] - 0s 892us/step - loss: 422.7110 - val_loss: 641.6008\n",
      "Epoch 353/1000\n",
      "289/289 [==============================] - 0s 830us/step - loss: 425.6685 - val_loss: 739.2458\n",
      "Epoch 354/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 419.8000 - val_loss: 665.7795\n",
      "Epoch 355/1000\n",
      "289/289 [==============================] - 0s 654us/step - loss: 418.7082 - val_loss: 660.7458\n",
      "Epoch 356/1000\n",
      "289/289 [==============================] - 0s 752us/step - loss: 420.9299 - val_loss: 659.9781\n",
      "Epoch 357/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 427.4442 - val_loss: 630.9954\n",
      "Epoch 358/1000\n",
      "289/289 [==============================] - 0s 750us/step - loss: 428.8425 - val_loss: 720.7338\n",
      "Epoch 359/1000\n",
      "289/289 [==============================] - 0s 948us/step - loss: 427.2635 - val_loss: 792.6577\n",
      "Epoch 360/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 426.3459 - val_loss: 677.6953\n",
      "Epoch 361/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 5268.3882 - val_loss: 1540.2955\n",
      "Epoch 362/1000\n",
      "289/289 [==============================] - 0s 682us/step - loss: 963.7295 - val_loss: 1528.6041\n",
      "Epoch 363/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 954.3454 - val_loss: 1516.2135\n",
      "Epoch 364/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 944.4683 - val_loss: 1503.1975\n",
      "Epoch 365/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 934.1706 - val_loss: 1489.6932\n",
      "Epoch 366/1000\n",
      "289/289 [==============================] - 0s 722us/step - loss: 923.5442 - val_loss: 1475.7611\n",
      "Epoch 367/1000\n",
      "289/289 [==============================] - 0s 871us/step - loss: 912.6686 - val_loss: 1461.5330\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 752us/step - loss: 901.6155 - val_loss: 1447.0682\n",
      "Epoch 369/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 890.4498 - val_loss: 1432.4662\n",
      "Epoch 370/1000\n",
      "289/289 [==============================] - 0s 732us/step - loss: 879.2330 - val_loss: 1417.8032\n",
      "Epoch 371/1000\n",
      "289/289 [==============================] - 0s 888us/step - loss: 868.0050 - val_loss: 1403.0726\n",
      "Epoch 372/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 856.8105 - val_loss: 1388.4003\n",
      "Epoch 373/1000\n",
      "289/289 [==============================] - 0s 741us/step - loss: 845.6729 - val_loss: 1373.7759\n",
      "Epoch 374/1000\n",
      "289/289 [==============================] - 0s 753us/step - loss: 834.6174 - val_loss: 1359.2156\n",
      "Epoch 375/1000\n",
      "289/289 [==============================] - 0s 812us/step - loss: 823.6627 - val_loss: 1344.7247\n",
      "Epoch 376/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 812.8220 - val_loss: 1330.4139\n",
      "Epoch 377/1000\n",
      "289/289 [==============================] - 0s 752us/step - loss: 802.1012 - val_loss: 1316.1361\n",
      "Epoch 378/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 791.5120 - val_loss: 1302.0515\n",
      "Epoch 379/1000\n",
      "289/289 [==============================] - 0s 719us/step - loss: 781.0583 - val_loss: 1288.0645\n",
      "Epoch 380/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 770.7538 - val_loss: 1274.2755\n",
      "Epoch 381/1000\n",
      "289/289 [==============================] - 0s 906us/step - loss: 760.6092 - val_loss: 1260.6121\n",
      "Epoch 382/1000\n",
      "289/289 [==============================] - 0s 742us/step - loss: 750.6079 - val_loss: 1247.1171\n",
      "Epoch 383/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 740.7555 - val_loss: 1233.7468\n",
      "Epoch 384/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 731.0537 - val_loss: 1220.5586\n",
      "Epoch 385/1000\n",
      "289/289 [==============================] - 0s 738us/step - loss: 721.4941 - val_loss: 1207.5331\n",
      "Epoch 386/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 712.0993 - val_loss: 1194.6219\n",
      "Epoch 387/1000\n",
      "289/289 [==============================] - 0s 683us/step - loss: 702.8581 - val_loss: 1181.9098\n",
      "Epoch 388/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 693.7707 - val_loss: 1169.3217\n",
      "Epoch 389/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 684.8482 - val_loss: 1156.9177\n",
      "Epoch 390/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 676.0712 - val_loss: 1144.6973\n",
      "Epoch 391/1000\n",
      "289/289 [==============================] - 0s 842us/step - loss: 667.4465 - val_loss: 1132.5912\n",
      "Epoch 392/1000\n",
      "289/289 [==============================] - 0s 785us/step - loss: 658.9901 - val_loss: 1120.6570\n",
      "Epoch 393/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 650.6968 - val_loss: 1108.9203\n",
      "Epoch 394/1000\n",
      "289/289 [==============================] - 0s 844us/step - loss: 642.5588 - val_loss: 1097.3538\n",
      "Epoch 395/1000\n",
      "289/289 [==============================] - 0s 879us/step - loss: 634.5612 - val_loss: 1085.9015\n",
      "Epoch 396/1000\n",
      "289/289 [==============================] - 0s 772us/step - loss: 626.7099 - val_loss: 1074.6587\n",
      "Epoch 397/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 619.0138 - val_loss: 1063.4763\n",
      "Epoch 398/1000\n",
      "289/289 [==============================] - 0s 956us/step - loss: 611.4780 - val_loss: 1052.5229\n",
      "Epoch 399/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 604.1043 - val_loss: 1041.7701\n",
      "Epoch 400/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 596.8902 - val_loss: 1031.1294\n",
      "Epoch 401/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 589.8222 - val_loss: 1020.6653\n",
      "Epoch 402/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 582.8972 - val_loss: 1010.3008\n",
      "Epoch 403/1000\n",
      "289/289 [==============================] - 0s 798us/step - loss: 576.1328 - val_loss: 1000.1737\n",
      "Epoch 404/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 569.5217 - val_loss: 990.1671\n",
      "Epoch 405/1000\n",
      "289/289 [==============================] - 0s 690us/step - loss: 563.0642 - val_loss: 980.3648\n",
      "Epoch 406/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 556.7410 - val_loss: 970.6562\n",
      "Epoch 407/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 550.5607 - val_loss: 961.1157\n",
      "Epoch 408/1000\n",
      "289/289 [==============================] - 0s 694us/step - loss: 544.5408 - val_loss: 951.7870\n",
      "Epoch 409/1000\n",
      "289/289 [==============================] - 0s 732us/step - loss: 538.6774 - val_loss: 942.5579\n",
      "Epoch 410/1000\n",
      "289/289 [==============================] - 0s 907us/step - loss: 532.9789 - val_loss: 933.5728\n",
      "Epoch 411/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 527.4316 - val_loss: 924.7340\n",
      "Epoch 412/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 522.0278 - val_loss: 916.0676\n",
      "Epoch 413/1000\n",
      "289/289 [==============================] - 0s 778us/step - loss: 516.7745 - val_loss: 907.4942\n",
      "Epoch 414/1000\n",
      "289/289 [==============================] - 0s 843us/step - loss: 511.6696 - val_loss: 899.1639\n",
      "Epoch 415/1000\n",
      "289/289 [==============================] - 0s 783us/step - loss: 506.7094 - val_loss: 890.9142\n",
      "Epoch 416/1000\n",
      "289/289 [==============================] - 0s 744us/step - loss: 501.8824 - val_loss: 882.8506\n",
      "Epoch 417/1000\n",
      "289/289 [==============================] - 0s 623us/step - loss: 497.1973 - val_loss: 874.9091\n",
      "Epoch 418/1000\n",
      "289/289 [==============================] - 0s 632us/step - loss: 492.6592 - val_loss: 867.2041\n",
      "Epoch 419/1000\n",
      "289/289 [==============================] - 0s 649us/step - loss: 488.2676 - val_loss: 859.5886\n",
      "Epoch 420/1000\n",
      "289/289 [==============================] - 0s 653us/step - loss: 484.0248 - val_loss: 852.1530\n",
      "Epoch 421/1000\n",
      "289/289 [==============================] - 0s 823us/step - loss: 479.9273 - val_loss: 844.9321\n",
      "Epoch 422/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 475.9681 - val_loss: 837.7836\n",
      "Epoch 423/1000\n",
      "289/289 [==============================] - 0s 725us/step - loss: 472.1610 - val_loss: 830.9133\n",
      "Epoch 424/1000\n",
      "289/289 [==============================] - 0s 714us/step - loss: 468.4949 - val_loss: 824.1309\n",
      "Epoch 425/1000\n",
      "289/289 [==============================] - 0s 699us/step - loss: 464.9648 - val_loss: 817.5089\n",
      "Epoch 426/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 461.5790 - val_loss: 811.1057\n",
      "Epoch 427/1000\n",
      "289/289 [==============================] - 0s 760us/step - loss: 458.3306 - val_loss: 804.8292\n",
      "Epoch 428/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 455.2032 - val_loss: 798.6995\n",
      "Epoch 429/1000\n",
      "289/289 [==============================] - 0s 753us/step - loss: 452.2035 - val_loss: 792.7124\n",
      "Epoch 430/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 449.3433 - val_loss: 786.9062\n",
      "Epoch 431/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 446.6223 - val_loss: 781.2672\n",
      "Epoch 432/1000\n",
      "289/289 [==============================] - 0s 754us/step - loss: 444.0300 - val_loss: 775.8035\n",
      "Epoch 433/1000\n",
      "289/289 [==============================] - 0s 687us/step - loss: 441.5589 - val_loss: 770.5173\n",
      "Epoch 434/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 439.2159 - val_loss: 765.3242\n",
      "Epoch 435/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 436.9906 - val_loss: 760.3224\n",
      "Epoch 436/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 434.8853 - val_loss: 755.5062\n",
      "Epoch 437/1000\n",
      "289/289 [==============================] - 0s 876us/step - loss: 432.9015 - val_loss: 750.8182\n",
      "Epoch 438/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 431.0439 - val_loss: 746.3034\n",
      "Epoch 439/1000\n",
      "289/289 [==============================] - 0s 724us/step - loss: 429.3182 - val_loss: 742.0221\n",
      "Epoch 440/1000\n",
      "289/289 [==============================] - 0s 774us/step - loss: 427.7021 - val_loss: 737.8970\n",
      "Epoch 441/1000\n",
      "289/289 [==============================] - 0s 838us/step - loss: 426.1851 - val_loss: 733.9360\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 880us/step - loss: 424.7650 - val_loss: 730.0643\n",
      "Epoch 443/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 423.4584 - val_loss: 726.3736\n",
      "Epoch 444/1000\n",
      "289/289 [==============================] - 0s 917us/step - loss: 422.2421 - val_loss: 722.8353\n",
      "Epoch 445/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 421.1097 - val_loss: 719.4846\n",
      "Epoch 446/1000\n",
      "289/289 [==============================] - 0s 895us/step - loss: 420.0730 - val_loss: 716.1963\n",
      "Epoch 447/1000\n",
      "289/289 [==============================] - 0s 770us/step - loss: 419.1306 - val_loss: 713.1639\n",
      "Epoch 448/1000\n",
      "289/289 [==============================] - 0s 787us/step - loss: 418.2687 - val_loss: 710.2592\n",
      "Epoch 449/1000\n",
      "289/289 [==============================] - 0s 794us/step - loss: 417.4916 - val_loss: 707.5453\n",
      "Epoch 450/1000\n",
      "289/289 [==============================] - 0s 662us/step - loss: 416.7965 - val_loss: 704.9751\n",
      "Epoch 451/1000\n",
      "289/289 [==============================] - 0s 777us/step - loss: 416.1632 - val_loss: 702.5335\n",
      "Epoch 452/1000\n",
      "289/289 [==============================] - 0s 899us/step - loss: 415.5915 - val_loss: 700.2852\n",
      "Epoch 453/1000\n",
      "289/289 [==============================] - 0s 896us/step - loss: 415.0860 - val_loss: 698.0682\n",
      "Epoch 454/1000\n",
      "289/289 [==============================] - 0s 803us/step - loss: 414.6293 - val_loss: 696.1418\n",
      "Epoch 455/1000\n",
      "289/289 [==============================] - 0s 780us/step - loss: 414.2218 - val_loss: 694.2109\n",
      "Epoch 456/1000\n",
      "289/289 [==============================] - 0s 759us/step - loss: 413.8589 - val_loss: 692.3970\n",
      "Epoch 457/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 413.5387 - val_loss: 690.7013\n",
      "Epoch 458/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 413.2538 - val_loss: 689.1252\n",
      "Epoch 459/1000\n",
      "289/289 [==============================] - 0s 799us/step - loss: 412.9997 - val_loss: 687.6309\n",
      "Epoch 460/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 412.7771 - val_loss: 686.2736\n",
      "Epoch 461/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 412.5886 - val_loss: 685.0144\n",
      "Epoch 462/1000\n",
      "289/289 [==============================] - 0s 872us/step - loss: 412.4247 - val_loss: 683.8804\n",
      "Epoch 463/1000\n",
      "289/289 [==============================] - 0s 729us/step - loss: 412.2834 - val_loss: 682.8195\n",
      "Epoch 464/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 412.1616 - val_loss: 681.8345\n",
      "Epoch 465/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 412.0571 - val_loss: 680.9553\n",
      "Epoch 466/1000\n",
      "289/289 [==============================] - 0s 755us/step - loss: 411.9648 - val_loss: 680.0511\n",
      "Epoch 467/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 411.8881 - val_loss: 679.2479\n",
      "Epoch 468/1000\n",
      "289/289 [==============================] - 0s 759us/step - loss: 411.8210 - val_loss: 678.6545\n",
      "Epoch 469/1000\n",
      "289/289 [==============================] - 0s 764us/step - loss: 411.7632 - val_loss: 677.9735\n",
      "Epoch 470/1000\n",
      "289/289 [==============================] - 0s 766us/step - loss: 411.7144 - val_loss: 677.3445\n",
      "Epoch 471/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.6724 - val_loss: 676.8066\n",
      "Epoch 472/1000\n",
      "289/289 [==============================] - 0s 917us/step - loss: 411.6357 - val_loss: 676.2379\n",
      "Epoch 473/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.6025 - val_loss: 675.7881\n",
      "Epoch 474/1000\n",
      "289/289 [==============================] - 0s 945us/step - loss: 411.5755 - val_loss: 675.3098\n",
      "Epoch 475/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 411.5532 - val_loss: 674.9222\n",
      "Epoch 476/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 411.5329 - val_loss: 674.5718\n",
      "Epoch 477/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 411.5148 - val_loss: 674.2147\n",
      "Epoch 478/1000\n",
      "289/289 [==============================] - 0s 694us/step - loss: 411.5005 - val_loss: 673.8947\n",
      "Epoch 479/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 411.4887 - val_loss: 673.5889\n",
      "Epoch 480/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 411.4772 - val_loss: 673.2717\n",
      "Epoch 481/1000\n",
      "289/289 [==============================] - 0s 691us/step - loss: 411.4692 - val_loss: 673.0504\n",
      "Epoch 482/1000\n",
      "289/289 [==============================] - 0s 697us/step - loss: 411.4635 - val_loss: 672.7988\n",
      "Epoch 483/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 411.4549 - val_loss: 672.6254\n",
      "Epoch 484/1000\n",
      "289/289 [==============================] - 0s 988us/step - loss: 411.4488 - val_loss: 672.4450\n",
      "Epoch 485/1000\n",
      "289/289 [==============================] - 0s 850us/step - loss: 411.4437 - val_loss: 672.2215\n",
      "Epoch 486/1000\n",
      "289/289 [==============================] - 0s 824us/step - loss: 411.4394 - val_loss: 672.0576\n",
      "Epoch 487/1000\n",
      "289/289 [==============================] - 0s 852us/step - loss: 411.4378 - val_loss: 671.8903\n",
      "Epoch 488/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4340 - val_loss: 671.7906\n",
      "Epoch 489/1000\n",
      "289/289 [==============================] - 0s 682us/step - loss: 411.4346 - val_loss: 671.6579\n",
      "Epoch 490/1000\n",
      "289/289 [==============================] - 0s 670us/step - loss: 411.4294 - val_loss: 671.5317\n",
      "Epoch 491/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 411.4274 - val_loss: 671.4595\n",
      "Epoch 492/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 411.4272 - val_loss: 671.3337\n",
      "Epoch 493/1000\n",
      "289/289 [==============================] - 0s 863us/step - loss: 411.4241 - val_loss: 671.2626\n",
      "Epoch 494/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 411.4249 - val_loss: 671.1356\n",
      "Epoch 495/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 411.4238 - val_loss: 671.0063\n",
      "Epoch 496/1000\n",
      "289/289 [==============================] - 0s 697us/step - loss: 411.4222 - val_loss: 671.0023\n",
      "Epoch 497/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 411.4201 - val_loss: 670.9504\n",
      "Epoch 498/1000\n",
      "289/289 [==============================] - 0s 696us/step - loss: 411.4201 - val_loss: 670.8622\n",
      "Epoch 499/1000\n",
      "289/289 [==============================] - 0s 702us/step - loss: 411.4213 - val_loss: 670.8438\n",
      "Epoch 500/1000\n",
      "289/289 [==============================] - 0s 772us/step - loss: 411.4180 - val_loss: 670.7476\n",
      "Epoch 501/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 411.4180 - val_loss: 670.6566\n",
      "Epoch 502/1000\n",
      "289/289 [==============================] - 0s 688us/step - loss: 411.4187 - val_loss: 670.6127\n",
      "Epoch 503/1000\n",
      "289/289 [==============================] - 0s 857us/step - loss: 411.4180 - val_loss: 670.6234\n",
      "Epoch 504/1000\n",
      "289/289 [==============================] - 0s 726us/step - loss: 411.4184 - val_loss: 670.6218\n",
      "Epoch 505/1000\n",
      "289/289 [==============================] - 0s 859us/step - loss: 411.4185 - val_loss: 670.5482\n",
      "Epoch 506/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 411.4180 - val_loss: 670.5223\n",
      "Epoch 507/1000\n",
      "289/289 [==============================] - 0s 751us/step - loss: 411.4166 - val_loss: 670.4689\n",
      "Epoch 508/1000\n",
      "289/289 [==============================] - 0s 741us/step - loss: 411.4170 - val_loss: 670.4988\n",
      "Epoch 509/1000\n",
      "289/289 [==============================] - 0s 681us/step - loss: 411.4164 - val_loss: 670.4362\n",
      "Epoch 510/1000\n",
      "289/289 [==============================] - 0s 833us/step - loss: 411.4169 - val_loss: 670.4348\n",
      "Epoch 511/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 411.4163 - val_loss: 670.3936\n",
      "Epoch 512/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 411.4178 - val_loss: 670.3682\n",
      "Epoch 513/1000\n",
      "289/289 [==============================] - 0s 881us/step - loss: 411.4170 - val_loss: 670.3564\n",
      "Epoch 514/1000\n",
      "289/289 [==============================] - 0s 794us/step - loss: 411.4160 - val_loss: 670.3561\n",
      "Epoch 515/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 411.4177 - val_loss: 670.3619\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 926us/step - loss: 411.4165 - val_loss: 670.3693\n",
      "Epoch 517/1000\n",
      "289/289 [==============================] - 0s 739us/step - loss: 411.4161 - val_loss: 670.2386\n",
      "Epoch 518/1000\n",
      "289/289 [==============================] - 0s 799us/step - loss: 411.4171 - val_loss: 670.2278\n",
      "Epoch 519/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 411.4168 - val_loss: 670.2743\n",
      "Epoch 520/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 411.4158 - val_loss: 670.1822\n",
      "Epoch 521/1000\n",
      "289/289 [==============================] - 0s 764us/step - loss: 411.4194 - val_loss: 670.2259\n",
      "Epoch 522/1000\n",
      "289/289 [==============================] - 0s 780us/step - loss: 411.4163 - val_loss: 670.2438\n",
      "Epoch 523/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.4167 - val_loss: 670.2831\n",
      "Epoch 524/1000\n",
      "289/289 [==============================] - 0s 693us/step - loss: 411.4160 - val_loss: 670.2075\n",
      "Epoch 525/1000\n",
      "289/289 [==============================] - 0s 981us/step - loss: 411.4159 - val_loss: 670.1902\n",
      "Epoch 526/1000\n",
      "289/289 [==============================] - 0s 923us/step - loss: 411.4169 - val_loss: 670.1907\n",
      "Epoch 527/1000\n",
      "289/289 [==============================] - 0s 785us/step - loss: 411.4165 - val_loss: 670.1736\n",
      "Epoch 528/1000\n",
      "289/289 [==============================] - 0s 895us/step - loss: 411.4174 - val_loss: 670.1602\n",
      "Epoch 529/1000\n",
      "289/289 [==============================] - 0s 888us/step - loss: 411.4173 - val_loss: 670.1720\n",
      "Epoch 530/1000\n",
      "289/289 [==============================] - 0s 798us/step - loss: 411.4173 - val_loss: 670.1758\n",
      "Epoch 531/1000\n",
      "289/289 [==============================] - 0s 886us/step - loss: 411.4164 - val_loss: 670.1561\n",
      "Epoch 532/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 411.4165 - val_loss: 670.1712\n",
      "Epoch 533/1000\n",
      "289/289 [==============================] - 0s 854us/step - loss: 411.4164 - val_loss: 670.1701\n",
      "Epoch 534/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4153 - val_loss: 670.1008\n",
      "Epoch 535/1000\n",
      "289/289 [==============================] - 0s 705us/step - loss: 411.4158 - val_loss: 670.1320\n",
      "Epoch 536/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 411.4165 - val_loss: 670.1612\n",
      "Epoch 537/1000\n",
      "289/289 [==============================] - 0s 712us/step - loss: 411.4162 - val_loss: 670.1014\n",
      "Epoch 538/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 411.4169 - val_loss: 670.1041\n",
      "Epoch 539/1000\n",
      "289/289 [==============================] - 0s 758us/step - loss: 411.4168 - val_loss: 670.1700\n",
      "Epoch 540/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.1046\n",
      "Epoch 541/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4155 - val_loss: 670.1433\n",
      "Epoch 542/1000\n",
      "289/289 [==============================] - 0s 708us/step - loss: 411.4159 - val_loss: 670.1170\n",
      "Epoch 543/1000\n",
      "289/289 [==============================] - 0s 676us/step - loss: 411.4162 - val_loss: 670.1157\n",
      "Epoch 544/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 411.4166 - val_loss: 670.0753\n",
      "Epoch 545/1000\n",
      "289/289 [==============================] - 0s 686us/step - loss: 411.4169 - val_loss: 670.0667\n",
      "Epoch 546/1000\n",
      "289/289 [==============================] - 0s 773us/step - loss: 411.4178 - val_loss: 670.0953\n",
      "Epoch 547/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 411.4181 - val_loss: 670.0952\n",
      "Epoch 548/1000\n",
      "289/289 [==============================] - 0s 950us/step - loss: 411.4174 - val_loss: 670.1458\n",
      "Epoch 549/1000\n",
      "289/289 [==============================] - 0s 849us/step - loss: 411.4175 - val_loss: 670.1074\n",
      "Epoch 550/1000\n",
      "289/289 [==============================] - 0s 855us/step - loss: 411.4147 - val_loss: 670.0959\n",
      "Epoch 551/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4167 - val_loss: 670.0738\n",
      "Epoch 552/1000\n",
      "289/289 [==============================] - 0s 774us/step - loss: 411.4164 - val_loss: 670.0906\n",
      "Epoch 553/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 411.4160 - val_loss: 670.1093\n",
      "Epoch 554/1000\n",
      "289/289 [==============================] - 0s 904us/step - loss: 411.4181 - val_loss: 670.0854\n",
      "Epoch 555/1000\n",
      "289/289 [==============================] - 0s 889us/step - loss: 411.4159 - val_loss: 670.1048\n",
      "Epoch 556/1000\n",
      "289/289 [==============================] - 0s 697us/step - loss: 411.4151 - val_loss: 670.1053\n",
      "Epoch 557/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 411.4163 - val_loss: 670.0504\n",
      "Epoch 558/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 411.4170 - val_loss: 670.1284\n",
      "Epoch 559/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0677\n",
      "Epoch 560/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4169 - val_loss: 670.0766\n",
      "Epoch 561/1000\n",
      "289/289 [==============================] - 0s 802us/step - loss: 411.4158 - val_loss: 670.1071\n",
      "Epoch 562/1000\n",
      "289/289 [==============================] - 0s 751us/step - loss: 411.4167 - val_loss: 670.1335\n",
      "Epoch 563/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 411.4157 - val_loss: 670.1278\n",
      "Epoch 564/1000\n",
      "289/289 [==============================] - 0s 967us/step - loss: 411.4178 - val_loss: 670.0521\n",
      "Epoch 565/1000\n",
      "289/289 [==============================] - 0s 726us/step - loss: 411.4151 - val_loss: 670.1747\n",
      "Epoch 566/1000\n",
      "289/289 [==============================] - 0s 728us/step - loss: 411.4163 - val_loss: 670.1577\n",
      "Epoch 567/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 411.4157 - val_loss: 670.0780\n",
      "Epoch 568/1000\n",
      "289/289 [==============================] - 0s 811us/step - loss: 411.4160 - val_loss: 670.1373\n",
      "Epoch 569/1000\n",
      "289/289 [==============================] - 0s 731us/step - loss: 411.4171 - val_loss: 670.0946\n",
      "Epoch 570/1000\n",
      "289/289 [==============================] - 0s 698us/step - loss: 411.4166 - val_loss: 670.1401\n",
      "Epoch 571/1000\n",
      "289/289 [==============================] - 0s 813us/step - loss: 411.4162 - val_loss: 670.1573\n",
      "Epoch 572/1000\n",
      "289/289 [==============================] - 0s 839us/step - loss: 411.4167 - val_loss: 670.1053\n",
      "Epoch 573/1000\n",
      "289/289 [==============================] - 0s 822us/step - loss: 411.4155 - val_loss: 670.1556\n",
      "Epoch 574/1000\n",
      "289/289 [==============================] - 0s 848us/step - loss: 411.4165 - val_loss: 670.1545\n",
      "Epoch 575/1000\n",
      "289/289 [==============================] - 0s 830us/step - loss: 411.4166 - val_loss: 670.1342\n",
      "Epoch 576/1000\n",
      "289/289 [==============================] - 0s 791us/step - loss: 411.4172 - val_loss: 670.1154\n",
      "Epoch 577/1000\n",
      "289/289 [==============================] - 0s 892us/step - loss: 411.4171 - val_loss: 670.0984\n",
      "Epoch 578/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 411.4165 - val_loss: 670.0995\n",
      "Epoch 579/1000\n",
      "289/289 [==============================] - 0s 941us/step - loss: 411.4155 - val_loss: 670.1007\n",
      "Epoch 580/1000\n",
      "289/289 [==============================] - 0s 683us/step - loss: 411.4149 - val_loss: 670.0968\n",
      "Epoch 581/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 411.4163 - val_loss: 670.0943\n",
      "Epoch 582/1000\n",
      "289/289 [==============================] - 0s 760us/step - loss: 411.4162 - val_loss: 670.0832\n",
      "Epoch 583/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 411.4153 - val_loss: 670.1077\n",
      "Epoch 584/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4156 - val_loss: 670.0908\n",
      "Epoch 585/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 411.4154 - val_loss: 670.1307\n",
      "Epoch 586/1000\n",
      "289/289 [==============================] - 0s 755us/step - loss: 411.4165 - val_loss: 670.1265\n",
      "Epoch 587/1000\n",
      "289/289 [==============================] - 0s 880us/step - loss: 411.4157 - val_loss: 670.1032\n",
      "Epoch 588/1000\n",
      "289/289 [==============================] - 0s 840us/step - loss: 411.4174 - val_loss: 670.1379\n",
      "Epoch 589/1000\n",
      "289/289 [==============================] - 0s 859us/step - loss: 411.4165 - val_loss: 670.0931\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 667us/step - loss: 411.4181 - val_loss: 670.0842\n",
      "Epoch 591/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 411.4158 - val_loss: 670.0985\n",
      "Epoch 592/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 411.4157 - val_loss: 670.0862\n",
      "Epoch 593/1000\n",
      "289/289 [==============================] - 0s 877us/step - loss: 411.4166 - val_loss: 670.0599\n",
      "Epoch 594/1000\n",
      "289/289 [==============================] - 0s 721us/step - loss: 411.4175 - val_loss: 670.1052\n",
      "Epoch 595/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4152 - val_loss: 670.0533\n",
      "Epoch 596/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 411.4154 - val_loss: 670.0704\n",
      "Epoch 597/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 411.4169 - val_loss: 670.1282\n",
      "Epoch 598/1000\n",
      "289/289 [==============================] - 0s 855us/step - loss: 411.4169 - val_loss: 670.0961\n",
      "Epoch 599/1000\n",
      "289/289 [==============================] - 0s 732us/step - loss: 411.4165 - val_loss: 670.0959\n",
      "Epoch 600/1000\n",
      "289/289 [==============================] - 0s 906us/step - loss: 411.4164 - val_loss: 670.0951\n",
      "Epoch 601/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4172 - val_loss: 670.1021\n",
      "Epoch 602/1000\n",
      "289/289 [==============================] - 0s 964us/step - loss: 411.4169 - val_loss: 670.0761\n",
      "Epoch 603/1000\n",
      "289/289 [==============================] - 0s 701us/step - loss: 411.4166 - val_loss: 670.0609\n",
      "Epoch 604/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 411.4170 - val_loss: 670.0800\n",
      "Epoch 605/1000\n",
      "289/289 [==============================] - 0s 706us/step - loss: 411.4163 - val_loss: 670.0760\n",
      "Epoch 606/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.4168 - val_loss: 670.0820\n",
      "Epoch 607/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4159 - val_loss: 670.0848\n",
      "Epoch 608/1000\n",
      "289/289 [==============================] - 0s 754us/step - loss: 411.4159 - val_loss: 670.0833\n",
      "Epoch 609/1000\n",
      "289/289 [==============================] - 0s 929us/step - loss: 411.4166 - val_loss: 670.0492\n",
      "Epoch 610/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 411.4161 - val_loss: 670.1379\n",
      "Epoch 611/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 411.4163 - val_loss: 670.1160\n",
      "Epoch 612/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 411.4167 - val_loss: 670.0838\n",
      "Epoch 613/1000\n",
      "289/289 [==============================] - 0s 718us/step - loss: 411.4159 - val_loss: 670.0914\n",
      "Epoch 614/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 411.4169 - val_loss: 670.0858\n",
      "Epoch 615/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4173 - val_loss: 670.1284\n",
      "Epoch 616/1000\n",
      "289/289 [==============================] - 0s 876us/step - loss: 411.4156 - val_loss: 670.0833\n",
      "Epoch 617/1000\n",
      "289/289 [==============================] - 0s 768us/step - loss: 411.4164 - val_loss: 670.0880\n",
      "Epoch 618/1000\n",
      "289/289 [==============================] - 0s 694us/step - loss: 411.4156 - val_loss: 670.1053\n",
      "Epoch 619/1000\n",
      "289/289 [==============================] - 0s 695us/step - loss: 411.4176 - val_loss: 670.1906\n",
      "Epoch 620/1000\n",
      "289/289 [==============================] - 0s 686us/step - loss: 411.4163 - val_loss: 670.1448\n",
      "Epoch 621/1000\n",
      "289/289 [==============================] - 0s 696us/step - loss: 411.4164 - val_loss: 670.1075\n",
      "Epoch 622/1000\n",
      "289/289 [==============================] - 0s 749us/step - loss: 411.4177 - val_loss: 670.1129\n",
      "Epoch 623/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4164 - val_loss: 670.1077\n",
      "Epoch 624/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 411.4150 - val_loss: 670.1366\n",
      "Epoch 625/1000\n",
      "289/289 [==============================] - 0s 933us/step - loss: 411.4166 - val_loss: 670.1562\n",
      "Epoch 626/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 411.4168 - val_loss: 670.1337\n",
      "Epoch 627/1000\n",
      "289/289 [==============================] - 0s 737us/step - loss: 411.4176 - val_loss: 670.0833\n",
      "Epoch 628/1000\n",
      "289/289 [==============================] - 0s 842us/step - loss: 411.4158 - val_loss: 670.1362\n",
      "Epoch 629/1000\n",
      "289/289 [==============================] - 0s 845us/step - loss: 411.4160 - val_loss: 670.1171\n",
      "Epoch 630/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 411.4167 - val_loss: 670.1581\n",
      "Epoch 631/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 411.4164 - val_loss: 670.1895\n",
      "Epoch 632/1000\n",
      "289/289 [==============================] - 0s 719us/step - loss: 411.4148 - val_loss: 670.1281\n",
      "Epoch 633/1000\n",
      "289/289 [==============================] - 0s 722us/step - loss: 411.4175 - val_loss: 670.1954\n",
      "Epoch 634/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4162 - val_loss: 670.1173\n",
      "Epoch 635/1000\n",
      "289/289 [==============================] - 0s 812us/step - loss: 411.4199 - val_loss: 670.1182\n",
      "Epoch 636/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 411.4183 - val_loss: 670.0634\n",
      "Epoch 637/1000\n",
      "289/289 [==============================] - 0s 863us/step - loss: 411.4200 - val_loss: 670.1222\n",
      "Epoch 638/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 411.4161 - val_loss: 670.1342\n",
      "Epoch 639/1000\n",
      "289/289 [==============================] - 0s 729us/step - loss: 411.4167 - val_loss: 670.1754\n",
      "Epoch 640/1000\n",
      "289/289 [==============================] - 0s 679us/step - loss: 411.4161 - val_loss: 670.1439\n",
      "Epoch 641/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 411.4177 - val_loss: 670.0969\n",
      "Epoch 642/1000\n",
      "289/289 [==============================] - 0s 710us/step - loss: 411.4158 - val_loss: 670.1053\n",
      "Epoch 643/1000\n",
      "289/289 [==============================] - 0s 687us/step - loss: 411.4155 - val_loss: 670.1429\n",
      "Epoch 644/1000\n",
      "289/289 [==============================] - 0s 729us/step - loss: 411.4192 - val_loss: 670.1320\n",
      "Epoch 645/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 411.4153 - val_loss: 670.1208\n",
      "Epoch 646/1000\n",
      "289/289 [==============================] - 0s 927us/step - loss: 411.4174 - val_loss: 670.1210\n",
      "Epoch 647/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 411.4166 - val_loss: 670.0881\n",
      "Epoch 648/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0656\n",
      "Epoch 649/1000\n",
      "289/289 [==============================] - 0s 746us/step - loss: 411.4162 - val_loss: 670.1185\n",
      "Epoch 650/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 411.4176 - val_loss: 670.0283\n",
      "Epoch 651/1000\n",
      "289/289 [==============================] - 0s 883us/step - loss: 411.4169 - val_loss: 670.1114\n",
      "Epoch 652/1000\n",
      "289/289 [==============================] - 0s 859us/step - loss: 411.4161 - val_loss: 670.0863\n",
      "Epoch 653/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.0974\n",
      "Epoch 654/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 411.4162 - val_loss: 670.1193\n",
      "Epoch 655/1000\n",
      "289/289 [==============================] - 0s 747us/step - loss: 411.4171 - val_loss: 670.1612\n",
      "Epoch 656/1000\n",
      "289/289 [==============================] - 0s 900us/step - loss: 411.4156 - val_loss: 670.0521\n",
      "Epoch 657/1000\n",
      "289/289 [==============================] - 0s 939us/step - loss: 411.4160 - val_loss: 670.1171\n",
      "Epoch 658/1000\n",
      "289/289 [==============================] - 0s 875us/step - loss: 411.4163 - val_loss: 670.0733\n",
      "Epoch 659/1000\n",
      "289/289 [==============================] - 0s 786us/step - loss: 411.4180 - val_loss: 670.1094\n",
      "Epoch 660/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 411.4158 - val_loss: 670.1014\n",
      "Epoch 661/1000\n",
      "289/289 [==============================] - 0s 965us/step - loss: 411.4173 - val_loss: 670.1016\n",
      "Epoch 662/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 411.4178 - val_loss: 670.1515\n",
      "Epoch 663/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 411.4168 - val_loss: 670.1271\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 918us/step - loss: 411.4151 - val_loss: 670.1086\n",
      "Epoch 665/1000\n",
      "289/289 [==============================] - 0s 842us/step - loss: 411.4166 - val_loss: 670.1305\n",
      "Epoch 666/1000\n",
      "289/289 [==============================] - 0s 719us/step - loss: 411.4167 - val_loss: 670.1286\n",
      "Epoch 667/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 411.4168 - val_loss: 670.0923\n",
      "Epoch 668/1000\n",
      "289/289 [==============================] - 0s 880us/step - loss: 411.4168 - val_loss: 670.1165\n",
      "Epoch 669/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4183 - val_loss: 670.0670\n",
      "Epoch 670/1000\n",
      "289/289 [==============================] - 0s 882us/step - loss: 411.4159 - val_loss: 670.0553\n",
      "Epoch 671/1000\n",
      "289/289 [==============================] - 0s 927us/step - loss: 411.4153 - val_loss: 670.0914\n",
      "Epoch 672/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4165 - val_loss: 670.1137\n",
      "Epoch 673/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 411.4179 - val_loss: 670.1154\n",
      "Epoch 674/1000\n",
      "289/289 [==============================] - 0s 889us/step - loss: 411.4165 - val_loss: 670.0861\n",
      "Epoch 675/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 411.4166 - val_loss: 670.1097\n",
      "Epoch 676/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 411.4171 - val_loss: 670.1180\n",
      "Epoch 677/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 411.4176 - val_loss: 670.1534\n",
      "Epoch 678/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 411.4168 - val_loss: 670.1033\n",
      "Epoch 679/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4167 - val_loss: 670.0971\n",
      "Epoch 680/1000\n",
      "289/289 [==============================] - 0s 721us/step - loss: 411.4164 - val_loss: 670.1107\n",
      "Epoch 681/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 411.4170 - val_loss: 670.0951\n",
      "Epoch 682/1000\n",
      "289/289 [==============================] - 0s 911us/step - loss: 411.4161 - val_loss: 670.0952\n",
      "Epoch 683/1000\n",
      "289/289 [==============================] - 0s 737us/step - loss: 411.4166 - val_loss: 670.1347\n",
      "Epoch 684/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4166 - val_loss: 670.1415\n",
      "Epoch 685/1000\n",
      "289/289 [==============================] - 0s 717us/step - loss: 411.4164 - val_loss: 670.0681\n",
      "Epoch 686/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 411.4164 - val_loss: 670.1238\n",
      "Epoch 687/1000\n",
      "289/289 [==============================] - 0s 810us/step - loss: 411.4157 - val_loss: 670.0735\n",
      "Epoch 688/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 411.4157 - val_loss: 670.0784\n",
      "Epoch 689/1000\n",
      "289/289 [==============================] - 0s 908us/step - loss: 411.4159 - val_loss: 670.1235\n",
      "Epoch 690/1000\n",
      "289/289 [==============================] - 0s 803us/step - loss: 411.4173 - val_loss: 670.0810\n",
      "Epoch 691/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 411.4175 - val_loss: 670.0293\n",
      "Epoch 692/1000\n",
      "289/289 [==============================] - 0s 934us/step - loss: 411.4163 - val_loss: 670.1217\n",
      "Epoch 693/1000\n",
      "289/289 [==============================] - 0s 938us/step - loss: 411.4163 - val_loss: 670.0887\n",
      "Epoch 694/1000\n",
      "289/289 [==============================] - 0s 937us/step - loss: 411.4161 - val_loss: 670.0272\n",
      "Epoch 695/1000\n",
      "289/289 [==============================] - 0s 871us/step - loss: 411.4154 - val_loss: 670.1166\n",
      "Epoch 696/1000\n",
      "289/289 [==============================] - 0s 883us/step - loss: 411.4164 - val_loss: 670.0790\n",
      "Epoch 697/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 411.4155 - val_loss: 670.1044\n",
      "Epoch 698/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 411.4157 - val_loss: 670.0715\n",
      "Epoch 699/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 411.4157 - val_loss: 670.1012\n",
      "Epoch 700/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.4156 - val_loss: 670.1021\n",
      "Epoch 701/1000\n",
      "289/289 [==============================] - 0s 750us/step - loss: 411.4156 - val_loss: 670.0514\n",
      "Epoch 702/1000\n",
      "289/289 [==============================] - 0s 902us/step - loss: 411.4177 - val_loss: 670.0812\n",
      "Epoch 703/1000\n",
      "289/289 [==============================] - 0s 863us/step - loss: 411.4182 - val_loss: 670.0538\n",
      "Epoch 704/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 411.4174 - val_loss: 670.0577\n",
      "Epoch 705/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 411.4174 - val_loss: 670.0837\n",
      "Epoch 706/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 411.4167 - val_loss: 670.1001\n",
      "Epoch 707/1000\n",
      "289/289 [==============================] - 0s 875us/step - loss: 411.4164 - val_loss: 670.0804\n",
      "Epoch 708/1000\n",
      "289/289 [==============================] - 0s 903us/step - loss: 411.4165 - val_loss: 670.0635\n",
      "Epoch 709/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4170 - val_loss: 670.0506\n",
      "Epoch 710/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 411.4171 - val_loss: 670.0632\n",
      "Epoch 711/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 411.4163 - val_loss: 670.0952\n",
      "Epoch 712/1000\n",
      "289/289 [==============================] - 0s 976us/step - loss: 411.4171 - val_loss: 670.0753\n",
      "Epoch 713/1000\n",
      "289/289 [==============================] - 0s 787us/step - loss: 411.4159 - val_loss: 670.0501\n",
      "Epoch 714/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.0996\n",
      "Epoch 715/1000\n",
      "289/289 [==============================] - 0s 898us/step - loss: 411.4169 - val_loss: 670.1014\n",
      "Epoch 716/1000\n",
      "289/289 [==============================] - 0s 744us/step - loss: 411.4168 - val_loss: 670.1025\n",
      "Epoch 717/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 411.4159 - val_loss: 670.0985\n",
      "Epoch 718/1000\n",
      "289/289 [==============================] - 0s 810us/step - loss: 411.4160 - val_loss: 670.1433\n",
      "Epoch 719/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 411.4165 - val_loss: 670.0712\n",
      "Epoch 720/1000\n",
      "289/289 [==============================] - 0s 915us/step - loss: 411.4153 - val_loss: 670.1198\n",
      "Epoch 721/1000\n",
      "289/289 [==============================] - 0s 967us/step - loss: 411.4169 - val_loss: 670.1380\n",
      "Epoch 722/1000\n",
      "289/289 [==============================] - 0s 919us/step - loss: 411.4167 - val_loss: 670.1145\n",
      "Epoch 723/1000\n",
      "289/289 [==============================] - 0s 944us/step - loss: 411.4174 - val_loss: 670.1033\n",
      "Epoch 724/1000\n",
      "289/289 [==============================] - 0s 803us/step - loss: 411.4195 - val_loss: 670.0375\n",
      "Epoch 725/1000\n",
      "289/289 [==============================] - 0s 906us/step - loss: 411.4158 - val_loss: 670.0991\n",
      "Epoch 726/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0901\n",
      "Epoch 727/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4167 - val_loss: 670.1341\n",
      "Epoch 728/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 411.4171 - val_loss: 670.1344\n",
      "Epoch 729/1000\n",
      "289/289 [==============================] - 0s 954us/step - loss: 411.4171 - val_loss: 670.1118\n",
      "Epoch 730/1000\n",
      "289/289 [==============================] - 0s 959us/step - loss: 411.4161 - val_loss: 670.1124\n",
      "Epoch 731/1000\n",
      "289/289 [==============================] - 0s 914us/step - loss: 411.4192 - val_loss: 670.1338\n",
      "Epoch 732/1000\n",
      "289/289 [==============================] - 0s 992us/step - loss: 411.4163 - val_loss: 670.0989\n",
      "Epoch 733/1000\n",
      "289/289 [==============================] - 0s 902us/step - loss: 411.4165 - val_loss: 670.1277\n",
      "Epoch 734/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 411.4176 - val_loss: 670.0607\n",
      "Epoch 735/1000\n",
      "289/289 [==============================] - 0s 850us/step - loss: 411.4158 - val_loss: 670.1375\n",
      "Epoch 736/1000\n",
      "289/289 [==============================] - 0s 760us/step - loss: 411.4162 - val_loss: 670.1295\n",
      "Epoch 737/1000\n",
      "289/289 [==============================] - 0s 838us/step - loss: 411.4165 - val_loss: 670.0921\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 914us/step - loss: 411.4154 - val_loss: 670.1682\n",
      "Epoch 739/1000\n",
      "289/289 [==============================] - 0s 936us/step - loss: 411.4174 - val_loss: 670.1422\n",
      "Epoch 740/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.1232\n",
      "Epoch 741/1000\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 411.4165 - val_loss: 670.0794\n",
      "Epoch 742/1000\n",
      "289/289 [==============================] - 0s 969us/step - loss: 411.4161 - val_loss: 670.1012\n",
      "Epoch 743/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4154 - val_loss: 670.0814\n",
      "Epoch 744/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.0757\n",
      "Epoch 745/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0917\n",
      "Epoch 746/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.0573\n",
      "Epoch 747/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0902\n",
      "Epoch 748/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4175 - val_loss: 670.0838\n",
      "Epoch 749/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.1390\n",
      "Epoch 750/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.1320\n",
      "Epoch 751/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.0827\n",
      "Epoch 752/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4154 - val_loss: 670.1221\n",
      "Epoch 753/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4174 - val_loss: 670.0870\n",
      "Epoch 754/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.0663\n",
      "Epoch 755/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4153 - val_loss: 670.0919\n",
      "Epoch 756/1000\n",
      "289/289 [==============================] - 0s 982us/step - loss: 411.4162 - val_loss: 670.1155\n",
      "Epoch 757/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.1553\n",
      "Epoch 758/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4156 - val_loss: 670.1166\n",
      "Epoch 759/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.1352\n",
      "Epoch 760/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.1125\n",
      "Epoch 761/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4178 - val_loss: 670.0781\n",
      "Epoch 762/1000\n",
      "289/289 [==============================] - 0s 987us/step - loss: 411.4164 - val_loss: 670.0723\n",
      "Epoch 763/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.1102\n",
      "Epoch 764/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4171 - val_loss: 670.1243\n",
      "Epoch 765/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.0695\n",
      "Epoch 766/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4153 - val_loss: 670.1044\n",
      "Epoch 767/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4157 - val_loss: 670.0928\n",
      "Epoch 768/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4175 - val_loss: 670.1085\n",
      "Epoch 769/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4170 - val_loss: 670.1155\n",
      "Epoch 770/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4170 - val_loss: 670.0675\n",
      "Epoch 771/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.1274\n",
      "Epoch 772/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0947\n",
      "Epoch 773/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.1372\n",
      "Epoch 774/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4172 - val_loss: 670.0668\n",
      "Epoch 775/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.1112\n",
      "Epoch 776/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0560\n",
      "Epoch 777/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4157 - val_loss: 670.1101\n",
      "Epoch 778/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.0635\n",
      "Epoch 779/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4152 - val_loss: 670.0764\n",
      "Epoch 780/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0641\n",
      "Epoch 781/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0770\n",
      "Epoch 782/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4167 - val_loss: 670.0928\n",
      "Epoch 783/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4156 - val_loss: 670.1108\n",
      "Epoch 784/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0869\n",
      "Epoch 785/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4172 - val_loss: 670.0528\n",
      "Epoch 786/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4173 - val_loss: 670.1252\n",
      "Epoch 787/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4162 - val_loss: 670.1003\n",
      "Epoch 788/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.0432\n",
      "Epoch 789/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0840\n",
      "Epoch 790/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4176 - val_loss: 670.0181\n",
      "Epoch 791/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4180 - val_loss: 670.1177\n",
      "Epoch 792/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4201 - val_loss: 670.0465\n",
      "Epoch 793/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4175 - val_loss: 670.0433\n",
      "Epoch 794/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4158 - val_loss: 670.0928\n",
      "Epoch 795/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4174 - val_loss: 670.0857\n",
      "Epoch 796/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4180 - val_loss: 670.0469\n",
      "Epoch 797/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4174 - val_loss: 670.0496\n",
      "Epoch 798/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4175 - val_loss: 670.0513\n",
      "Epoch 799/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.0812\n",
      "Epoch 800/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4169 - val_loss: 670.1266\n",
      "Epoch 801/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.1193\n",
      "Epoch 802/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4155 - val_loss: 670.0671\n",
      "Epoch 803/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.0756\n",
      "Epoch 804/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4158 - val_loss: 670.0856\n",
      "Epoch 805/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.1087\n",
      "Epoch 806/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.1191\n",
      "Epoch 807/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4152 - val_loss: 670.0853\n",
      "Epoch 808/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4153 - val_loss: 670.0818\n",
      "Epoch 809/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.1107\n",
      "Epoch 810/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4150 - val_loss: 670.0663\n",
      "Epoch 811/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.0513\n",
      "Epoch 812/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.0708\n",
      "Epoch 813/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4167 - val_loss: 670.0447\n",
      "Epoch 815/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0968\n",
      "Epoch 816/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.1039\n",
      "Epoch 817/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4156 - val_loss: 670.1099\n",
      "Epoch 818/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.0610\n",
      "Epoch 819/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4171 - val_loss: 670.0801\n",
      "Epoch 820/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4172 - val_loss: 670.0998\n",
      "Epoch 821/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4177 - val_loss: 670.1011\n",
      "Epoch 822/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4181 - val_loss: 670.0915\n",
      "Epoch 823/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4182 - val_loss: 670.0723\n",
      "Epoch 824/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4178 - val_loss: 670.0421\n",
      "Epoch 825/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.1307\n",
      "Epoch 826/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.0857\n",
      "Epoch 827/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.0967\n",
      "Epoch 828/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4174 - val_loss: 670.0895\n",
      "Epoch 829/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4155 - val_loss: 670.1219\n",
      "Epoch 830/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0635\n",
      "Epoch 831/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0821\n",
      "Epoch 832/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4155 - val_loss: 670.1022\n",
      "Epoch 833/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4151 - val_loss: 670.0903\n",
      "Epoch 834/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.0906\n",
      "Epoch 835/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.0761\n",
      "Epoch 836/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.0923\n",
      "Epoch 837/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4162 - val_loss: 670.1058\n",
      "Epoch 838/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4158 - val_loss: 670.1083\n",
      "Epoch 839/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4182 - val_loss: 670.1053\n",
      "Epoch 840/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4180 - val_loss: 670.1346\n",
      "Epoch 841/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4147 - val_loss: 670.1350\n",
      "Epoch 842/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4171 - val_loss: 670.1388\n",
      "Epoch 843/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4157 - val_loss: 670.1129\n",
      "Epoch 844/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.1119\n",
      "Epoch 845/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4163 - val_loss: 670.0995\n",
      "Epoch 846/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4167 - val_loss: 670.1106\n",
      "Epoch 847/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4172 - val_loss: 670.1022\n",
      "Epoch 848/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4164 - val_loss: 670.1437\n",
      "Epoch 849/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.0798\n",
      "Epoch 850/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4158 - val_loss: 670.1144\n",
      "Epoch 851/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4180 - val_loss: 670.1405\n",
      "Epoch 852/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4153 - val_loss: 670.0785\n",
      "Epoch 853/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4154 - val_loss: 670.1115\n",
      "Epoch 854/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4192 - val_loss: 670.0780\n",
      "Epoch 855/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4185 - val_loss: 670.1057\n",
      "Epoch 856/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.1100\n",
      "Epoch 857/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4179 - val_loss: 670.1033\n",
      "Epoch 858/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4154 - val_loss: 670.0887\n",
      "Epoch 859/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4153 - val_loss: 670.0818\n",
      "Epoch 860/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4153 - val_loss: 670.1124\n",
      "Epoch 861/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4174 - val_loss: 670.1448\n",
      "Epoch 862/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.0539\n",
      "Epoch 863/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4170 - val_loss: 670.0998\n",
      "Epoch 864/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4154 - val_loss: 670.0917\n",
      "Epoch 865/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4181 - val_loss: 670.0934\n",
      "Epoch 866/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4169 - val_loss: 670.1435\n",
      "Epoch 867/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4156 - val_loss: 670.1475\n",
      "Epoch 868/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4161 - val_loss: 670.0659\n",
      "Epoch 869/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.1466\n",
      "Epoch 870/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.1285\n",
      "Epoch 871/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4154 - val_loss: 670.1279\n",
      "Epoch 872/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4152 - val_loss: 670.1218\n",
      "Epoch 873/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4162 - val_loss: 670.1269\n",
      "Epoch 874/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4165 - val_loss: 670.1047\n",
      "Epoch 875/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4167 - val_loss: 670.1454\n",
      "Epoch 876/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4153 - val_loss: 670.1278\n",
      "Epoch 877/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4177 - val_loss: 670.1116\n",
      "Epoch 878/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4166 - val_loss: 670.0936\n",
      "Epoch 879/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4157 - val_loss: 670.1133\n",
      "Epoch 880/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4153 - val_loss: 670.1362\n",
      "Epoch 881/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4168 - val_loss: 670.1190\n",
      "Epoch 882/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.1056\n",
      "Epoch 883/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4160 - val_loss: 670.0866\n",
      "Epoch 884/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4160 - val_loss: 670.0828\n",
      "Epoch 885/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4170 - val_loss: 670.1070\n",
      "Epoch 886/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.0703\n",
      "Epoch 887/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.1100\n",
      "Epoch 888/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.1349\n",
      "Epoch 889/1000\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 411.4180 - val_loss: 670.1198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 890/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4154 - val_loss: 670.1390\n",
      "Epoch 891/1000\n",
      "289/289 [==============================] - 0s 934us/step - loss: 411.4161 - val_loss: 670.0742\n",
      "Epoch 892/1000\n",
      "289/289 [==============================] - 0s 949us/step - loss: 411.4160 - val_loss: 670.1237\n",
      "Epoch 893/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 411.4159 - val_loss: 670.1760\n",
      "Epoch 894/1000\n",
      "289/289 [==============================] - 0s 932us/step - loss: 411.4163 - val_loss: 670.1296\n",
      "Epoch 895/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 411.4167 - val_loss: 670.1020\n",
      "Epoch 896/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 411.4172 - val_loss: 670.1049\n",
      "Epoch 897/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 411.4166 - val_loss: 670.1000\n",
      "Epoch 898/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 411.4162 - val_loss: 670.0969\n",
      "Epoch 899/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4170 - val_loss: 670.1191\n",
      "Epoch 900/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 411.4168 - val_loss: 670.0655\n",
      "Epoch 901/1000\n",
      "289/289 [==============================] - 0s 899us/step - loss: 411.4166 - val_loss: 670.0667\n",
      "Epoch 902/1000\n",
      "289/289 [==============================] - 0s 943us/step - loss: 411.4176 - val_loss: 670.1609\n",
      "Epoch 903/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 411.4154 - val_loss: 670.1530\n",
      "Epoch 904/1000\n",
      "289/289 [==============================] - 0s 837us/step - loss: 411.4161 - val_loss: 670.1458\n",
      "Epoch 905/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 411.4184 - val_loss: 670.0728\n",
      "Epoch 906/1000\n",
      "289/289 [==============================] - 0s 967us/step - loss: 411.4164 - val_loss: 670.0944\n",
      "Epoch 907/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 411.4177 - val_loss: 670.1136\n",
      "Epoch 908/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.4153 - val_loss: 670.1146\n",
      "Epoch 909/1000\n",
      "289/289 [==============================] - 0s 897us/step - loss: 411.4156 - val_loss: 670.1091\n",
      "Epoch 910/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 411.4157 - val_loss: 670.0980\n",
      "Epoch 911/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 411.4171 - val_loss: 670.1033\n",
      "Epoch 912/1000\n",
      "289/289 [==============================] - 0s 835us/step - loss: 411.4164 - val_loss: 670.0923\n",
      "Epoch 913/1000\n",
      "289/289 [==============================] - 0s 923us/step - loss: 411.4153 - val_loss: 670.1143\n",
      "Epoch 914/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4172 - val_loss: 670.0738\n",
      "Epoch 915/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 411.4159 - val_loss: 670.0807\n",
      "Epoch 916/1000\n",
      "289/289 [==============================] - 0s 903us/step - loss: 411.4158 - val_loss: 670.0568\n",
      "Epoch 917/1000\n",
      "289/289 [==============================] - 0s 852us/step - loss: 411.4169 - val_loss: 670.0616\n",
      "Epoch 918/1000\n",
      "289/289 [==============================] - 0s 879us/step - loss: 411.4166 - val_loss: 670.0894\n",
      "Epoch 919/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 411.4176 - val_loss: 670.1093\n",
      "Epoch 920/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4164 - val_loss: 670.0781\n",
      "Epoch 921/1000\n",
      "289/289 [==============================] - 0s 860us/step - loss: 411.4166 - val_loss: 670.1091\n",
      "Epoch 922/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 411.4167 - val_loss: 670.1464\n",
      "Epoch 923/1000\n",
      "289/289 [==============================] - 0s 848us/step - loss: 411.4174 - val_loss: 670.0928\n",
      "Epoch 924/1000\n",
      "289/289 [==============================] - 0s 874us/step - loss: 411.4156 - val_loss: 670.0803\n",
      "Epoch 925/1000\n",
      "289/289 [==============================] - 0s 922us/step - loss: 411.4157 - val_loss: 670.1222\n",
      "Epoch 926/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4171 - val_loss: 670.1672\n",
      "Epoch 927/1000\n",
      "289/289 [==============================] - 0s 876us/step - loss: 411.4169 - val_loss: 670.1382\n",
      "Epoch 928/1000\n",
      "289/289 [==============================] - 0s 813us/step - loss: 411.4152 - val_loss: 670.1060\n",
      "Epoch 929/1000\n",
      "289/289 [==============================] - 0s 869us/step - loss: 411.4165 - val_loss: 670.1046\n",
      "Epoch 930/1000\n",
      "289/289 [==============================] - 0s 875us/step - loss: 411.4161 - val_loss: 670.0798\n",
      "Epoch 931/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4164 - val_loss: 670.1150\n",
      "Epoch 932/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 411.4166 - val_loss: 670.1230\n",
      "Epoch 933/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 411.4152 - val_loss: 670.1190\n",
      "Epoch 934/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4151 - val_loss: 670.0944\n",
      "Epoch 935/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 411.4162 - val_loss: 670.1028\n",
      "Epoch 936/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 411.4172 - val_loss: 670.1065\n",
      "Epoch 937/1000\n",
      "289/289 [==============================] - 0s 790us/step - loss: 411.4161 - val_loss: 670.1220\n",
      "Epoch 938/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 411.4169 - val_loss: 670.0757\n",
      "Epoch 939/1000\n",
      "289/289 [==============================] - 0s 892us/step - loss: 411.4174 - val_loss: 670.0773\n",
      "Epoch 940/1000\n",
      "289/289 [==============================] - 0s 856us/step - loss: 411.4171 - val_loss: 670.0621\n",
      "Epoch 941/1000\n",
      "289/289 [==============================] - 0s 899us/step - loss: 411.4152 - val_loss: 670.0985\n",
      "Epoch 942/1000\n",
      "289/289 [==============================] - 0s 911us/step - loss: 411.4181 - val_loss: 670.1053\n",
      "Epoch 943/1000\n",
      "289/289 [==============================] - 0s 936us/step - loss: 411.4166 - val_loss: 670.0985\n",
      "Epoch 944/1000\n",
      "289/289 [==============================] - 0s 972us/step - loss: 411.4154 - val_loss: 670.1298\n",
      "Epoch 945/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 411.4163 - val_loss: 670.0596\n",
      "Epoch 946/1000\n",
      "289/289 [==============================] - 0s 863us/step - loss: 411.4179 - val_loss: 670.1563\n",
      "Epoch 947/1000\n",
      "289/289 [==============================] - 0s 781us/step - loss: 411.4158 - val_loss: 670.1007\n",
      "Epoch 948/1000\n",
      "289/289 [==============================] - 0s 794us/step - loss: 411.4166 - val_loss: 670.0956\n",
      "Epoch 949/1000\n",
      "289/289 [==============================] - 0s 854us/step - loss: 411.4167 - val_loss: 670.0905\n",
      "Epoch 950/1000\n",
      "289/289 [==============================] - 0s 949us/step - loss: 411.4158 - val_loss: 670.0935\n",
      "Epoch 951/1000\n",
      "289/289 [==============================] - 0s 931us/step - loss: 411.4153 - val_loss: 670.1475\n",
      "Epoch 952/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 411.4174 - val_loss: 670.0687\n",
      "Epoch 953/1000\n",
      "289/289 [==============================] - 0s 834us/step - loss: 411.4165 - val_loss: 670.1450\n",
      "Epoch 954/1000\n",
      "289/289 [==============================] - 0s 844us/step - loss: 411.4157 - val_loss: 670.1382\n",
      "Epoch 955/1000\n",
      "289/289 [==============================] - 0s 820us/step - loss: 411.4158 - val_loss: 670.1284\n",
      "Epoch 956/1000\n",
      "289/289 [==============================] - 0s 894us/step - loss: 411.4161 - val_loss: 670.1078\n",
      "Epoch 957/1000\n",
      "289/289 [==============================] - 0s 969us/step - loss: 411.4158 - val_loss: 670.1125\n",
      "Epoch 958/1000\n",
      "289/289 [==============================] - 0s 873us/step - loss: 411.4167 - val_loss: 670.1271\n",
      "Epoch 959/1000\n",
      "289/289 [==============================] - 0s 932us/step - loss: 411.4166 - val_loss: 670.1195\n",
      "Epoch 960/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 411.4155 - val_loss: 670.1475\n",
      "Epoch 961/1000\n",
      "289/289 [==============================] - 0s 926us/step - loss: 411.4151 - val_loss: 670.0995\n",
      "Epoch 962/1000\n",
      "289/289 [==============================] - 0s 938us/step - loss: 411.4169 - val_loss: 670.1237\n",
      "Epoch 963/1000\n",
      "289/289 [==============================] - 0s 840us/step - loss: 411.4165 - val_loss: 670.1103\n",
      "Epoch 964/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 779us/step - loss: 411.4156 - val_loss: 670.1448\n",
      "Epoch 965/1000\n",
      "289/289 [==============================] - 0s 805us/step - loss: 411.4160 - val_loss: 670.1233\n",
      "Epoch 966/1000\n",
      "289/289 [==============================] - 0s 785us/step - loss: 411.4156 - val_loss: 670.1265\n",
      "Epoch 967/1000\n",
      "289/289 [==============================] - 0s 856us/step - loss: 411.4169 - val_loss: 670.0591\n",
      "Epoch 968/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4178 - val_loss: 670.1599\n",
      "Epoch 969/1000\n",
      "289/289 [==============================] - 0s 846us/step - loss: 411.4169 - val_loss: 670.1230\n",
      "Epoch 970/1000\n",
      "289/289 [==============================] - 0s 864us/step - loss: 411.4160 - val_loss: 670.1091\n",
      "Epoch 971/1000\n",
      "289/289 [==============================] - 0s 871us/step - loss: 411.4158 - val_loss: 670.0868\n",
      "Epoch 972/1000\n",
      "289/289 [==============================] - 0s 790us/step - loss: 411.4179 - val_loss: 670.1400\n",
      "Epoch 973/1000\n",
      "289/289 [==============================] - 0s 997us/step - loss: 411.4164 - val_loss: 670.1421\n",
      "Epoch 974/1000\n",
      "289/289 [==============================] - 0s 906us/step - loss: 411.4154 - val_loss: 670.1053\n",
      "Epoch 975/1000\n",
      "289/289 [==============================] - 0s 845us/step - loss: 411.4160 - val_loss: 670.1097\n",
      "Epoch 976/1000\n",
      "289/289 [==============================] - 0s 874us/step - loss: 411.4161 - val_loss: 670.0781\n",
      "Epoch 977/1000\n",
      "289/289 [==============================] - 0s 849us/step - loss: 411.4157 - val_loss: 670.0962\n",
      "Epoch 978/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4162 - val_loss: 670.1061\n",
      "Epoch 979/1000\n",
      "289/289 [==============================] - 0s 783us/step - loss: 411.4161 - val_loss: 670.1094\n",
      "Epoch 980/1000\n",
      "289/289 [==============================] - 0s 878us/step - loss: 411.4154 - val_loss: 670.0970\n",
      "Epoch 981/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 411.4168 - val_loss: 670.1044\n",
      "Epoch 982/1000\n",
      "289/289 [==============================] - 0s 782us/step - loss: 411.4178 - val_loss: 670.1127\n",
      "Epoch 983/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 411.4166 - val_loss: 670.1028\n",
      "Epoch 984/1000\n",
      "289/289 [==============================] - 0s 755us/step - loss: 411.4160 - val_loss: 670.0779\n",
      "Epoch 985/1000\n",
      "289/289 [==============================] - 0s 886us/step - loss: 411.4163 - val_loss: 670.1022\n",
      "Epoch 986/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 411.4153 - val_loss: 670.1055\n",
      "Epoch 987/1000\n",
      "289/289 [==============================] - 0s 857us/step - loss: 411.4174 - val_loss: 670.0914\n",
      "Epoch 988/1000\n",
      "289/289 [==============================] - 0s 811us/step - loss: 411.4189 - val_loss: 670.1273\n",
      "Epoch 989/1000\n",
      "289/289 [==============================] - 0s 843us/step - loss: 411.4162 - val_loss: 670.1108\n",
      "Epoch 990/1000\n",
      "289/289 [==============================] - 0s 799us/step - loss: 411.4176 - val_loss: 670.1033\n",
      "Epoch 991/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 411.4196 - val_loss: 670.1602\n",
      "Epoch 992/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 411.4168 - val_loss: 670.1232\n",
      "Epoch 993/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4173 - val_loss: 670.1004\n",
      "Epoch 994/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 411.4170 - val_loss: 670.1003\n",
      "Epoch 995/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 411.4172 - val_loss: 670.1340\n",
      "Epoch 996/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4164 - val_loss: 670.1495\n",
      "Epoch 997/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 411.4167 - val_loss: 670.0927\n",
      "Epoch 998/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 411.4166 - val_loss: 670.1179\n",
      "Epoch 999/1000\n",
      "289/289 [==============================] - 0s 808us/step - loss: 411.4169 - val_loss: 670.1577\n",
      "Epoch 1000/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 411.4156 - val_loss: 670.1353\n",
      "66/66 [==============================] - 0s 498us/step\n",
      "689753 successful\n",
      "Epoch 1/1000\n",
      "320/320 [==============================] - 1s 964us/step - loss: 111535896.0000 - val_loss: 640.3176\n",
      "Epoch 2/1000\n",
      "320/320 [==============================] - 0s 780us/step - loss: 332.7872 - val_loss: 759.7542\n",
      "Epoch 3/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 337.0701 - val_loss: 643.9401\n",
      "Epoch 4/1000\n",
      "320/320 [==============================] - 0s 796us/step - loss: 340.0969 - val_loss: 606.8678\n",
      "Epoch 5/1000\n",
      "320/320 [==============================] - 0s 783us/step - loss: 359.2371 - val_loss: 709.3022\n",
      "Epoch 6/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 348.8002 - val_loss: 602.7874\n",
      "Epoch 7/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 363.0086 - val_loss: 608.3472\n",
      "Epoch 8/1000\n",
      "320/320 [==============================] - 0s 849us/step - loss: 365.6725 - val_loss: 611.1189\n",
      "Epoch 9/1000\n",
      "320/320 [==============================] - 0s 824us/step - loss: 377.4344 - val_loss: 636.5237\n",
      "Epoch 10/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 391.7129 - val_loss: 644.8176\n",
      "Epoch 11/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 446.8802 - val_loss: 594.1233\n",
      "Epoch 12/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 468.8480 - val_loss: 835.3882\n",
      "Epoch 13/1000\n",
      "320/320 [==============================] - 0s 906us/step - loss: 439.1221 - val_loss: 823.4122\n",
      "Epoch 14/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 502.9620 - val_loss: 829.5080\n",
      "Epoch 15/1000\n",
      "320/320 [==============================] - 0s 825us/step - loss: 626.8143 - val_loss: 693.1590\n",
      "Epoch 16/1000\n",
      "320/320 [==============================] - 0s 989us/step - loss: 707.0212 - val_loss: 719.4247\n",
      "Epoch 17/1000\n",
      "320/320 [==============================] - 0s 833us/step - loss: 964.4324 - val_loss: 4047.7856\n",
      "Epoch 18/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 4710.1426 - val_loss: 13939.7988\n",
      "Epoch 19/1000\n",
      "320/320 [==============================] - 0s 834us/step - loss: 122056.0625 - val_loss: 95600.8828\n",
      "Epoch 20/1000\n",
      "320/320 [==============================] - 0s 858us/step - loss: 113983.7656 - val_loss: 51025.9648\n",
      "Epoch 21/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 90897.8906 - val_loss: 35428.2344\n",
      "Epoch 22/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 120592.1094 - val_loss: 629.0220\n",
      "Epoch 23/1000\n",
      "320/320 [==============================] - 0s 855us/step - loss: 96530.2656 - val_loss: 146177.4844\n",
      "Epoch 24/1000\n",
      "320/320 [==============================] - 0s 864us/step - loss: 103839.5078 - val_loss: 3778.9016\n",
      "Epoch 25/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 102421.4844 - val_loss: 205933.9688\n",
      "Epoch 26/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 97507.7656 - val_loss: 7170.1528\n",
      "Epoch 27/1000\n",
      "320/320 [==============================] - 0s 978us/step - loss: 107181.2266 - val_loss: 36329.9297\n",
      "Epoch 28/1000\n",
      "320/320 [==============================] - 0s 858us/step - loss: 107798.1719 - val_loss: 25437.8691\n",
      "Epoch 29/1000\n",
      "320/320 [==============================] - 0s 923us/step - loss: 79066.5703 - val_loss: 290590.5312\n",
      "Epoch 30/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 99245.5234 - val_loss: 116076.4922\n",
      "Epoch 31/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 84816.3594 - val_loss: 3784.6028\n",
      "Epoch 32/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 86982.8281 - val_loss: 115493.2266\n",
      "Epoch 33/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 100574.6484 - val_loss: 94704.2656\n",
      "Epoch 34/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 74932.6172 - val_loss: 12584.2744\n",
      "Epoch 35/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 85965.7734 - val_loss: 331455.0312\n",
      "Epoch 36/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 89285.3281 - val_loss: 6123.5977\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 927us/step - loss: 73763.5391 - val_loss: 253816.5000\n",
      "Epoch 38/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 84012.4844 - val_loss: 177123.7812\n",
      "Epoch 39/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 70740.0156 - val_loss: 29936.2285\n",
      "Epoch 40/1000\n",
      "320/320 [==============================] - 0s 833us/step - loss: 94050.2109 - val_loss: 225017.2812\n",
      "Epoch 41/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 52493.7383 - val_loss: 78291.4062\n",
      "Epoch 42/1000\n",
      "320/320 [==============================] - 0s 901us/step - loss: 65702.9297 - val_loss: 14069.8574\n",
      "Epoch 43/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 75191.7969 - val_loss: 33752.6680\n",
      "Epoch 44/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 63027.8320 - val_loss: 2611.3777\n",
      "Epoch 45/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 67584.0000 - val_loss: 78145.3281\n",
      "Epoch 46/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 78494.8047 - val_loss: 36771.9336\n",
      "Epoch 47/1000\n",
      "320/320 [==============================] - 0s 915us/step - loss: 41347.5859 - val_loss: 1888.7761\n",
      "Epoch 48/1000\n",
      "320/320 [==============================] - 0s 928us/step - loss: 61443.5820 - val_loss: 6381.3027\n",
      "Epoch 49/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 61151.0703 - val_loss: 596388.7500\n",
      "Epoch 50/1000\n",
      "320/320 [==============================] - 0s 899us/step - loss: 57952.1758 - val_loss: 635.9000\n",
      "Epoch 51/1000\n",
      "320/320 [==============================] - 0s 937us/step - loss: 2459624.5000 - val_loss: 36427.1719\n",
      "Epoch 52/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 879.1107 - val_loss: 648.3398\n",
      "Epoch 53/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 402.5546 - val_loss: 593.2598\n",
      "Epoch 54/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 439.4899 - val_loss: 921.9290\n",
      "Epoch 55/1000\n",
      "320/320 [==============================] - 0s 936us/step - loss: 403.1886 - val_loss: 598.2621\n",
      "Epoch 56/1000\n",
      "320/320 [==============================] - 0s 864us/step - loss: 504.4069 - val_loss: 677.2372\n",
      "Epoch 57/1000\n",
      "320/320 [==============================] - 0s 861us/step - loss: 641.2565 - val_loss: 1177.2294\n",
      "Epoch 58/1000\n",
      "320/320 [==============================] - 0s 846us/step - loss: 635.5887 - val_loss: 1839.2195\n",
      "Epoch 59/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 944.0381 - val_loss: 764.7851\n",
      "Epoch 60/1000\n",
      "320/320 [==============================] - 0s 902us/step - loss: 2232.1494 - val_loss: 589.4845\n",
      "Epoch 61/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 31492.1094 - val_loss: 39387.5547\n",
      "Epoch 62/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 38487.3008 - val_loss: 33815.2539\n",
      "Epoch 63/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 40615.6094 - val_loss: 1512.9724\n",
      "Epoch 64/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 39006.3750 - val_loss: 26148.9844\n",
      "Epoch 65/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 39684.6836 - val_loss: 31587.7051\n",
      "Epoch 66/1000\n",
      "320/320 [==============================] - 0s 965us/step - loss: 39372.4219 - val_loss: 1873.8206\n",
      "Epoch 67/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 33076.6680 - val_loss: 3091.1904\n",
      "Epoch 68/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 34500.6016 - val_loss: 9270.6729\n",
      "Epoch 69/1000\n",
      "320/320 [==============================] - 0s 862us/step - loss: 36008.6016 - val_loss: 34794.0078\n",
      "Epoch 70/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 32762.1973 - val_loss: 84194.2266\n",
      "Epoch 71/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 32005.6973 - val_loss: 13009.2109\n",
      "Epoch 72/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 30916.7539 - val_loss: 38291.8047\n",
      "Epoch 73/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 35877.2891 - val_loss: 1965.6260\n",
      "Epoch 74/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 24717.5977 - val_loss: 33542.9492\n",
      "Epoch 75/1000\n",
      "320/320 [==============================] - 0s 996us/step - loss: 29964.3320 - val_loss: 14458.3789\n",
      "Epoch 76/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 31034.3867 - val_loss: 2033.5092\n",
      "Epoch 77/1000\n",
      "320/320 [==============================] - 0s 957us/step - loss: 25520.9414 - val_loss: 46447.2852\n",
      "Epoch 78/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 25285.6289 - val_loss: 5610.8550\n",
      "Epoch 79/1000\n",
      "320/320 [==============================] - 0s 915us/step - loss: 26208.7227 - val_loss: 6386.3833\n",
      "Epoch 80/1000\n",
      "320/320 [==============================] - 0s 960us/step - loss: 24893.8867 - val_loss: 10155.7334\n",
      "Epoch 81/1000\n",
      "320/320 [==============================] - 0s 971us/step - loss: 11648.7188 - val_loss: 629.5471\n",
      "Epoch 82/1000\n",
      "320/320 [==============================] - 0s 920us/step - loss: 21687.9141 - val_loss: 5996.8145\n",
      "Epoch 83/1000\n",
      "320/320 [==============================] - 0s 953us/step - loss: 18180.9023 - val_loss: 13612.6309\n",
      "Epoch 84/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 21573.4883 - val_loss: 9600.4365\n",
      "Epoch 85/1000\n",
      "320/320 [==============================] - 0s 839us/step - loss: 20610.0586 - val_loss: 8389.4209\n",
      "Epoch 86/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 22549.9492 - val_loss: 612.2779\n",
      "Epoch 87/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 13322.7324 - val_loss: 7512.8745\n",
      "Epoch 88/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 18929.9512 - val_loss: 3027.9363\n",
      "Epoch 89/1000\n",
      "320/320 [==============================] - 0s 912us/step - loss: 17138.5449 - val_loss: 1031.7833\n",
      "Epoch 90/1000\n",
      "320/320 [==============================] - 0s 946us/step - loss: 20548.0234 - val_loss: 39055.1445\n",
      "Epoch 91/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 19444.4160 - val_loss: 632.8966\n",
      "Epoch 92/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 15115.2080 - val_loss: 12339.5156\n",
      "Epoch 93/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 16186.3643 - val_loss: 27315.0684\n",
      "Epoch 94/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 18493.8086 - val_loss: 1500.2615\n",
      "Epoch 95/1000\n",
      "320/320 [==============================] - 0s 963us/step - loss: 14904.7363 - val_loss: 45243.2461\n",
      "Epoch 96/1000\n",
      "320/320 [==============================] - 0s 982us/step - loss: 18167.3926 - val_loss: 9199.1328\n",
      "Epoch 97/1000\n",
      "320/320 [==============================] - 0s 933us/step - loss: 15663.4424 - val_loss: 12487.2646\n",
      "Epoch 98/1000\n",
      "320/320 [==============================] - 0s 945us/step - loss: 12451.0439 - val_loss: 4183.3950\n",
      "Epoch 99/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 15450.4326 - val_loss: 4216.1938\n",
      "Epoch 100/1000\n",
      "320/320 [==============================] - 0s 998us/step - loss: 14156.4795 - val_loss: 1943.3807\n",
      "Epoch 101/1000\n",
      "320/320 [==============================] - 0s 926us/step - loss: 14415.6250 - val_loss: 11195.5518\n",
      "Epoch 102/1000\n",
      "320/320 [==============================] - 0s 987us/step - loss: 15713.5059 - val_loss: 15710.1133\n",
      "Epoch 103/1000\n",
      "320/320 [==============================] - 0s 920us/step - loss: 11272.7734 - val_loss: 1107.9006\n",
      "Epoch 104/1000\n",
      "320/320 [==============================] - 0s 911us/step - loss: 13694.4160 - val_loss: 5218.4941\n",
      "Epoch 105/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 11483.5654 - val_loss: 56510.3945\n",
      "Epoch 106/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 11842.3691 - val_loss: 12369.9932\n",
      "Epoch 107/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 12392.9854 - val_loss: 11867.6318\n",
      "Epoch 108/1000\n",
      "320/320 [==============================] - 0s 890us/step - loss: 14149.5801 - val_loss: 19568.8066\n",
      "Epoch 109/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 11427.4014 - val_loss: 10732.9043\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 924us/step - loss: 10819.1387 - val_loss: 26304.9902\n",
      "Epoch 111/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 9891.5967 - val_loss: 5403.6021\n",
      "Epoch 112/1000\n",
      "320/320 [==============================] - 0s 941us/step - loss: 13282.6699 - val_loss: 6493.7319\n",
      "Epoch 113/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 10188.6396 - val_loss: 8528.5840\n",
      "Epoch 114/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 11782.3730 - val_loss: 4550.8315\n",
      "Epoch 115/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 10246.4297 - val_loss: 20693.4395\n",
      "Epoch 116/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 7990.0781 - val_loss: 15884.6387\n",
      "Epoch 117/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 10516.5762 - val_loss: 1265.8334\n",
      "Epoch 118/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 8287.7979 - val_loss: 11263.4141\n",
      "Epoch 119/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 10185.2061 - val_loss: 2170.3523\n",
      "Epoch 120/1000\n",
      "320/320 [==============================] - 0s 912us/step - loss: 9114.1699 - val_loss: 7832.9839\n",
      "Epoch 121/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 8795.2480 - val_loss: 4258.9185\n",
      "Epoch 122/1000\n",
      "320/320 [==============================] - 0s 913us/step - loss: 8640.2061 - val_loss: 36354.5820\n",
      "Epoch 123/1000\n",
      "320/320 [==============================] - 0s 970us/step - loss: 8971.0938 - val_loss: 36947.1328\n",
      "Epoch 124/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 163952.0469 - val_loss: 80639.4219\n",
      "Epoch 125/1000\n",
      "320/320 [==============================] - 0s 990us/step - loss: 2332.4482 - val_loss: 592.0613\n",
      "Epoch 126/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 448.3381 - val_loss: 1501.6346\n",
      "Epoch 127/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 439.1208 - val_loss: 590.7931\n",
      "Epoch 128/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 668.2992 - val_loss: 589.7318\n",
      "Epoch 129/1000\n",
      "320/320 [==============================] - 0s 936us/step - loss: 724.6893 - val_loss: 705.9939\n",
      "Epoch 130/1000\n",
      "320/320 [==============================] - 0s 963us/step - loss: 847.5073 - val_loss: 958.8857\n",
      "Epoch 131/1000\n",
      "320/320 [==============================] - 0s 880us/step - loss: 1376.7562 - val_loss: 1016.0143\n",
      "Epoch 132/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 3775.0984 - val_loss: 2632.0427\n",
      "Epoch 133/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 7064.1084 - val_loss: 8154.5225\n",
      "Epoch 134/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 5767.5923 - val_loss: 18927.3457\n",
      "Epoch 135/1000\n",
      "320/320 [==============================] - 0s 818us/step - loss: 6883.9570 - val_loss: 3206.7715\n",
      "Epoch 136/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 4447.4082 - val_loss: 11481.7891\n",
      "Epoch 137/1000\n",
      "320/320 [==============================] - 0s 789us/step - loss: 5223.0029 - val_loss: 12821.7676\n",
      "Epoch 138/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 6504.2349 - val_loss: 17650.4121\n",
      "Epoch 139/1000\n",
      "320/320 [==============================] - 0s 794us/step - loss: 3389.5562 - val_loss: 7268.3467\n",
      "Epoch 140/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 4593.4834 - val_loss: 4095.7881\n",
      "Epoch 141/1000\n",
      "320/320 [==============================] - 0s 963us/step - loss: 4829.8462 - val_loss: 4501.0088\n",
      "Epoch 142/1000\n",
      "320/320 [==============================] - 0s 909us/step - loss: 4168.4092 - val_loss: 689.0182\n",
      "Epoch 143/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 4103.7891 - val_loss: 11642.6357\n",
      "Epoch 144/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 4016.0591 - val_loss: 824.8760\n",
      "Epoch 145/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 4548.6748 - val_loss: 626.5961\n",
      "Epoch 146/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 4236.5381 - val_loss: 9303.2236\n",
      "Epoch 147/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 3820.5833 - val_loss: 9328.3428\n",
      "Epoch 148/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 3239.8403 - val_loss: 6340.3628\n",
      "Epoch 149/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 4495.5752 - val_loss: 12346.8652\n",
      "Epoch 150/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3347.6987 - val_loss: 7350.7686\n",
      "Epoch 151/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3496.1531 - val_loss: 2901.2969\n",
      "Epoch 152/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3844.0344 - val_loss: 8391.6074\n",
      "Epoch 153/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3375.6050 - val_loss: 829.9620\n",
      "Epoch 154/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2789.4951 - val_loss: 3018.2510\n",
      "Epoch 155/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2824.9685 - val_loss: 6661.4902\n",
      "Epoch 156/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2762.0515 - val_loss: 1133.9625\n",
      "Epoch 157/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3148.8772 - val_loss: 3523.0610\n",
      "Epoch 158/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2427.6909 - val_loss: 1356.2817\n",
      "Epoch 159/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3432.5996 - val_loss: 7648.3477\n",
      "Epoch 160/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1986.1270 - val_loss: 2155.3171\n",
      "Epoch 161/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3678.0417 - val_loss: 7228.7339\n",
      "Epoch 162/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2433.2131 - val_loss: 673.5927\n",
      "Epoch 163/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2354.3623 - val_loss: 3310.1838\n",
      "Epoch 164/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2557.2300 - val_loss: 4512.3936\n",
      "Epoch 165/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1841.4293 - val_loss: 1333.2294\n",
      "Epoch 166/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2601.9868 - val_loss: 8206.4707\n",
      "Epoch 167/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2196.8462 - val_loss: 4639.4355\n",
      "Epoch 168/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2764.2358 - val_loss: 608.7726\n",
      "Epoch 169/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1268.6272 - val_loss: 1793.0309\n",
      "Epoch 170/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2707.3999 - val_loss: 1225.0868\n",
      "Epoch 171/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2344.7090 - val_loss: 1197.7177\n",
      "Epoch 172/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2235.7246 - val_loss: 6014.0513\n",
      "Epoch 173/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1786.3037 - val_loss: 5441.7593\n",
      "Epoch 174/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1331.0573 - val_loss: 2490.3894\n",
      "Epoch 175/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1733.6804 - val_loss: 889.3549\n",
      "Epoch 176/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1758.3684 - val_loss: 1065.9503\n",
      "Epoch 177/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1249.8020 - val_loss: 601.2772\n",
      "Epoch 178/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1593.4691 - val_loss: 598.1956\n",
      "Epoch 179/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1757.3699 - val_loss: 1880.5890\n",
      "Epoch 180/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1720.9958 - val_loss: 642.5709\n",
      "Epoch 181/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1429.2734 - val_loss: 1104.9778\n",
      "Epoch 182/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1357.0785 - val_loss: 1130.6514\n",
      "Epoch 183/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1169.6610 - val_loss: 593.5399\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 1444.0652 - val_loss: 3728.7727\n",
      "Epoch 185/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1860.0912 - val_loss: 8329.9756\n",
      "Epoch 186/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1559.2400 - val_loss: 7738.4731\n",
      "Epoch 187/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1086.0531 - val_loss: 1706.9159\n",
      "Epoch 188/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1186.5870 - val_loss: 666.9517\n",
      "Epoch 189/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1229.9197 - val_loss: 970.7610\n",
      "Epoch 190/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1611.2795 - val_loss: 4487.0342\n",
      "Epoch 191/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1072.9838 - val_loss: 2911.9983\n",
      "Epoch 192/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1096.4703 - val_loss: 965.1544\n",
      "Epoch 193/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1170.2819 - val_loss: 605.7997\n",
      "Epoch 194/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 857.6546 - val_loss: 4091.7966\n",
      "Epoch 195/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 963.6538 - val_loss: 673.4782\n",
      "Epoch 196/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1006.8353 - val_loss: 1791.4691\n",
      "Epoch 197/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 943.9095 - val_loss: 801.2745\n",
      "Epoch 198/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5720.2534 - val_loss: 2073.6465\n",
      "Epoch 199/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 415.7636 - val_loss: 708.1495\n",
      "Epoch 200/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 350.5342 - val_loss: 824.0825\n",
      "Epoch 201/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 352.5003 - val_loss: 589.5018\n",
      "Epoch 202/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 359.4178 - val_loss: 652.9088\n",
      "Epoch 203/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 358.4810 - val_loss: 669.0707\n",
      "Epoch 204/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 360.5936 - val_loss: 590.0331\n",
      "Epoch 205/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 381.3539 - val_loss: 880.7217\n",
      "Epoch 206/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 361.2071 - val_loss: 837.4938\n",
      "Epoch 207/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 363.8390 - val_loss: 602.4195\n",
      "Epoch 208/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 369.5933 - val_loss: 628.5784\n",
      "Epoch 209/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 400.6934 - val_loss: 911.0521\n",
      "Epoch 210/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 383.8371 - val_loss: 623.4597\n",
      "Epoch 211/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 347.3307 - val_loss: 820.2615\n",
      "Epoch 212/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 360.2651 - val_loss: 631.4154\n",
      "Epoch 213/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 364.2320 - val_loss: 658.2905\n",
      "Epoch 214/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 350.2792 - val_loss: 652.2092\n",
      "Epoch 215/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 335.7984 - val_loss: 655.1741\n",
      "Epoch 216/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 335.9904 - val_loss: 686.4881\n",
      "Epoch 217/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 328.9955 - val_loss: 601.0240\n",
      "Epoch 218/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 328.8202 - val_loss: 632.2189\n",
      "Epoch 219/1000\n",
      "320/320 [==============================] - 0s 967us/step - loss: 329.7919 - val_loss: 595.7990\n",
      "Epoch 220/1000\n",
      "320/320 [==============================] - 0s 968us/step - loss: 332.0870 - val_loss: 637.3690\n",
      "Epoch 221/1000\n",
      "320/320 [==============================] - 0s 916us/step - loss: 329.5620 - val_loss: 632.7009\n",
      "Epoch 222/1000\n",
      "320/320 [==============================] - 0s 939us/step - loss: 332.5515 - val_loss: 606.2673\n",
      "Epoch 223/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 331.0345 - val_loss: 615.7585\n",
      "Epoch 224/1000\n",
      "320/320 [==============================] - 0s 926us/step - loss: 331.7344 - val_loss: 657.5681\n",
      "Epoch 225/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 331.7802 - val_loss: 739.3727\n",
      "Epoch 226/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 337.7395 - val_loss: 652.1851\n",
      "Epoch 227/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 335.5361 - val_loss: 726.7637\n",
      "Epoch 228/1000\n",
      "320/320 [==============================] - 0s 865us/step - loss: 334.5543 - val_loss: 620.6514\n",
      "Epoch 229/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 331.6520 - val_loss: 624.2010\n",
      "Epoch 230/1000\n",
      "320/320 [==============================] - 0s 970us/step - loss: 333.6514 - val_loss: 656.2820\n",
      "Epoch 231/1000\n",
      "320/320 [==============================] - 0s 991us/step - loss: 335.4269 - val_loss: 664.7892\n",
      "Epoch 232/1000\n",
      "320/320 [==============================] - 0s 952us/step - loss: 334.7498 - val_loss: 640.5403\n",
      "Epoch 233/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 337.8496 - val_loss: 670.7089\n",
      "Epoch 234/1000\n",
      "320/320 [==============================] - 0s 909us/step - loss: 336.7692 - val_loss: 615.4728\n",
      "Epoch 235/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 334.9412 - val_loss: 622.5452\n",
      "Epoch 236/1000\n",
      "320/320 [==============================] - 0s 924us/step - loss: 338.9909 - val_loss: 618.0469\n",
      "Epoch 237/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 337.9772 - val_loss: 672.7003\n",
      "Epoch 238/1000\n",
      "320/320 [==============================] - 0s 799us/step - loss: 337.5945 - val_loss: 696.3571\n",
      "Epoch 239/1000\n",
      "320/320 [==============================] - 0s 832us/step - loss: 337.3258 - val_loss: 723.1598\n",
      "Epoch 240/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 335.3924 - val_loss: 655.2231\n",
      "Epoch 241/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 337.8311 - val_loss: 622.8802\n",
      "Epoch 242/1000\n",
      "320/320 [==============================] - 0s 841us/step - loss: 335.8850 - val_loss: 651.6843\n",
      "Epoch 243/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 344.4521 - val_loss: 689.7322\n",
      "Epoch 244/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 336.7702 - val_loss: 778.8967\n",
      "Epoch 245/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 341.4091 - val_loss: 695.3396\n",
      "Epoch 246/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 334.6245 - val_loss: 759.8997\n",
      "Epoch 247/1000\n",
      "320/320 [==============================] - 0s 923us/step - loss: 338.5300 - val_loss: 590.6391\n",
      "Epoch 248/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 7960.1484 - val_loss: 624.5074\n",
      "Epoch 249/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 344.1604 - val_loss: 604.4495\n",
      "Epoch 250/1000\n",
      "320/320 [==============================] - 0s 801us/step - loss: 341.3057 - val_loss: 673.7933\n",
      "Epoch 251/1000\n",
      "320/320 [==============================] - 0s 758us/step - loss: 338.4102 - val_loss: 610.8992\n",
      "Epoch 252/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 332.7134 - val_loss: 601.0540\n",
      "Epoch 253/1000\n",
      "320/320 [==============================] - 0s 819us/step - loss: 334.5418 - val_loss: 666.6968\n",
      "Epoch 254/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 338.4431 - val_loss: 733.8336\n",
      "Epoch 255/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 333.8182 - val_loss: 678.7823\n",
      "Epoch 256/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 339.9483 - val_loss: 591.2063\n",
      "Epoch 257/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 335.1353 - val_loss: 695.3058\n",
      "Epoch 258/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 332.2640 - val_loss: 685.8441\n",
      "Epoch 259/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 880us/step - loss: 341.2778 - val_loss: 666.9804\n",
      "Epoch 260/1000\n",
      "320/320 [==============================] - 0s 789us/step - loss: 340.0689 - val_loss: 612.8167\n",
      "Epoch 261/1000\n",
      "320/320 [==============================] - 0s 766us/step - loss: 331.3000 - val_loss: 624.4341\n",
      "Epoch 262/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 336.1635 - val_loss: 648.4045\n",
      "Epoch 263/1000\n",
      "320/320 [==============================] - 0s 799us/step - loss: 339.5234 - val_loss: 663.9865\n",
      "Epoch 264/1000\n",
      "320/320 [==============================] - 0s 765us/step - loss: 335.1804 - val_loss: 718.9734\n",
      "Epoch 265/1000\n",
      "320/320 [==============================] - 0s 773us/step - loss: 333.5516 - val_loss: 674.4270\n",
      "Epoch 266/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 337.7031 - val_loss: 710.6555\n",
      "Epoch 267/1000\n",
      "320/320 [==============================] - 0s 767us/step - loss: 331.5582 - val_loss: 644.6478\n",
      "Epoch 268/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 341.6313 - val_loss: 636.8036\n",
      "Epoch 269/1000\n",
      "320/320 [==============================] - 0s 743us/step - loss: 338.8976 - val_loss: 709.5805\n",
      "Epoch 270/1000\n",
      "320/320 [==============================] - 0s 773us/step - loss: 339.1920 - val_loss: 651.0745\n",
      "Epoch 271/1000\n",
      "320/320 [==============================] - 0s 757us/step - loss: 336.6129 - val_loss: 613.4219\n",
      "Epoch 272/1000\n",
      "320/320 [==============================] - 0s 734us/step - loss: 333.5384 - val_loss: 730.5641\n",
      "Epoch 273/1000\n",
      "320/320 [==============================] - 0s 751us/step - loss: 333.8183 - val_loss: 659.4632\n",
      "Epoch 274/1000\n",
      "320/320 [==============================] - 0s 790us/step - loss: 335.8391 - val_loss: 631.8227\n",
      "Epoch 275/1000\n",
      "320/320 [==============================] - 0s 816us/step - loss: 334.0124 - val_loss: 663.9093\n",
      "Epoch 276/1000\n",
      "320/320 [==============================] - 0s 782us/step - loss: 340.5954 - val_loss: 652.5684\n",
      "Epoch 277/1000\n",
      "320/320 [==============================] - 0s 804us/step - loss: 334.9527 - val_loss: 741.4293\n",
      "Epoch 278/1000\n",
      "320/320 [==============================] - 0s 807us/step - loss: 340.7457 - val_loss: 726.3693\n",
      "Epoch 279/1000\n",
      "320/320 [==============================] - 0s 752us/step - loss: 336.0462 - val_loss: 764.0065\n",
      "Epoch 280/1000\n",
      "320/320 [==============================] - 0s 751us/step - loss: 341.7364 - val_loss: 652.5726\n",
      "Epoch 281/1000\n",
      "320/320 [==============================] - 0s 762us/step - loss: 336.2031 - val_loss: 598.7698\n",
      "Epoch 282/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 331.5094 - val_loss: 612.5153\n",
      "Epoch 283/1000\n",
      "320/320 [==============================] - 0s 770us/step - loss: 340.2734 - val_loss: 598.6920\n",
      "Epoch 284/1000\n",
      "320/320 [==============================] - 0s 784us/step - loss: 337.1873 - val_loss: 612.1788\n",
      "Epoch 285/1000\n",
      "320/320 [==============================] - 0s 783us/step - loss: 342.5469 - val_loss: 667.2615\n",
      "Epoch 286/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 333.7826 - val_loss: 647.6529\n",
      "Epoch 287/1000\n",
      "320/320 [==============================] - 0s 801us/step - loss: 341.0157 - val_loss: 743.1490\n",
      "Epoch 288/1000\n",
      "320/320 [==============================] - 0s 800us/step - loss: 333.7637 - val_loss: 592.1100\n",
      "Epoch 289/1000\n",
      "320/320 [==============================] - 0s 738us/step - loss: 346.9576 - val_loss: 656.1846\n",
      "Epoch 290/1000\n",
      "320/320 [==============================] - 0s 792us/step - loss: 341.1361 - val_loss: 708.0442\n",
      "Epoch 291/1000\n",
      "320/320 [==============================] - 0s 771us/step - loss: 334.8825 - val_loss: 621.5423\n",
      "Epoch 292/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 337.4381 - val_loss: 691.4001\n",
      "Epoch 293/1000\n",
      "320/320 [==============================] - 0s 765us/step - loss: 334.4780 - val_loss: 801.2275\n",
      "Epoch 294/1000\n",
      "320/320 [==============================] - 0s 758us/step - loss: 338.2146 - val_loss: 805.4738\n",
      "Epoch 295/1000\n",
      "320/320 [==============================] - 0s 752us/step - loss: 2315.9524 - val_loss: 1417.3929\n",
      "Epoch 296/1000\n",
      "320/320 [==============================] - 0s 809us/step - loss: 769.0316 - val_loss: 1400.8101\n",
      "Epoch 297/1000\n",
      "320/320 [==============================] - 0s 773us/step - loss: 756.8670 - val_loss: 1384.2457\n",
      "Epoch 298/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 744.7597 - val_loss: 1367.7341\n",
      "Epoch 299/1000\n",
      "320/320 [==============================] - 0s 785us/step - loss: 732.7420 - val_loss: 1351.2850\n",
      "Epoch 300/1000\n",
      "320/320 [==============================] - 0s 811us/step - loss: 720.8444 - val_loss: 1334.9696\n",
      "Epoch 301/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 709.0762 - val_loss: 1318.7894\n",
      "Epoch 302/1000\n",
      "320/320 [==============================] - 0s 798us/step - loss: 697.4609 - val_loss: 1302.7236\n",
      "Epoch 303/1000\n",
      "320/320 [==============================] - 0s 803us/step - loss: 686.0041 - val_loss: 1286.8014\n",
      "Epoch 304/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 674.7203 - val_loss: 1271.0717\n",
      "Epoch 305/1000\n",
      "320/320 [==============================] - 0s 758us/step - loss: 663.6036 - val_loss: 1255.5477\n",
      "Epoch 306/1000\n",
      "320/320 [==============================] - 0s 759us/step - loss: 652.6796 - val_loss: 1240.1942\n",
      "Epoch 307/1000\n",
      "320/320 [==============================] - 0s 779us/step - loss: 641.9438 - val_loss: 1225.0323\n",
      "Epoch 308/1000\n",
      "320/320 [==============================] - 0s 805us/step - loss: 631.3861 - val_loss: 1210.0736\n",
      "Epoch 309/1000\n",
      "320/320 [==============================] - 0s 820us/step - loss: 621.0184 - val_loss: 1195.2546\n",
      "Epoch 310/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 610.8493 - val_loss: 1180.6869\n",
      "Epoch 311/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 600.8657 - val_loss: 1166.3029\n",
      "Epoch 312/1000\n",
      "320/320 [==============================] - 0s 757us/step - loss: 591.0756 - val_loss: 1152.0913\n",
      "Epoch 313/1000\n",
      "320/320 [==============================] - 0s 814us/step - loss: 581.4631 - val_loss: 1138.1104\n",
      "Epoch 314/1000\n",
      "320/320 [==============================] - 0s 803us/step - loss: 572.0529 - val_loss: 1124.3024\n",
      "Epoch 315/1000\n",
      "320/320 [==============================] - 0s 807us/step - loss: 562.8356 - val_loss: 1110.7170\n",
      "Epoch 316/1000\n",
      "320/320 [==============================] - 0s 807us/step - loss: 553.8033 - val_loss: 1097.3087\n",
      "Epoch 317/1000\n",
      "320/320 [==============================] - 0s 778us/step - loss: 544.9673 - val_loss: 1084.1128\n",
      "Epoch 318/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 536.3248 - val_loss: 1071.1445\n",
      "Epoch 319/1000\n",
      "320/320 [==============================] - 0s 942us/step - loss: 527.8650 - val_loss: 1058.3361\n",
      "Epoch 320/1000\n",
      "320/320 [==============================] - 0s 816us/step - loss: 519.5870 - val_loss: 1045.7538\n",
      "Epoch 321/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 511.5098 - val_loss: 1033.3231\n",
      "Epoch 322/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 503.6185 - val_loss: 1021.0959\n",
      "Epoch 323/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 495.9098 - val_loss: 1009.0975\n",
      "Epoch 324/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 488.3832 - val_loss: 997.2766\n",
      "Epoch 325/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 481.0502 - val_loss: 985.6351\n",
      "Epoch 326/1000\n",
      "320/320 [==============================] - 0s 805us/step - loss: 473.9164 - val_loss: 974.2772\n",
      "Epoch 327/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 466.9705 - val_loss: 963.0391\n",
      "Epoch 328/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 460.2042 - val_loss: 952.0376\n",
      "Epoch 329/1000\n",
      "320/320 [==============================] - 0s 794us/step - loss: 453.6192 - val_loss: 941.2007\n",
      "Epoch 330/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 447.2304 - val_loss: 930.5833\n",
      "Epoch 331/1000\n",
      "320/320 [==============================] - 0s 825us/step - loss: 441.0193 - val_loss: 920.2011\n",
      "Epoch 332/1000\n",
      "320/320 [==============================] - 0s 817us/step - loss: 434.9904 - val_loss: 909.9905\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 818us/step - loss: 429.1426 - val_loss: 900.0040\n",
      "Epoch 334/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 423.4613 - val_loss: 890.1267\n",
      "Epoch 335/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 417.9692 - val_loss: 880.4914\n",
      "Epoch 336/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 412.6581 - val_loss: 871.1049\n",
      "Epoch 337/1000\n",
      "320/320 [==============================] - 0s 799us/step - loss: 407.5475 - val_loss: 861.8760\n",
      "Epoch 338/1000\n",
      "320/320 [==============================] - 0s 867us/step - loss: 402.6212 - val_loss: 852.8680\n",
      "Epoch 339/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 397.8746 - val_loss: 844.0757\n",
      "Epoch 340/1000\n",
      "320/320 [==============================] - 0s 794us/step - loss: 393.2881 - val_loss: 835.4984\n",
      "Epoch 341/1000\n",
      "320/320 [==============================] - 0s 830us/step - loss: 388.8649 - val_loss: 827.0215\n",
      "Epoch 342/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 384.6203 - val_loss: 818.8168\n",
      "Epoch 343/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 380.5569 - val_loss: 810.8242\n",
      "Epoch 344/1000\n",
      "320/320 [==============================] - 0s 880us/step - loss: 376.6484 - val_loss: 802.9667\n",
      "Epoch 345/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 372.9142 - val_loss: 795.3369\n",
      "Epoch 346/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 369.3538 - val_loss: 787.9129\n",
      "Epoch 347/1000\n",
      "320/320 [==============================] - 0s 986us/step - loss: 365.9630 - val_loss: 780.6855\n",
      "Epoch 348/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 362.7423 - val_loss: 773.6825\n",
      "Epoch 349/1000\n",
      "320/320 [==============================] - 0s 964us/step - loss: 359.6826 - val_loss: 766.9023\n",
      "Epoch 350/1000\n",
      "320/320 [==============================] - 0s 992us/step - loss: 356.7815 - val_loss: 760.2788\n",
      "Epoch 351/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 354.0446 - val_loss: 753.9075\n",
      "Epoch 352/1000\n",
      "320/320 [==============================] - 0s 938us/step - loss: 351.4676 - val_loss: 747.6991\n",
      "Epoch 353/1000\n",
      "320/320 [==============================] - 0s 991us/step - loss: 349.0428 - val_loss: 741.7527\n",
      "Epoch 354/1000\n",
      "320/320 [==============================] - 0s 911us/step - loss: 346.7803 - val_loss: 736.0235\n",
      "Epoch 355/1000\n",
      "320/320 [==============================] - 0s 840us/step - loss: 344.6532 - val_loss: 730.4784\n",
      "Epoch 356/1000\n",
      "320/320 [==============================] - 0s 951us/step - loss: 342.6672 - val_loss: 725.1301\n",
      "Epoch 357/1000\n",
      "320/320 [==============================] - 0s 880us/step - loss: 340.8319 - val_loss: 719.9789\n",
      "Epoch 358/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 339.1291 - val_loss: 715.0721\n",
      "Epoch 359/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 337.5536 - val_loss: 710.3615\n",
      "Epoch 360/1000\n",
      "320/320 [==============================] - 0s 832us/step - loss: 336.1064 - val_loss: 705.8225\n",
      "Epoch 361/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 334.7910 - val_loss: 701.5505\n",
      "Epoch 362/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 333.5918 - val_loss: 697.4749\n",
      "Epoch 363/1000\n",
      "320/320 [==============================] - 0s 906us/step - loss: 332.5064 - val_loss: 693.6035\n",
      "Epoch 364/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 331.5351 - val_loss: 689.9266\n",
      "Epoch 365/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 330.6663 - val_loss: 686.4974\n",
      "Epoch 366/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 329.8936 - val_loss: 683.3168\n",
      "Epoch 367/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 329.2131 - val_loss: 680.3561\n",
      "Epoch 368/1000\n",
      "320/320 [==============================] - 0s 802us/step - loss: 328.6146 - val_loss: 677.5914\n",
      "Epoch 369/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 328.0837 - val_loss: 674.9276\n",
      "Epoch 370/1000\n",
      "320/320 [==============================] - 0s 792us/step - loss: 327.6191 - val_loss: 672.3552\n",
      "Epoch 371/1000\n",
      "320/320 [==============================] - 0s 982us/step - loss: 327.2130 - val_loss: 670.0965\n",
      "Epoch 372/1000\n",
      "320/320 [==============================] - 0s 995us/step - loss: 326.8664 - val_loss: 668.1315\n",
      "Epoch 373/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 326.5744 - val_loss: 666.1100\n",
      "Epoch 374/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 326.3195 - val_loss: 664.3990\n",
      "Epoch 375/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 326.1036 - val_loss: 662.7023\n",
      "Epoch 376/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.9173 - val_loss: 661.2145\n",
      "Epoch 377/1000\n",
      "320/320 [==============================] - 0s 968us/step - loss: 325.7636 - val_loss: 659.8500\n",
      "Epoch 378/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 325.6319 - val_loss: 658.5614\n",
      "Epoch 379/1000\n",
      "320/320 [==============================] - 0s 969us/step - loss: 325.5213 - val_loss: 657.4262\n",
      "Epoch 380/1000\n",
      "320/320 [==============================] - 0s 933us/step - loss: 325.4326 - val_loss: 656.3706\n",
      "Epoch 381/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.3563 - val_loss: 655.4301\n",
      "Epoch 382/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 325.2934 - val_loss: 654.5856\n",
      "Epoch 383/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.2421 - val_loss: 653.7664\n",
      "Epoch 384/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 325.1996 - val_loss: 653.0896\n",
      "Epoch 385/1000\n",
      "320/320 [==============================] - 0s 960us/step - loss: 325.1650 - val_loss: 652.4886\n",
      "Epoch 386/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.1388 - val_loss: 651.8929\n",
      "Epoch 387/1000\n",
      "320/320 [==============================] - 0s 897us/step - loss: 325.1139 - val_loss: 651.4310\n",
      "Epoch 388/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 325.0967 - val_loss: 650.9178\n",
      "Epoch 389/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0795 - val_loss: 650.5784\n",
      "Epoch 390/1000\n",
      "320/320 [==============================] - 0s 890us/step - loss: 325.0665 - val_loss: 650.1493\n",
      "Epoch 391/1000\n",
      "320/320 [==============================] - 0s 902us/step - loss: 325.0558 - val_loss: 649.8331\n",
      "Epoch 392/1000\n",
      "320/320 [==============================] - 0s 937us/step - loss: 325.0472 - val_loss: 649.5815\n",
      "Epoch 393/1000\n",
      "320/320 [==============================] - 0s 901us/step - loss: 325.0390 - val_loss: 649.2650\n",
      "Epoch 394/1000\n",
      "320/320 [==============================] - 0s 947us/step - loss: 325.0344 - val_loss: 648.9648\n",
      "Epoch 395/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 325.0287 - val_loss: 648.7714\n",
      "Epoch 396/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0260 - val_loss: 648.5693\n",
      "Epoch 397/1000\n",
      "320/320 [==============================] - 0s 827us/step - loss: 325.0217 - val_loss: 648.3726\n",
      "Epoch 398/1000\n",
      "320/320 [==============================] - 0s 945us/step - loss: 325.0193 - val_loss: 648.2145\n",
      "Epoch 399/1000\n",
      "320/320 [==============================] - 0s 978us/step - loss: 325.0176 - val_loss: 647.9843\n",
      "Epoch 400/1000\n",
      "320/320 [==============================] - 0s 941us/step - loss: 325.0152 - val_loss: 647.9611\n",
      "Epoch 401/1000\n",
      "320/320 [==============================] - 0s 839us/step - loss: 325.0143 - val_loss: 647.7676\n",
      "Epoch 402/1000\n",
      "320/320 [==============================] - 0s 899us/step - loss: 325.0128 - val_loss: 647.6938\n",
      "Epoch 403/1000\n",
      "320/320 [==============================] - 0s 841us/step - loss: 325.0116 - val_loss: 647.5877\n",
      "Epoch 404/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 325.0118 - val_loss: 647.4882\n",
      "Epoch 405/1000\n",
      "320/320 [==============================] - 0s 904us/step - loss: 325.0110 - val_loss: 647.4407\n",
      "Epoch 406/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 325.0096 - val_loss: 647.4166\n",
      "Epoch 407/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 871us/step - loss: 325.0092 - val_loss: 647.2628\n",
      "Epoch 408/1000\n",
      "320/320 [==============================] - 0s 901us/step - loss: 325.0084 - val_loss: 647.1929\n",
      "Epoch 409/1000\n",
      "320/320 [==============================] - 0s 811us/step - loss: 325.0081 - val_loss: 647.1346\n",
      "Epoch 410/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0080 - val_loss: 647.1158\n",
      "Epoch 411/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0076 - val_loss: 647.0607\n",
      "Epoch 412/1000\n",
      "320/320 [==============================] - 0s 882us/step - loss: 325.0078 - val_loss: 646.9792\n",
      "Epoch 413/1000\n",
      "320/320 [==============================] - 0s 836us/step - loss: 325.0091 - val_loss: 646.9435\n",
      "Epoch 414/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0084 - val_loss: 646.8931\n",
      "Epoch 415/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0069 - val_loss: 646.9078\n",
      "Epoch 416/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 325.0084 - val_loss: 646.8712\n",
      "Epoch 417/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0081 - val_loss: 646.8270\n",
      "Epoch 418/1000\n",
      "320/320 [==============================] - 0s 825us/step - loss: 325.0073 - val_loss: 646.8552\n",
      "Epoch 419/1000\n",
      "320/320 [==============================] - 0s 884us/step - loss: 325.0074 - val_loss: 646.8122\n",
      "Epoch 420/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0078 - val_loss: 646.7816\n",
      "Epoch 421/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0075 - val_loss: 646.8069\n",
      "Epoch 422/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0076 - val_loss: 646.8064\n",
      "Epoch 423/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0067 - val_loss: 646.7541\n",
      "Epoch 424/1000\n",
      "320/320 [==============================] - 0s 858us/step - loss: 325.0072 - val_loss: 646.7852\n",
      "Epoch 425/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0069 - val_loss: 646.7269\n",
      "Epoch 426/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 325.0069 - val_loss: 646.7467\n",
      "Epoch 427/1000\n",
      "320/320 [==============================] - 0s 846us/step - loss: 325.0074 - val_loss: 646.7607\n",
      "Epoch 428/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 325.0081 - val_loss: 646.6677\n",
      "Epoch 429/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 325.0066 - val_loss: 646.6697\n",
      "Epoch 430/1000\n",
      "320/320 [==============================] - 0s 945us/step - loss: 325.0076 - val_loss: 646.6805\n",
      "Epoch 431/1000\n",
      "320/320 [==============================] - 0s 978us/step - loss: 325.0068 - val_loss: 646.6500\n",
      "Epoch 432/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0066 - val_loss: 646.6443\n",
      "Epoch 433/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0069 - val_loss: 646.6244\n",
      "Epoch 434/1000\n",
      "320/320 [==============================] - 0s 965us/step - loss: 325.0069 - val_loss: 646.6509\n",
      "Epoch 435/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0074 - val_loss: 646.6238\n",
      "Epoch 436/1000\n",
      "320/320 [==============================] - 0s 968us/step - loss: 325.0077 - val_loss: 646.6475\n",
      "Epoch 437/1000\n",
      "320/320 [==============================] - 0s 963us/step - loss: 325.0071 - val_loss: 646.6715\n",
      "Epoch 438/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0064 - val_loss: 646.6382\n",
      "Epoch 439/1000\n",
      "320/320 [==============================] - 0s 933us/step - loss: 325.0066 - val_loss: 646.6390\n",
      "Epoch 440/1000\n",
      "320/320 [==============================] - 0s 934us/step - loss: 325.0074 - val_loss: 646.6700\n",
      "Epoch 441/1000\n",
      "320/320 [==============================] - 0s 957us/step - loss: 325.0069 - val_loss: 646.6378\n",
      "Epoch 442/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0073 - val_loss: 646.6358\n",
      "Epoch 443/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0071 - val_loss: 646.7020\n",
      "Epoch 444/1000\n",
      "320/320 [==============================] - 0s 937us/step - loss: 325.0065 - val_loss: 646.6555\n",
      "Epoch 445/1000\n",
      "320/320 [==============================] - 0s 924us/step - loss: 325.0064 - val_loss: 646.6097\n",
      "Epoch 446/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0096 - val_loss: 646.6586\n",
      "Epoch 447/1000\n",
      "320/320 [==============================] - 0s 942us/step - loss: 325.0061 - val_loss: 646.6257\n",
      "Epoch 448/1000\n",
      "320/320 [==============================] - 0s 929us/step - loss: 325.0073 - val_loss: 646.6517\n",
      "Epoch 449/1000\n",
      "320/320 [==============================] - 0s 915us/step - loss: 325.0085 - val_loss: 646.6656\n",
      "Epoch 450/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0079 - val_loss: 646.6627\n",
      "Epoch 451/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 325.0070 - val_loss: 646.6545\n",
      "Epoch 452/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0069 - val_loss: 646.6369\n",
      "Epoch 453/1000\n",
      "320/320 [==============================] - 0s 913us/step - loss: 325.0077 - val_loss: 646.5905\n",
      "Epoch 454/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0072 - val_loss: 646.6112\n",
      "Epoch 455/1000\n",
      "320/320 [==============================] - 0s 936us/step - loss: 325.0077 - val_loss: 646.6509\n",
      "Epoch 456/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0064 - val_loss: 646.5800\n",
      "Epoch 457/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0076 - val_loss: 646.6161\n",
      "Epoch 458/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0074 - val_loss: 646.6234\n",
      "Epoch 459/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0075 - val_loss: 646.6166\n",
      "Epoch 460/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0071 - val_loss: 646.6408\n",
      "Epoch 461/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0070 - val_loss: 646.6262\n",
      "Epoch 462/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0068 - val_loss: 646.6121\n",
      "Epoch 463/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0077 - val_loss: 646.5797\n",
      "Epoch 464/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0080 - val_loss: 646.6233\n",
      "Epoch 465/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.5628\n",
      "Epoch 466/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0069 - val_loss: 646.6268\n",
      "Epoch 467/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0074 - val_loss: 646.6412\n",
      "Epoch 468/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0082 - val_loss: 646.5942\n",
      "Epoch 469/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0090 - val_loss: 646.6135\n",
      "Epoch 470/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0078 - val_loss: 646.5944\n",
      "Epoch 471/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0077 - val_loss: 646.5784\n",
      "Epoch 472/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0079 - val_loss: 646.5975\n",
      "Epoch 473/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0072 - val_loss: 646.6254\n",
      "Epoch 474/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0071 - val_loss: 646.6216\n",
      "Epoch 475/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.5809\n",
      "Epoch 476/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0068 - val_loss: 646.6046\n",
      "Epoch 477/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.5983\n",
      "Epoch 478/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0077 - val_loss: 646.5854\n",
      "Epoch 479/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.5786\n",
      "Epoch 480/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0085 - val_loss: 646.6046\n",
      "Epoch 481/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0072 - val_loss: 646.5563\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0088 - val_loss: 646.6315\n",
      "Epoch 483/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0070 - val_loss: 646.5771\n",
      "Epoch 484/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0065 - val_loss: 646.6141\n",
      "Epoch 485/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0071 - val_loss: 646.5793\n",
      "Epoch 486/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0071 - val_loss: 646.5801\n",
      "Epoch 487/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6308\n",
      "Epoch 488/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0066 - val_loss: 646.6221\n",
      "Epoch 489/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0067 - val_loss: 646.6292\n",
      "Epoch 490/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.6467\n",
      "Epoch 491/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.6610\n",
      "Epoch 492/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0073 - val_loss: 646.6350\n",
      "Epoch 493/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0079 - val_loss: 646.6074\n",
      "Epoch 494/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0082 - val_loss: 646.6404\n",
      "Epoch 495/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0063 - val_loss: 646.5998\n",
      "Epoch 496/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0071 - val_loss: 646.6300\n",
      "Epoch 497/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.6339\n",
      "Epoch 498/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.6475\n",
      "Epoch 499/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0072 - val_loss: 646.5945\n",
      "Epoch 500/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0077 - val_loss: 646.5895\n",
      "Epoch 501/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0069 - val_loss: 646.5937\n",
      "Epoch 502/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.6146\n",
      "Epoch 503/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0063 - val_loss: 646.6417\n",
      "Epoch 504/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0076 - val_loss: 646.6387\n",
      "Epoch 505/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0066 - val_loss: 646.5908\n",
      "Epoch 506/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0070 - val_loss: 646.6772\n",
      "Epoch 507/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0077 - val_loss: 646.5610\n",
      "Epoch 508/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0077 - val_loss: 646.6104\n",
      "Epoch 509/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0072 - val_loss: 646.6193\n",
      "Epoch 510/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0078 - val_loss: 646.5903\n",
      "Epoch 511/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0075 - val_loss: 646.6013\n",
      "Epoch 512/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0066 - val_loss: 646.5389\n",
      "Epoch 513/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0082 - val_loss: 646.5774\n",
      "Epoch 514/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6107\n",
      "Epoch 515/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0080 - val_loss: 646.5940\n",
      "Epoch 516/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0073 - val_loss: 646.5878\n",
      "Epoch 517/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0081 - val_loss: 646.5731\n",
      "Epoch 518/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6346\n",
      "Epoch 519/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0069 - val_loss: 646.5782\n",
      "Epoch 520/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0089 - val_loss: 646.5546\n",
      "Epoch 521/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0076 - val_loss: 646.6122\n",
      "Epoch 522/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0062 - val_loss: 646.6100\n",
      "Epoch 523/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0093 - val_loss: 646.5944\n",
      "Epoch 524/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0061 - val_loss: 646.6265\n",
      "Epoch 525/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0074 - val_loss: 646.5895\n",
      "Epoch 526/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0076 - val_loss: 646.6059\n",
      "Epoch 527/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0088 - val_loss: 646.5752\n",
      "Epoch 528/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0061 - val_loss: 646.6132\n",
      "Epoch 529/1000\n",
      "320/320 [==============================] - 0s 964us/step - loss: 325.0074 - val_loss: 646.6249\n",
      "Epoch 530/1000\n",
      "320/320 [==============================] - 0s 897us/step - loss: 325.0076 - val_loss: 646.6254\n",
      "Epoch 531/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0079 - val_loss: 646.6456\n",
      "Epoch 532/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0077 - val_loss: 646.6610\n",
      "Epoch 533/1000\n",
      "320/320 [==============================] - 0s 938us/step - loss: 325.0074 - val_loss: 646.6281\n",
      "Epoch 534/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0073 - val_loss: 646.6446\n",
      "Epoch 535/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0074 - val_loss: 646.5811\n",
      "Epoch 536/1000\n",
      "320/320 [==============================] - 0s 980us/step - loss: 325.0076 - val_loss: 646.6249\n",
      "Epoch 537/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0069 - val_loss: 646.6418\n",
      "Epoch 538/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0066 - val_loss: 646.6047\n",
      "Epoch 539/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0069 - val_loss: 646.6182\n",
      "Epoch 540/1000\n",
      "320/320 [==============================] - 0s 946us/step - loss: 325.0067 - val_loss: 646.6190\n",
      "Epoch 541/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0074 - val_loss: 646.5776\n",
      "Epoch 542/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 325.0066 - val_loss: 646.6399\n",
      "Epoch 543/1000\n",
      "320/320 [==============================] - 0s 970us/step - loss: 325.0076 - val_loss: 646.6013\n",
      "Epoch 544/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0065 - val_loss: 646.6071\n",
      "Epoch 545/1000\n",
      "320/320 [==============================] - 0s 926us/step - loss: 325.0081 - val_loss: 646.6356\n",
      "Epoch 546/1000\n",
      "320/320 [==============================] - 0s 944us/step - loss: 325.0067 - val_loss: 646.5847\n",
      "Epoch 547/1000\n",
      "320/320 [==============================] - 0s 923us/step - loss: 325.0071 - val_loss: 646.5351\n",
      "Epoch 548/1000\n",
      "320/320 [==============================] - 0s 829us/step - loss: 325.0065 - val_loss: 646.6060\n",
      "Epoch 549/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0068 - val_loss: 646.6205\n",
      "Epoch 550/1000\n",
      "320/320 [==============================] - 0s 927us/step - loss: 325.0075 - val_loss: 646.5921\n",
      "Epoch 551/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0073 - val_loss: 646.5952\n",
      "Epoch 552/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0074 - val_loss: 646.6091\n",
      "Epoch 553/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 325.0070 - val_loss: 646.5932\n",
      "Epoch 554/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 325.0071 - val_loss: 646.6188\n",
      "Epoch 555/1000\n",
      "320/320 [==============================] - 0s 788us/step - loss: 325.0065 - val_loss: 646.6225\n",
      "Epoch 556/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0081 - val_loss: 646.5987\n",
      "Epoch 557/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 835us/step - loss: 325.0091 - val_loss: 646.5652\n",
      "Epoch 558/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 325.0094 - val_loss: 646.6236\n",
      "Epoch 559/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0074 - val_loss: 646.5471\n",
      "Epoch 560/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0072 - val_loss: 646.6533\n",
      "Epoch 561/1000\n",
      "320/320 [==============================] - 0s 788us/step - loss: 325.0078 - val_loss: 646.6245\n",
      "Epoch 562/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 325.0079 - val_loss: 646.5875\n",
      "Epoch 563/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 325.0065 - val_loss: 646.5970\n",
      "Epoch 564/1000\n",
      "320/320 [==============================] - 0s 944us/step - loss: 325.0074 - val_loss: 646.6144\n",
      "Epoch 565/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 325.0068 - val_loss: 646.6111\n",
      "Epoch 566/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0070 - val_loss: 646.6059\n",
      "Epoch 567/1000\n",
      "320/320 [==============================] - 0s 812us/step - loss: 325.0073 - val_loss: 646.6530\n",
      "Epoch 568/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0078 - val_loss: 646.6487\n",
      "Epoch 569/1000\n",
      "320/320 [==============================] - 0s 899us/step - loss: 325.0085 - val_loss: 646.6035\n",
      "Epoch 570/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0070 - val_loss: 646.6434\n",
      "Epoch 571/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0074 - val_loss: 646.6393\n",
      "Epoch 572/1000\n",
      "320/320 [==============================] - 0s 819us/step - loss: 325.0073 - val_loss: 646.6335\n",
      "Epoch 573/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0074 - val_loss: 646.6133\n",
      "Epoch 574/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0061 - val_loss: 646.6252\n",
      "Epoch 575/1000\n",
      "320/320 [==============================] - 0s 980us/step - loss: 325.0078 - val_loss: 646.6276\n",
      "Epoch 576/1000\n",
      "320/320 [==============================] - 0s 871us/step - loss: 325.0083 - val_loss: 646.6624\n",
      "Epoch 577/1000\n",
      "320/320 [==============================] - 0s 830us/step - loss: 325.0068 - val_loss: 646.6310\n",
      "Epoch 578/1000\n",
      "320/320 [==============================] - 0s 901us/step - loss: 325.0088 - val_loss: 646.6173\n",
      "Epoch 579/1000\n",
      "320/320 [==============================] - 0s 763us/step - loss: 325.0085 - val_loss: 646.6545\n",
      "Epoch 580/1000\n",
      "320/320 [==============================] - 0s 818us/step - loss: 325.0071 - val_loss: 646.6122\n",
      "Epoch 581/1000\n",
      "320/320 [==============================] - 0s 738us/step - loss: 325.0081 - val_loss: 646.6240\n",
      "Epoch 582/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 325.0062 - val_loss: 646.6337\n",
      "Epoch 583/1000\n",
      "320/320 [==============================] - 0s 832us/step - loss: 325.0070 - val_loss: 646.6506\n",
      "Epoch 584/1000\n",
      "320/320 [==============================] - 0s 777us/step - loss: 325.0074 - val_loss: 646.6918\n",
      "Epoch 585/1000\n",
      "320/320 [==============================] - 0s 764us/step - loss: 325.0071 - val_loss: 646.6667\n",
      "Epoch 586/1000\n",
      "320/320 [==============================] - 0s 805us/step - loss: 325.0063 - val_loss: 646.6761\n",
      "Epoch 587/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0063 - val_loss: 646.6629\n",
      "Epoch 588/1000\n",
      "320/320 [==============================] - 0s 821us/step - loss: 325.0079 - val_loss: 646.6476\n",
      "Epoch 589/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0072 - val_loss: 646.6806\n",
      "Epoch 590/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0080 - val_loss: 646.6978\n",
      "Epoch 591/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 325.0071 - val_loss: 646.6483\n",
      "Epoch 592/1000\n",
      "320/320 [==============================] - 0s 847us/step - loss: 325.0070 - val_loss: 646.5962\n",
      "Epoch 593/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0067 - val_loss: 646.6180\n",
      "Epoch 594/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 325.0082 - val_loss: 646.6335\n",
      "Epoch 595/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 325.0077 - val_loss: 646.6013\n",
      "Epoch 596/1000\n",
      "320/320 [==============================] - 0s 834us/step - loss: 325.0075 - val_loss: 646.6194\n",
      "Epoch 597/1000\n",
      "320/320 [==============================] - 0s 768us/step - loss: 325.0067 - val_loss: 646.5936\n",
      "Epoch 598/1000\n",
      "320/320 [==============================] - 0s 909us/step - loss: 325.0065 - val_loss: 646.6163\n",
      "Epoch 599/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0080 - val_loss: 646.6100\n",
      "Epoch 600/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0076 - val_loss: 646.6486\n",
      "Epoch 601/1000\n",
      "320/320 [==============================] - 0s 797us/step - loss: 325.0073 - val_loss: 646.6565\n",
      "Epoch 602/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0069 - val_loss: 646.6078\n",
      "Epoch 603/1000\n",
      "320/320 [==============================] - 0s 767us/step - loss: 325.0070 - val_loss: 646.6484\n",
      "Epoch 604/1000\n",
      "320/320 [==============================] - 0s 800us/step - loss: 325.0076 - val_loss: 646.6398\n",
      "Epoch 605/1000\n",
      "320/320 [==============================] - 0s 798us/step - loss: 325.0084 - val_loss: 646.5814\n",
      "Epoch 606/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 325.0067 - val_loss: 646.6393\n",
      "Epoch 607/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0061 - val_loss: 646.6068\n",
      "Epoch 608/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0075 - val_loss: 646.6348\n",
      "Epoch 609/1000\n",
      "320/320 [==============================] - 0s 803us/step - loss: 325.0078 - val_loss: 646.6208\n",
      "Epoch 610/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 325.0073 - val_loss: 646.6325\n",
      "Epoch 611/1000\n",
      "320/320 [==============================] - 0s 910us/step - loss: 325.0074 - val_loss: 646.6544\n",
      "Epoch 612/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 325.0073 - val_loss: 646.6559\n",
      "Epoch 613/1000\n",
      "320/320 [==============================] - 0s 915us/step - loss: 325.0080 - val_loss: 646.6775\n",
      "Epoch 614/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0072 - val_loss: 646.6871\n",
      "Epoch 615/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0087 - val_loss: 646.7166\n",
      "Epoch 616/1000\n",
      "320/320 [==============================] - 0s 919us/step - loss: 325.0074 - val_loss: 646.6653\n",
      "Epoch 617/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0080 - val_loss: 646.6344\n",
      "Epoch 618/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0072 - val_loss: 646.6887\n",
      "Epoch 619/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0090 - val_loss: 646.6340\n",
      "Epoch 620/1000\n",
      "320/320 [==============================] - 0s 836us/step - loss: 325.0066 - val_loss: 646.6287\n",
      "Epoch 621/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 325.0079 - val_loss: 646.6620\n",
      "Epoch 622/1000\n",
      "320/320 [==============================] - 0s 921us/step - loss: 325.0076 - val_loss: 646.6524\n",
      "Epoch 623/1000\n",
      "320/320 [==============================] - 0s 808us/step - loss: 325.0081 - val_loss: 646.6215\n",
      "Epoch 624/1000\n",
      "320/320 [==============================] - 0s 830us/step - loss: 325.0066 - val_loss: 646.6240\n",
      "Epoch 625/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0067 - val_loss: 646.6803\n",
      "Epoch 626/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0085 - val_loss: 646.6325\n",
      "Epoch 627/1000\n",
      "320/320 [==============================] - 0s 824us/step - loss: 325.0067 - val_loss: 646.6429\n",
      "Epoch 628/1000\n",
      "320/320 [==============================] - 0s 899us/step - loss: 325.0070 - val_loss: 646.5822\n",
      "Epoch 629/1000\n",
      "320/320 [==============================] - 0s 820us/step - loss: 325.0102 - val_loss: 646.6248\n",
      "Epoch 630/1000\n",
      "320/320 [==============================] - 0s 861us/step - loss: 325.0081 - val_loss: 646.6347\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 872us/step - loss: 325.0064 - val_loss: 646.6216\n",
      "Epoch 632/1000\n",
      "320/320 [==============================] - 0s 939us/step - loss: 325.0074 - val_loss: 646.6132\n",
      "Epoch 633/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0068 - val_loss: 646.6451\n",
      "Epoch 634/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 325.0072 - val_loss: 646.6358\n",
      "Epoch 635/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 325.0081 - val_loss: 646.6191\n",
      "Epoch 636/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0068 - val_loss: 646.6182\n",
      "Epoch 637/1000\n",
      "320/320 [==============================] - 0s 795us/step - loss: 325.0071 - val_loss: 646.6307\n",
      "Epoch 638/1000\n",
      "320/320 [==============================] - 0s 880us/step - loss: 325.0074 - val_loss: 646.6141\n",
      "Epoch 639/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0084 - val_loss: 646.6434\n",
      "Epoch 640/1000\n",
      "320/320 [==============================] - 0s 882us/step - loss: 325.0075 - val_loss: 646.6101\n",
      "Epoch 641/1000\n",
      "320/320 [==============================] - 0s 834us/step - loss: 325.0069 - val_loss: 646.6581\n",
      "Epoch 642/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 325.0077 - val_loss: 646.6428\n",
      "Epoch 643/1000\n",
      "320/320 [==============================] - 0s 818us/step - loss: 325.0077 - val_loss: 646.6158\n",
      "Epoch 644/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 325.0077 - val_loss: 646.6008\n",
      "Epoch 645/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0078 - val_loss: 646.6100\n",
      "Epoch 646/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 325.0087 - val_loss: 646.6323\n",
      "Epoch 647/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 325.0077 - val_loss: 646.6169\n",
      "Epoch 648/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0081 - val_loss: 646.6752\n",
      "Epoch 649/1000\n",
      "320/320 [==============================] - 0s 810us/step - loss: 325.0078 - val_loss: 646.6692\n",
      "Epoch 650/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0065 - val_loss: 646.6400\n",
      "Epoch 651/1000\n",
      "320/320 [==============================] - 0s 796us/step - loss: 325.0076 - val_loss: 646.5795\n",
      "Epoch 652/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0069 - val_loss: 646.6193\n",
      "Epoch 653/1000\n",
      "320/320 [==============================] - 0s 788us/step - loss: 325.0071 - val_loss: 646.6358\n",
      "Epoch 654/1000\n",
      "320/320 [==============================] - 0s 896us/step - loss: 325.0070 - val_loss: 646.6038\n",
      "Epoch 655/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0065 - val_loss: 646.6083\n",
      "Epoch 656/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 325.0077 - val_loss: 646.6238\n",
      "Epoch 657/1000\n",
      "320/320 [==============================] - 0s 783us/step - loss: 325.0074 - val_loss: 646.6350\n",
      "Epoch 658/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 325.0079 - val_loss: 646.6264\n",
      "Epoch 659/1000\n",
      "320/320 [==============================] - 0s 802us/step - loss: 325.0085 - val_loss: 646.6120\n",
      "Epoch 660/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 325.0074 - val_loss: 646.5974\n",
      "Epoch 661/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 325.0074 - val_loss: 646.5821\n",
      "Epoch 662/1000\n",
      "320/320 [==============================] - 0s 849us/step - loss: 325.0074 - val_loss: 646.6595\n",
      "Epoch 663/1000\n",
      "320/320 [==============================] - 0s 815us/step - loss: 325.0070 - val_loss: 646.6456\n",
      "Epoch 664/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 325.0064 - val_loss: 646.6476\n",
      "Epoch 665/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0072 - val_loss: 646.6660\n",
      "Epoch 666/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0085 - val_loss: 646.7054\n",
      "Epoch 667/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 325.0067 - val_loss: 646.5937\n",
      "Epoch 668/1000\n",
      "320/320 [==============================] - 0s 911us/step - loss: 325.0075 - val_loss: 646.6064\n",
      "Epoch 669/1000\n",
      "320/320 [==============================] - 0s 849us/step - loss: 325.0073 - val_loss: 646.6067\n",
      "Epoch 670/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 325.0070 - val_loss: 646.6103\n",
      "Epoch 671/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0091 - val_loss: 646.6006\n",
      "Epoch 672/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0077 - val_loss: 646.6135\n",
      "Epoch 673/1000\n",
      "320/320 [==============================] - 0s 983us/step - loss: 325.0081 - val_loss: 646.6422\n",
      "Epoch 674/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0074 - val_loss: 646.5806\n",
      "Epoch 675/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0092 - val_loss: 646.6500\n",
      "Epoch 676/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 325.0074 - val_loss: 646.5966\n",
      "Epoch 677/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 325.0077 - val_loss: 646.6032\n",
      "Epoch 678/1000\n",
      "320/320 [==============================] - 0s 920us/step - loss: 325.0079 - val_loss: 646.6358\n",
      "Epoch 679/1000\n",
      "320/320 [==============================] - 0s 973us/step - loss: 325.0095 - val_loss: 646.5728\n",
      "Epoch 680/1000\n",
      "320/320 [==============================] - 0s 864us/step - loss: 325.0076 - val_loss: 646.6078\n",
      "Epoch 681/1000\n",
      "320/320 [==============================] - 0s 922us/step - loss: 325.0072 - val_loss: 646.6054\n",
      "Epoch 682/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 325.0074 - val_loss: 646.6105\n",
      "Epoch 683/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 325.0085 - val_loss: 646.6270\n",
      "Epoch 684/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 325.0074 - val_loss: 646.5546\n",
      "Epoch 685/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0079 - val_loss: 646.5883\n",
      "Epoch 686/1000\n",
      "320/320 [==============================] - 0s 839us/step - loss: 325.0066 - val_loss: 646.5905\n",
      "Epoch 687/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 325.0085 - val_loss: 646.6141\n",
      "Epoch 688/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0077 - val_loss: 646.6053\n",
      "Epoch 689/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 325.0069 - val_loss: 646.5800\n",
      "Epoch 690/1000\n",
      "320/320 [==============================] - 0s 936us/step - loss: 325.0076 - val_loss: 646.6557\n",
      "Epoch 691/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0067 - val_loss: 646.6744\n",
      "Epoch 692/1000\n",
      "320/320 [==============================] - 0s 846us/step - loss: 325.0080 - val_loss: 646.5822\n",
      "Epoch 693/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 325.0071 - val_loss: 646.6266\n",
      "Epoch 694/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0080 - val_loss: 646.7017\n",
      "Epoch 695/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0072 - val_loss: 646.6161\n",
      "Epoch 696/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0074 - val_loss: 646.6506\n",
      "Epoch 697/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0073 - val_loss: 646.6970\n",
      "Epoch 698/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0068 - val_loss: 646.6311\n",
      "Epoch 699/1000\n",
      "320/320 [==============================] - 0s 955us/step - loss: 325.0063 - val_loss: 646.6196\n",
      "Epoch 700/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 325.0063 - val_loss: 646.6183\n",
      "Epoch 701/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0075 - val_loss: 646.6268\n",
      "Epoch 702/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 325.0073 - val_loss: 646.6107\n",
      "Epoch 703/1000\n",
      "320/320 [==============================] - 0s 916us/step - loss: 325.0073 - val_loss: 646.6551\n",
      "Epoch 704/1000\n",
      "320/320 [==============================] - 0s 896us/step - loss: 325.0075 - val_loss: 646.6215\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 807us/step - loss: 325.0074 - val_loss: 646.6060\n",
      "Epoch 706/1000\n",
      "320/320 [==============================] - 0s 874us/step - loss: 325.0078 - val_loss: 646.6684\n",
      "Epoch 707/1000\n",
      "320/320 [==============================] - 0s 839us/step - loss: 325.0078 - val_loss: 646.6555\n",
      "Epoch 708/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0075 - val_loss: 646.6505\n",
      "Epoch 709/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0080 - val_loss: 646.6644\n",
      "Epoch 710/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0065 - val_loss: 646.6009\n",
      "Epoch 711/1000\n",
      "320/320 [==============================] - 0s 855us/step - loss: 325.0074 - val_loss: 646.6899\n",
      "Epoch 712/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 325.0069 - val_loss: 646.6100\n",
      "Epoch 713/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0062 - val_loss: 646.6641\n",
      "Epoch 714/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 325.0070 - val_loss: 646.6339\n",
      "Epoch 715/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0078 - val_loss: 646.6259\n",
      "Epoch 716/1000\n",
      "320/320 [==============================] - 0s 902us/step - loss: 325.0065 - val_loss: 646.5668\n",
      "Epoch 717/1000\n",
      "320/320 [==============================] - 0s 910us/step - loss: 325.0066 - val_loss: 646.6212\n",
      "Epoch 718/1000\n",
      "320/320 [==============================] - 0s 961us/step - loss: 325.0080 - val_loss: 646.6433\n",
      "Epoch 719/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 325.0067 - val_loss: 646.6103\n",
      "Epoch 720/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 325.0076 - val_loss: 646.6191\n",
      "Epoch 721/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 325.0071 - val_loss: 646.6286\n",
      "Epoch 722/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 325.0073 - val_loss: 646.6134\n",
      "Epoch 723/1000\n",
      "320/320 [==============================] - 0s 912us/step - loss: 325.0087 - val_loss: 646.6479\n",
      "Epoch 724/1000\n",
      "320/320 [==============================] - 0s 911us/step - loss: 325.0078 - val_loss: 646.6650\n",
      "Epoch 725/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 325.0075 - val_loss: 646.5840\n",
      "Epoch 726/1000\n",
      "320/320 [==============================] - 0s 953us/step - loss: 325.0071 - val_loss: 646.6509\n",
      "Epoch 727/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0067 - val_loss: 646.6732\n",
      "Epoch 728/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0073 - val_loss: 646.6690\n",
      "Epoch 729/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0069 - val_loss: 646.6100\n",
      "Epoch 730/1000\n",
      "320/320 [==============================] - 0s 909us/step - loss: 325.0071 - val_loss: 646.6631\n",
      "Epoch 731/1000\n",
      "320/320 [==============================] - 0s 978us/step - loss: 325.0092 - val_loss: 646.6387\n",
      "Epoch 732/1000\n",
      "320/320 [==============================] - 0s 902us/step - loss: 325.0076 - val_loss: 646.6215\n",
      "Epoch 733/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0074 - val_loss: 646.6005\n",
      "Epoch 734/1000\n",
      "320/320 [==============================] - 0s 933us/step - loss: 325.0078 - val_loss: 646.6027\n",
      "Epoch 735/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 325.0070 - val_loss: 646.6456\n",
      "Epoch 736/1000\n",
      "320/320 [==============================] - 0s 946us/step - loss: 325.0065 - val_loss: 646.6223\n",
      "Epoch 737/1000\n",
      "320/320 [==============================] - 0s 920us/step - loss: 325.0076 - val_loss: 646.5921\n",
      "Epoch 738/1000\n",
      "320/320 [==============================] - 0s 987us/step - loss: 325.0071 - val_loss: 646.6146\n",
      "Epoch 739/1000\n",
      "320/320 [==============================] - 0s 941us/step - loss: 325.0071 - val_loss: 646.6508\n",
      "Epoch 740/1000\n",
      "320/320 [==============================] - 0s 959us/step - loss: 325.0065 - val_loss: 646.6202\n",
      "Epoch 741/1000\n",
      "320/320 [==============================] - 0s 916us/step - loss: 325.0070 - val_loss: 646.6619\n",
      "Epoch 742/1000\n",
      "320/320 [==============================] - 0s 969us/step - loss: 325.0080 - val_loss: 646.6298\n",
      "Epoch 743/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 325.0077 - val_loss: 646.6850\n",
      "Epoch 744/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 325.0081 - val_loss: 646.6010\n",
      "Epoch 745/1000\n",
      "320/320 [==============================] - 0s 882us/step - loss: 325.0067 - val_loss: 646.6619\n",
      "Epoch 746/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0064 - val_loss: 646.6287\n",
      "Epoch 747/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0083 - val_loss: 646.5788\n",
      "Epoch 748/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0078 - val_loss: 646.6692\n",
      "Epoch 749/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0067 - val_loss: 646.6362\n",
      "Epoch 750/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0065 - val_loss: 646.6612\n",
      "Epoch 751/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0081 - val_loss: 646.6390\n",
      "Epoch 752/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0072 - val_loss: 646.5992\n",
      "Epoch 753/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0075 - val_loss: 646.6476\n",
      "Epoch 754/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 325.0071 - val_loss: 646.6743\n",
      "Epoch 755/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 325.0073 - val_loss: 646.6622\n",
      "Epoch 756/1000\n",
      "320/320 [==============================] - 0s 928us/step - loss: 325.0074 - val_loss: 646.5878\n",
      "Epoch 757/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0073 - val_loss: 646.6262\n",
      "Epoch 758/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 325.0069 - val_loss: 646.6194\n",
      "Epoch 759/1000\n",
      "320/320 [==============================] - 0s 944us/step - loss: 325.0069 - val_loss: 646.5692\n",
      "Epoch 760/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0070 - val_loss: 646.6190\n",
      "Epoch 761/1000\n",
      "320/320 [==============================] - 0s 858us/step - loss: 325.0082 - val_loss: 646.5570\n",
      "Epoch 762/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 325.0076 - val_loss: 646.6458\n",
      "Epoch 763/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0069 - val_loss: 646.6628\n",
      "Epoch 764/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0077 - val_loss: 646.6245\n",
      "Epoch 765/1000\n",
      "320/320 [==============================] - 0s 906us/step - loss: 325.0075 - val_loss: 646.6136\n",
      "Epoch 766/1000\n",
      "320/320 [==============================] - 0s 946us/step - loss: 325.0081 - val_loss: 646.6050\n",
      "Epoch 767/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0074 - val_loss: 646.6250\n",
      "Epoch 768/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0072 - val_loss: 646.5905\n",
      "Epoch 769/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0076 - val_loss: 646.6066\n",
      "Epoch 770/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0065 - val_loss: 646.6008\n",
      "Epoch 771/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0077 - val_loss: 646.5836\n",
      "Epoch 772/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0073 - val_loss: 646.6244\n",
      "Epoch 773/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0065 - val_loss: 646.5821\n",
      "Epoch 774/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0067 - val_loss: 646.6288\n",
      "Epoch 775/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0071 - val_loss: 646.6503\n",
      "Epoch 776/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0066 - val_loss: 646.6326\n",
      "Epoch 777/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0074 - val_loss: 646.6219\n",
      "Epoch 778/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0076 - val_loss: 646.6656\n",
      "Epoch 779/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0070 - val_loss: 646.5965\n",
      "Epoch 780/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0070 - val_loss: 646.5981\n",
      "Epoch 781/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0080 - val_loss: 646.6550\n",
      "Epoch 782/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0069 - val_loss: 646.6152\n",
      "Epoch 783/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0074 - val_loss: 646.6340\n",
      "Epoch 784/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0071 - val_loss: 646.6091\n",
      "Epoch 785/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0068 - val_loss: 646.6198\n",
      "Epoch 786/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.6722\n",
      "Epoch 787/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0074 - val_loss: 646.5811\n",
      "Epoch 788/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0074 - val_loss: 646.6450\n",
      "Epoch 789/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0082 - val_loss: 646.6057\n",
      "Epoch 790/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0076 - val_loss: 646.6069\n",
      "Epoch 791/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0083 - val_loss: 646.6011\n",
      "Epoch 792/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0063 - val_loss: 646.6383\n",
      "Epoch 793/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.5891\n",
      "Epoch 794/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0084 - val_loss: 646.5965\n",
      "Epoch 795/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0074 - val_loss: 646.6084\n",
      "Epoch 796/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0094 - val_loss: 646.6042\n",
      "Epoch 797/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0076 - val_loss: 646.5846\n",
      "Epoch 798/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0078 - val_loss: 646.6171\n",
      "Epoch 799/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6136\n",
      "Epoch 800/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0080 - val_loss: 646.6181\n",
      "Epoch 801/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0080 - val_loss: 646.6469\n",
      "Epoch 802/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0067 - val_loss: 646.6613\n",
      "Epoch 803/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0084 - val_loss: 646.5991\n",
      "Epoch 804/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0073 - val_loss: 646.6198\n",
      "Epoch 805/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0073 - val_loss: 646.6755\n",
      "Epoch 806/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0081 - val_loss: 646.6390\n",
      "Epoch 807/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0081 - val_loss: 646.6417\n",
      "Epoch 808/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0068 - val_loss: 646.6488\n",
      "Epoch 809/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0076 - val_loss: 646.6013\n",
      "Epoch 810/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0061 - val_loss: 646.6504\n",
      "Epoch 811/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0072 - val_loss: 646.6536\n",
      "Epoch 812/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0073 - val_loss: 646.6163\n",
      "Epoch 813/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0092 - val_loss: 646.5946\n",
      "Epoch 814/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0098 - val_loss: 646.6585\n",
      "Epoch 815/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0070 - val_loss: 646.6635\n",
      "Epoch 816/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0085 - val_loss: 646.6772\n",
      "Epoch 817/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.5993\n",
      "Epoch 818/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0084 - val_loss: 646.5877\n",
      "Epoch 819/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6358\n",
      "Epoch 820/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0078 - val_loss: 646.6810\n",
      "Epoch 821/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0079 - val_loss: 646.6619\n",
      "Epoch 822/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6024\n",
      "Epoch 823/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.5757\n",
      "Epoch 824/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0096 - val_loss: 646.6128\n",
      "Epoch 825/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0077 - val_loss: 646.6261\n",
      "Epoch 826/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0065 - val_loss: 646.6464\n",
      "Epoch 827/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0078 - val_loss: 646.6262\n",
      "Epoch 828/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0082 - val_loss: 646.6152\n",
      "Epoch 829/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0076 - val_loss: 646.6318\n",
      "Epoch 830/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0080 - val_loss: 646.5930\n",
      "Epoch 831/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0069 - val_loss: 646.5963\n",
      "Epoch 832/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0078 - val_loss: 646.6166\n",
      "Epoch 833/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0063 - val_loss: 646.6218\n",
      "Epoch 834/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0069 - val_loss: 646.6415\n",
      "Epoch 835/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0072 - val_loss: 646.6550\n",
      "Epoch 836/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0067 - val_loss: 646.6318\n",
      "Epoch 837/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.6122\n",
      "Epoch 838/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0074 - val_loss: 646.6380\n",
      "Epoch 839/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0089 - val_loss: 646.6405\n",
      "Epoch 840/1000\n",
      "320/320 [==============================] - 0s 928us/step - loss: 325.0080 - val_loss: 646.5797\n",
      "Epoch 841/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 325.0079 - val_loss: 646.6284\n",
      "Epoch 842/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0086 - val_loss: 646.6288\n",
      "Epoch 843/1000\n",
      "320/320 [==============================] - 0s 774us/step - loss: 325.0069 - val_loss: 646.6387\n",
      "Epoch 844/1000\n",
      "320/320 [==============================] - 0s 797us/step - loss: 325.0080 - val_loss: 646.6061\n",
      "Epoch 845/1000\n",
      "320/320 [==============================] - 0s 778us/step - loss: 325.0071 - val_loss: 646.6086\n",
      "Epoch 846/1000\n",
      "320/320 [==============================] - 0s 862us/step - loss: 325.0077 - val_loss: 646.6369\n",
      "Epoch 847/1000\n",
      "320/320 [==============================] - 0s 815us/step - loss: 325.0077 - val_loss: 646.5718\n",
      "Epoch 848/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0074 - val_loss: 646.5971\n",
      "Epoch 849/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 325.0066 - val_loss: 646.6744\n",
      "Epoch 850/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 325.0071 - val_loss: 646.6483\n",
      "Epoch 851/1000\n",
      "320/320 [==============================] - 0s 784us/step - loss: 325.0076 - val_loss: 646.5754\n",
      "Epoch 852/1000\n",
      "320/320 [==============================] - 0s 811us/step - loss: 325.0077 - val_loss: 646.6198\n",
      "Epoch 853/1000\n",
      "320/320 [==============================] - 0s 871us/step - loss: 325.0061 - val_loss: 646.6270\n",
      "Epoch 854/1000\n",
      "320/320 [==============================] - 0s 955us/step - loss: 325.0095 - val_loss: 646.6027\n",
      "Epoch 855/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 899us/step - loss: 325.0074 - val_loss: 646.5934\n",
      "Epoch 856/1000\n",
      "320/320 [==============================] - 0s 924us/step - loss: 325.0067 - val_loss: 646.5937\n",
      "Epoch 857/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 325.0063 - val_loss: 646.5942\n",
      "Epoch 858/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 325.0075 - val_loss: 646.6185\n",
      "Epoch 859/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0095 - val_loss: 646.5774\n",
      "Epoch 860/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0092 - val_loss: 646.6143\n",
      "Epoch 861/1000\n",
      "320/320 [==============================] - 0s 913us/step - loss: 325.0069 - val_loss: 646.5890\n",
      "Epoch 862/1000\n",
      "320/320 [==============================] - 0s 958us/step - loss: 325.0073 - val_loss: 646.6137\n",
      "Epoch 863/1000\n",
      "320/320 [==============================] - 0s 961us/step - loss: 325.0071 - val_loss: 646.5974\n",
      "Epoch 864/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0074 - val_loss: 646.6497\n",
      "Epoch 865/1000\n",
      "320/320 [==============================] - 0s 819us/step - loss: 325.0072 - val_loss: 646.5792\n",
      "Epoch 866/1000\n",
      "320/320 [==============================] - 0s 821us/step - loss: 325.0062 - val_loss: 646.6308\n",
      "Epoch 867/1000\n",
      "320/320 [==============================] - 0s 825us/step - loss: 325.0072 - val_loss: 646.6116\n",
      "Epoch 868/1000\n",
      "320/320 [==============================] - 0s 918us/step - loss: 325.0075 - val_loss: 646.6566\n",
      "Epoch 869/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 325.0080 - val_loss: 646.5905\n",
      "Epoch 870/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 325.0078 - val_loss: 646.6354\n",
      "Epoch 871/1000\n",
      "320/320 [==============================] - 0s 884us/step - loss: 325.0078 - val_loss: 646.6418\n",
      "Epoch 872/1000\n",
      "320/320 [==============================] - 0s 971us/step - loss: 325.0075 - val_loss: 646.6395\n",
      "Epoch 873/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0069 - val_loss: 646.6489\n",
      "Epoch 874/1000\n",
      "320/320 [==============================] - 0s 929us/step - loss: 325.0074 - val_loss: 646.6382\n",
      "Epoch 875/1000\n",
      "320/320 [==============================] - 0s 913us/step - loss: 325.0074 - val_loss: 646.6530\n",
      "Epoch 876/1000\n",
      "320/320 [==============================] - 0s 799us/step - loss: 325.0078 - val_loss: 646.6404\n",
      "Epoch 877/1000\n",
      "320/320 [==============================] - 0s 896us/step - loss: 325.0063 - val_loss: 646.6409\n",
      "Epoch 878/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 325.0068 - val_loss: 646.6342\n",
      "Epoch 879/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0078 - val_loss: 646.5966\n",
      "Epoch 880/1000\n",
      "320/320 [==============================] - 0s 826us/step - loss: 325.0076 - val_loss: 646.6080\n",
      "Epoch 881/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 325.0079 - val_loss: 646.5871\n",
      "Epoch 882/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0078 - val_loss: 646.6230\n",
      "Epoch 883/1000\n",
      "320/320 [==============================] - 0s 784us/step - loss: 325.0071 - val_loss: 646.6639\n",
      "Epoch 884/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0071 - val_loss: 646.6434\n",
      "Epoch 885/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0075 - val_loss: 646.6547\n",
      "Epoch 886/1000\n",
      "320/320 [==============================] - 0s 862us/step - loss: 325.0075 - val_loss: 646.5809\n",
      "Epoch 887/1000\n",
      "320/320 [==============================] - 0s 865us/step - loss: 325.0063 - val_loss: 646.6017\n",
      "Epoch 888/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0067 - val_loss: 646.6245\n",
      "Epoch 889/1000\n",
      "320/320 [==============================] - 0s 818us/step - loss: 325.0085 - val_loss: 646.6559\n",
      "Epoch 890/1000\n",
      "320/320 [==============================] - 0s 800us/step - loss: 325.0070 - val_loss: 646.6260\n",
      "Epoch 891/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0074 - val_loss: 646.5742\n",
      "Epoch 892/1000\n",
      "320/320 [==============================] - 0s 770us/step - loss: 325.0060 - val_loss: 646.6093\n",
      "Epoch 893/1000\n",
      "320/320 [==============================] - 0s 807us/step - loss: 325.0077 - val_loss: 646.6340\n",
      "Epoch 894/1000\n",
      "320/320 [==============================] - 0s 982us/step - loss: 325.0068 - val_loss: 646.5652\n",
      "Epoch 895/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 325.0074 - val_loss: 646.5695\n",
      "Epoch 896/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0072 - val_loss: 646.6181\n",
      "Epoch 897/1000\n",
      "320/320 [==============================] - 0s 864us/step - loss: 325.0081 - val_loss: 646.6489\n",
      "Epoch 898/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0069 - val_loss: 646.6226\n",
      "Epoch 899/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 325.0079 - val_loss: 646.6314\n",
      "Epoch 900/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0063 - val_loss: 646.6080\n",
      "Epoch 901/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0074 - val_loss: 646.6299\n",
      "Epoch 902/1000\n",
      "320/320 [==============================] - 0s 784us/step - loss: 325.0060 - val_loss: 646.6193\n",
      "Epoch 903/1000\n",
      "320/320 [==============================] - 0s 821us/step - loss: 325.0067 - val_loss: 646.5935\n",
      "Epoch 904/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0076 - val_loss: 646.6545\n",
      "Epoch 905/1000\n",
      "320/320 [==============================] - 0s 815us/step - loss: 325.0068 - val_loss: 646.6344\n",
      "Epoch 906/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0069 - val_loss: 646.6359\n",
      "Epoch 907/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 325.0081 - val_loss: 646.6146\n",
      "Epoch 908/1000\n",
      "320/320 [==============================] - 0s 759us/step - loss: 325.0078 - val_loss: 646.6378\n",
      "Epoch 909/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 325.0073 - val_loss: 646.5970\n",
      "Epoch 910/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 325.0074 - val_loss: 646.5986\n",
      "Epoch 911/1000\n",
      "320/320 [==============================] - 0s 921us/step - loss: 325.0074 - val_loss: 646.6083\n",
      "Epoch 912/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0062 - val_loss: 646.6723\n",
      "Epoch 913/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 325.0085 - val_loss: 646.5944\n",
      "Epoch 914/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0081 - val_loss: 646.6573\n",
      "Epoch 915/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0065 - val_loss: 646.6198\n",
      "Epoch 916/1000\n",
      "320/320 [==============================] - 0s 959us/step - loss: 325.0070 - val_loss: 646.6439\n",
      "Epoch 917/1000\n",
      "320/320 [==============================] - 0s 954us/step - loss: 325.0063 - val_loss: 646.6448\n",
      "Epoch 918/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0074 - val_loss: 646.6473\n",
      "Epoch 919/1000\n",
      "320/320 [==============================] - 0s 808us/step - loss: 325.0070 - val_loss: 646.6295\n",
      "Epoch 920/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0075 - val_loss: 646.6218\n",
      "Epoch 921/1000\n",
      "320/320 [==============================] - 0s 785us/step - loss: 325.0069 - val_loss: 646.6753\n",
      "Epoch 922/1000\n",
      "320/320 [==============================] - 0s 808us/step - loss: 325.0078 - val_loss: 646.6212\n",
      "Epoch 923/1000\n",
      "320/320 [==============================] - 0s 849us/step - loss: 325.0084 - val_loss: 646.6919\n",
      "Epoch 924/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 325.0067 - val_loss: 646.6242\n",
      "Epoch 925/1000\n",
      "320/320 [==============================] - 0s 840us/step - loss: 325.0072 - val_loss: 646.6075\n",
      "Epoch 926/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0071 - val_loss: 646.5861\n",
      "Epoch 927/1000\n",
      "320/320 [==============================] - 0s 770us/step - loss: 325.0074 - val_loss: 646.6046\n",
      "Epoch 928/1000\n",
      "320/320 [==============================] - 0s 841us/step - loss: 325.0074 - val_loss: 646.6166\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 864us/step - loss: 325.0073 - val_loss: 646.6024\n",
      "Epoch 930/1000\n",
      "320/320 [==============================] - 0s 778us/step - loss: 325.0065 - val_loss: 646.6393\n",
      "Epoch 931/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0070 - val_loss: 646.6526\n",
      "Epoch 932/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0078 - val_loss: 646.6290\n",
      "Epoch 933/1000\n",
      "320/320 [==============================] - 0s 826us/step - loss: 325.0079 - val_loss: 646.5964\n",
      "Epoch 934/1000\n",
      "320/320 [==============================] - 0s 808us/step - loss: 325.0065 - val_loss: 646.6116\n",
      "Epoch 935/1000\n",
      "320/320 [==============================] - 0s 854us/step - loss: 325.0068 - val_loss: 646.5693\n",
      "Epoch 936/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0073 - val_loss: 646.6495\n",
      "Epoch 937/1000\n",
      "320/320 [==============================] - 0s 834us/step - loss: 325.0080 - val_loss: 646.6423\n",
      "Epoch 938/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0085 - val_loss: 646.6133\n",
      "Epoch 939/1000\n",
      "320/320 [==============================] - 0s 806us/step - loss: 325.0071 - val_loss: 646.6946\n",
      "Epoch 940/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0068 - val_loss: 646.6257\n",
      "Epoch 941/1000\n",
      "320/320 [==============================] - 0s 832us/step - loss: 325.0066 - val_loss: 646.5911\n",
      "Epoch 942/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0071 - val_loss: 646.5993\n",
      "Epoch 943/1000\n",
      "320/320 [==============================] - 0s 790us/step - loss: 325.0075 - val_loss: 646.6551\n",
      "Epoch 944/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0080 - val_loss: 646.6014\n",
      "Epoch 945/1000\n",
      "320/320 [==============================] - 0s 821us/step - loss: 325.0076 - val_loss: 646.5643\n",
      "Epoch 946/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 325.0074 - val_loss: 646.5978\n",
      "Epoch 947/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0069 - val_loss: 646.5836\n",
      "Epoch 948/1000\n",
      "320/320 [==============================] - 0s 815us/step - loss: 325.0066 - val_loss: 646.5864\n",
      "Epoch 949/1000\n",
      "320/320 [==============================] - 0s 861us/step - loss: 325.0074 - val_loss: 646.5844\n",
      "Epoch 950/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 325.0085 - val_loss: 646.5871\n",
      "Epoch 951/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 325.0068 - val_loss: 646.6506\n",
      "Epoch 952/1000\n",
      "320/320 [==============================] - 0s 814us/step - loss: 325.0073 - val_loss: 646.6442\n",
      "Epoch 953/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0077 - val_loss: 646.6180\n",
      "Epoch 954/1000\n",
      "320/320 [==============================] - 0s 867us/step - loss: 325.0075 - val_loss: 646.5953\n",
      "Epoch 955/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 325.0089 - val_loss: 646.5965\n",
      "Epoch 956/1000\n",
      "320/320 [==============================] - 0s 855us/step - loss: 325.0070 - val_loss: 646.6242\n",
      "Epoch 957/1000\n",
      "320/320 [==============================] - 0s 854us/step - loss: 325.0077 - val_loss: 646.6146\n",
      "Epoch 958/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0070 - val_loss: 646.6523\n",
      "Epoch 959/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0083 - val_loss: 646.5720\n",
      "Epoch 960/1000\n",
      "320/320 [==============================] - 0s 854us/step - loss: 325.0081 - val_loss: 646.5898\n",
      "Epoch 961/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0079 - val_loss: 646.6315\n",
      "Epoch 962/1000\n",
      "320/320 [==============================] - 0s 847us/step - loss: 325.0075 - val_loss: 646.6631\n",
      "Epoch 963/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0069 - val_loss: 646.6365\n",
      "Epoch 964/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0068 - val_loss: 646.5945\n",
      "Epoch 965/1000\n",
      "320/320 [==============================] - 0s 788us/step - loss: 325.0070 - val_loss: 646.6320\n",
      "Epoch 966/1000\n",
      "320/320 [==============================] - 0s 796us/step - loss: 325.0082 - val_loss: 646.6807\n",
      "Epoch 967/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0063 - val_loss: 646.6216\n",
      "Epoch 968/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 325.0074 - val_loss: 646.6257\n",
      "Epoch 969/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 325.0070 - val_loss: 646.5886\n",
      "Epoch 970/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0081 - val_loss: 646.5648\n",
      "Epoch 971/1000\n",
      "320/320 [==============================] - 0s 977us/step - loss: 325.0082 - val_loss: 646.6290\n",
      "Epoch 972/1000\n",
      "320/320 [==============================] - 0s 938us/step - loss: 325.0065 - val_loss: 646.6323\n",
      "Epoch 973/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0082 - val_loss: 646.6477\n",
      "Epoch 974/1000\n",
      "320/320 [==============================] - 0s 971us/step - loss: 325.0078 - val_loss: 646.6600\n",
      "Epoch 975/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 325.0067 - val_loss: 646.5932\n",
      "Epoch 976/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 325.0066 - val_loss: 646.6341\n",
      "Epoch 977/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0074 - val_loss: 646.6097\n",
      "Epoch 978/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 325.0091 - val_loss: 646.6508\n",
      "Epoch 979/1000\n",
      "320/320 [==============================] - 0s 841us/step - loss: 325.0076 - val_loss: 646.6282\n",
      "Epoch 980/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 325.0070 - val_loss: 646.6280\n",
      "Epoch 981/1000\n",
      "320/320 [==============================] - 0s 906us/step - loss: 325.0068 - val_loss: 646.6069\n",
      "Epoch 982/1000\n",
      "320/320 [==============================] - 0s 919us/step - loss: 325.0073 - val_loss: 646.5587\n",
      "Epoch 983/1000\n",
      "320/320 [==============================] - 0s 971us/step - loss: 325.0078 - val_loss: 646.6450\n",
      "Epoch 984/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 325.0093 - val_loss: 646.6052\n",
      "Epoch 985/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0077 - val_loss: 646.5608\n",
      "Epoch 986/1000\n",
      "320/320 [==============================] - 0s 785us/step - loss: 325.0080 - val_loss: 646.6806\n",
      "Epoch 987/1000\n",
      "320/320 [==============================] - 0s 812us/step - loss: 325.0091 - val_loss: 646.6035\n",
      "Epoch 988/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0073 - val_loss: 646.6673\n",
      "Epoch 989/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0066 - val_loss: 646.6411\n",
      "Epoch 990/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0067 - val_loss: 646.6132\n",
      "Epoch 991/1000\n",
      "320/320 [==============================] - 0s 923us/step - loss: 325.0089 - val_loss: 646.6812\n",
      "Epoch 992/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 325.0065 - val_loss: 646.6318\n",
      "Epoch 993/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 325.0076 - val_loss: 646.6370\n",
      "Epoch 994/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 325.0078 - val_loss: 646.6378\n",
      "Epoch 995/1000\n",
      "320/320 [==============================] - 0s 944us/step - loss: 325.0071 - val_loss: 646.6720\n",
      "Epoch 996/1000\n",
      "320/320 [==============================] - 0s 917us/step - loss: 325.0071 - val_loss: 646.6976\n",
      "Epoch 997/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 325.0078 - val_loss: 646.6100\n",
      "Epoch 998/1000\n",
      "320/320 [==============================] - 0s 813us/step - loss: 325.0081 - val_loss: 646.6265\n",
      "Epoch 999/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0070 - val_loss: 646.6334\n",
      "Epoch 1000/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0084 - val_loss: 646.6619\n",
      "27/27 [==============================] - 0s 643us/step\n",
      "1014698 successful\n",
      "Epoch 1/1000\n",
      "306/306 [==============================] - 1s 1ms/step - loss: 16668715.0000 - val_loss: 725.5707\n",
      "Epoch 2/1000\n",
      "306/306 [==============================] - 0s 915us/step - loss: 413.8571 - val_loss: 691.2295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "306/306 [==============================] - 0s 960us/step - loss: 408.1015 - val_loss: 702.6375\n",
      "Epoch 4/1000\n",
      "306/306 [==============================] - 0s 934us/step - loss: 438.0848 - val_loss: 1316.0536\n",
      "Epoch 5/1000\n",
      "306/306 [==============================] - 0s 985us/step - loss: 448.6719 - val_loss: 607.1311\n",
      "Epoch 6/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 466.9186 - val_loss: 772.7614\n",
      "Epoch 7/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 515.5212 - val_loss: 1615.5800\n",
      "Epoch 8/1000\n",
      "306/306 [==============================] - 0s 961us/step - loss: 557.0758 - val_loss: 706.5131\n",
      "Epoch 9/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 630.1960 - val_loss: 677.6092\n",
      "Epoch 10/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1086.3212 - val_loss: 2120.9656\n",
      "Epoch 11/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 1828.8801 - val_loss: 847.9664\n",
      "Epoch 12/1000\n",
      "306/306 [==============================] - 0s 912us/step - loss: 4288.4043 - val_loss: 162024.4531\n",
      "Epoch 13/1000\n",
      "306/306 [==============================] - 0s 904us/step - loss: 118506.8516 - val_loss: 282737.6562\n",
      "Epoch 14/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 127414.7578 - val_loss: 2302.5471\n",
      "Epoch 15/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 135182.5625 - val_loss: 49323.2500\n",
      "Epoch 16/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 121896.5625 - val_loss: 283099.5000\n",
      "Epoch 17/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 132480.7969 - val_loss: 1072.4496\n",
      "Epoch 18/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 94078.5781 - val_loss: 311203.7812\n",
      "Epoch 19/1000\n",
      "306/306 [==============================] - 0s 993us/step - loss: 135262.5312 - val_loss: 38914.9805\n",
      "Epoch 20/1000\n",
      "306/306 [==============================] - 0s 950us/step - loss: 99642.6250 - val_loss: 28578.3652\n",
      "Epoch 21/1000\n",
      "306/306 [==============================] - 0s 963us/step - loss: 101245.0547 - val_loss: 1419.8972\n",
      "Epoch 22/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 129956.1797 - val_loss: 3153.1877\n",
      "Epoch 23/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 105828.4219 - val_loss: 1336.4606\n",
      "Epoch 24/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 95783.7812 - val_loss: 5891.1802\n",
      "Epoch 25/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 96904.2500 - val_loss: 24202.5254\n",
      "Epoch 26/1000\n",
      "306/306 [==============================] - 0s 988us/step - loss: 95931.8828 - val_loss: 125198.4609\n",
      "Epoch 27/1000\n",
      "306/306 [==============================] - 0s 997us/step - loss: 105839.0312 - val_loss: 1227661.0000\n",
      "Epoch 28/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 78325.0703 - val_loss: 94561.1641\n",
      "Epoch 29/1000\n",
      "306/306 [==============================] - 0s 873us/step - loss: 98217.5391 - val_loss: 1254.1084\n",
      "Epoch 30/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 92727.8906 - val_loss: 50428.1406\n",
      "Epoch 31/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 86330.5703 - val_loss: 301037.6250\n",
      "Epoch 32/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 83629.3438 - val_loss: 76323.1406\n",
      "Epoch 33/1000\n",
      "306/306 [==============================] - 0s 961us/step - loss: 105379.2969 - val_loss: 106116.8125\n",
      "Epoch 34/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 64321.6641 - val_loss: 652.5743\n",
      "Epoch 35/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 98715.2969 - val_loss: 9438.2500\n",
      "Epoch 36/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 70689.2031 - val_loss: 93886.3203\n",
      "Epoch 37/1000\n",
      "306/306 [==============================] - 0s 997us/step - loss: 82320.2500 - val_loss: 13538.8438\n",
      "Epoch 38/1000\n",
      "306/306 [==============================] - 0s 859us/step - loss: 80637.4531 - val_loss: 1028.7812\n",
      "Epoch 39/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 67642.8359 - val_loss: 45850.8516\n",
      "Epoch 40/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 81207.0859 - val_loss: 33398.4219\n",
      "Epoch 41/1000\n",
      "306/306 [==============================] - 0s 930us/step - loss: 71387.1328 - val_loss: 397208.9375\n",
      "Epoch 42/1000\n",
      "306/306 [==============================] - 0s 899us/step - loss: 74110.0078 - val_loss: 231590.4375\n",
      "Epoch 43/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 72412.1016 - val_loss: 73485.9922\n",
      "Epoch 44/1000\n",
      "306/306 [==============================] - 0s 889us/step - loss: 69486.2578 - val_loss: 2196.8879\n",
      "Epoch 45/1000\n",
      "306/306 [==============================] - 0s 960us/step - loss: 78622.0078 - val_loss: 46591.3359\n",
      "Epoch 46/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 67562.2812 - val_loss: 4123.7954\n",
      "Epoch 47/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 56476.6680 - val_loss: 40313.3906\n",
      "Epoch 48/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 70369.0078 - val_loss: 911.8373\n",
      "Epoch 49/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 57321.0508 - val_loss: 82574.0781\n",
      "Epoch 50/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 65629.1562 - val_loss: 654499.5625\n",
      "Epoch 51/1000\n",
      "306/306 [==============================] - 0s 974us/step - loss: 52174.0781 - val_loss: 17440.4883\n",
      "Epoch 52/1000\n",
      "306/306 [==============================] - 0s 954us/step - loss: 71196.2500 - val_loss: 7085.2437\n",
      "Epoch 53/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 46855.5234 - val_loss: 25415.0957\n",
      "Epoch 54/1000\n",
      "306/306 [==============================] - 0s 994us/step - loss: 58003.5117 - val_loss: 87016.4922\n",
      "Epoch 55/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 52312.7930 - val_loss: 111463.1641\n",
      "Epoch 56/1000\n",
      "306/306 [==============================] - 0s 981us/step - loss: 54852.0352 - val_loss: 32580.8301\n",
      "Epoch 57/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 48434.0664 - val_loss: 24931.8066\n",
      "Epoch 58/1000\n",
      "306/306 [==============================] - 0s 975us/step - loss: 43487.2188 - val_loss: 629.4955\n",
      "Epoch 59/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 47018.9492 - val_loss: 639.1681\n",
      "Epoch 60/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 40593.8438 - val_loss: 14802.3301\n",
      "Epoch 61/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 44663.1211 - val_loss: 66758.1250\n",
      "Epoch 62/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 46035.7852 - val_loss: 62026.7148\n",
      "Epoch 63/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 40068.0781 - val_loss: 75706.2500\n",
      "Epoch 64/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 46318.3242 - val_loss: 607.0827\n",
      "Epoch 65/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 44725.2266 - val_loss: 2249.1990\n",
      "Epoch 66/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 34554.9727 - val_loss: 99635.4375\n",
      "Epoch 67/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 47151.0977 - val_loss: 3847.5632\n",
      "Epoch 68/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 36491.5664 - val_loss: 31115.7852\n",
      "Epoch 69/1000\n",
      "306/306 [==============================] - 0s 936us/step - loss: 41641.0469 - val_loss: 18822.6680\n",
      "Epoch 70/1000\n",
      "306/306 [==============================] - 0s 908us/step - loss: 38139.6719 - val_loss: 383468.0625\n",
      "Epoch 71/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 34773.7578 - val_loss: 83701.4062\n",
      "Epoch 72/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 37367.6055 - val_loss: 28276.0645\n",
      "Epoch 73/1000\n",
      "306/306 [==============================] - 0s 872us/step - loss: 38640.1641 - val_loss: 18210.7207\n",
      "Epoch 74/1000\n",
      "306/306 [==============================] - 0s 930us/step - loss: 33756.2656 - val_loss: 21730.5039\n",
      "Epoch 75/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 33888.1719 - val_loss: 3547.2068\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 1ms/step - loss: 37608.0391 - val_loss: 2622.5811\n",
      "Epoch 77/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 37954.8438 - val_loss: 27902.5430\n",
      "Epoch 78/1000\n",
      "306/306 [==============================] - 0s 899us/step - loss: 28946.1758 - val_loss: 672.9514\n",
      "Epoch 79/1000\n",
      "306/306 [==============================] - 0s 833us/step - loss: 30965.0469 - val_loss: 17054.3438\n",
      "Epoch 80/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 32764.0430 - val_loss: 203628.2344\n",
      "Epoch 81/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 29601.0449 - val_loss: 17514.3047\n",
      "Epoch 82/1000\n",
      "306/306 [==============================] - 0s 846us/step - loss: 30744.3652 - val_loss: 27044.2070\n",
      "Epoch 83/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 29508.1074 - val_loss: 16936.2188\n",
      "Epoch 84/1000\n",
      "306/306 [==============================] - 0s 971us/step - loss: 28361.3496 - val_loss: 31307.1699\n",
      "Epoch 85/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 28358.2207 - val_loss: 28241.3984\n",
      "Epoch 86/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 30233.3828 - val_loss: 871.2748\n",
      "Epoch 87/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 30525.2812 - val_loss: 30456.1152\n",
      "Epoch 88/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 22634.4258 - val_loss: 89656.9219\n",
      "Epoch 89/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 13894.3809 - val_loss: 24245.2422\n",
      "Epoch 90/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 21441.7285 - val_loss: 9054.0078\n",
      "Epoch 91/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 19560.6016 - val_loss: 881.0236\n",
      "Epoch 92/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 24314.2383 - val_loss: 13830.3613\n",
      "Epoch 93/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 20153.1113 - val_loss: 23999.4375\n",
      "Epoch 94/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 23835.8535 - val_loss: 25800.3438\n",
      "Epoch 95/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 20264.2363 - val_loss: 729.9648\n",
      "Epoch 96/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 19175.8066 - val_loss: 32733.4102\n",
      "Epoch 97/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 21075.5273 - val_loss: 13431.0801\n",
      "Epoch 98/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 21289.0957 - val_loss: 22946.9375\n",
      "Epoch 99/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 18293.0625 - val_loss: 54287.5430\n",
      "Epoch 100/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 21788.8164 - val_loss: 4165.5425\n",
      "Epoch 101/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 16941.1641 - val_loss: 27512.4316\n",
      "Epoch 102/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 18783.4668 - val_loss: 7287.2974\n",
      "Epoch 103/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 24327.6191 - val_loss: 679.3000\n",
      "Epoch 104/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 17442.0645 - val_loss: 51399.2617\n",
      "Epoch 105/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14081.9082 - val_loss: 18963.2812\n",
      "Epoch 106/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 19020.1719 - val_loss: 12023.7188\n",
      "Epoch 107/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 18163.4707 - val_loss: 11902.7480\n",
      "Epoch 108/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 17347.5332 - val_loss: 20061.7266\n",
      "Epoch 109/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 15965.3516 - val_loss: 9430.3076\n",
      "Epoch 110/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 19754.4961 - val_loss: 40493.8828\n",
      "Epoch 111/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 17143.2891 - val_loss: 8809.3242\n",
      "Epoch 112/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14163.2646 - val_loss: 1078.0966\n",
      "Epoch 113/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 17193.6777 - val_loss: 6306.5391\n",
      "Epoch 114/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 16690.0371 - val_loss: 5205.9507\n",
      "Epoch 115/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 14877.0049 - val_loss: 1106.1935\n",
      "Epoch 116/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 15710.4502 - val_loss: 9980.1182\n",
      "Epoch 117/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14779.4111 - val_loss: 8417.7422\n",
      "Epoch 118/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 15433.2324 - val_loss: 9083.0078\n",
      "Epoch 119/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 14423.3428 - val_loss: 7134.1450\n",
      "Epoch 120/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 15368.9521 - val_loss: 748.6712\n",
      "Epoch 121/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13347.9648 - val_loss: 2144.5955\n",
      "Epoch 122/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13299.9180 - val_loss: 12114.6260\n",
      "Epoch 123/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 15696.1230 - val_loss: 2888.4512\n",
      "Epoch 124/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 12235.9492 - val_loss: 17634.6973\n",
      "Epoch 125/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14635.8584 - val_loss: 2056.6309\n",
      "Epoch 126/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 12937.9805 - val_loss: 77274.7891\n",
      "Epoch 127/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 12821.2256 - val_loss: 2164.5657\n",
      "Epoch 128/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13312.6592 - val_loss: 3954.8408\n",
      "Epoch 129/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 12096.6211 - val_loss: 9243.3564\n",
      "Epoch 130/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13538.2236 - val_loss: 3368.8582\n",
      "Epoch 131/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 11749.2344 - val_loss: 13105.0801\n",
      "Epoch 132/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 12145.3252 - val_loss: 7183.8643\n",
      "Epoch 133/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13752.3252 - val_loss: 6482.1196\n",
      "Epoch 134/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 10894.8564 - val_loss: 856.9147\n",
      "Epoch 135/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 12208.8271 - val_loss: 3111.1375\n",
      "Epoch 136/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 10802.4678 - val_loss: 103237.4766\n",
      "Epoch 137/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 12729.8428 - val_loss: 735.6696\n",
      "Epoch 138/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 10927.4492 - val_loss: 1902.3760\n",
      "Epoch 139/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 9129.8193 - val_loss: 21334.4785\n",
      "Epoch 140/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14192.9053 - val_loss: 1246.0626\n",
      "Epoch 141/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 10321.0566 - val_loss: 9656.2520\n",
      "Epoch 142/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9837.2803 - val_loss: 1065.4534\n",
      "Epoch 143/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 11960.6084 - val_loss: 7980.5942\n",
      "Epoch 144/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9454.9473 - val_loss: 8311.6875\n",
      "Epoch 145/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 11514.9531 - val_loss: 1998.5070\n",
      "Epoch 146/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 9459.6182 - val_loss: 738.6403\n",
      "Epoch 147/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 10116.4736 - val_loss: 11639.1934\n",
      "Epoch 148/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 11418.0723 - val_loss: 8330.7822\n",
      "Epoch 149/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9373.5273 - val_loss: 3324.7244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9657.4990 - val_loss: 656.5884\n",
      "Epoch 151/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9228.1875 - val_loss: 60851.7188\n",
      "Epoch 152/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 11495.0039 - val_loss: 2304.9561\n",
      "Epoch 153/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9378.6113 - val_loss: 615.1285\n",
      "Epoch 154/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 8006.0200 - val_loss: 2159.8604\n",
      "Epoch 155/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 10494.0938 - val_loss: 10768.1982\n",
      "Epoch 156/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 8535.5264 - val_loss: 7725.3682\n",
      "Epoch 157/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 10510.2930 - val_loss: 23021.0117\n",
      "Epoch 158/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 8417.5391 - val_loss: 41033.2734\n",
      "Epoch 159/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 7942.3779 - val_loss: 614.2337\n",
      "Epoch 160/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 11561.5176 - val_loss: 13320.9678\n",
      "Epoch 161/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 6489.8604 - val_loss: 3605.6238\n",
      "Epoch 162/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 9259.8525 - val_loss: 3488.8760\n",
      "Epoch 163/1000\n",
      "306/306 [==============================] - 0s 930us/step - loss: 8541.4834 - val_loss: 24932.2344\n",
      "Epoch 164/1000\n",
      "306/306 [==============================] - 0s 870us/step - loss: 10551.9854 - val_loss: 1048.0784\n",
      "Epoch 165/1000\n",
      "306/306 [==============================] - 0s 939us/step - loss: 6472.8340 - val_loss: 662.3831\n",
      "Epoch 166/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 7333.7007 - val_loss: 7737.5874\n",
      "Epoch 167/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 8185.7729 - val_loss: 6043.3638\n",
      "Epoch 168/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 7512.5938 - val_loss: 705.0790\n",
      "Epoch 169/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 8840.4297 - val_loss: 5466.5801\n",
      "Epoch 170/1000\n",
      "306/306 [==============================] - 0s 984us/step - loss: 6302.0269 - val_loss: 1310.4414\n",
      "Epoch 171/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 9130.4424 - val_loss: 706.6184\n",
      "Epoch 172/1000\n",
      "306/306 [==============================] - 0s 854us/step - loss: 7617.3047 - val_loss: 4972.6855\n",
      "Epoch 173/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 7214.3701 - val_loss: 1118.6888\n",
      "Epoch 174/1000\n",
      "306/306 [==============================] - 0s 798us/step - loss: 8060.9658 - val_loss: 994.3734\n",
      "Epoch 175/1000\n",
      "306/306 [==============================] - 0s 867us/step - loss: 6662.9209 - val_loss: 1797.4165\n",
      "Epoch 176/1000\n",
      "306/306 [==============================] - 0s 885us/step - loss: 6583.7285 - val_loss: 10759.9121\n",
      "Epoch 177/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 7638.7085 - val_loss: 651.7644\n",
      "Epoch 178/1000\n",
      "306/306 [==============================] - 0s 981us/step - loss: 6842.1318 - val_loss: 608.9406\n",
      "Epoch 179/1000\n",
      "306/306 [==============================] - 0s 841us/step - loss: 7670.0928 - val_loss: 7939.8257\n",
      "Epoch 180/1000\n",
      "306/306 [==============================] - 0s 854us/step - loss: 5667.5654 - val_loss: 4167.4170\n",
      "Epoch 181/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 6465.7925 - val_loss: 831.5353\n",
      "Epoch 182/1000\n",
      "306/306 [==============================] - 0s 838us/step - loss: 6515.3267 - val_loss: 2777.1416\n",
      "Epoch 183/1000\n",
      "306/306 [==============================] - 0s 969us/step - loss: 6884.7192 - val_loss: 33839.4219\n",
      "Epoch 184/1000\n",
      "306/306 [==============================] - 0s 890us/step - loss: 6355.0527 - val_loss: 4490.9854\n",
      "Epoch 185/1000\n",
      "306/306 [==============================] - 0s 848us/step - loss: 5932.2090 - val_loss: 12019.7471\n",
      "Epoch 186/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 6947.3984 - val_loss: 4641.7490\n",
      "Epoch 187/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 6366.1895 - val_loss: 46595.0117\n",
      "Epoch 188/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 5443.2012 - val_loss: 1957.3756\n",
      "Epoch 189/1000\n",
      "306/306 [==============================] - 0s 861us/step - loss: 6837.9043 - val_loss: 5312.8442\n",
      "Epoch 190/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 5740.1230 - val_loss: 791.5732\n",
      "Epoch 191/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 5447.5269 - val_loss: 1010.3875\n",
      "Epoch 192/1000\n",
      "306/306 [==============================] - 0s 845us/step - loss: 6507.5396 - val_loss: 3895.9771\n",
      "Epoch 193/1000\n",
      "306/306 [==============================] - 0s 839us/step - loss: 5782.6118 - val_loss: 2072.1284\n",
      "Epoch 194/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 5839.4106 - val_loss: 3638.2385\n",
      "Epoch 195/1000\n",
      "306/306 [==============================] - 0s 825us/step - loss: 5593.9478 - val_loss: 11955.0029\n",
      "Epoch 196/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 5791.3379 - val_loss: 3361.1079\n",
      "Epoch 197/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 5186.5234 - val_loss: 1556.0217\n",
      "Epoch 198/1000\n",
      "306/306 [==============================] - 0s 956us/step - loss: 5148.5562 - val_loss: 35273.7305\n",
      "Epoch 199/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 6148.9194 - val_loss: 14623.7285\n",
      "Epoch 200/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 4826.6597 - val_loss: 4864.0190\n",
      "Epoch 201/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5518.8213 - val_loss: 9238.0195\n",
      "Epoch 202/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5992.4351 - val_loss: 3691.5591\n",
      "Epoch 203/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 4695.0503 - val_loss: 664.0105\n",
      "Epoch 204/1000\n",
      "306/306 [==============================] - 0s 994us/step - loss: 5410.5117 - val_loss: 13823.3594\n",
      "Epoch 205/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5706.2666 - val_loss: 7611.2148\n",
      "Epoch 206/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 4748.3867 - val_loss: 765.9823\n",
      "Epoch 207/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5288.2686 - val_loss: 7643.0151\n",
      "Epoch 208/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 4835.5083 - val_loss: 4513.4126\n",
      "Epoch 209/1000\n",
      "306/306 [==============================] - 0s 953us/step - loss: 4336.9980 - val_loss: 4679.1875\n",
      "Epoch 210/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5200.4072 - val_loss: 3922.8486\n",
      "Epoch 211/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 4235.3115 - val_loss: 4022.1052\n",
      "Epoch 212/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 4589.4512 - val_loss: 23416.0957\n",
      "Epoch 213/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 5861.1099 - val_loss: 927.6387\n",
      "Epoch 214/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 3982.2107 - val_loss: 3065.5056\n",
      "Epoch 215/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 4899.7603 - val_loss: 1963.1022\n",
      "Epoch 216/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 4643.3286 - val_loss: 755.5576\n",
      "Epoch 217/1000\n",
      "306/306 [==============================] - 0s 824us/step - loss: 4814.1323 - val_loss: 2433.1482\n",
      "Epoch 218/1000\n",
      "306/306 [==============================] - 0s 826us/step - loss: 3836.7559 - val_loss: 1706.7617\n",
      "Epoch 219/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 4387.8643 - val_loss: 2986.6301\n",
      "Epoch 220/1000\n",
      "306/306 [==============================] - 0s 885us/step - loss: 5307.3340 - val_loss: 28191.3086\n",
      "Epoch 221/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 4185.7715 - val_loss: 764.5091\n",
      "Epoch 222/1000\n",
      "306/306 [==============================] - 0s 861us/step - loss: 4003.4087 - val_loss: 3612.3582\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 939us/step - loss: 4132.7041 - val_loss: 12866.1855\n",
      "Epoch 224/1000\n",
      "306/306 [==============================] - 0s 981us/step - loss: 4271.3545 - val_loss: 18319.9980\n",
      "Epoch 225/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 3186.4849 - val_loss: 11377.7139\n",
      "Epoch 226/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 4036.6372 - val_loss: 2033.9355\n",
      "Epoch 227/1000\n",
      "306/306 [==============================] - 0s 850us/step - loss: 6214.3184 - val_loss: 1964.3491\n",
      "Epoch 228/1000\n",
      "306/306 [==============================] - 0s 878us/step - loss: 2568.0283 - val_loss: 1187.9968\n",
      "Epoch 229/1000\n",
      "306/306 [==============================] - 0s 848us/step - loss: 3636.9329 - val_loss: 10016.7773\n",
      "Epoch 230/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 3917.0413 - val_loss: 2063.7109\n",
      "Epoch 231/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 3794.1968 - val_loss: 934.5334\n",
      "Epoch 232/1000\n",
      "306/306 [==============================] - 0s 877us/step - loss: 3675.6875 - val_loss: 3169.3203\n",
      "Epoch 233/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 3445.3079 - val_loss: 13396.7744\n",
      "Epoch 234/1000\n",
      "306/306 [==============================] - 0s 818us/step - loss: 4600.5747 - val_loss: 674.9542\n",
      "Epoch 235/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 2569.2480 - val_loss: 1470.7275\n",
      "Epoch 236/1000\n",
      "306/306 [==============================] - 0s 907us/step - loss: 3328.8503 - val_loss: 2753.6780\n",
      "Epoch 237/1000\n",
      "306/306 [==============================] - 0s 841us/step - loss: 4057.8992 - val_loss: 612.5664\n",
      "Epoch 238/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 3516.0164 - val_loss: 824.5460\n",
      "Epoch 239/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 3705.1370 - val_loss: 1944.2159\n",
      "Epoch 240/1000\n",
      "306/306 [==============================] - 0s 847us/step - loss: 3644.7830 - val_loss: 3652.5259\n",
      "Epoch 241/1000\n",
      "306/306 [==============================] - 0s 849us/step - loss: 2732.5637 - val_loss: 2341.1304\n",
      "Epoch 242/1000\n",
      "306/306 [==============================] - 0s 829us/step - loss: 4315.6157 - val_loss: 20669.0820\n",
      "Epoch 243/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 3111.5779 - val_loss: 1811.3115\n",
      "Epoch 244/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 2316.3298 - val_loss: 1052.1354\n",
      "Epoch 245/1000\n",
      "306/306 [==============================] - 0s 896us/step - loss: 3144.4995 - val_loss: 3452.8789\n",
      "Epoch 246/1000\n",
      "306/306 [==============================] - 0s 865us/step - loss: 3646.2996 - val_loss: 1147.9042\n",
      "Epoch 247/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 2667.7078 - val_loss: 17256.4805\n",
      "Epoch 248/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 3199.3494 - val_loss: 942518.5625\n",
      "Epoch 249/1000\n",
      "306/306 [==============================] - 0s 844us/step - loss: 133019.0781 - val_loss: 609.6250\n",
      "Epoch 250/1000\n",
      "306/306 [==============================] - 0s 973us/step - loss: 471.5370 - val_loss: 607.2972\n",
      "Epoch 251/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 477.1196 - val_loss: 614.3410\n",
      "Epoch 252/1000\n",
      "306/306 [==============================] - 0s 904us/step - loss: 506.5826 - val_loss: 5591.6353\n",
      "Epoch 253/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 666.9664 - val_loss: 618.5117\n",
      "Epoch 254/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 609.6807 - val_loss: 613.4217\n",
      "Epoch 255/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 784.5018 - val_loss: 1630.1910\n",
      "Epoch 256/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1021.1002 - val_loss: 1150.1526\n",
      "Epoch 257/1000\n",
      "306/306 [==============================] - 0s 890us/step - loss: 1219.4906 - val_loss: 1433.6161\n",
      "Epoch 258/1000\n",
      "306/306 [==============================] - 0s 858us/step - loss: 1784.3798 - val_loss: 5422.1328\n",
      "Epoch 259/1000\n",
      "306/306 [==============================] - 0s 960us/step - loss: 2385.8499 - val_loss: 607.0482\n",
      "Epoch 260/1000\n",
      "306/306 [==============================] - 0s 845us/step - loss: 2543.3237 - val_loss: 18242.8633\n",
      "Epoch 261/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 2790.7173 - val_loss: 3093.5850\n",
      "Epoch 262/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 2768.3362 - val_loss: 3730.9958\n",
      "Epoch 263/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 2343.3591 - val_loss: 2854.8044\n",
      "Epoch 264/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 3459.6704 - val_loss: 3793.2104\n",
      "Epoch 265/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2109.5771 - val_loss: 1172.7953\n",
      "Epoch 266/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 3061.2595 - val_loss: 753.4849\n",
      "Epoch 267/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2134.4771 - val_loss: 3861.0193\n",
      "Epoch 268/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2812.1946 - val_loss: 4186.0698\n",
      "Epoch 269/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2065.9634 - val_loss: 5081.1743\n",
      "Epoch 270/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2641.6191 - val_loss: 976.3381\n",
      "Epoch 271/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 2689.9373 - val_loss: 4071.4985\n",
      "Epoch 272/1000\n",
      "306/306 [==============================] - 0s 935us/step - loss: 3024.4688 - val_loss: 1142.8173\n",
      "Epoch 273/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 1990.8163 - val_loss: 3623.3569\n",
      "Epoch 274/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 2507.2183 - val_loss: 1849.3690\n",
      "Epoch 275/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 2159.7266 - val_loss: 3170.4875\n",
      "Epoch 276/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 2172.1643 - val_loss: 3501.7107\n",
      "Epoch 277/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 2512.5530 - val_loss: 6396.0137\n",
      "Epoch 278/1000\n",
      "306/306 [==============================] - 0s 864us/step - loss: 2275.5154 - val_loss: 1870.9736\n",
      "Epoch 279/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 1931.8209 - val_loss: 4788.6318\n",
      "Epoch 280/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 2752.7214 - val_loss: 1031.0298\n",
      "Epoch 281/1000\n",
      "306/306 [==============================] - 0s 862us/step - loss: 2458.2126 - val_loss: 9477.9824\n",
      "Epoch 282/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 1644.8848 - val_loss: 611.4601\n",
      "Epoch 283/1000\n",
      "306/306 [==============================] - 0s 953us/step - loss: 2238.3523 - val_loss: 662.7614\n",
      "Epoch 284/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 2003.4990 - val_loss: 3748.6001\n",
      "Epoch 285/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 1706.3503 - val_loss: 3806.3901\n",
      "Epoch 286/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 1753.9613 - val_loss: 1952.9915\n",
      "Epoch 287/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 2110.9531 - val_loss: 610.0207\n",
      "Epoch 288/1000\n",
      "306/306 [==============================] - 0s 859us/step - loss: 2616.0208 - val_loss: 870.1334\n",
      "Epoch 289/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 1636.6757 - val_loss: 1387.2517\n",
      "Epoch 290/1000\n",
      "306/306 [==============================] - 0s 938us/step - loss: 2197.0215 - val_loss: 627.5295\n",
      "Epoch 291/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 1648.6974 - val_loss: 1742.7574\n",
      "Epoch 292/1000\n",
      "306/306 [==============================] - 0s 858us/step - loss: 1896.4091 - val_loss: 1253.5547\n",
      "Epoch 293/1000\n",
      "306/306 [==============================] - 0s 859us/step - loss: 1859.9895 - val_loss: 4706.0220\n",
      "Epoch 294/1000\n",
      "306/306 [==============================] - 0s 890us/step - loss: 1963.4589 - val_loss: 1686.8086\n",
      "Epoch 295/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 1572.5634 - val_loss: 788.4106\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 870us/step - loss: 1746.0009 - val_loss: 2720.8533\n",
      "Epoch 297/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 1845.8716 - val_loss: 1926.6818\n",
      "Epoch 298/1000\n",
      "306/306 [==============================] - 0s 885us/step - loss: 1989.0122 - val_loss: 741.9368\n",
      "Epoch 299/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 1717.7363 - val_loss: 2485.6428\n",
      "Epoch 300/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 1527.6232 - val_loss: 2836.3833\n",
      "Epoch 301/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 1462.4349 - val_loss: 4007.3250\n",
      "Epoch 302/1000\n",
      "306/306 [==============================] - 0s 916us/step - loss: 2162.3279 - val_loss: 1832.8621\n",
      "Epoch 303/1000\n",
      "306/306 [==============================] - 0s 968us/step - loss: 1311.6842 - val_loss: 6384.6177\n",
      "Epoch 304/1000\n",
      "306/306 [==============================] - 0s 936us/step - loss: 1679.2806 - val_loss: 4121.0444\n",
      "Epoch 305/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 1660.2469 - val_loss: 701.0318\n",
      "Epoch 306/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 1171.4725 - val_loss: 776.8340\n",
      "Epoch 307/1000\n",
      "306/306 [==============================] - 0s 932us/step - loss: 1722.2627 - val_loss: 8645.9219\n",
      "Epoch 308/1000\n",
      "306/306 [==============================] - 0s 869us/step - loss: 1697.9387 - val_loss: 811.7822\n",
      "Epoch 309/1000\n",
      "306/306 [==============================] - 0s 929us/step - loss: 1847.7295 - val_loss: 607.1248\n",
      "Epoch 310/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 1337.6189 - val_loss: 607.7951\n",
      "Epoch 311/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 1469.0153 - val_loss: 614.5013\n",
      "Epoch 312/1000\n",
      "306/306 [==============================] - 0s 865us/step - loss: 1087.6727 - val_loss: 636.1938\n",
      "Epoch 313/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 1752.7419 - val_loss: 856.8623\n",
      "Epoch 314/1000\n",
      "306/306 [==============================] - 0s 925us/step - loss: 1265.4551 - val_loss: 4547.1270\n",
      "Epoch 315/1000\n",
      "306/306 [==============================] - 0s 853us/step - loss: 1497.4698 - val_loss: 3882.4585\n",
      "Epoch 316/1000\n",
      "306/306 [==============================] - 0s 874us/step - loss: 1264.4863 - val_loss: 1162.1062\n",
      "Epoch 317/1000\n",
      "306/306 [==============================] - 0s 952us/step - loss: 1738.9917 - val_loss: 607.3597\n",
      "Epoch 318/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 1336.5104 - val_loss: 2052.0740\n",
      "Epoch 319/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 1213.2737 - val_loss: 4195.4976\n",
      "Epoch 320/1000\n",
      "306/306 [==============================] - 0s 826us/step - loss: 1110.7797 - val_loss: 667.5617\n",
      "Epoch 321/1000\n",
      "306/306 [==============================] - 0s 933us/step - loss: 1196.4869 - val_loss: 671.3657\n",
      "Epoch 322/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 1688.4670 - val_loss: 902.9481\n",
      "Epoch 323/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 1280.5698 - val_loss: 694.7286\n",
      "Epoch 324/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 1125.2427 - val_loss: 1878.6727\n",
      "Epoch 325/1000\n",
      "306/306 [==============================] - 0s 950us/step - loss: 1194.5859 - val_loss: 4052.9795\n",
      "Epoch 326/1000\n",
      "306/306 [==============================] - 0s 951us/step - loss: 1253.1367 - val_loss: 1884.4480\n",
      "Epoch 327/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 1324.8976 - val_loss: 4100.9688\n",
      "Epoch 328/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 1168.1066 - val_loss: 792.7118\n",
      "Epoch 329/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 1138.4144 - val_loss: 616.2256\n",
      "Epoch 330/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 949.8411 - val_loss: 1983.4573\n",
      "Epoch 331/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 1149.7544 - val_loss: 608.0836\n",
      "Epoch 332/1000\n",
      "306/306 [==============================] - 0s 988us/step - loss: 989.0343 - val_loss: 715.9363\n",
      "Epoch 333/1000\n",
      "306/306 [==============================] - 0s 938us/step - loss: 1157.0326 - val_loss: 1095.8699\n",
      "Epoch 334/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1253.7091 - val_loss: 813.7879\n",
      "Epoch 335/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1001.3906 - val_loss: 697.7713\n",
      "Epoch 336/1000\n",
      "306/306 [==============================] - 0s 903us/step - loss: 1061.8680 - val_loss: 1356.9557\n",
      "Epoch 337/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 795.5116 - val_loss: 1546.7717\n",
      "Epoch 338/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1106.0447 - val_loss: 5172.9282\n",
      "Epoch 339/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 1066.5519 - val_loss: 855.3258\n",
      "Epoch 340/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 825.6463 - val_loss: 607.1808\n",
      "Epoch 341/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1007.1257 - val_loss: 838.5157\n",
      "Epoch 342/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 805.7062 - val_loss: 607.3561\n",
      "Epoch 343/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 954.7957 - val_loss: 2139.8665\n",
      "Epoch 344/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 825.8892 - val_loss: 1154.5149\n",
      "Epoch 345/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 772.6891 - val_loss: 617.3530\n",
      "Epoch 346/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 996.8129 - val_loss: 611.5004\n",
      "Epoch 347/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 823.4908 - val_loss: 1931.1519\n",
      "Epoch 348/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 866.7702 - val_loss: 1266.8806\n",
      "Epoch 349/1000\n",
      "306/306 [==============================] - 0s 956us/step - loss: 905.9921 - val_loss: 1102.0100\n",
      "Epoch 350/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 1004.0048 - val_loss: 607.0558\n",
      "Epoch 351/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 614.0606 - val_loss: 2626.5222\n",
      "Epoch 352/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 788.4722 - val_loss: 1211.9307\n",
      "Epoch 353/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 969.0801 - val_loss: 1661.0920\n",
      "Epoch 354/1000\n",
      "306/306 [==============================] - 0s 974us/step - loss: 876.1374 - val_loss: 847.7607\n",
      "Epoch 355/1000\n",
      "306/306 [==============================] - 0s 963us/step - loss: 1663.0695 - val_loss: 1524.8577\n",
      "Epoch 356/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 611.6880 - val_loss: 1181.3263\n",
      "Epoch 357/1000\n",
      "306/306 [==============================] - 0s 1000us/step - loss: 706.9654 - val_loss: 1076.2057\n",
      "Epoch 358/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 642.0895 - val_loss: 2833.0745\n",
      "Epoch 359/1000\n",
      "306/306 [==============================] - 0s 861us/step - loss: 742.9164 - val_loss: 609.2424\n",
      "Epoch 360/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 619.4577 - val_loss: 1584.8599\n",
      "Epoch 361/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 642.5148 - val_loss: 670.9694\n",
      "Epoch 362/1000\n",
      "306/306 [==============================] - 0s 940us/step - loss: 703.5944 - val_loss: 850.2440\n",
      "Epoch 363/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 783.8759 - val_loss: 946.5957\n",
      "Epoch 364/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 970.8426 - val_loss: 880.6207\n",
      "Epoch 365/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 613.9274 - val_loss: 907.4131\n",
      "Epoch 366/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 531.9572 - val_loss: 629.4715\n",
      "Epoch 367/1000\n",
      "306/306 [==============================] - 0s 947us/step - loss: 672.4662 - val_loss: 1246.0176\n",
      "Epoch 368/1000\n",
      "306/306 [==============================] - 0s 949us/step - loss: 604.3544 - val_loss: 766.9835\n",
      "Epoch 369/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 557.4422 - val_loss: 623.8615\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 1ms/step - loss: 540.3521 - val_loss: 607.0482\n",
      "Epoch 371/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 552.0441 - val_loss: 1256.7767\n",
      "Epoch 372/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 671.5490 - val_loss: 615.8571\n",
      "Epoch 373/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 571.6304 - val_loss: 1324.7808\n",
      "Epoch 374/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 590.7209 - val_loss: 946.0027\n",
      "Epoch 375/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 576.6691 - val_loss: 612.3185\n",
      "Epoch 376/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 619.8616 - val_loss: 677.9874\n",
      "Epoch 377/1000\n",
      "306/306 [==============================] - 0s 930us/step - loss: 521.3624 - val_loss: 1037.1196\n",
      "Epoch 378/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 574.0704 - val_loss: 630.0606\n",
      "Epoch 379/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 564.5197 - val_loss: 607.3055\n",
      "Epoch 380/1000\n",
      "306/306 [==============================] - 0s 886us/step - loss: 519.1439 - val_loss: 615.4191\n",
      "Epoch 381/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 504.8880 - val_loss: 1133.3444\n",
      "Epoch 382/1000\n",
      "306/306 [==============================] - 0s 860us/step - loss: 489.0091 - val_loss: 733.5192\n",
      "Epoch 383/1000\n",
      "306/306 [==============================] - 0s 969us/step - loss: 565.7144 - val_loss: 635.9088\n",
      "Epoch 384/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 551.0905 - val_loss: 970.6899\n",
      "Epoch 385/1000\n",
      "306/306 [==============================] - 0s 940us/step - loss: 594.5825 - val_loss: 864.0445\n",
      "Epoch 386/1000\n",
      "306/306 [==============================] - 0s 973us/step - loss: 478.6677 - val_loss: 607.1007\n",
      "Epoch 387/1000\n",
      "306/306 [==============================] - 0s 933us/step - loss: 485.9286 - val_loss: 615.2052\n",
      "Epoch 388/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 467.6794 - val_loss: 636.0529\n",
      "Epoch 389/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 552.7817 - val_loss: 623.9023\n",
      "Epoch 390/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 508.3239 - val_loss: 763.7941\n",
      "Epoch 391/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 477.9136 - val_loss: 615.0048\n",
      "Epoch 392/1000\n",
      "306/306 [==============================] - 0s 970us/step - loss: 528.4403 - val_loss: 609.2332\n",
      "Epoch 393/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2527.7532 - val_loss: 837.4306\n",
      "Epoch 394/1000\n",
      "306/306 [==============================] - 0s 962us/step - loss: 460.2236 - val_loss: 655.6032\n",
      "Epoch 395/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 491.7942 - val_loss: 867.2583\n",
      "Epoch 396/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 452.6700 - val_loss: 607.9589\n",
      "Epoch 397/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 450.6330 - val_loss: 699.8962\n",
      "Epoch 398/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 468.6014 - val_loss: 1046.4027\n",
      "Epoch 399/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 544.7422 - val_loss: 641.9581\n",
      "Epoch 400/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 452.3194 - val_loss: 911.8725\n",
      "Epoch 401/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 511.8178 - val_loss: 744.7930\n",
      "Epoch 402/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 462.7216 - val_loss: 666.6039\n",
      "Epoch 403/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 463.1289 - val_loss: 1017.4272\n",
      "Epoch 404/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 443.2993 - val_loss: 1024.9835\n",
      "Epoch 405/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 456.7134 - val_loss: 619.8807\n",
      "Epoch 406/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 462.5941 - val_loss: 881.8831\n",
      "Epoch 407/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 489.1949 - val_loss: 863.5627\n",
      "Epoch 408/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 427.4804 - val_loss: 694.0950\n",
      "Epoch 409/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 426.2229 - val_loss: 641.1624\n",
      "Epoch 410/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 434.6633 - val_loss: 613.1404\n",
      "Epoch 411/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 430.9522 - val_loss: 950.7548\n",
      "Epoch 412/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 432.6811 - val_loss: 607.8865\n",
      "Epoch 413/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 410.2742 - val_loss: 1043.1069\n",
      "Epoch 414/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 423.1266 - val_loss: 648.7973\n",
      "Epoch 415/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 416.2872 - val_loss: 608.3272\n",
      "Epoch 416/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 408.2766 - val_loss: 687.9895\n",
      "Epoch 417/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 403.4169 - val_loss: 618.8936\n",
      "Epoch 418/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 390.7841 - val_loss: 701.6559\n",
      "Epoch 419/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 395.3753 - val_loss: 648.0287\n",
      "Epoch 420/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 385.6523 - val_loss: 616.3853\n",
      "Epoch 421/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.8146 - val_loss: 654.8768\n",
      "Epoch 422/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.3561 - val_loss: 618.4406\n",
      "Epoch 423/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.6884 - val_loss: 685.2932\n",
      "Epoch 424/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 382.0437 - val_loss: 665.1138\n",
      "Epoch 425/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 379.7634 - val_loss: 654.9631\n",
      "Epoch 426/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.3862 - val_loss: 630.3732\n",
      "Epoch 427/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.0931 - val_loss: 656.8600\n",
      "Epoch 428/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.4029 - val_loss: 688.9035\n",
      "Epoch 429/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 379.2027 - val_loss: 621.1942\n",
      "Epoch 430/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 383.8317 - val_loss: 712.1896\n",
      "Epoch 431/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 381.3889 - val_loss: 715.2742\n",
      "Epoch 432/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 379.4250 - val_loss: 639.5250\n",
      "Epoch 433/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 387.3441 - val_loss: 670.1651\n",
      "Epoch 434/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 381.9585 - val_loss: 635.2475\n",
      "Epoch 435/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.1776 - val_loss: 683.2667\n",
      "Epoch 436/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 385.6148 - val_loss: 646.1642\n",
      "Epoch 437/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.5382 - val_loss: 710.8893\n",
      "Epoch 438/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 385.8145 - val_loss: 695.7615\n",
      "Epoch 439/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 382.9082 - val_loss: 612.2424\n",
      "Epoch 440/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.2710 - val_loss: 705.2453\n",
      "Epoch 441/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 381.9896 - val_loss: 679.5432\n",
      "Epoch 442/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.8966 - val_loss: 631.9717\n",
      "Epoch 443/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 379.7842 - val_loss: 695.7654\n",
      "Epoch 444/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.8922 - val_loss: 716.0536\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 1s 3ms/step - loss: 386.0393 - val_loss: 689.2476\n",
      "Epoch 446/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 385.1917 - val_loss: 651.5789\n",
      "Epoch 447/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.3344 - val_loss: 631.1815\n",
      "Epoch 448/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 387.3576 - val_loss: 616.1995\n",
      "Epoch 449/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 383.2095 - val_loss: 729.0262\n",
      "Epoch 450/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.2273 - val_loss: 641.3172\n",
      "Epoch 451/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 387.4947 - val_loss: 642.6745\n",
      "Epoch 452/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 381.8455 - val_loss: 629.7679\n",
      "Epoch 453/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 382.2401 - val_loss: 750.1331\n",
      "Epoch 454/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 386.0195 - val_loss: 643.2999\n",
      "Epoch 455/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 389.5758 - val_loss: 729.9733\n",
      "Epoch 456/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.8829 - val_loss: 616.4239\n",
      "Epoch 457/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 385.5749 - val_loss: 623.5909\n",
      "Epoch 458/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.4910 - val_loss: 687.5767\n",
      "Epoch 459/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.9742 - val_loss: 633.7936\n",
      "Epoch 460/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 1919.8401 - val_loss: 683.3868\n",
      "Epoch 461/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 425.3671 - val_loss: 627.9794\n",
      "Epoch 462/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 471.8341 - val_loss: 631.6039\n",
      "Epoch 463/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 447.8907 - val_loss: 1122.7294\n",
      "Epoch 464/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 442.8735 - val_loss: 607.5312\n",
      "Epoch 465/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 440.5974 - val_loss: 672.7077\n",
      "Epoch 466/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 442.5316 - val_loss: 649.8514\n",
      "Epoch 467/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 412.7520 - val_loss: 607.2936\n",
      "Epoch 468/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 404.3259 - val_loss: 653.2616\n",
      "Epoch 469/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 401.4364 - val_loss: 677.1576\n",
      "Epoch 470/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 412.0883 - val_loss: 702.3746\n",
      "Epoch 471/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 404.3593 - val_loss: 701.5547\n",
      "Epoch 472/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 396.6338 - val_loss: 626.4902\n",
      "Epoch 473/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 388.4953 - val_loss: 647.1082\n",
      "Epoch 474/1000\n",
      "306/306 [==============================] - 0s 2ms/step - loss: 384.2805 - val_loss: 621.9481\n",
      "Epoch 475/1000\n",
      "306/306 [==============================] - 0s 995us/step - loss: 381.6373 - val_loss: 614.9226\n",
      "Epoch 476/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 376.8417 - val_loss: 651.9719\n",
      "Epoch 477/1000\n",
      "306/306 [==============================] - 0s 886us/step - loss: 377.4615 - val_loss: 699.9698\n",
      "Epoch 478/1000\n",
      "306/306 [==============================] - 0s 971us/step - loss: 379.1318 - val_loss: 803.7655\n",
      "Epoch 479/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 380.3319 - val_loss: 664.6282\n",
      "Epoch 480/1000\n",
      "306/306 [==============================] - 0s 975us/step - loss: 381.4890 - val_loss: 757.1438\n",
      "Epoch 481/1000\n",
      "306/306 [==============================] - 0s 992us/step - loss: 379.6194 - val_loss: 644.2708\n",
      "Epoch 482/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 380.6621 - val_loss: 654.0461\n",
      "Epoch 483/1000\n",
      "306/306 [==============================] - 0s 883us/step - loss: 378.4532 - val_loss: 658.2359\n",
      "Epoch 484/1000\n",
      "306/306 [==============================] - 0s 840us/step - loss: 380.8285 - val_loss: 669.1510\n",
      "Epoch 485/1000\n",
      "306/306 [==============================] - 0s 814us/step - loss: 380.2426 - val_loss: 634.5624\n",
      "Epoch 486/1000\n",
      "306/306 [==============================] - 0s 906us/step - loss: 379.3519 - val_loss: 636.1279\n",
      "Epoch 487/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 381.9780 - val_loss: 628.1847\n",
      "Epoch 488/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 380.4121 - val_loss: 660.1187\n",
      "Epoch 489/1000\n",
      "306/306 [==============================] - 0s 907us/step - loss: 381.9637 - val_loss: 675.0434\n",
      "Epoch 490/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 383.0612 - val_loss: 662.4160\n",
      "Epoch 491/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 388.7469 - val_loss: 611.4634\n",
      "Epoch 492/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 379.3073 - val_loss: 690.7944\n",
      "Epoch 493/1000\n",
      "306/306 [==============================] - 0s 885us/step - loss: 380.9128 - val_loss: 619.0511\n",
      "Epoch 494/1000\n",
      "306/306 [==============================] - 0s 950us/step - loss: 381.8376 - val_loss: 685.3217\n",
      "Epoch 495/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 383.3893 - val_loss: 840.7905\n",
      "Epoch 496/1000\n",
      "306/306 [==============================] - 0s 820us/step - loss: 386.1125 - val_loss: 686.5382\n",
      "Epoch 497/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 380.4142 - val_loss: 638.9217\n",
      "Epoch 498/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 380.6472 - val_loss: 647.0397\n",
      "Epoch 499/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 381.8467 - val_loss: 677.3044\n",
      "Epoch 500/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 378.6154 - val_loss: 648.7399\n",
      "Epoch 501/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 386.0033 - val_loss: 710.4496\n",
      "Epoch 502/1000\n",
      "306/306 [==============================] - 0s 941us/step - loss: 384.0037 - val_loss: 668.4327\n",
      "Epoch 503/1000\n",
      "306/306 [==============================] - 0s 850us/step - loss: 380.8074 - val_loss: 688.4353\n",
      "Epoch 504/1000\n",
      "306/306 [==============================] - 0s 867us/step - loss: 380.0085 - val_loss: 607.1276\n",
      "Epoch 505/1000\n",
      "306/306 [==============================] - 0s 845us/step - loss: 386.8750 - val_loss: 625.1722\n",
      "Epoch 506/1000\n",
      "306/306 [==============================] - 0s 873us/step - loss: 383.5259 - val_loss: 661.0062\n",
      "Epoch 507/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 379.9553 - val_loss: 647.4133\n",
      "Epoch 508/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 379.2422 - val_loss: 650.8442\n",
      "Epoch 509/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 384.7340 - val_loss: 693.5223\n",
      "Epoch 510/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 380.4644 - val_loss: 632.8323\n",
      "Epoch 511/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 380.3701 - val_loss: 626.7885\n",
      "Epoch 512/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 382.7770 - val_loss: 609.9416\n",
      "Epoch 513/1000\n",
      "306/306 [==============================] - 0s 932us/step - loss: 376.7277 - val_loss: 645.8135\n",
      "Epoch 514/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 383.9512 - val_loss: 609.6615\n",
      "Epoch 515/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 382.7135 - val_loss: 655.5881\n",
      "Epoch 516/1000\n",
      "306/306 [==============================] - 0s 874us/step - loss: 379.5602 - val_loss: 609.9935\n",
      "Epoch 517/1000\n",
      "306/306 [==============================] - 0s 877us/step - loss: 380.9116 - val_loss: 656.0610\n",
      "Epoch 518/1000\n",
      "306/306 [==============================] - 0s 836us/step - loss: 380.4185 - val_loss: 704.3799\n",
      "Epoch 519/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 385.8263 - val_loss: 738.8667\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 878us/step - loss: 384.5012 - val_loss: 661.5733\n",
      "Epoch 521/1000\n",
      "306/306 [==============================] - 0s 868us/step - loss: 382.8943 - val_loss: 673.3890\n",
      "Epoch 522/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 380.0968 - val_loss: 654.4653\n",
      "Epoch 523/1000\n",
      "306/306 [==============================] - 0s 915us/step - loss: 378.7118 - val_loss: 643.9149\n",
      "Epoch 524/1000\n",
      "306/306 [==============================] - 0s 872us/step - loss: 510.4176 - val_loss: 613.3794\n",
      "Epoch 525/1000\n",
      "306/306 [==============================] - 0s 999us/step - loss: 382.5098 - val_loss: 609.1193\n",
      "Epoch 526/1000\n",
      "306/306 [==============================] - 0s 873us/step - loss: 380.0996 - val_loss: 630.9150\n",
      "Epoch 527/1000\n",
      "306/306 [==============================] - 0s 812us/step - loss: 378.7896 - val_loss: 626.0932\n",
      "Epoch 528/1000\n",
      "306/306 [==============================] - 0s 853us/step - loss: 378.9686 - val_loss: 641.2444\n",
      "Epoch 529/1000\n",
      "306/306 [==============================] - 0s 862us/step - loss: 378.8961 - val_loss: 661.9940\n",
      "Epoch 530/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 377.1290 - val_loss: 695.6086\n",
      "Epoch 531/1000\n",
      "306/306 [==============================] - 0s 936us/step - loss: 379.2143 - val_loss: 658.7288\n",
      "Epoch 532/1000\n",
      "306/306 [==============================] - 0s 833us/step - loss: 378.3226 - val_loss: 694.5400\n",
      "Epoch 533/1000\n",
      "306/306 [==============================] - 0s 874us/step - loss: 381.0753 - val_loss: 671.1061\n",
      "Epoch 534/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 378.2032 - val_loss: 621.0607\n",
      "Epoch 535/1000\n",
      "306/306 [==============================] - 0s 835us/step - loss: 376.9479 - val_loss: 714.2715\n",
      "Epoch 536/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 379.6342 - val_loss: 711.8933\n",
      "Epoch 537/1000\n",
      "306/306 [==============================] - 0s 890us/step - loss: 380.0999 - val_loss: 609.8049\n",
      "Epoch 538/1000\n",
      "306/306 [==============================] - 0s 999us/step - loss: 379.5694 - val_loss: 720.1092\n",
      "Epoch 539/1000\n",
      "306/306 [==============================] - 0s 916us/step - loss: 380.3593 - val_loss: 752.2755\n",
      "Epoch 540/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 380.8100 - val_loss: 660.8930\n",
      "Epoch 541/1000\n",
      "306/306 [==============================] - 0s 896us/step - loss: 378.4909 - val_loss: 684.2240\n",
      "Epoch 542/1000\n",
      "306/306 [==============================] - 0s 971us/step - loss: 377.1404 - val_loss: 633.9117\n",
      "Epoch 543/1000\n",
      "306/306 [==============================] - 0s 962us/step - loss: 378.8397 - val_loss: 670.5391\n",
      "Epoch 544/1000\n",
      "306/306 [==============================] - 0s 906us/step - loss: 378.2586 - val_loss: 669.1613\n",
      "Epoch 545/1000\n",
      "306/306 [==============================] - 0s 839us/step - loss: 377.2805 - val_loss: 623.6254\n",
      "Epoch 546/1000\n",
      "306/306 [==============================] - 0s 897us/step - loss: 378.7245 - val_loss: 720.1158\n",
      "Epoch 547/1000\n",
      "306/306 [==============================] - 0s 976us/step - loss: 377.1714 - val_loss: 615.4306\n",
      "Epoch 548/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 377.9181 - val_loss: 658.5963\n",
      "Epoch 549/1000\n",
      "306/306 [==============================] - 0s 925us/step - loss: 379.1973 - val_loss: 635.3198\n",
      "Epoch 550/1000\n",
      "306/306 [==============================] - 0s 889us/step - loss: 377.5854 - val_loss: 686.8234\n",
      "Epoch 551/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 378.2204 - val_loss: 693.5844\n",
      "Epoch 552/1000\n",
      "306/306 [==============================] - 0s 929us/step - loss: 377.6084 - val_loss: 649.8775\n",
      "Epoch 553/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 378.8821 - val_loss: 677.9280\n",
      "Epoch 554/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.3557 - val_loss: 678.8102\n",
      "Epoch 555/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 378.9579 - val_loss: 630.2932\n",
      "Epoch 556/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 381.1468 - val_loss: 737.6845\n",
      "Epoch 557/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 377.3904 - val_loss: 627.9634\n",
      "Epoch 558/1000\n",
      "306/306 [==============================] - 0s 915us/step - loss: 377.7580 - val_loss: 670.3625\n",
      "Epoch 559/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 377.4197 - val_loss: 692.4166\n",
      "Epoch 560/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 377.1057 - val_loss: 627.4651\n",
      "Epoch 561/1000\n",
      "306/306 [==============================] - 0s 881us/step - loss: 378.5836 - val_loss: 650.1039\n",
      "Epoch 562/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 377.4421 - val_loss: 693.7755\n",
      "Epoch 563/1000\n",
      "306/306 [==============================] - 0s 941us/step - loss: 377.0983 - val_loss: 655.1773\n",
      "Epoch 564/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 379.1245 - val_loss: 669.6045\n",
      "Epoch 565/1000\n",
      "306/306 [==============================] - 0s 844us/step - loss: 377.6536 - val_loss: 697.8429\n",
      "Epoch 566/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 377.8735 - val_loss: 621.1257\n",
      "Epoch 567/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 377.6666 - val_loss: 643.5308\n",
      "Epoch 568/1000\n",
      "306/306 [==============================] - 0s 935us/step - loss: 376.8991 - val_loss: 634.0764\n",
      "Epoch 569/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 377.6879 - val_loss: 630.2073\n",
      "Epoch 570/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 376.5260 - val_loss: 653.6832\n",
      "Epoch 571/1000\n",
      "306/306 [==============================] - 0s 996us/step - loss: 376.4849 - val_loss: 707.2960\n",
      "Epoch 572/1000\n",
      "306/306 [==============================] - 0s 931us/step - loss: 377.7026 - val_loss: 629.5424\n",
      "Epoch 573/1000\n",
      "306/306 [==============================] - 0s 905us/step - loss: 377.9329 - val_loss: 687.8543\n",
      "Epoch 574/1000\n",
      "306/306 [==============================] - 0s 865us/step - loss: 378.3842 - val_loss: 661.4381\n",
      "Epoch 575/1000\n",
      "306/306 [==============================] - 0s 941us/step - loss: 489.2314 - val_loss: 633.0910\n",
      "Epoch 576/1000\n",
      "306/306 [==============================] - 0s 904us/step - loss: 378.0047 - val_loss: 710.2337\n",
      "Epoch 577/1000\n",
      "306/306 [==============================] - 0s 956us/step - loss: 378.3040 - val_loss: 655.4273\n",
      "Epoch 578/1000\n",
      "306/306 [==============================] - 0s 889us/step - loss: 376.2010 - val_loss: 668.7061\n",
      "Epoch 579/1000\n",
      "306/306 [==============================] - 0s 935us/step - loss: 375.8859 - val_loss: 643.5104\n",
      "Epoch 580/1000\n",
      "306/306 [==============================] - 0s 926us/step - loss: 377.6039 - val_loss: 681.0623\n",
      "Epoch 581/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 377.0047 - val_loss: 641.4384\n",
      "Epoch 582/1000\n",
      "306/306 [==============================] - 0s 982us/step - loss: 375.8761 - val_loss: 680.4501\n",
      "Epoch 583/1000\n",
      "306/306 [==============================] - 0s 872us/step - loss: 377.1521 - val_loss: 651.4413\n",
      "Epoch 584/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 378.4850 - val_loss: 687.6457\n",
      "Epoch 585/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 376.1753 - val_loss: 683.9448\n",
      "Epoch 586/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 378.2903 - val_loss: 667.8625\n",
      "Epoch 587/1000\n",
      "306/306 [==============================] - 0s 968us/step - loss: 377.2577 - val_loss: 622.8897\n",
      "Epoch 588/1000\n",
      "306/306 [==============================] - 0s 989us/step - loss: 377.1519 - val_loss: 624.6587\n",
      "Epoch 589/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.0248 - val_loss: 656.2777\n",
      "Epoch 590/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 375.9427 - val_loss: 638.7142\n",
      "Epoch 591/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.5791 - val_loss: 631.6568\n",
      "Epoch 592/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 376.5082 - val_loss: 636.2502\n",
      "Epoch 593/1000\n",
      "306/306 [==============================] - 0s 886us/step - loss: 376.2857 - val_loss: 688.6438\n",
      "Epoch 594/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2348 - val_loss: 662.7648\n",
      "Epoch 595/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 376.4305 - val_loss: 645.2972\n",
      "Epoch 596/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.6353 - val_loss: 694.4736\n",
      "Epoch 597/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 377.0313 - val_loss: 667.3429\n",
      "Epoch 598/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 376.3071 - val_loss: 652.5056\n",
      "Epoch 599/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.9135 - val_loss: 696.5133\n",
      "Epoch 600/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.5792 - val_loss: 613.3531\n",
      "Epoch 601/1000\n",
      "306/306 [==============================] - 0s 869us/step - loss: 375.9987 - val_loss: 622.5969\n",
      "Epoch 602/1000\n",
      "306/306 [==============================] - 0s 899us/step - loss: 376.5986 - val_loss: 661.0005\n",
      "Epoch 603/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 376.7249 - val_loss: 671.9553\n",
      "Epoch 604/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 375.0324 - val_loss: 659.7099\n",
      "Epoch 605/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 376.2190 - val_loss: 643.4714\n",
      "Epoch 606/1000\n",
      "306/306 [==============================] - 0s 854us/step - loss: 377.0793 - val_loss: 644.0903\n",
      "Epoch 607/1000\n",
      "306/306 [==============================] - 0s 950us/step - loss: 376.6642 - val_loss: 689.8336\n",
      "Epoch 608/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 376.5060 - val_loss: 646.2273\n",
      "Epoch 609/1000\n",
      "306/306 [==============================] - 0s 974us/step - loss: 376.2976 - val_loss: 631.9302\n",
      "Epoch 610/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 376.2881 - val_loss: 667.8256\n",
      "Epoch 611/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 376.8148 - val_loss: 644.4129\n",
      "Epoch 612/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 378.1985 - val_loss: 636.4717\n",
      "Epoch 613/1000\n",
      "306/306 [==============================] - 0s 978us/step - loss: 377.8645 - val_loss: 720.3883\n",
      "Epoch 614/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 377.1385 - val_loss: 662.5665\n",
      "Epoch 615/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 377.3224 - val_loss: 614.3807\n",
      "Epoch 616/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 376.8461 - val_loss: 671.6952\n",
      "Epoch 617/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 376.5786 - val_loss: 632.5612\n",
      "Epoch 618/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 378.6157 - val_loss: 709.5941\n",
      "Epoch 619/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 376.5233 - val_loss: 649.0588\n",
      "Epoch 620/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 376.4880 - val_loss: 654.4189\n",
      "Epoch 621/1000\n",
      "306/306 [==============================] - 0s 873us/step - loss: 376.8681 - val_loss: 642.4490\n",
      "Epoch 622/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 376.7723 - val_loss: 663.1664\n",
      "Epoch 623/1000\n",
      "306/306 [==============================] - 0s 912us/step - loss: 376.1878 - val_loss: 668.2679\n",
      "Epoch 624/1000\n",
      "306/306 [==============================] - 0s 925us/step - loss: 377.3406 - val_loss: 641.8679\n",
      "Epoch 625/1000\n",
      "306/306 [==============================] - 0s 952us/step - loss: 377.7323 - val_loss: 619.0206\n",
      "Epoch 626/1000\n",
      "306/306 [==============================] - 0s 936us/step - loss: 376.8056 - val_loss: 689.1937\n",
      "Epoch 627/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 376.4234 - val_loss: 626.9756\n",
      "Epoch 628/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 377.9835 - val_loss: 650.7441\n",
      "Epoch 629/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 377.0557 - val_loss: 638.8100\n",
      "Epoch 630/1000\n",
      "306/306 [==============================] - 0s 849us/step - loss: 375.8389 - val_loss: 647.8394\n",
      "Epoch 631/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 377.6708 - val_loss: 663.9260\n",
      "Epoch 632/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 376.5601 - val_loss: 647.9697\n",
      "Epoch 633/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 376.9947 - val_loss: 677.6040\n",
      "Epoch 634/1000\n",
      "306/306 [==============================] - 0s 864us/step - loss: 376.0370 - val_loss: 696.0208\n",
      "Epoch 635/1000\n",
      "306/306 [==============================] - 0s 860us/step - loss: 376.6003 - val_loss: 662.8782\n",
      "Epoch 636/1000\n",
      "306/306 [==============================] - 0s 825us/step - loss: 377.0258 - val_loss: 673.1530\n",
      "Epoch 637/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 378.2504 - val_loss: 640.7031\n",
      "Epoch 638/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 376.0988 - val_loss: 644.7477\n",
      "Epoch 639/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 376.8435 - val_loss: 636.2907\n",
      "Epoch 640/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 376.9403 - val_loss: 667.3924\n",
      "Epoch 641/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 376.7224 - val_loss: 650.5624\n",
      "Epoch 642/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 376.6206 - val_loss: 685.3616\n",
      "Epoch 643/1000\n",
      "306/306 [==============================] - 0s 846us/step - loss: 376.7452 - val_loss: 688.8026\n",
      "Epoch 644/1000\n",
      "306/306 [==============================] - 0s 843us/step - loss: 376.5594 - val_loss: 679.2167\n",
      "Epoch 645/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 376.2780 - val_loss: 647.0001\n",
      "Epoch 646/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 377.0300 - val_loss: 626.2236\n",
      "Epoch 647/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 376.8429 - val_loss: 650.7755\n",
      "Epoch 648/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 376.2442 - val_loss: 661.9079\n",
      "Epoch 649/1000\n",
      "306/306 [==============================] - 0s 962us/step - loss: 377.8907 - val_loss: 617.0954\n",
      "Epoch 650/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 377.4855 - val_loss: 642.8545\n",
      "Epoch 651/1000\n",
      "306/306 [==============================] - 0s 978us/step - loss: 377.5182 - val_loss: 711.1230\n",
      "Epoch 652/1000\n",
      "306/306 [==============================] - 0s 892us/step - loss: 376.6950 - val_loss: 684.3265\n",
      "Epoch 653/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 376.7488 - val_loss: 683.6440\n",
      "Epoch 654/1000\n",
      "306/306 [==============================] - 0s 863us/step - loss: 376.9096 - val_loss: 635.3293\n",
      "Epoch 655/1000\n",
      "306/306 [==============================] - 0s 878us/step - loss: 377.2785 - val_loss: 644.2148\n",
      "Epoch 656/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 375.3190 - val_loss: 657.7761\n",
      "Epoch 657/1000\n",
      "306/306 [==============================] - 0s 908us/step - loss: 377.3221 - val_loss: 652.5300\n",
      "Epoch 658/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 375.8461 - val_loss: 684.7001\n",
      "Epoch 659/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 377.4250 - val_loss: 641.1451\n",
      "Epoch 660/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.8349 - val_loss: 639.8049\n",
      "Epoch 661/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 377.2783 - val_loss: 671.8363\n",
      "Epoch 662/1000\n",
      "306/306 [==============================] - 0s 929us/step - loss: 375.9897 - val_loss: 681.6264\n",
      "Epoch 663/1000\n",
      "306/306 [==============================] - 0s 887us/step - loss: 378.0841 - val_loss: 687.7638\n",
      "Epoch 664/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 376.3175 - val_loss: 642.7339\n",
      "Epoch 665/1000\n",
      "306/306 [==============================] - 0s 878us/step - loss: 377.3005 - val_loss: 671.2556\n",
      "Epoch 666/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 377.3542 - val_loss: 652.8085\n",
      "Epoch 667/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 377.0508 - val_loss: 656.2308\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 909us/step - loss: 376.9092 - val_loss: 675.7454\n",
      "Epoch 669/1000\n",
      "306/306 [==============================] - 0s 934us/step - loss: 376.7347 - val_loss: 635.0182\n",
      "Epoch 670/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.0347 - val_loss: 655.2822\n",
      "Epoch 671/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 375.7325 - val_loss: 712.2958\n",
      "Epoch 672/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 378.0164 - val_loss: 669.6467\n",
      "Epoch 673/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 377.5810 - val_loss: 635.6053\n",
      "Epoch 674/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 376.9995 - val_loss: 663.7004\n",
      "Epoch 675/1000\n",
      "306/306 [==============================] - 0s 993us/step - loss: 377.4976 - val_loss: 677.3223\n",
      "Epoch 676/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 376.7515 - val_loss: 677.9197\n",
      "Epoch 677/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 376.5007 - val_loss: 701.6075\n",
      "Epoch 678/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.6872 - val_loss: 661.5366\n",
      "Epoch 679/1000\n",
      "306/306 [==============================] - 0s 984us/step - loss: 378.8089 - val_loss: 715.4069\n",
      "Epoch 680/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.8506 - val_loss: 639.8581\n",
      "Epoch 681/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 377.6400 - val_loss: 663.4951\n",
      "Epoch 682/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.6572 - val_loss: 659.6277\n",
      "Epoch 683/1000\n",
      "306/306 [==============================] - 0s 934us/step - loss: 376.4321 - val_loss: 673.9665\n",
      "Epoch 684/1000\n",
      "306/306 [==============================] - 0s 907us/step - loss: 376.1377 - val_loss: 643.7318\n",
      "Epoch 685/1000\n",
      "306/306 [==============================] - 0s 867us/step - loss: 376.8488 - val_loss: 637.6694\n",
      "Epoch 686/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 377.8770 - val_loss: 688.5317\n",
      "Epoch 687/1000\n",
      "306/306 [==============================] - 0s 869us/step - loss: 376.6292 - val_loss: 664.2802\n",
      "Epoch 688/1000\n",
      "306/306 [==============================] - 0s 853us/step - loss: 377.2326 - val_loss: 636.1234\n",
      "Epoch 689/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 376.1572 - val_loss: 706.0605\n",
      "Epoch 690/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 377.0964 - val_loss: 667.7667\n",
      "Epoch 691/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.0556 - val_loss: 624.2533\n",
      "Epoch 692/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.5027 - val_loss: 642.9907\n",
      "Epoch 693/1000\n",
      "306/306 [==============================] - 0s 985us/step - loss: 376.7585 - val_loss: 652.6745\n",
      "Epoch 694/1000\n",
      "306/306 [==============================] - 0s 989us/step - loss: 376.0464 - val_loss: 634.7463\n",
      "Epoch 695/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 376.0313 - val_loss: 685.8876\n",
      "Epoch 696/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 376.9363 - val_loss: 682.7558\n",
      "Epoch 697/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 376.3641 - val_loss: 634.8413\n",
      "Epoch 698/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 378.6664 - val_loss: 643.9186\n",
      "Epoch 699/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 376.4449 - val_loss: 647.8596\n",
      "Epoch 700/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 377.0503 - val_loss: 642.3953\n",
      "Epoch 701/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 376.0399 - val_loss: 662.7514\n",
      "Epoch 702/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 378.0288 - val_loss: 681.3101\n",
      "Epoch 703/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 376.1057 - val_loss: 672.5002\n",
      "Epoch 704/1000\n",
      "306/306 [==============================] - 0s 994us/step - loss: 376.8806 - val_loss: 653.8751\n",
      "Epoch 705/1000\n",
      "306/306 [==============================] - 0s 854us/step - loss: 378.5056 - val_loss: 652.7948\n",
      "Epoch 706/1000\n",
      "306/306 [==============================] - 0s 892us/step - loss: 376.1119 - val_loss: 676.7064\n",
      "Epoch 707/1000\n",
      "306/306 [==============================] - 0s 883us/step - loss: 376.6378 - val_loss: 663.9268\n",
      "Epoch 708/1000\n",
      "306/306 [==============================] - 0s 905us/step - loss: 376.5472 - val_loss: 636.8503\n",
      "Epoch 709/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 377.6707 - val_loss: 642.6044\n",
      "Epoch 710/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 376.6144 - val_loss: 644.0809\n",
      "Epoch 711/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 376.6292 - val_loss: 655.0801\n",
      "Epoch 712/1000\n",
      "306/306 [==============================] - 0s 839us/step - loss: 375.9389 - val_loss: 668.8815\n",
      "Epoch 713/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 377.3212 - val_loss: 674.6505\n",
      "Epoch 714/1000\n",
      "306/306 [==============================] - 0s 994us/step - loss: 377.2412 - val_loss: 623.2220\n",
      "Epoch 715/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 379.0218 - val_loss: 655.2317\n",
      "Epoch 716/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 377.6677 - val_loss: 679.0309\n",
      "Epoch 717/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 377.2104 - val_loss: 661.6793\n",
      "Epoch 718/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 376.5610 - val_loss: 636.0692\n",
      "Epoch 719/1000\n",
      "306/306 [==============================] - 0s 931us/step - loss: 376.2521 - val_loss: 663.4333\n",
      "Epoch 720/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 376.1362 - val_loss: 648.0845\n",
      "Epoch 721/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 378.2043 - val_loss: 692.1182\n",
      "Epoch 722/1000\n",
      "306/306 [==============================] - 0s 915us/step - loss: 377.7040 - val_loss: 675.2767\n",
      "Epoch 723/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 377.5144 - val_loss: 691.1908\n",
      "Epoch 724/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 377.9456 - val_loss: 632.2688\n",
      "Epoch 725/1000\n",
      "306/306 [==============================] - 0s 935us/step - loss: 377.1724 - val_loss: 665.1630\n",
      "Epoch 726/1000\n",
      "306/306 [==============================] - 0s 864us/step - loss: 376.9303 - val_loss: 672.1413\n",
      "Epoch 727/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.6799 - val_loss: 679.7904\n",
      "Epoch 728/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.9463 - val_loss: 629.8104\n",
      "Epoch 729/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.3446 - val_loss: 669.8149\n",
      "Epoch 730/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.0388 - val_loss: 692.2561\n",
      "Epoch 731/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.4867 - val_loss: 680.4970\n",
      "Epoch 732/1000\n",
      "306/306 [==============================] - 0s 2ms/step - loss: 377.1932 - val_loss: 645.1942\n",
      "Epoch 733/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.4868 - val_loss: 650.0972\n",
      "Epoch 734/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4909 - val_loss: 649.4406\n",
      "Epoch 735/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.5571 - val_loss: 645.6816\n",
      "Epoch 736/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.9972 - val_loss: 661.1218\n",
      "Epoch 737/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2416 - val_loss: 687.0497\n",
      "Epoch 738/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.6511 - val_loss: 649.2706\n",
      "Epoch 739/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 375.9078 - val_loss: 695.3884\n",
      "Epoch 740/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5446 - val_loss: 636.1955\n",
      "Epoch 741/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3445 - val_loss: 643.7911\n",
      "Epoch 742/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.8272 - val_loss: 656.0799\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 1s 3ms/step - loss: 375.9662 - val_loss: 621.6361\n",
      "Epoch 744/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.3323 - val_loss: 657.9429\n",
      "Epoch 745/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2889 - val_loss: 639.2589\n",
      "Epoch 746/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.7948 - val_loss: 670.2809\n",
      "Epoch 747/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5822 - val_loss: 620.3749\n",
      "Epoch 748/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.8896 - val_loss: 681.6067\n",
      "Epoch 749/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 378.0412 - val_loss: 644.1850\n",
      "Epoch 750/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3217 - val_loss: 644.6945\n",
      "Epoch 751/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2463 - val_loss: 615.2487\n",
      "Epoch 752/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.7047 - val_loss: 644.5419\n",
      "Epoch 753/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2003 - val_loss: 667.3175\n",
      "Epoch 754/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.8281 - val_loss: 630.8337\n",
      "Epoch 755/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.8235 - val_loss: 657.0488\n",
      "Epoch 756/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3208 - val_loss: 685.9169\n",
      "Epoch 757/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.6684 - val_loss: 682.1901\n",
      "Epoch 758/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 378.3432 - val_loss: 632.8505\n",
      "Epoch 759/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6205 - val_loss: 656.0213\n",
      "Epoch 760/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3777 - val_loss: 644.6340\n",
      "Epoch 761/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6462 - val_loss: 638.9598\n",
      "Epoch 762/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.9252 - val_loss: 656.4146\n",
      "Epoch 763/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2752 - val_loss: 650.4332\n",
      "Epoch 764/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.1118 - val_loss: 663.5994\n",
      "Epoch 765/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5525 - val_loss: 708.3444\n",
      "Epoch 766/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 375.9284 - val_loss: 678.5513\n",
      "Epoch 767/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.2604 - val_loss: 630.6543\n",
      "Epoch 768/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.9580 - val_loss: 674.9218\n",
      "Epoch 769/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 376.5146 - val_loss: 642.1942\n",
      "Epoch 770/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2187 - val_loss: 629.0030\n",
      "Epoch 771/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4886 - val_loss: 655.4245\n",
      "Epoch 772/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.1438 - val_loss: 648.9896\n",
      "Epoch 773/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.3046 - val_loss: 649.5635\n",
      "Epoch 774/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.9012 - val_loss: 678.2202\n",
      "Epoch 775/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 376.1821 - val_loss: 711.1792\n",
      "Epoch 776/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6074 - val_loss: 621.3558\n",
      "Epoch 777/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4532 - val_loss: 678.5924\n",
      "Epoch 778/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.9081 - val_loss: 646.8958\n",
      "Epoch 779/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5933 - val_loss: 660.2280\n",
      "Epoch 780/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.0161 - val_loss: 636.8649\n",
      "Epoch 781/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.7109 - val_loss: 645.0392\n",
      "Epoch 782/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.9636 - val_loss: 672.1355\n",
      "Epoch 783/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5128 - val_loss: 621.7065\n",
      "Epoch 784/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.3619 - val_loss: 664.7277\n",
      "Epoch 785/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.0557 - val_loss: 646.2784\n",
      "Epoch 786/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.5388 - val_loss: 634.1542\n",
      "Epoch 787/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2095 - val_loss: 651.6707\n",
      "Epoch 788/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4297 - val_loss: 612.0688\n",
      "Epoch 789/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.2157 - val_loss: 648.7983\n",
      "Epoch 790/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.1952 - val_loss: 631.5474\n",
      "Epoch 791/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.7208 - val_loss: 645.2198\n",
      "Epoch 792/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.9052 - val_loss: 695.3229\n",
      "Epoch 793/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.4003 - val_loss: 677.3256\n",
      "Epoch 794/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6694 - val_loss: 631.4750\n",
      "Epoch 795/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.3290 - val_loss: 633.4065\n",
      "Epoch 796/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.2279 - val_loss: 616.5826\n",
      "Epoch 797/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.9923 - val_loss: 703.4385\n",
      "Epoch 798/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.1658 - val_loss: 679.3597\n",
      "Epoch 799/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4260 - val_loss: 672.5338\n",
      "Epoch 800/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.0538 - val_loss: 661.0735\n",
      "Epoch 801/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.0413 - val_loss: 664.7501\n",
      "Epoch 802/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3775 - val_loss: 656.8723\n",
      "Epoch 803/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 376.0717 - val_loss: 646.7596\n",
      "Epoch 804/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3947 - val_loss: 658.3408\n",
      "Epoch 805/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.1560 - val_loss: 697.8878\n",
      "Epoch 806/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.1587 - val_loss: 669.4421\n",
      "Epoch 807/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.7628 - val_loss: 647.5587\n",
      "Epoch 808/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.5418 - val_loss: 627.8096\n",
      "Epoch 809/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.7155 - val_loss: 676.4584\n",
      "Epoch 810/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.5623 - val_loss: 635.1232\n",
      "Epoch 811/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6140 - val_loss: 667.8131\n",
      "Epoch 812/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 376.3835 - val_loss: 615.4677\n",
      "Epoch 813/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.6826 - val_loss: 727.4700\n",
      "Epoch 814/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6575 - val_loss: 652.7770\n",
      "Epoch 815/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5668 - val_loss: 656.9316\n",
      "Epoch 816/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.7660 - val_loss: 673.9147\n",
      "Epoch 817/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.5699 - val_loss: 693.2495\n",
      "Epoch 818/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.9351 - val_loss: 632.4337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 819/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.9803 - val_loss: 673.4084\n",
      "Epoch 820/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.7097 - val_loss: 685.7318\n",
      "Epoch 821/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 375.6098 - val_loss: 641.6798\n",
      "Epoch 822/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2856 - val_loss: 673.7183\n",
      "Epoch 823/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2470 - val_loss: 644.0342\n",
      "Epoch 824/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 376.8452 - val_loss: 651.8534\n",
      "Epoch 825/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.8758 - val_loss: 630.7347\n",
      "Epoch 826/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.6207 - val_loss: 673.8694\n",
      "Epoch 827/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.5339 - val_loss: 677.7422\n",
      "Epoch 828/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.7716 - val_loss: 619.3248\n",
      "Epoch 829/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.4400 - val_loss: 652.4818\n",
      "Epoch 830/1000\n",
      "306/306 [==============================] - 0s 982us/step - loss: 376.8164 - val_loss: 672.5909\n",
      "Epoch 831/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2828 - val_loss: 692.4475\n",
      "Epoch 832/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 377.1952 - val_loss: 631.6225\n",
      "Epoch 833/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 376.3767 - val_loss: 669.2245\n",
      "Epoch 834/1000\n",
      "306/306 [==============================] - 0s 894us/step - loss: 378.4596 - val_loss: 614.5948\n",
      "Epoch 835/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 376.4516 - val_loss: 681.5825\n",
      "Epoch 836/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 376.6028 - val_loss: 692.5552\n",
      "Epoch 837/1000\n",
      "306/306 [==============================] - 0s 983us/step - loss: 376.3314 - val_loss: 659.8584\n",
      "Epoch 838/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.0592 - val_loss: 662.3749\n",
      "Epoch 839/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.0758 - val_loss: 656.0809\n",
      "Epoch 840/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.3615 - val_loss: 654.8185\n",
      "Epoch 841/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.9484 - val_loss: 642.8793\n",
      "Epoch 842/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 376.5606 - val_loss: 659.3664\n",
      "Epoch 843/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.2611 - val_loss: 645.2925\n",
      "Epoch 844/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.8439 - val_loss: 675.9528\n",
      "Epoch 845/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 375.7941 - val_loss: 634.6713\n",
      "Epoch 846/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 377.5859 - val_loss: 644.6177\n",
      "Epoch 847/1000\n",
      "306/306 [==============================] - 0s 887us/step - loss: 376.5500 - val_loss: 635.6949\n",
      "Epoch 848/1000\n",
      "306/306 [==============================] - 0s 836us/step - loss: 376.8910 - val_loss: 664.6506\n",
      "Epoch 849/1000\n",
      "306/306 [==============================] - 0s 864us/step - loss: 376.0017 - val_loss: 676.4493\n",
      "Epoch 850/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 375.6820 - val_loss: 645.5939\n",
      "Epoch 851/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 377.0928 - val_loss: 668.7535\n",
      "Epoch 852/1000\n",
      "306/306 [==============================] - 0s 862us/step - loss: 375.6805 - val_loss: 637.8798\n",
      "Epoch 853/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 377.1203 - val_loss: 669.9186\n",
      "Epoch 854/1000\n",
      "306/306 [==============================] - 0s 919us/step - loss: 376.5682 - val_loss: 689.7025\n",
      "Epoch 855/1000\n",
      "306/306 [==============================] - 0s 970us/step - loss: 376.3637 - val_loss: 673.6945\n",
      "Epoch 856/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 376.2603 - val_loss: 627.2698\n",
      "Epoch 857/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 376.3824 - val_loss: 656.5515\n",
      "Epoch 858/1000\n",
      "306/306 [==============================] - 0s 847us/step - loss: 377.5110 - val_loss: 700.0521\n",
      "Epoch 859/1000\n",
      "306/306 [==============================] - 0s 883us/step - loss: 377.3620 - val_loss: 692.1343\n",
      "Epoch 860/1000\n",
      "306/306 [==============================] - 0s 837us/step - loss: 375.9878 - val_loss: 631.9848\n",
      "Epoch 861/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 376.5908 - val_loss: 656.6349\n",
      "Epoch 862/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 378.1565 - val_loss: 653.8523\n",
      "Epoch 863/1000\n",
      "306/306 [==============================] - 0s 889us/step - loss: 375.9209 - val_loss: 669.0185\n",
      "Epoch 864/1000\n",
      "306/306 [==============================] - 0s 848us/step - loss: 375.8548 - val_loss: 725.5286\n",
      "Epoch 865/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 377.2180 - val_loss: 654.4992\n",
      "Epoch 866/1000\n",
      "306/306 [==============================] - 0s 960us/step - loss: 377.7008 - val_loss: 678.8164\n",
      "Epoch 867/1000\n",
      "306/306 [==============================] - 0s 983us/step - loss: 375.8256 - val_loss: 644.8284\n",
      "Epoch 868/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 376.8470 - val_loss: 646.9789\n",
      "Epoch 869/1000\n",
      "306/306 [==============================] - 0s 971us/step - loss: 377.0365 - val_loss: 685.9563\n",
      "Epoch 870/1000\n",
      "306/306 [==============================] - 0s 951us/step - loss: 377.0413 - val_loss: 668.7973\n",
      "Epoch 871/1000\n",
      "306/306 [==============================] - 0s 969us/step - loss: 377.7573 - val_loss: 656.3199\n",
      "Epoch 872/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 376.7097 - val_loss: 629.5068\n",
      "Epoch 873/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 377.6718 - val_loss: 681.9343\n",
      "Epoch 874/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 377.4704 - val_loss: 638.9189\n",
      "Epoch 875/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 376.9142 - val_loss: 684.1799\n",
      "Epoch 876/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 376.8150 - val_loss: 670.0425\n",
      "Epoch 877/1000\n",
      "306/306 [==============================] - 0s 932us/step - loss: 375.6219 - val_loss: 651.0414\n",
      "Epoch 878/1000\n",
      "306/306 [==============================] - 0s 861us/step - loss: 376.3769 - val_loss: 649.7325\n",
      "Epoch 879/1000\n",
      "306/306 [==============================] - 0s 912us/step - loss: 376.6575 - val_loss: 682.6642\n",
      "Epoch 880/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 378.5685 - val_loss: 709.9277\n",
      "Epoch 881/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 376.6885 - val_loss: 633.4992\n",
      "Epoch 882/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 376.9831 - val_loss: 633.4531\n",
      "Epoch 883/1000\n",
      "306/306 [==============================] - 0s 840us/step - loss: 376.8391 - val_loss: 653.1478\n",
      "Epoch 884/1000\n",
      "306/306 [==============================] - 0s 860us/step - loss: 377.2471 - val_loss: 693.1755\n",
      "Epoch 885/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.7449 - val_loss: 654.1600\n",
      "Epoch 886/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 377.0142 - val_loss: 691.8387\n",
      "Epoch 887/1000\n",
      "306/306 [==============================] - 0s 984us/step - loss: 376.2705 - val_loss: 648.6395\n",
      "Epoch 888/1000\n",
      "306/306 [==============================] - 0s 932us/step - loss: 376.6567 - val_loss: 649.6604\n",
      "Epoch 889/1000\n",
      "306/306 [==============================] - 0s 951us/step - loss: 376.9191 - val_loss: 713.3937\n",
      "Epoch 890/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 376.1132 - val_loss: 667.3622\n",
      "Epoch 891/1000\n",
      "306/306 [==============================] - 0s 941us/step - loss: 376.7582 - val_loss: 674.8460\n",
      "Epoch 892/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 378.9479 - val_loss: 673.5698\n",
      "Epoch 893/1000\n",
      "306/306 [==============================] - 0s 887us/step - loss: 376.5374 - val_loss: 681.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 376.2024 - val_loss: 718.7902\n",
      "Epoch 895/1000\n",
      "306/306 [==============================] - 0s 938us/step - loss: 376.1560 - val_loss: 665.6384\n",
      "Epoch 896/1000\n",
      "306/306 [==============================] - 0s 963us/step - loss: 375.7243 - val_loss: 650.5802\n",
      "Epoch 897/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 376.5804 - val_loss: 665.7024\n",
      "Epoch 898/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 377.8563 - val_loss: 690.4075\n",
      "Epoch 899/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 376.6646 - val_loss: 653.5164\n",
      "Epoch 900/1000\n",
      "306/306 [==============================] - 0s 983us/step - loss: 378.3756 - val_loss: 664.0841\n",
      "Epoch 901/1000\n",
      "306/306 [==============================] - 0s 839us/step - loss: 377.1407 - val_loss: 642.1483\n",
      "Epoch 902/1000\n",
      "306/306 [==============================] - 0s 899us/step - loss: 376.4655 - val_loss: 629.6737\n",
      "Epoch 903/1000\n",
      "306/306 [==============================] - 0s 887us/step - loss: 377.0901 - val_loss: 634.9009\n",
      "Epoch 904/1000\n",
      "306/306 [==============================] - 0s 862us/step - loss: 376.4613 - val_loss: 672.1472\n",
      "Epoch 905/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 376.7114 - val_loss: 715.8499\n",
      "Epoch 906/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 375.9740 - val_loss: 624.2642\n",
      "Epoch 907/1000\n",
      "306/306 [==============================] - 0s 851us/step - loss: 376.1053 - val_loss: 670.9909\n",
      "Epoch 908/1000\n",
      "306/306 [==============================] - 0s 896us/step - loss: 376.8742 - val_loss: 683.8243\n",
      "Epoch 909/1000\n",
      "306/306 [==============================] - 0s 868us/step - loss: 376.3737 - val_loss: 664.5647\n",
      "Epoch 910/1000\n",
      "306/306 [==============================] - 0s 840us/step - loss: 377.0817 - val_loss: 641.6296\n",
      "Epoch 911/1000\n",
      "306/306 [==============================] - 0s 823us/step - loss: 375.8200 - val_loss: 653.0757\n",
      "Epoch 912/1000\n",
      "306/306 [==============================] - 0s 903us/step - loss: 377.9650 - val_loss: 664.1348\n",
      "Epoch 913/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 375.7127 - val_loss: 655.4456\n",
      "Epoch 914/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 376.3341 - val_loss: 699.3244\n",
      "Epoch 915/1000\n",
      "306/306 [==============================] - 0s 925us/step - loss: 376.7147 - val_loss: 642.5801\n",
      "Epoch 916/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 376.6499 - val_loss: 671.4103\n",
      "Epoch 917/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 375.7707 - val_loss: 658.3116\n",
      "Epoch 918/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 376.8659 - val_loss: 676.3306\n",
      "Epoch 919/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 376.2986 - val_loss: 634.6673\n",
      "Epoch 920/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 376.7167 - val_loss: 627.2319\n",
      "Epoch 921/1000\n",
      "306/306 [==============================] - 0s 897us/step - loss: 377.7003 - val_loss: 644.1177\n",
      "Epoch 922/1000\n",
      "306/306 [==============================] - 0s 903us/step - loss: 376.6106 - val_loss: 638.2476\n",
      "Epoch 923/1000\n",
      "306/306 [==============================] - 0s 934us/step - loss: 376.2052 - val_loss: 631.7530\n",
      "Epoch 924/1000\n",
      "306/306 [==============================] - 0s 988us/step - loss: 376.6042 - val_loss: 676.8166\n",
      "Epoch 925/1000\n",
      "306/306 [==============================] - 0s 875us/step - loss: 377.6440 - val_loss: 683.5294\n",
      "Epoch 926/1000\n",
      "306/306 [==============================] - 0s 908us/step - loss: 377.0313 - val_loss: 682.1138\n",
      "Epoch 927/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 376.2799 - val_loss: 677.3655\n",
      "Epoch 928/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 377.5099 - val_loss: 666.1989\n",
      "Epoch 929/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 378.2057 - val_loss: 651.0715\n",
      "Epoch 930/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2247 - val_loss: 665.0895\n",
      "Epoch 931/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 375.4558 - val_loss: 630.4020\n",
      "Epoch 932/1000\n",
      "306/306 [==============================] - 0s 916us/step - loss: 377.0088 - val_loss: 675.0096\n",
      "Epoch 933/1000\n",
      "306/306 [==============================] - 0s 939us/step - loss: 375.8731 - val_loss: 630.1809\n",
      "Epoch 934/1000\n",
      "306/306 [==============================] - 0s 878us/step - loss: 376.5651 - val_loss: 655.4441\n",
      "Epoch 935/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.3121 - val_loss: 621.8265\n",
      "Epoch 936/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 376.5160 - val_loss: 701.8004\n",
      "Epoch 937/1000\n",
      "306/306 [==============================] - 0s 867us/step - loss: 375.9202 - val_loss: 630.7947\n",
      "Epoch 938/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.8928 - val_loss: 636.2429\n",
      "Epoch 939/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 376.6832 - val_loss: 640.5786\n",
      "Epoch 940/1000\n",
      "306/306 [==============================] - 0s 857us/step - loss: 377.5161 - val_loss: 634.1090\n",
      "Epoch 941/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 377.0765 - val_loss: 690.1431\n",
      "Epoch 942/1000\n",
      "306/306 [==============================] - 0s 952us/step - loss: 375.9776 - val_loss: 628.7468\n",
      "Epoch 943/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 376.9547 - val_loss: 619.8049\n",
      "Epoch 944/1000\n",
      "306/306 [==============================] - 0s 845us/step - loss: 377.5578 - val_loss: 642.0438\n",
      "Epoch 945/1000\n",
      "306/306 [==============================] - 0s 868us/step - loss: 377.2819 - val_loss: 626.0226\n",
      "Epoch 946/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 376.8075 - val_loss: 669.8616\n",
      "Epoch 947/1000\n",
      "306/306 [==============================] - 0s 875us/step - loss: 376.6404 - val_loss: 635.4019\n",
      "Epoch 948/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 377.7452 - val_loss: 649.6267\n",
      "Epoch 949/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 377.1042 - val_loss: 658.4584\n",
      "Epoch 950/1000\n",
      "306/306 [==============================] - 0s 886us/step - loss: 375.9863 - val_loss: 662.2129\n",
      "Epoch 951/1000\n",
      "306/306 [==============================] - 0s 954us/step - loss: 376.3385 - val_loss: 721.1440\n",
      "Epoch 952/1000\n",
      "306/306 [==============================] - 0s 905us/step - loss: 376.6025 - val_loss: 724.8478\n",
      "Epoch 953/1000\n",
      "306/306 [==============================] - 0s 896us/step - loss: 377.3182 - val_loss: 659.1741\n",
      "Epoch 954/1000\n",
      "306/306 [==============================] - 0s 926us/step - loss: 375.7856 - val_loss: 662.9410\n",
      "Epoch 955/1000\n",
      "306/306 [==============================] - 0s 953us/step - loss: 376.4834 - val_loss: 663.8303\n",
      "Epoch 956/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 376.6987 - val_loss: 645.9927\n",
      "Epoch 957/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 375.7481 - val_loss: 641.6994\n",
      "Epoch 958/1000\n",
      "306/306 [==============================] - 0s 940us/step - loss: 376.2783 - val_loss: 679.0236\n",
      "Epoch 959/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 376.7026 - val_loss: 665.1874\n",
      "Epoch 960/1000\n",
      "306/306 [==============================] - 0s 815us/step - loss: 376.0112 - val_loss: 686.6555\n",
      "Epoch 961/1000\n",
      "306/306 [==============================] - 0s 874us/step - loss: 376.3078 - val_loss: 681.7307\n",
      "Epoch 962/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 377.8055 - val_loss: 672.3560\n",
      "Epoch 963/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 376.6385 - val_loss: 684.8071\n",
      "Epoch 964/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 376.1516 - val_loss: 698.9270\n",
      "Epoch 965/1000\n",
      "306/306 [==============================] - 0s 916us/step - loss: 376.5632 - val_loss: 686.8330\n",
      "Epoch 966/1000\n",
      "306/306 [==============================] - 0s 926us/step - loss: 377.6211 - val_loss: 663.4271\n",
      "Epoch 967/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 376.9543 - val_loss: 686.0061\n",
      "Epoch 968/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 977us/step - loss: 376.7314 - val_loss: 641.7000\n",
      "Epoch 969/1000\n",
      "306/306 [==============================] - 0s 843us/step - loss: 376.3375 - val_loss: 649.9773\n",
      "Epoch 970/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 376.2517 - val_loss: 623.9791\n",
      "Epoch 971/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 377.1015 - val_loss: 702.1207\n",
      "Epoch 972/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.1210 - val_loss: 648.8347\n",
      "Epoch 973/1000\n",
      "306/306 [==============================] - 0s 883us/step - loss: 376.2775 - val_loss: 642.9918\n",
      "Epoch 974/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 377.2425 - val_loss: 629.2966\n",
      "Epoch 975/1000\n",
      "306/306 [==============================] - 0s 865us/step - loss: 377.0097 - val_loss: 645.3540\n",
      "Epoch 976/1000\n",
      "306/306 [==============================] - 0s 908us/step - loss: 376.9926 - val_loss: 638.6667\n",
      "Epoch 977/1000\n",
      "306/306 [==============================] - 0s 998us/step - loss: 376.2220 - val_loss: 664.1487\n",
      "Epoch 978/1000\n",
      "306/306 [==============================] - 0s 877us/step - loss: 377.2578 - val_loss: 620.8152\n",
      "Epoch 979/1000\n",
      "306/306 [==============================] - 0s 872us/step - loss: 376.5573 - val_loss: 683.1656\n",
      "Epoch 980/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 376.5830 - val_loss: 619.4189\n",
      "Epoch 981/1000\n",
      "306/306 [==============================] - 0s 929us/step - loss: 376.4390 - val_loss: 669.0353\n",
      "Epoch 982/1000\n",
      "306/306 [==============================] - 0s 881us/step - loss: 376.1884 - val_loss: 679.0941\n",
      "Epoch 983/1000\n",
      "306/306 [==============================] - 0s 952us/step - loss: 377.0507 - val_loss: 634.9178\n",
      "Epoch 984/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 376.8678 - val_loss: 700.8135\n",
      "Epoch 985/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 377.6125 - val_loss: 632.4811\n",
      "Epoch 986/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 376.8264 - val_loss: 654.7578\n",
      "Epoch 987/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 376.2354 - val_loss: 646.8673\n",
      "Epoch 988/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 375.7956 - val_loss: 677.5084\n",
      "Epoch 989/1000\n",
      "306/306 [==============================] - 0s 962us/step - loss: 376.9041 - val_loss: 682.9476\n",
      "Epoch 990/1000\n",
      "306/306 [==============================] - 0s 894us/step - loss: 377.2148 - val_loss: 679.9526\n",
      "Epoch 991/1000\n",
      "306/306 [==============================] - 0s 949us/step - loss: 376.2468 - val_loss: 685.3542\n",
      "Epoch 992/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 375.8989 - val_loss: 643.4043\n",
      "Epoch 993/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.7576 - val_loss: 668.7538\n",
      "Epoch 994/1000\n",
      "306/306 [==============================] - 0s 978us/step - loss: 376.1052 - val_loss: 667.8942\n",
      "Epoch 995/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.8075 - val_loss: 635.0323\n",
      "Epoch 996/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.4827 - val_loss: 609.2195\n",
      "Epoch 997/1000\n",
      "306/306 [==============================] - 0s 988us/step - loss: 377.7238 - val_loss: 665.8333\n",
      "Epoch 998/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 375.8245 - val_loss: 684.0662\n",
      "Epoch 999/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 379.2137 - val_loss: 658.9714\n",
      "Epoch 1000/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.5586 - val_loss: 675.5674\n",
      "46/46 [==============================] - 0s 635us/step\n",
      "1014692 successful\n",
      "Epoch 1/1000\n",
      "302/302 [==============================] - 1s 1ms/step - loss: 51100936.0000 - val_loss: 673.1472\n",
      "Epoch 2/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.8465 - val_loss: 720.3132\n",
      "Epoch 3/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.6205 - val_loss: 729.0806\n",
      "Epoch 4/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.3606 - val_loss: 707.7944\n",
      "Epoch 5/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 361.8488 - val_loss: 798.5742\n",
      "Epoch 6/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 366.0503 - val_loss: 658.6378\n",
      "Epoch 7/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 362.0444 - val_loss: 644.7413\n",
      "Epoch 8/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 381.9134 - val_loss: 609.8887\n",
      "Epoch 9/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 392.2898 - val_loss: 611.8759\n",
      "Epoch 10/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 435.5177 - val_loss: 617.8886\n",
      "Epoch 11/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 430.1154 - val_loss: 609.7782\n",
      "Epoch 12/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 430.8732 - val_loss: 1013.3246\n",
      "Epoch 13/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 458.0296 - val_loss: 1048.5065\n",
      "Epoch 14/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 434.3365 - val_loss: 927.6290\n",
      "Epoch 15/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 502.2624 - val_loss: 707.9219\n",
      "Epoch 16/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 709.7697 - val_loss: 900.5232\n",
      "Epoch 17/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 615.2348 - val_loss: 737.6921\n",
      "Epoch 18/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 1152.2327 - val_loss: 2520.8625\n",
      "Epoch 19/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 4668.7188 - val_loss: 34606.5195\n",
      "Epoch 20/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 42406.7031 - val_loss: 96760.1797\n",
      "Epoch 21/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 54532.0742 - val_loss: 27977.8633\n",
      "Epoch 22/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 44625.6992 - val_loss: 1611.0031\n",
      "Epoch 23/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 47569.0117 - val_loss: 33476.5000\n",
      "Epoch 24/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 44878.7695 - val_loss: 19182.6562\n",
      "Epoch 25/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 58722.3984 - val_loss: 14218.8945\n",
      "Epoch 26/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 29898.2285 - val_loss: 18475.7363\n",
      "Epoch 27/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 44492.2500 - val_loss: 27830.1230\n",
      "Epoch 28/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 42945.1680 - val_loss: 818.5386\n",
      "Epoch 29/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 42059.4727 - val_loss: 19437.5762\n",
      "Epoch 30/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 41219.6406 - val_loss: 22117.4199\n",
      "Epoch 31/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 41177.5391 - val_loss: 5582.6865\n",
      "Epoch 32/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 39211.9844 - val_loss: 20150.3027\n",
      "Epoch 33/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 40519.7852 - val_loss: 756.5637\n",
      "Epoch 34/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 34183.8047 - val_loss: 5610.3862\n",
      "Epoch 35/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 33431.2188 - val_loss: 67335.0938\n",
      "Epoch 36/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 40728.7305 - val_loss: 668.6897\n",
      "Epoch 37/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 30716.1133 - val_loss: 16739.0684\n",
      "Epoch 38/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 35661.4531 - val_loss: 5452.7739\n",
      "Epoch 39/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 29288.1289 - val_loss: 8989.8398\n",
      "Epoch 40/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 31161.1582 - val_loss: 1262.3414\n",
      "Epoch 41/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 30180.2520 - val_loss: 11841.0479\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 1s 2ms/step - loss: 31388.7070 - val_loss: 37431.4180\n",
      "Epoch 43/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 25982.2500 - val_loss: 3984.8936\n",
      "Epoch 44/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 31891.8789 - val_loss: 16742.9316\n",
      "Epoch 45/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 23323.8086 - val_loss: 6219.7886\n",
      "Epoch 46/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 24710.6035 - val_loss: 795.3392\n",
      "Epoch 47/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 25137.9395 - val_loss: 2634.1118\n",
      "Epoch 48/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 23429.5488 - val_loss: 10250.7256\n",
      "Epoch 49/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 27215.0430 - val_loss: 722.1696\n",
      "Epoch 50/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 22008.7637 - val_loss: 13117.0029\n",
      "Epoch 51/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 22954.5371 - val_loss: 47609.4414\n",
      "Epoch 52/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 20195.3242 - val_loss: 51580.0430\n",
      "Epoch 53/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 23837.2910 - val_loss: 657.4044\n",
      "Epoch 54/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 20271.4727 - val_loss: 6557.0264\n",
      "Epoch 55/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 19145.8203 - val_loss: 31851.1953\n",
      "Epoch 56/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 11414.2783 - val_loss: 8368.8154\n",
      "Epoch 57/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 14494.1875 - val_loss: 27959.4727\n",
      "Epoch 58/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 15559.8584 - val_loss: 12038.5391\n",
      "Epoch 59/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 15002.2646 - val_loss: 107479.4766\n",
      "Epoch 60/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 13593.0078 - val_loss: 13433.4980\n",
      "Epoch 61/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 17942.0234 - val_loss: 1031.0311\n",
      "Epoch 62/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 16612.6953 - val_loss: 7332.0830\n",
      "Epoch 63/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 11426.8857 - val_loss: 701.5336\n",
      "Epoch 64/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 14194.7324 - val_loss: 5091.0034\n",
      "Epoch 65/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 14247.2578 - val_loss: 17706.1621\n",
      "Epoch 66/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 15678.3564 - val_loss: 615.5285\n",
      "Epoch 67/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 12647.2969 - val_loss: 5954.7729\n",
      "Epoch 68/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 13219.2705 - val_loss: 8251.3154\n",
      "Epoch 69/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 14337.0547 - val_loss: 1438.3291\n",
      "Epoch 70/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 11843.6211 - val_loss: 1270.4960\n",
      "Epoch 71/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 14105.3262 - val_loss: 6030.5366\n",
      "Epoch 72/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 12954.6699 - val_loss: 1455.1619\n",
      "Epoch 73/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 12422.9004 - val_loss: 743.0343\n",
      "Epoch 74/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 846277.3125 - val_loss: 154313.5625\n",
      "Epoch 75/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 12011.2549 - val_loss: 626.1301\n",
      "Epoch 76/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 406.8169 - val_loss: 770.7404\n",
      "Epoch 77/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 409.2556 - val_loss: 616.4680\n",
      "Epoch 78/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 434.9095 - val_loss: 646.9902\n",
      "Epoch 79/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 484.0474 - val_loss: 1045.1597\n",
      "Epoch 80/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 466.1638 - val_loss: 960.0068\n",
      "Epoch 81/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 509.6581 - val_loss: 663.8715\n",
      "Epoch 82/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 602.1584 - val_loss: 647.7128\n",
      "Epoch 83/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 669.2695 - val_loss: 2111.5229\n",
      "Epoch 84/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 839.9875 - val_loss: 641.6990\n",
      "Epoch 85/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 1823.3417 - val_loss: 734.8061\n",
      "Epoch 86/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6564.5562 - val_loss: 879.4422\n",
      "Epoch 87/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 8755.5000 - val_loss: 20097.2559\n",
      "Epoch 88/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 8054.2197 - val_loss: 1390.2949\n",
      "Epoch 89/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 9679.5059 - val_loss: 8734.1973\n",
      "Epoch 90/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 8162.1797 - val_loss: 19244.7812\n",
      "Epoch 91/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 9429.4248 - val_loss: 699.3543\n",
      "Epoch 92/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 7856.5723 - val_loss: 714.9976\n",
      "Epoch 93/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 9127.5205 - val_loss: 6706.3389\n",
      "Epoch 94/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 8082.2451 - val_loss: 6652.8730\n",
      "Epoch 95/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6792.5107 - val_loss: 711.5358\n",
      "Epoch 96/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 9184.7725 - val_loss: 2722.7554\n",
      "Epoch 97/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 7421.5688 - val_loss: 1366.5222\n",
      "Epoch 98/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6608.7222 - val_loss: 745.5944\n",
      "Epoch 99/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 9196.3955 - val_loss: 3616.0349\n",
      "Epoch 100/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 5528.4844 - val_loss: 681.0605\n",
      "Epoch 101/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 8085.2891 - val_loss: 26400.9219\n",
      "Epoch 102/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6307.9360 - val_loss: 43986.1406\n",
      "Epoch 103/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 7537.5796 - val_loss: 11390.5059\n",
      "Epoch 104/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 6440.9844 - val_loss: 1029.0469\n",
      "Epoch 105/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 5895.3774 - val_loss: 6494.3306\n",
      "Epoch 106/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6735.2319 - val_loss: 25207.0859\n",
      "Epoch 107/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6440.1162 - val_loss: 22080.0137\n",
      "Epoch 108/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6288.3564 - val_loss: 14829.7354\n",
      "Epoch 109/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 6541.1890 - val_loss: 908.1147\n",
      "Epoch 110/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6115.0063 - val_loss: 22369.8516\n",
      "Epoch 111/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 5381.0859 - val_loss: 2235.7231\n",
      "Epoch 112/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 6445.8335 - val_loss: 6642.5947\n",
      "Epoch 113/1000\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 5002.8105 - val_loss: 6909.0068\n",
      "Epoch 114/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5056.2261 - val_loss: 4194.1440\n",
      "Epoch 115/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 6329.3369 - val_loss: 4413.1602\n",
      "Epoch 116/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 4810.2607 - val_loss: 10359.0547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "302/302 [==============================] - 0s 956us/step - loss: 5809.5508 - val_loss: 940.1435\n",
      "Epoch 118/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 4014.3728 - val_loss: 9460.1006\n",
      "Epoch 119/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5678.3682 - val_loss: 7452.3979\n",
      "Epoch 120/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 4555.5508 - val_loss: 4758.4683\n",
      "Epoch 121/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 4477.3955 - val_loss: 14358.9775\n",
      "Epoch 122/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5272.7236 - val_loss: 834.0128\n",
      "Epoch 123/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5134.2275 - val_loss: 14185.4619\n",
      "Epoch 124/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3774.7083 - val_loss: 6985.9570\n",
      "Epoch 125/1000\n",
      "302/302 [==============================] - 0s 984us/step - loss: 4295.9385 - val_loss: 12231.3672\n",
      "Epoch 126/1000\n",
      "302/302 [==============================] - 0s 891us/step - loss: 4344.8853 - val_loss: 1764.5050\n",
      "Epoch 127/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5686.2271 - val_loss: 1061.1163\n",
      "Epoch 128/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3165.4167 - val_loss: 2607.9658\n",
      "Epoch 129/1000\n",
      "302/302 [==============================] - 0s 887us/step - loss: 4185.6011 - val_loss: 5092.5083\n",
      "Epoch 130/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 4334.9575 - val_loss: 1823.4004\n",
      "Epoch 131/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 3684.6931 - val_loss: 1113.3259\n",
      "Epoch 132/1000\n",
      "302/302 [==============================] - 0s 831us/step - loss: 3980.0369 - val_loss: 2313.4404\n",
      "Epoch 133/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 3614.7183 - val_loss: 4457.9746\n",
      "Epoch 134/1000\n",
      "302/302 [==============================] - 0s 911us/step - loss: 5013.5688 - val_loss: 1326.4246\n",
      "Epoch 135/1000\n",
      "302/302 [==============================] - 0s 990us/step - loss: 2676.0037 - val_loss: 9711.4277\n",
      "Epoch 136/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 4082.6531 - val_loss: 1672.3356\n",
      "Epoch 137/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3243.2639 - val_loss: 12948.4561\n",
      "Epoch 138/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3689.2637 - val_loss: 5640.5767\n",
      "Epoch 139/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 4224.1279 - val_loss: 1176.4232\n",
      "Epoch 140/1000\n",
      "302/302 [==============================] - 0s 974us/step - loss: 2454.8669 - val_loss: 1390.0646\n",
      "Epoch 141/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3826.9458 - val_loss: 2648.9058\n",
      "Epoch 142/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 2914.8501 - val_loss: 649.8594\n",
      "Epoch 143/1000\n",
      "302/302 [==============================] - 0s 941us/step - loss: 2839.3442 - val_loss: 679.8779\n",
      "Epoch 144/1000\n",
      "302/302 [==============================] - 0s 936us/step - loss: 3316.2126 - val_loss: 894.6457\n",
      "Epoch 145/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2559.8909 - val_loss: 1252.2040\n",
      "Epoch 146/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3606.1406 - val_loss: 818.6420\n",
      "Epoch 147/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2607.1274 - val_loss: 2045.1904\n",
      "Epoch 148/1000\n",
      "302/302 [==============================] - 0s 992us/step - loss: 2887.5930 - val_loss: 1226.8954\n",
      "Epoch 149/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 2891.5437 - val_loss: 3766.4504\n",
      "Epoch 150/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3281.6638 - val_loss: 4221.6294\n",
      "Epoch 151/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 2405.9431 - val_loss: 5120.3013\n",
      "Epoch 152/1000\n",
      "302/302 [==============================] - 0s 870us/step - loss: 2087.5203 - val_loss: 8037.3218\n",
      "Epoch 153/1000\n",
      "302/302 [==============================] - 0s 948us/step - loss: 3825.1758 - val_loss: 950.1523\n",
      "Epoch 154/1000\n",
      "302/302 [==============================] - 0s 897us/step - loss: 2108.5986 - val_loss: 695.5175\n",
      "Epoch 155/1000\n",
      "302/302 [==============================] - 0s 955us/step - loss: 2193.5396 - val_loss: 2178.0076\n",
      "Epoch 156/1000\n",
      "302/302 [==============================] - 0s 888us/step - loss: 2676.5776 - val_loss: 6904.3823\n",
      "Epoch 157/1000\n",
      "302/302 [==============================] - 0s 964us/step - loss: 1746.3994 - val_loss: 2067.0613\n",
      "Epoch 158/1000\n",
      "302/302 [==============================] - 0s 925us/step - loss: 2931.7961 - val_loss: 673.6808\n",
      "Epoch 159/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 2381.4089 - val_loss: 2902.1270\n",
      "Epoch 160/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2235.1968 - val_loss: 3868.0952\n",
      "Epoch 161/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2197.2046 - val_loss: 837.2858\n",
      "Epoch 162/1000\n",
      "302/302 [==============================] - 0s 937us/step - loss: 2274.9973 - val_loss: 1817.6227\n",
      "Epoch 163/1000\n",
      "302/302 [==============================] - 0s 893us/step - loss: 1898.4424 - val_loss: 1095.2871\n",
      "Epoch 164/1000\n",
      "302/302 [==============================] - 0s 993us/step - loss: 2333.9434 - val_loss: 6378.8359\n",
      "Epoch 165/1000\n",
      "302/302 [==============================] - 0s 870us/step - loss: 1782.3445 - val_loss: 4347.4263\n",
      "Epoch 166/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 1975.0486 - val_loss: 5203.7124\n",
      "Epoch 167/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 1682.1848 - val_loss: 2134.4106\n",
      "Epoch 168/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2251.5574 - val_loss: 864.9283\n",
      "Epoch 169/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2233.4382 - val_loss: 2104.1545\n",
      "Epoch 170/1000\n",
      "302/302 [==============================] - 0s 952us/step - loss: 1507.1143 - val_loss: 2742.6707\n",
      "Epoch 171/1000\n",
      "302/302 [==============================] - 0s 910us/step - loss: 1614.0203 - val_loss: 5525.0200\n",
      "Epoch 172/1000\n",
      "302/302 [==============================] - 0s 910us/step - loss: 2331.5847 - val_loss: 1558.9962\n",
      "Epoch 173/1000\n",
      "302/302 [==============================] - 0s 932us/step - loss: 1898.8784 - val_loss: 776.3033\n",
      "Epoch 174/1000\n",
      "302/302 [==============================] - 0s 869us/step - loss: 1476.7355 - val_loss: 771.6942\n",
      "Epoch 175/1000\n",
      "302/302 [==============================] - 0s 909us/step - loss: 1472.2594 - val_loss: 919.8709\n",
      "Epoch 176/1000\n",
      "302/302 [==============================] - 0s 894us/step - loss: 1813.8412 - val_loss: 4625.2344\n",
      "Epoch 177/1000\n",
      "302/302 [==============================] - 0s 960us/step - loss: 2182.5867 - val_loss: 695.5447\n",
      "Epoch 178/1000\n",
      "302/302 [==============================] - 0s 879us/step - loss: 1564.9768 - val_loss: 609.7604\n",
      "Epoch 179/1000\n",
      "302/302 [==============================] - 0s 937us/step - loss: 101663.9922 - val_loss: 829.0640\n",
      "Epoch 180/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 379.3944 - val_loss: 668.2944\n",
      "Epoch 181/1000\n",
      "302/302 [==============================] - 0s 938us/step - loss: 401.4668 - val_loss: 620.4416\n",
      "Epoch 182/1000\n",
      "302/302 [==============================] - 0s 992us/step - loss: 391.6537 - val_loss: 1261.3030\n",
      "Epoch 183/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 412.1355 - val_loss: 617.4804\n",
      "Epoch 184/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 419.7297 - val_loss: 741.3752\n",
      "Epoch 185/1000\n",
      "302/302 [==============================] - 0s 864us/step - loss: 482.3771 - val_loss: 694.2970\n",
      "Epoch 186/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 531.6913 - val_loss: 957.4276\n",
      "Epoch 187/1000\n",
      "302/302 [==============================] - 0s 920us/step - loss: 603.2005 - val_loss: 1845.0232\n",
      "Epoch 188/1000\n",
      "302/302 [==============================] - 0s 876us/step - loss: 668.0328 - val_loss: 1356.9709\n",
      "Epoch 189/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 748.7587 - val_loss: 1251.7003\n",
      "Epoch 190/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 921.7736 - val_loss: 770.0947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000\n",
      "302/302 [==============================] - 0s 990us/step - loss: 874.9353 - val_loss: 1212.7526\n",
      "Epoch 192/1000\n",
      "302/302 [==============================] - 0s 907us/step - loss: 1506.7682 - val_loss: 3236.5964\n",
      "Epoch 193/1000\n",
      "302/302 [==============================] - 0s 973us/step - loss: 1162.5272 - val_loss: 706.2133\n",
      "Epoch 194/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 1044.1482 - val_loss: 1562.7406\n",
      "Epoch 195/1000\n",
      "302/302 [==============================] - 0s 890us/step - loss: 1317.0007 - val_loss: 1277.5203\n",
      "Epoch 196/1000\n",
      "302/302 [==============================] - 0s 951us/step - loss: 1503.5309 - val_loss: 1313.4393\n",
      "Epoch 197/1000\n",
      "302/302 [==============================] - 0s 892us/step - loss: 1358.6023 - val_loss: 609.7560\n",
      "Epoch 198/1000\n",
      "302/302 [==============================] - 0s 860us/step - loss: 1356.5906 - val_loss: 725.4046\n",
      "Epoch 199/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 1122.5199 - val_loss: 1427.8354\n",
      "Epoch 200/1000\n",
      "302/302 [==============================] - 0s 964us/step - loss: 988.9862 - val_loss: 611.9610\n",
      "Epoch 201/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 1158.2626 - val_loss: 2685.9785\n",
      "Epoch 202/1000\n",
      "302/302 [==============================] - 0s 986us/step - loss: 1279.0563 - val_loss: 643.2633\n",
      "Epoch 203/1000\n",
      "302/302 [==============================] - 0s 944us/step - loss: 953.9678 - val_loss: 1891.9882\n",
      "Epoch 204/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 1124.7340 - val_loss: 854.8594\n",
      "Epoch 205/1000\n",
      "302/302 [==============================] - 0s 936us/step - loss: 1569.2407 - val_loss: 641.9446\n",
      "Epoch 206/1000\n",
      "302/302 [==============================] - 0s 919us/step - loss: 1017.1795 - val_loss: 825.0574\n",
      "Epoch 207/1000\n",
      "302/302 [==============================] - 0s 897us/step - loss: 1039.3146 - val_loss: 1038.2239\n",
      "Epoch 208/1000\n",
      "302/302 [==============================] - 0s 892us/step - loss: 1071.9409 - val_loss: 675.6155\n",
      "Epoch 209/1000\n",
      "302/302 [==============================] - 0s 921us/step - loss: 1218.3046 - val_loss: 4585.6963\n",
      "Epoch 210/1000\n",
      "302/302 [==============================] - 0s 901us/step - loss: 964.7979 - val_loss: 968.5969\n",
      "Epoch 211/1000\n",
      "302/302 [==============================] - 0s 895us/step - loss: 999.6813 - val_loss: 999.7687\n",
      "Epoch 212/1000\n",
      "302/302 [==============================] - 0s 875us/step - loss: 924.7620 - val_loss: 1986.6173\n",
      "Epoch 213/1000\n",
      "302/302 [==============================] - 0s 905us/step - loss: 815.2987 - val_loss: 764.8188\n",
      "Epoch 214/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 1016.5617 - val_loss: 4947.9204\n",
      "Epoch 215/1000\n",
      "302/302 [==============================] - 0s 863us/step - loss: 903.5056 - val_loss: 1634.7152\n",
      "Epoch 216/1000\n",
      "302/302 [==============================] - 0s 908us/step - loss: 1034.3701 - val_loss: 3341.3086\n",
      "Epoch 217/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 987.5701 - val_loss: 2028.3135\n",
      "Epoch 218/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 880.0004 - val_loss: 667.0215\n",
      "Epoch 219/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 1039.9846 - val_loss: 737.6312\n",
      "Epoch 220/1000\n",
      "302/302 [==============================] - 0s 918us/step - loss: 734.4320 - val_loss: 1173.4221\n",
      "Epoch 221/1000\n",
      "302/302 [==============================] - 0s 945us/step - loss: 959.3403 - val_loss: 785.3828\n",
      "Epoch 222/1000\n",
      "302/302 [==============================] - 0s 932us/step - loss: 956.0882 - val_loss: 1144.2034\n",
      "Epoch 223/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 871.5835 - val_loss: 1163.3510\n",
      "Epoch 224/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 877.2789 - val_loss: 718.2863\n",
      "Epoch 225/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 734.7435 - val_loss: 786.7766\n",
      "Epoch 226/1000\n",
      "302/302 [==============================] - 0s 929us/step - loss: 753.1737 - val_loss: 619.7064\n",
      "Epoch 227/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 1070.6354 - val_loss: 1245.5660\n",
      "Epoch 228/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 639.1213 - val_loss: 990.0416\n",
      "Epoch 229/1000\n",
      "302/302 [==============================] - 0s 912us/step - loss: 791.4896 - val_loss: 721.7175\n",
      "Epoch 230/1000\n",
      "302/302 [==============================] - 0s 901us/step - loss: 861.3198 - val_loss: 637.7672\n",
      "Epoch 231/1000\n",
      "302/302 [==============================] - 0s 908us/step - loss: 699.4260 - val_loss: 1074.4032\n",
      "Epoch 232/1000\n",
      "302/302 [==============================] - 0s 872us/step - loss: 849.0340 - val_loss: 2538.1484\n",
      "Epoch 233/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 24617.3672 - val_loss: 651.7870\n",
      "Epoch 234/1000\n",
      "302/302 [==============================] - 0s 877us/step - loss: 377.2501 - val_loss: 609.6814\n",
      "Epoch 235/1000\n",
      "302/302 [==============================] - 0s 882us/step - loss: 396.5244 - val_loss: 636.6959\n",
      "Epoch 236/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 432.5896 - val_loss: 610.2779\n",
      "Epoch 237/1000\n",
      "302/302 [==============================] - 0s 918us/step - loss: 417.7501 - val_loss: 910.4334\n",
      "Epoch 238/1000\n",
      "302/302 [==============================] - 0s 890us/step - loss: 465.6313 - val_loss: 669.1487\n",
      "Epoch 239/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 440.7091 - val_loss: 736.1321\n",
      "Epoch 240/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 448.3947 - val_loss: 943.4422\n",
      "Epoch 241/1000\n",
      "302/302 [==============================] - 0s 835us/step - loss: 528.9354 - val_loss: 1839.5469\n",
      "Epoch 242/1000\n",
      "302/302 [==============================] - 0s 938us/step - loss: 604.2061 - val_loss: 858.4398\n",
      "Epoch 243/1000\n",
      "302/302 [==============================] - 0s 911us/step - loss: 640.9922 - val_loss: 757.8486\n",
      "Epoch 244/1000\n",
      "302/302 [==============================] - 0s 874us/step - loss: 744.7093 - val_loss: 611.9178\n",
      "Epoch 245/1000\n",
      "302/302 [==============================] - 0s 824us/step - loss: 626.6125 - val_loss: 610.4592\n",
      "Epoch 246/1000\n",
      "302/302 [==============================] - 0s 903us/step - loss: 611.3005 - val_loss: 716.7757\n",
      "Epoch 247/1000\n",
      "302/302 [==============================] - 0s 862us/step - loss: 676.0948 - val_loss: 753.0624\n",
      "Epoch 248/1000\n",
      "302/302 [==============================] - 0s 829us/step - loss: 599.9234 - val_loss: 609.6769\n",
      "Epoch 249/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 777.2505 - val_loss: 645.3378\n",
      "Epoch 250/1000\n",
      "302/302 [==============================] - 0s 955us/step - loss: 728.2454 - val_loss: 688.0297\n",
      "Epoch 251/1000\n",
      "302/302 [==============================] - 0s 954us/step - loss: 653.4798 - val_loss: 648.8750\n",
      "Epoch 252/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 652.1392 - val_loss: 889.6928\n",
      "Epoch 253/1000\n",
      "302/302 [==============================] - 0s 962us/step - loss: 663.9341 - val_loss: 1131.0887\n",
      "Epoch 254/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 564.6245 - val_loss: 932.2742\n",
      "Epoch 255/1000\n",
      "302/302 [==============================] - 0s 974us/step - loss: 530.1215 - val_loss: 717.3122\n",
      "Epoch 256/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 508.9024 - val_loss: 1030.4729\n",
      "Epoch 257/1000\n",
      "302/302 [==============================] - 0s 968us/step - loss: 536.1398 - val_loss: 1727.6775\n",
      "Epoch 258/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 634.6039 - val_loss: 647.8228\n",
      "Epoch 259/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 614.9590 - val_loss: 1129.4620\n",
      "Epoch 260/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 502.0406 - val_loss: 619.8789\n",
      "Epoch 261/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 618.9888 - val_loss: 611.0923\n",
      "Epoch 262/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 518.9586 - val_loss: 783.2532\n",
      "Epoch 263/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 501.4996 - val_loss: 631.2279\n",
      "Epoch 264/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 509.8154 - val_loss: 648.7000\n",
      "Epoch 265/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 1ms/step - loss: 525.9444 - val_loss: 1345.4209\n",
      "Epoch 266/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 617.8246 - val_loss: 842.0434\n",
      "Epoch 267/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 513.8832 - val_loss: 926.8423\n",
      "Epoch 268/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 522.1829 - val_loss: 743.3925\n",
      "Epoch 269/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 507.5060 - val_loss: 624.2262\n",
      "Epoch 270/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 502.6042 - val_loss: 972.0355\n",
      "Epoch 271/1000\n",
      "302/302 [==============================] - 0s 937us/step - loss: 432.2763 - val_loss: 842.6530\n",
      "Epoch 272/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 416.5214 - val_loss: 670.0946\n",
      "Epoch 273/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 465.2347 - val_loss: 640.1290\n",
      "Epoch 274/1000\n",
      "302/302 [==============================] - 0s 1000us/step - loss: 457.8143 - val_loss: 640.2045\n",
      "Epoch 275/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 413.5594 - val_loss: 628.3948\n",
      "Epoch 276/1000\n",
      "302/302 [==============================] - 0s 982us/step - loss: 388.7867 - val_loss: 647.0944\n",
      "Epoch 277/1000\n",
      "302/302 [==============================] - 0s 984us/step - loss: 420.1449 - val_loss: 609.9892\n",
      "Epoch 278/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 385.9324 - val_loss: 643.5517\n",
      "Epoch 279/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 389.2169 - val_loss: 930.7077\n",
      "Epoch 280/1000\n",
      "302/302 [==============================] - 0s 933us/step - loss: 388.2551 - val_loss: 617.1459\n",
      "Epoch 281/1000\n",
      "302/302 [==============================] - 0s 957us/step - loss: 372.2403 - val_loss: 947.4092\n",
      "Epoch 282/1000\n",
      "302/302 [==============================] - 0s 899us/step - loss: 384.0511 - val_loss: 692.2394\n",
      "Epoch 283/1000\n",
      "302/302 [==============================] - 0s 952us/step - loss: 385.8345 - val_loss: 692.9703\n",
      "Epoch 284/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 368.2198 - val_loss: 1046.4442\n",
      "Epoch 285/1000\n",
      "302/302 [==============================] - 0s 970us/step - loss: 369.3187 - val_loss: 803.2834\n",
      "Epoch 286/1000\n",
      "302/302 [==============================] - 0s 965us/step - loss: 351.2103 - val_loss: 686.0201\n",
      "Epoch 287/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 351.3290 - val_loss: 735.6545\n",
      "Epoch 288/1000\n",
      "302/302 [==============================] - 0s 910us/step - loss: 349.7541 - val_loss: 734.5208\n",
      "Epoch 289/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 345.5001 - val_loss: 614.0955\n",
      "Epoch 290/1000\n",
      "302/302 [==============================] - 0s 865us/step - loss: 347.2324 - val_loss: 765.3307\n",
      "Epoch 291/1000\n",
      "302/302 [==============================] - 0s 903us/step - loss: 348.3275 - val_loss: 707.9213\n",
      "Epoch 292/1000\n",
      "302/302 [==============================] - 0s 893us/step - loss: 348.3391 - val_loss: 679.8081\n",
      "Epoch 293/1000\n",
      "302/302 [==============================] - 0s 874us/step - loss: 348.3135 - val_loss: 662.8438\n",
      "Epoch 294/1000\n",
      "302/302 [==============================] - 0s 927us/step - loss: 348.5982 - val_loss: 615.5341\n",
      "Epoch 295/1000\n",
      "302/302 [==============================] - 0s 968us/step - loss: 346.5860 - val_loss: 644.2631\n",
      "Epoch 296/1000\n",
      "302/302 [==============================] - 0s 955us/step - loss: 351.7690 - val_loss: 681.9666\n",
      "Epoch 297/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.0848 - val_loss: 681.6412\n",
      "Epoch 298/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 351.5768 - val_loss: 712.0864\n",
      "Epoch 299/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.2031 - val_loss: 726.5769\n",
      "Epoch 300/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 349.8889 - val_loss: 609.7900\n",
      "Epoch 301/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.5776 - val_loss: 754.5223\n",
      "Epoch 302/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 350.3106 - val_loss: 747.4485\n",
      "Epoch 303/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 349.4001 - val_loss: 752.0378\n",
      "Epoch 304/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 350.9003 - val_loss: 767.7598\n",
      "Epoch 305/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 348.4660 - val_loss: 703.9389\n",
      "Epoch 306/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.6023 - val_loss: 717.4054\n",
      "Epoch 307/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 354.7997 - val_loss: 739.3098\n",
      "Epoch 308/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 354.4614 - val_loss: 656.2707\n",
      "Epoch 309/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.4546 - val_loss: 844.2224\n",
      "Epoch 310/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 350.3930 - val_loss: 636.6224\n",
      "Epoch 311/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 351.8253 - val_loss: 792.2809\n",
      "Epoch 312/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 356.6343 - val_loss: 641.0130\n",
      "Epoch 313/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 355.4177 - val_loss: 628.2543\n",
      "Epoch 314/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 349.8180 - val_loss: 779.8055\n",
      "Epoch 315/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 2630.2305 - val_loss: 655.4810\n",
      "Epoch 316/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 346.0093 - val_loss: 629.9315\n",
      "Epoch 317/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 346.7593 - val_loss: 683.7201\n",
      "Epoch 318/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 346.9532 - val_loss: 682.9268\n",
      "Epoch 319/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 345.4867 - val_loss: 726.3668\n",
      "Epoch 320/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 347.8472 - val_loss: 728.1381\n",
      "Epoch 321/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 346.0378 - val_loss: 666.3027\n",
      "Epoch 322/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.6159 - val_loss: 644.7845\n",
      "Epoch 323/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.5840 - val_loss: 645.0831\n",
      "Epoch 324/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 345.1511 - val_loss: 649.6809\n",
      "Epoch 325/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.7399 - val_loss: 655.7217\n",
      "Epoch 326/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.4119 - val_loss: 647.2905\n",
      "Epoch 327/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.1841 - val_loss: 736.5056\n",
      "Epoch 328/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.9195 - val_loss: 639.5077\n",
      "Epoch 329/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.2335 - val_loss: 654.2010\n",
      "Epoch 330/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 345.8241 - val_loss: 659.3793\n",
      "Epoch 331/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 350.7527 - val_loss: 696.6140\n",
      "Epoch 332/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.0445 - val_loss: 769.5503\n",
      "Epoch 333/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 347.0214 - val_loss: 637.1560\n",
      "Epoch 334/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.9997 - val_loss: 665.9566\n",
      "Epoch 335/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.8112 - val_loss: 736.8879\n",
      "Epoch 336/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 351.8170 - val_loss: 670.9724\n",
      "Epoch 337/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.6492 - val_loss: 719.0919\n",
      "Epoch 338/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 347.7042 - val_loss: 687.9066\n",
      "Epoch 339/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 353.2447 - val_loss: 675.1471\n",
      "Epoch 340/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 1s 3ms/step - loss: 349.6817 - val_loss: 762.9915\n",
      "Epoch 341/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.3745 - val_loss: 643.0799\n",
      "Epoch 342/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.6250 - val_loss: 640.4437\n",
      "Epoch 343/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.9340 - val_loss: 689.3500\n",
      "Epoch 344/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.3217 - val_loss: 619.2307\n",
      "Epoch 345/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 354.1462 - val_loss: 738.0648\n",
      "Epoch 346/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 351.7758 - val_loss: 624.9252\n",
      "Epoch 347/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.9849 - val_loss: 709.7390\n",
      "Epoch 348/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 350.4437 - val_loss: 640.0834\n",
      "Epoch 349/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.8842 - val_loss: 735.3585\n",
      "Epoch 350/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.4173 - val_loss: 664.5638\n",
      "Epoch 351/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.2263 - val_loss: 635.3000\n",
      "Epoch 352/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 353.5087 - val_loss: 644.8169\n",
      "Epoch 353/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.4173 - val_loss: 667.6273\n",
      "Epoch 354/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 348.5054 - val_loss: 657.2829\n",
      "Epoch 355/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.5418 - val_loss: 690.4017\n",
      "Epoch 356/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 354.3057 - val_loss: 645.2009\n",
      "Epoch 357/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 348.3809 - val_loss: 697.0779\n",
      "Epoch 358/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 351.3253 - val_loss: 728.9750\n",
      "Epoch 359/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.1530 - val_loss: 639.9359\n",
      "Epoch 360/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 354.7825 - val_loss: 817.7932\n",
      "Epoch 361/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.0349 - val_loss: 668.4048\n",
      "Epoch 362/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 355.0090 - val_loss: 758.9641\n",
      "Epoch 363/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.3001 - val_loss: 717.8715\n",
      "Epoch 364/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.3476 - val_loss: 884.9746\n",
      "Epoch 365/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.1985 - val_loss: 776.5832\n",
      "Epoch 366/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 351.3293 - val_loss: 646.6601\n",
      "Epoch 367/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 350.8627 - val_loss: 708.2081\n",
      "Epoch 368/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 348.2843 - val_loss: 675.0658\n",
      "Epoch 369/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.0278 - val_loss: 659.2234\n",
      "Epoch 370/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 351.7507 - val_loss: 624.6656\n",
      "Epoch 371/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 2325.0305 - val_loss: 1460.1570\n",
      "Epoch 372/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 780.1894 - val_loss: 1443.4285\n",
      "Epoch 373/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 768.2201 - val_loss: 1426.9095\n",
      "Epoch 374/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 756.4504 - val_loss: 1410.6088\n",
      "Epoch 375/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 744.8751 - val_loss: 1394.4873\n",
      "Epoch 376/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 733.4856 - val_loss: 1378.6056\n",
      "Epoch 377/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 722.2826 - val_loss: 1362.8577\n",
      "Epoch 378/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 711.2487 - val_loss: 1347.3066\n",
      "Epoch 379/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 700.3924 - val_loss: 1331.9840\n",
      "Epoch 380/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 689.7255 - val_loss: 1316.7900\n",
      "Epoch 381/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 679.2367 - val_loss: 1301.8596\n",
      "Epoch 382/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 668.9084 - val_loss: 1287.0059\n",
      "Epoch 383/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 658.7535 - val_loss: 1272.3905\n",
      "Epoch 384/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 648.7833 - val_loss: 1257.9592\n",
      "Epoch 385/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 638.9751 - val_loss: 1243.6624\n",
      "Epoch 386/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 629.3546 - val_loss: 1229.5785\n",
      "Epoch 387/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 619.8901 - val_loss: 1215.6412\n",
      "Epoch 388/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 610.5861 - val_loss: 1201.8882\n",
      "Epoch 389/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 601.4744 - val_loss: 1188.3293\n",
      "Epoch 390/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 592.5305 - val_loss: 1174.9568\n",
      "Epoch 391/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 583.7543 - val_loss: 1161.7720\n",
      "Epoch 392/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 575.1516 - val_loss: 1148.7325\n",
      "Epoch 393/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 566.7202 - val_loss: 1135.9027\n",
      "Epoch 394/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 558.4473 - val_loss: 1123.2515\n",
      "Epoch 395/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 550.3516 - val_loss: 1110.7134\n",
      "Epoch 396/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 542.4333 - val_loss: 1098.4723\n",
      "Epoch 397/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 534.6812 - val_loss: 1086.2930\n",
      "Epoch 398/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 527.0963 - val_loss: 1074.3850\n",
      "Epoch 399/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 519.6718 - val_loss: 1062.5565\n",
      "Epoch 400/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 512.4223 - val_loss: 1050.9808\n",
      "Epoch 401/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 505.3366 - val_loss: 1039.5356\n",
      "Epoch 402/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 498.4077 - val_loss: 1028.2860\n",
      "Epoch 403/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 491.6492 - val_loss: 1017.2108\n",
      "Epoch 404/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 485.0556 - val_loss: 1006.3190\n",
      "Epoch 405/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 478.6254 - val_loss: 995.5704\n",
      "Epoch 406/1000\n",
      "302/302 [==============================] - 0s 976us/step - loss: 472.3601 - val_loss: 985.0042\n",
      "Epoch 407/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 466.2733 - val_loss: 974.6292\n",
      "Epoch 408/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 460.3527 - val_loss: 964.4902\n",
      "Epoch 409/1000\n",
      "302/302 [==============================] - 0s 951us/step - loss: 454.5985 - val_loss: 954.5276\n",
      "Epoch 410/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 449.0106 - val_loss: 944.7162\n",
      "Epoch 411/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 443.5730 - val_loss: 935.0372\n",
      "Epoch 412/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 438.2799 - val_loss: 925.5591\n",
      "Epoch 413/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 433.1485 - val_loss: 916.2158\n",
      "Epoch 414/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 428.1848 - val_loss: 907.1055\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 1ms/step - loss: 423.3734 - val_loss: 898.1221\n",
      "Epoch 416/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 418.7350 - val_loss: 889.3859\n",
      "Epoch 417/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 414.2630 - val_loss: 880.8248\n",
      "Epoch 418/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 409.9344 - val_loss: 872.4033\n",
      "Epoch 419/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 405.7744 - val_loss: 864.2061\n",
      "Epoch 420/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 401.7682 - val_loss: 856.1878\n",
      "Epoch 421/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 397.9065 - val_loss: 848.3327\n",
      "Epoch 422/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 394.2117 - val_loss: 840.6868\n",
      "Epoch 423/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 390.6655 - val_loss: 833.1888\n",
      "Epoch 424/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 387.2640 - val_loss: 825.8864\n",
      "Epoch 425/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 384.0231 - val_loss: 818.7795\n",
      "Epoch 426/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 380.9380 - val_loss: 811.8768\n",
      "Epoch 427/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 378.0061 - val_loss: 805.2476\n",
      "Epoch 428/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 375.2079 - val_loss: 798.6529\n",
      "Epoch 429/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 372.5471 - val_loss: 792.2896\n",
      "Epoch 430/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 370.0250 - val_loss: 786.0961\n",
      "Epoch 431/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 367.6322 - val_loss: 780.1194\n",
      "Epoch 432/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 365.3810 - val_loss: 774.3080\n",
      "Epoch 433/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 363.2761 - val_loss: 768.6984\n",
      "Epoch 434/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 361.2988 - val_loss: 763.3162\n",
      "Epoch 435/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 359.4549 - val_loss: 758.0958\n",
      "Epoch 436/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 357.7346 - val_loss: 753.1218\n",
      "Epoch 437/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 356.1301 - val_loss: 748.2884\n",
      "Epoch 438/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 354.6475 - val_loss: 743.6157\n",
      "Epoch 439/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.2736 - val_loss: 739.1625\n",
      "Epoch 440/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 351.9944 - val_loss: 734.8529\n",
      "Epoch 441/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 350.8286 - val_loss: 730.6937\n",
      "Epoch 442/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 349.7741 - val_loss: 726.8345\n",
      "Epoch 443/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 348.8121 - val_loss: 723.1783\n",
      "Epoch 444/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 347.9445 - val_loss: 719.7038\n",
      "Epoch 445/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 347.1609 - val_loss: 716.3998\n",
      "Epoch 446/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 346.4521 - val_loss: 713.1984\n",
      "Epoch 447/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 345.8238 - val_loss: 710.1998\n",
      "Epoch 448/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 345.2710 - val_loss: 707.4879\n",
      "Epoch 449/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 344.7849 - val_loss: 704.9641\n",
      "Epoch 450/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 344.3588 - val_loss: 702.5352\n",
      "Epoch 451/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 343.9813 - val_loss: 700.2565\n",
      "Epoch 452/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 343.6520 - val_loss: 698.1990\n",
      "Epoch 453/1000\n",
      "302/302 [==============================] - 0s 989us/step - loss: 343.3697 - val_loss: 696.2742\n",
      "Epoch 454/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 343.1250 - val_loss: 694.5433\n",
      "Epoch 455/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.9111 - val_loss: 692.8211\n",
      "Epoch 456/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.7276 - val_loss: 691.3180\n",
      "Epoch 457/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.5720 - val_loss: 689.8238\n",
      "Epoch 458/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.4380 - val_loss: 688.5822\n",
      "Epoch 459/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.3235 - val_loss: 687.3306\n",
      "Epoch 460/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.2281 - val_loss: 686.1674\n",
      "Epoch 461/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.1487 - val_loss: 685.2104\n",
      "Epoch 462/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.0823 - val_loss: 684.3781\n",
      "Epoch 463/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.0244 - val_loss: 683.4799\n",
      "Epoch 464/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.9768 - val_loss: 682.6868\n",
      "Epoch 465/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.9375 - val_loss: 682.0228\n",
      "Epoch 466/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.9044 - val_loss: 681.4084\n",
      "Epoch 467/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.8766 - val_loss: 680.7969\n",
      "Epoch 468/1000\n",
      "302/302 [==============================] - 0s 965us/step - loss: 341.8550 - val_loss: 680.2838\n",
      "Epoch 469/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.8350 - val_loss: 679.8891\n",
      "Epoch 470/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.8171 - val_loss: 679.3339\n",
      "Epoch 471/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.8047 - val_loss: 679.0081\n",
      "Epoch 472/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7933 - val_loss: 678.5876\n",
      "Epoch 473/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7847 - val_loss: 678.2567\n",
      "Epoch 474/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7763 - val_loss: 677.9067\n",
      "Epoch 475/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7715 - val_loss: 677.6851\n",
      "Epoch 476/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7654 - val_loss: 677.4090\n",
      "Epoch 477/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7613 - val_loss: 677.2410\n",
      "Epoch 478/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7575 - val_loss: 677.0652\n",
      "Epoch 479/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7547 - val_loss: 676.8591\n",
      "Epoch 480/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7520 - val_loss: 676.6575\n",
      "Epoch 481/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7504 - val_loss: 676.5791\n",
      "Epoch 482/1000\n",
      "302/302 [==============================] - 0s 985us/step - loss: 341.7490 - val_loss: 676.3758\n",
      "Epoch 483/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7460 - val_loss: 676.2646\n",
      "Epoch 484/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7458 - val_loss: 676.1741\n",
      "Epoch 485/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7452 - val_loss: 676.1033\n",
      "Epoch 486/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7454 - val_loss: 676.0098\n",
      "Epoch 487/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7433 - val_loss: 675.9061\n",
      "Epoch 488/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7432 - val_loss: 675.7937\n",
      "Epoch 489/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7430 - val_loss: 675.7683\n",
      "Epoch 490/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7421 - val_loss: 675.7020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7423 - val_loss: 675.6353\n",
      "Epoch 492/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7417 - val_loss: 675.5685\n",
      "Epoch 493/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 675.5396\n",
      "Epoch 494/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 675.4380\n",
      "Epoch 495/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7419 - val_loss: 675.4582\n",
      "Epoch 496/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 675.3810\n",
      "Epoch 497/1000\n",
      "302/302 [==============================] - 0s 984us/step - loss: 341.7425 - val_loss: 675.3776\n",
      "Epoch 498/1000\n",
      "302/302 [==============================] - 0s 985us/step - loss: 341.7403 - val_loss: 675.3469\n",
      "Epoch 499/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7398 - val_loss: 675.2989\n",
      "Epoch 500/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.3118\n",
      "Epoch 501/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7403 - val_loss: 675.2687\n",
      "Epoch 502/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7407 - val_loss: 675.2828\n",
      "Epoch 503/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.2715\n",
      "Epoch 504/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7417 - val_loss: 675.2404\n",
      "Epoch 505/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7398 - val_loss: 675.1777\n",
      "Epoch 506/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 675.2003\n",
      "Epoch 507/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.1298\n",
      "Epoch 508/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 675.1594\n",
      "Epoch 509/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 675.0751\n",
      "Epoch 510/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 341.7410 - val_loss: 675.0731\n",
      "Epoch 511/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7409 - val_loss: 675.0935\n",
      "Epoch 512/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 675.1522\n",
      "Epoch 513/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7405 - val_loss: 675.0909\n",
      "Epoch 514/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7403 - val_loss: 675.0531\n",
      "Epoch 515/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7409 - val_loss: 675.0240\n",
      "Epoch 516/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 675.0568\n",
      "Epoch 517/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7416 - val_loss: 675.0080\n",
      "Epoch 518/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.0458\n",
      "Epoch 519/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 675.0446\n",
      "Epoch 520/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 674.9882\n",
      "Epoch 521/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 674.9847\n",
      "Epoch 522/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.0170\n",
      "Epoch 523/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9675\n",
      "Epoch 524/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7414 - val_loss: 675.0219\n",
      "Epoch 525/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 674.9783\n",
      "Epoch 526/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7405 - val_loss: 675.0148\n",
      "Epoch 527/1000\n",
      "302/302 [==============================] - 0s 956us/step - loss: 341.7414 - val_loss: 675.0121\n",
      "Epoch 528/1000\n",
      "302/302 [==============================] - 0s 973us/step - loss: 341.7409 - val_loss: 675.0120\n",
      "Epoch 529/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 341.7399 - val_loss: 674.9978\n",
      "Epoch 530/1000\n",
      "302/302 [==============================] - 0s 914us/step - loss: 341.7404 - val_loss: 674.9257\n",
      "Epoch 531/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 341.7413 - val_loss: 674.9820\n",
      "Epoch 532/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7395 - val_loss: 674.9894\n",
      "Epoch 533/1000\n",
      "302/302 [==============================] - 0s 931us/step - loss: 341.7401 - val_loss: 674.9915\n",
      "Epoch 534/1000\n",
      "302/302 [==============================] - 0s 914us/step - loss: 341.7406 - val_loss: 675.0144\n",
      "Epoch 535/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 341.7398 - val_loss: 675.0161\n",
      "Epoch 536/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7403 - val_loss: 675.0035\n",
      "Epoch 537/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 341.7395 - val_loss: 674.9976\n",
      "Epoch 538/1000\n",
      "302/302 [==============================] - 0s 909us/step - loss: 341.7399 - val_loss: 674.9977\n",
      "Epoch 539/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 674.9882\n",
      "Epoch 540/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 674.9728\n",
      "Epoch 541/1000\n",
      "302/302 [==============================] - 0s 962us/step - loss: 341.7402 - val_loss: 674.9675\n",
      "Epoch 542/1000\n",
      "302/302 [==============================] - 0s 924us/step - loss: 341.7404 - val_loss: 674.9739\n",
      "Epoch 543/1000\n",
      "302/302 [==============================] - 0s 958us/step - loss: 341.7403 - val_loss: 675.0156\n",
      "Epoch 544/1000\n",
      "302/302 [==============================] - 0s 988us/step - loss: 341.7401 - val_loss: 675.0248\n",
      "Epoch 545/1000\n",
      "302/302 [==============================] - 0s 885us/step - loss: 341.7411 - val_loss: 674.9882\n",
      "Epoch 546/1000\n",
      "302/302 [==============================] - 0s 967us/step - loss: 341.7413 - val_loss: 674.9913\n",
      "Epoch 547/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7407 - val_loss: 674.9702\n",
      "Epoch 548/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 341.7419 - val_loss: 674.9924\n",
      "Epoch 549/1000\n",
      "302/302 [==============================] - 0s 923us/step - loss: 341.7407 - val_loss: 674.9675\n",
      "Epoch 550/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7405 - val_loss: 674.9741\n",
      "Epoch 551/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 341.7402 - val_loss: 674.9831\n",
      "Epoch 552/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7393 - val_loss: 674.9820\n",
      "Epoch 553/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 341.7393 - val_loss: 675.0207\n",
      "Epoch 554/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 341.7401 - val_loss: 674.9588\n",
      "Epoch 555/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 341.7409 - val_loss: 675.0332\n",
      "Epoch 556/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 341.7401 - val_loss: 675.0476\n",
      "Epoch 557/1000\n",
      "302/302 [==============================] - 0s 978us/step - loss: 341.7396 - val_loss: 675.0125\n",
      "Epoch 558/1000\n",
      "302/302 [==============================] - 0s 949us/step - loss: 341.7413 - val_loss: 675.0975\n",
      "Epoch 559/1000\n",
      "302/302 [==============================] - 0s 975us/step - loss: 341.7414 - val_loss: 675.0311\n",
      "Epoch 560/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 674.9744\n",
      "Epoch 561/1000\n",
      "302/302 [==============================] - 0s 962us/step - loss: 341.7401 - val_loss: 675.0183\n",
      "Epoch 562/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 674.9238\n",
      "Epoch 563/1000\n",
      "302/302 [==============================] - 0s 927us/step - loss: 341.7402 - val_loss: 674.9460\n",
      "Epoch 564/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7420 - val_loss: 674.9154\n",
      "Epoch 565/1000\n",
      "302/302 [==============================] - 0s 978us/step - loss: 341.7419 - val_loss: 674.9517\n",
      "Epoch 566/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 893us/step - loss: 341.7405 - val_loss: 674.9276\n",
      "Epoch 567/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7412 - val_loss: 674.9828\n",
      "Epoch 568/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7394 - val_loss: 674.9997\n",
      "Epoch 569/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7407 - val_loss: 674.9844\n",
      "Epoch 570/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.0071\n",
      "Epoch 571/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9999\n",
      "Epoch 572/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7403 - val_loss: 674.9762\n",
      "Epoch 573/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7409 - val_loss: 674.9706\n",
      "Epoch 574/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9590\n",
      "Epoch 575/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9520\n",
      "Epoch 576/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7392 - val_loss: 674.9995\n",
      "Epoch 577/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7392 - val_loss: 675.0115\n",
      "Epoch 578/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 675.0305\n",
      "Epoch 579/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 674.9160\n",
      "Epoch 580/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.9460\n",
      "Epoch 581/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7415 - val_loss: 674.9974\n",
      "Epoch 582/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7403 - val_loss: 674.9605\n",
      "Epoch 583/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7393 - val_loss: 674.9540\n",
      "Epoch 584/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 674.9790\n",
      "Epoch 585/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0314\n",
      "Epoch 586/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 675.0470\n",
      "Epoch 587/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9559\n",
      "Epoch 588/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7400 - val_loss: 674.9598\n",
      "Epoch 589/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7409 - val_loss: 674.9913\n",
      "Epoch 590/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0401\n",
      "Epoch 591/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 675.0648\n",
      "Epoch 592/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 675.0029\n",
      "Epoch 593/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0243\n",
      "Epoch 594/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 675.0159\n",
      "Epoch 595/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7397 - val_loss: 675.0495\n",
      "Epoch 596/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 675.0346\n",
      "Epoch 597/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0092\n",
      "Epoch 598/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9763\n",
      "Epoch 599/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0014\n",
      "Epoch 600/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 675.0190\n",
      "Epoch 601/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9628\n",
      "Epoch 602/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7408 - val_loss: 675.0028\n",
      "Epoch 603/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 675.0565\n",
      "Epoch 604/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7400 - val_loss: 675.0396\n",
      "Epoch 605/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7390 - val_loss: 675.0165\n",
      "Epoch 606/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 675.0026\n",
      "Epoch 607/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 675.0049\n",
      "Epoch 608/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0423\n",
      "Epoch 609/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 675.0269\n",
      "Epoch 610/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7404 - val_loss: 675.0242\n",
      "Epoch 611/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7412 - val_loss: 674.9225\n",
      "Epoch 612/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7394 - val_loss: 675.0145\n",
      "Epoch 613/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7410 - val_loss: 675.0753\n",
      "Epoch 614/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7411 - val_loss: 675.0576\n",
      "Epoch 615/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7409 - val_loss: 674.9858\n",
      "Epoch 616/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0116\n",
      "Epoch 617/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7425 - val_loss: 675.0577\n",
      "Epoch 618/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 675.0330\n",
      "Epoch 619/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7407 - val_loss: 675.0449\n",
      "Epoch 620/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7403 - val_loss: 675.0156\n",
      "Epoch 621/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9835\n",
      "Epoch 622/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7406 - val_loss: 675.0211\n",
      "Epoch 623/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7400 - val_loss: 675.0510\n",
      "Epoch 624/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7413 - val_loss: 675.0865\n",
      "Epoch 625/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 675.0781\n",
      "Epoch 626/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0454\n",
      "Epoch 627/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7411 - val_loss: 675.0782\n",
      "Epoch 628/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7412 - val_loss: 675.0285\n",
      "Epoch 629/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 675.0121\n",
      "Epoch 630/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7402 - val_loss: 675.0337\n",
      "Epoch 631/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 674.9836\n",
      "Epoch 632/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7411 - val_loss: 674.9639\n",
      "Epoch 633/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 674.9320\n",
      "Epoch 634/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0344\n",
      "Epoch 635/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 674.9743\n",
      "Epoch 636/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 675.0083\n",
      "Epoch 637/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7415 - val_loss: 675.0519\n",
      "Epoch 638/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 674.9920\n",
      "Epoch 639/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 675.0057\n",
      "Epoch 640/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7408 - val_loss: 674.9830\n",
      "Epoch 641/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7412 - val_loss: 675.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 642/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7415 - val_loss: 675.0024\n",
      "Epoch 643/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 675.0165\n",
      "Epoch 644/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7413 - val_loss: 675.0162\n",
      "Epoch 645/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7396 - val_loss: 675.0151\n",
      "Epoch 646/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9584\n",
      "Epoch 647/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9810\n",
      "Epoch 648/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7413 - val_loss: 675.0303\n",
      "Epoch 649/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 674.9604\n",
      "Epoch 650/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7397 - val_loss: 675.0191\n",
      "Epoch 651/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7423 - val_loss: 674.9148\n",
      "Epoch 652/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 674.9709\n",
      "Epoch 653/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7407 - val_loss: 674.9288\n",
      "Epoch 654/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.8723\n",
      "Epoch 655/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.9539\n",
      "Epoch 656/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 674.9488\n",
      "Epoch 657/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9379\n",
      "Epoch 658/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9257\n",
      "Epoch 659/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 674.9526\n",
      "Epoch 660/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 674.9216\n",
      "Epoch 661/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7418 - val_loss: 674.8325\n",
      "Epoch 662/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.9313\n",
      "Epoch 663/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.8851\n",
      "Epoch 664/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7392 - val_loss: 674.9555\n",
      "Epoch 665/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7410 - val_loss: 674.9711\n",
      "Epoch 666/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7396 - val_loss: 674.9426\n",
      "Epoch 667/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 674.9708\n",
      "Epoch 668/1000\n",
      "302/302 [==============================] - 0s 920us/step - loss: 341.7406 - val_loss: 674.9005\n",
      "Epoch 669/1000\n",
      "302/302 [==============================] - 0s 880us/step - loss: 341.7405 - val_loss: 674.9516\n",
      "Epoch 670/1000\n",
      "302/302 [==============================] - 0s 918us/step - loss: 341.7403 - val_loss: 674.9593\n",
      "Epoch 671/1000\n",
      "302/302 [==============================] - 0s 921us/step - loss: 341.7400 - val_loss: 674.9913\n",
      "Epoch 672/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 341.7403 - val_loss: 674.9481\n",
      "Epoch 673/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7404 - val_loss: 675.0396\n",
      "Epoch 674/1000\n",
      "302/302 [==============================] - 0s 990us/step - loss: 341.7396 - val_loss: 674.9807\n",
      "Epoch 675/1000\n",
      "302/302 [==============================] - 0s 981us/step - loss: 341.7411 - val_loss: 675.0091\n",
      "Epoch 676/1000\n",
      "302/302 [==============================] - 0s 963us/step - loss: 341.7397 - val_loss: 674.9757\n",
      "Epoch 677/1000\n",
      "302/302 [==============================] - 0s 865us/step - loss: 341.7407 - val_loss: 674.9638\n",
      "Epoch 678/1000\n",
      "302/302 [==============================] - 0s 911us/step - loss: 341.7407 - val_loss: 675.0180\n",
      "Epoch 679/1000\n",
      "302/302 [==============================] - 0s 840us/step - loss: 341.7425 - val_loss: 675.0464\n",
      "Epoch 680/1000\n",
      "302/302 [==============================] - 0s 920us/step - loss: 341.7414 - val_loss: 674.9885\n",
      "Epoch 681/1000\n",
      "302/302 [==============================] - 0s 851us/step - loss: 341.7408 - val_loss: 674.9944\n",
      "Epoch 682/1000\n",
      "302/302 [==============================] - 0s 874us/step - loss: 341.7413 - val_loss: 674.9940\n",
      "Epoch 683/1000\n",
      "302/302 [==============================] - 0s 981us/step - loss: 341.7393 - val_loss: 675.0362\n",
      "Epoch 684/1000\n",
      "302/302 [==============================] - 0s 911us/step - loss: 341.7396 - val_loss: 674.9788\n",
      "Epoch 685/1000\n",
      "302/302 [==============================] - 0s 871us/step - loss: 341.7393 - val_loss: 674.9922\n",
      "Epoch 686/1000\n",
      "302/302 [==============================] - 0s 867us/step - loss: 341.7400 - val_loss: 674.9825\n",
      "Epoch 687/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 341.7407 - val_loss: 675.0031\n",
      "Epoch 688/1000\n",
      "302/302 [==============================] - 0s 958us/step - loss: 341.7399 - val_loss: 674.9363\n",
      "Epoch 689/1000\n",
      "302/302 [==============================] - 0s 968us/step - loss: 341.7401 - val_loss: 674.9625\n",
      "Epoch 690/1000\n",
      "302/302 [==============================] - 0s 903us/step - loss: 341.7399 - val_loss: 674.9286\n",
      "Epoch 691/1000\n",
      "302/302 [==============================] - 0s 905us/step - loss: 341.7404 - val_loss: 674.9830\n",
      "Epoch 692/1000\n",
      "302/302 [==============================] - 0s 975us/step - loss: 341.7412 - val_loss: 674.9022\n",
      "Epoch 693/1000\n",
      "302/302 [==============================] - 0s 945us/step - loss: 341.7408 - val_loss: 674.9229\n",
      "Epoch 694/1000\n",
      "302/302 [==============================] - 0s 914us/step - loss: 341.7402 - val_loss: 674.9505\n",
      "Epoch 695/1000\n",
      "302/302 [==============================] - 0s 846us/step - loss: 341.7404 - val_loss: 675.0120\n",
      "Epoch 696/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7406 - val_loss: 674.9470\n",
      "Epoch 697/1000\n",
      "302/302 [==============================] - 0s 932us/step - loss: 341.7408 - val_loss: 675.0023\n",
      "Epoch 698/1000\n",
      "302/302 [==============================] - 0s 949us/step - loss: 341.7408 - val_loss: 674.9637\n",
      "Epoch 699/1000\n",
      "302/302 [==============================] - 0s 840us/step - loss: 341.7395 - val_loss: 674.9578\n",
      "Epoch 700/1000\n",
      "302/302 [==============================] - 0s 961us/step - loss: 341.7398 - val_loss: 675.0219\n",
      "Epoch 701/1000\n",
      "302/302 [==============================] - 0s 903us/step - loss: 341.7397 - val_loss: 675.0070\n",
      "Epoch 702/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 341.7413 - val_loss: 674.9543\n",
      "Epoch 703/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 341.7405 - val_loss: 674.9322\n",
      "Epoch 704/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7396 - val_loss: 675.0012\n",
      "Epoch 705/1000\n",
      "302/302 [==============================] - 0s 945us/step - loss: 341.7413 - val_loss: 675.0062\n",
      "Epoch 706/1000\n",
      "302/302 [==============================] - 0s 919us/step - loss: 341.7400 - val_loss: 674.9677\n",
      "Epoch 707/1000\n",
      "302/302 [==============================] - 0s 838us/step - loss: 341.7407 - val_loss: 675.0190\n",
      "Epoch 708/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.0346\n",
      "Epoch 709/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7402 - val_loss: 675.0203\n",
      "Epoch 710/1000\n",
      "302/302 [==============================] - 0s 964us/step - loss: 341.7413 - val_loss: 675.0105\n",
      "Epoch 711/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7396 - val_loss: 674.9846\n",
      "Epoch 712/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7390 - val_loss: 674.9503\n",
      "Epoch 713/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 341.7405 - val_loss: 675.0040\n",
      "Epoch 714/1000\n",
      "302/302 [==============================] - 0s 977us/step - loss: 341.7404 - val_loss: 674.9345\n",
      "Epoch 715/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9066\n",
      "Epoch 716/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9788\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 967us/step - loss: 341.7402 - val_loss: 675.0137\n",
      "Epoch 718/1000\n",
      "302/302 [==============================] - 0s 969us/step - loss: 341.7408 - val_loss: 675.0068\n",
      "Epoch 719/1000\n",
      "302/302 [==============================] - 0s 956us/step - loss: 341.7411 - val_loss: 674.9584\n",
      "Epoch 720/1000\n",
      "302/302 [==============================] - 0s 849us/step - loss: 341.7408 - val_loss: 675.0109\n",
      "Epoch 721/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 341.7413 - val_loss: 674.9570\n",
      "Epoch 722/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.0139\n",
      "Epoch 723/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7420 - val_loss: 675.0879\n",
      "Epoch 724/1000\n",
      "302/302 [==============================] - 0s 892us/step - loss: 341.7410 - val_loss: 674.9921\n",
      "Epoch 725/1000\n",
      "302/302 [==============================] - 0s 971us/step - loss: 341.7397 - val_loss: 675.0198\n",
      "Epoch 726/1000\n",
      "302/302 [==============================] - 0s 854us/step - loss: 341.7398 - val_loss: 675.0088\n",
      "Epoch 727/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7402 - val_loss: 675.0338\n",
      "Epoch 728/1000\n",
      "302/302 [==============================] - 0s 841us/step - loss: 341.7416 - val_loss: 674.9944\n",
      "Epoch 729/1000\n",
      "302/302 [==============================] - 0s 933us/step - loss: 341.7395 - val_loss: 675.0150\n",
      "Epoch 730/1000\n",
      "302/302 [==============================] - 0s 901us/step - loss: 341.7413 - val_loss: 674.9555\n",
      "Epoch 731/1000\n",
      "302/302 [==============================] - 0s 857us/step - loss: 341.7392 - val_loss: 675.0181\n",
      "Epoch 732/1000\n",
      "302/302 [==============================] - 0s 930us/step - loss: 341.7401 - val_loss: 674.9661\n",
      "Epoch 733/1000\n",
      "302/302 [==============================] - 0s 919us/step - loss: 341.7396 - val_loss: 675.0151\n",
      "Epoch 734/1000\n",
      "302/302 [==============================] - 0s 854us/step - loss: 341.7396 - val_loss: 674.9994\n",
      "Epoch 735/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 341.7403 - val_loss: 675.0394\n",
      "Epoch 736/1000\n",
      "302/302 [==============================] - 0s 948us/step - loss: 341.7404 - val_loss: 675.0272\n",
      "Epoch 737/1000\n",
      "302/302 [==============================] - 0s 846us/step - loss: 341.7401 - val_loss: 675.0015\n",
      "Epoch 738/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 341.7415 - val_loss: 675.0109\n",
      "Epoch 739/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7398 - val_loss: 674.9995\n",
      "Epoch 740/1000\n",
      "302/302 [==============================] - 0s 858us/step - loss: 341.7397 - val_loss: 675.0098\n",
      "Epoch 741/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 341.7416 - val_loss: 675.0374\n",
      "Epoch 742/1000\n",
      "302/302 [==============================] - 0s 889us/step - loss: 341.7407 - val_loss: 674.9831\n",
      "Epoch 743/1000\n",
      "302/302 [==============================] - 0s 925us/step - loss: 341.7407 - val_loss: 675.0157\n",
      "Epoch 744/1000\n",
      "302/302 [==============================] - 0s 898us/step - loss: 341.7393 - val_loss: 674.9879\n",
      "Epoch 745/1000\n",
      "302/302 [==============================] - 0s 866us/step - loss: 341.7401 - val_loss: 675.0082\n",
      "Epoch 746/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 341.7408 - val_loss: 675.0032\n",
      "Epoch 747/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7409 - val_loss: 675.0134\n",
      "Epoch 748/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 341.7398 - val_loss: 674.9741\n",
      "Epoch 749/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7421 - val_loss: 675.0623\n",
      "Epoch 750/1000\n",
      "302/302 [==============================] - 0s 932us/step - loss: 341.7403 - val_loss: 674.9808\n",
      "Epoch 751/1000\n",
      "302/302 [==============================] - 0s 957us/step - loss: 341.7415 - val_loss: 675.0301\n",
      "Epoch 752/1000\n",
      "302/302 [==============================] - 0s 909us/step - loss: 341.7401 - val_loss: 675.0316\n",
      "Epoch 753/1000\n",
      "302/302 [==============================] - 0s 855us/step - loss: 341.7401 - val_loss: 674.9984\n",
      "Epoch 754/1000\n",
      "302/302 [==============================] - 0s 973us/step - loss: 341.7391 - val_loss: 674.9963\n",
      "Epoch 755/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7410 - val_loss: 674.9749\n",
      "Epoch 756/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 341.7405 - val_loss: 674.9529\n",
      "Epoch 757/1000\n",
      "302/302 [==============================] - 0s 988us/step - loss: 341.7403 - val_loss: 674.9738\n",
      "Epoch 758/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 341.7397 - val_loss: 675.0093\n",
      "Epoch 759/1000\n",
      "302/302 [==============================] - 0s 941us/step - loss: 341.7403 - val_loss: 674.9897\n",
      "Epoch 760/1000\n",
      "302/302 [==============================] - 0s 944us/step - loss: 341.7400 - val_loss: 674.9637\n",
      "Epoch 761/1000\n",
      "302/302 [==============================] - 0s 926us/step - loss: 341.7391 - val_loss: 674.9885\n",
      "Epoch 762/1000\n",
      "302/302 [==============================] - 0s 909us/step - loss: 341.7396 - val_loss: 674.9241\n",
      "Epoch 763/1000\n",
      "302/302 [==============================] - 0s 873us/step - loss: 341.7412 - val_loss: 674.9430\n",
      "Epoch 764/1000\n",
      "302/302 [==============================] - 0s 944us/step - loss: 341.7416 - val_loss: 674.9555\n",
      "Epoch 765/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 674.9368\n",
      "Epoch 766/1000\n",
      "302/302 [==============================] - 0s 990us/step - loss: 341.7412 - val_loss: 674.9866\n",
      "Epoch 767/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 341.7394 - val_loss: 674.9775\n",
      "Epoch 768/1000\n",
      "302/302 [==============================] - 0s 886us/step - loss: 341.7395 - val_loss: 674.9828\n",
      "Epoch 769/1000\n",
      "302/302 [==============================] - 0s 927us/step - loss: 341.7399 - val_loss: 674.9970\n",
      "Epoch 770/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7400 - val_loss: 674.9930\n",
      "Epoch 771/1000\n",
      "302/302 [==============================] - 0s 948us/step - loss: 341.7394 - val_loss: 675.0082\n",
      "Epoch 772/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 341.7401 - val_loss: 674.9543\n",
      "Epoch 773/1000\n",
      "302/302 [==============================] - 0s 959us/step - loss: 341.7393 - val_loss: 675.0225\n",
      "Epoch 774/1000\n",
      "302/302 [==============================] - 0s 999us/step - loss: 341.7400 - val_loss: 675.0187\n",
      "Epoch 775/1000\n",
      "302/302 [==============================] - 0s 947us/step - loss: 341.7410 - val_loss: 674.9838\n",
      "Epoch 776/1000\n",
      "302/302 [==============================] - 0s 971us/step - loss: 341.7405 - val_loss: 675.0543\n",
      "Epoch 777/1000\n",
      "302/302 [==============================] - 0s 965us/step - loss: 341.7401 - val_loss: 675.0347\n",
      "Epoch 778/1000\n",
      "302/302 [==============================] - 0s 971us/step - loss: 341.7396 - val_loss: 674.9731\n",
      "Epoch 779/1000\n",
      "302/302 [==============================] - 0s 991us/step - loss: 341.7402 - val_loss: 674.9677\n",
      "Epoch 780/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 341.7407 - val_loss: 675.0416\n",
      "Epoch 781/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 341.7401 - val_loss: 675.0181\n",
      "Epoch 782/1000\n",
      "302/302 [==============================] - 0s 872us/step - loss: 341.7405 - val_loss: 675.0108\n",
      "Epoch 783/1000\n",
      "302/302 [==============================] - 0s 839us/step - loss: 341.7422 - val_loss: 674.9955\n",
      "Epoch 784/1000\n",
      "302/302 [==============================] - 0s 901us/step - loss: 341.7413 - val_loss: 675.0055\n",
      "Epoch 785/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7405 - val_loss: 674.9810\n",
      "Epoch 786/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9779\n",
      "Epoch 787/1000\n",
      "302/302 [==============================] - 0s 922us/step - loss: 341.7403 - val_loss: 675.0220\n",
      "Epoch 788/1000\n",
      "302/302 [==============================] - 0s 889us/step - loss: 341.7403 - val_loss: 674.9662\n",
      "Epoch 789/1000\n",
      "302/302 [==============================] - 0s 907us/step - loss: 341.7408 - val_loss: 674.9536\n",
      "Epoch 790/1000\n",
      "302/302 [==============================] - 0s 936us/step - loss: 341.7405 - val_loss: 675.0697\n",
      "Epoch 791/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7406 - val_loss: 675.0168\n",
      "Epoch 792/1000\n",
      "302/302 [==============================] - 0s 987us/step - loss: 341.7401 - val_loss: 675.0279\n",
      "Epoch 793/1000\n",
      "302/302 [==============================] - 0s 881us/step - loss: 341.7402 - val_loss: 674.9807\n",
      "Epoch 794/1000\n",
      "302/302 [==============================] - 0s 879us/step - loss: 341.7409 - val_loss: 674.9930\n",
      "Epoch 795/1000\n",
      "302/302 [==============================] - 0s 846us/step - loss: 341.7393 - val_loss: 674.9988\n",
      "Epoch 796/1000\n",
      "302/302 [==============================] - 0s 925us/step - loss: 341.7417 - val_loss: 674.9944\n",
      "Epoch 797/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 341.7415 - val_loss: 674.9996\n",
      "Epoch 798/1000\n",
      "302/302 [==============================] - 0s 866us/step - loss: 341.7402 - val_loss: 674.9913\n",
      "Epoch 799/1000\n",
      "302/302 [==============================] - 0s 859us/step - loss: 341.7413 - val_loss: 675.0081\n",
      "Epoch 800/1000\n",
      "302/302 [==============================] - 0s 924us/step - loss: 341.7400 - val_loss: 674.9748\n",
      "Epoch 801/1000\n",
      "302/302 [==============================] - 0s 871us/step - loss: 341.7402 - val_loss: 674.9985\n",
      "Epoch 802/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7405 - val_loss: 675.0118\n",
      "Epoch 803/1000\n",
      "302/302 [==============================] - 0s 953us/step - loss: 341.7397 - val_loss: 674.9651\n",
      "Epoch 804/1000\n",
      "302/302 [==============================] - 0s 867us/step - loss: 341.7399 - val_loss: 674.9783\n",
      "Epoch 805/1000\n",
      "302/302 [==============================] - 0s 881us/step - loss: 341.7407 - val_loss: 675.0121\n",
      "Epoch 806/1000\n",
      "302/302 [==============================] - 0s 921us/step - loss: 341.7397 - val_loss: 675.0120\n",
      "Epoch 807/1000\n",
      "302/302 [==============================] - 0s 842us/step - loss: 341.7401 - val_loss: 674.9775\n",
      "Epoch 808/1000\n",
      "302/302 [==============================] - 0s 906us/step - loss: 341.7399 - val_loss: 674.9816\n",
      "Epoch 809/1000\n",
      "302/302 [==============================] - 0s 874us/step - loss: 341.7412 - val_loss: 675.0712\n",
      "Epoch 810/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 341.7405 - val_loss: 675.0119\n",
      "Epoch 811/1000\n",
      "302/302 [==============================] - 0s 863us/step - loss: 341.7400 - val_loss: 675.0383\n",
      "Epoch 812/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7403 - val_loss: 675.0529\n",
      "Epoch 813/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 341.7403 - val_loss: 675.0029\n",
      "Epoch 814/1000\n",
      "302/302 [==============================] - 0s 857us/step - loss: 341.7414 - val_loss: 675.0567\n",
      "Epoch 815/1000\n",
      "302/302 [==============================] - 0s 940us/step - loss: 341.7410 - val_loss: 675.0085\n",
      "Epoch 816/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 341.7411 - val_loss: 675.0955\n",
      "Epoch 817/1000\n",
      "302/302 [==============================] - 0s 896us/step - loss: 341.7421 - val_loss: 674.9933\n",
      "Epoch 818/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7409 - val_loss: 675.0366\n",
      "Epoch 819/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 341.7421 - val_loss: 674.9882\n",
      "Epoch 820/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 341.7400 - val_loss: 675.0782\n",
      "Epoch 821/1000\n",
      "302/302 [==============================] - 0s 844us/step - loss: 341.7400 - val_loss: 675.0394\n",
      "Epoch 822/1000\n",
      "302/302 [==============================] - 0s 975us/step - loss: 341.7401 - val_loss: 675.0477\n",
      "Epoch 823/1000\n",
      "302/302 [==============================] - 0s 939us/step - loss: 341.7394 - val_loss: 675.0042\n",
      "Epoch 824/1000\n",
      "302/302 [==============================] - 0s 896us/step - loss: 341.7397 - val_loss: 675.0096\n",
      "Epoch 825/1000\n",
      "302/302 [==============================] - 0s 907us/step - loss: 341.7412 - val_loss: 674.9869\n",
      "Epoch 826/1000\n",
      "302/302 [==============================] - 0s 886us/step - loss: 341.7404 - val_loss: 675.0170\n",
      "Epoch 827/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 341.7417 - val_loss: 674.9956\n",
      "Epoch 828/1000\n",
      "302/302 [==============================] - 0s 930us/step - loss: 341.7392 - val_loss: 674.9758\n",
      "Epoch 829/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 341.7398 - val_loss: 675.0332\n",
      "Epoch 830/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7400 - val_loss: 674.9998\n",
      "Epoch 831/1000\n",
      "302/302 [==============================] - 0s 847us/step - loss: 341.7391 - val_loss: 675.0346\n",
      "Epoch 832/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7394 - val_loss: 674.9717\n",
      "Epoch 833/1000\n",
      "302/302 [==============================] - 0s 893us/step - loss: 341.7403 - val_loss: 674.9597\n",
      "Epoch 834/1000\n",
      "302/302 [==============================] - 0s 944us/step - loss: 341.7411 - val_loss: 675.0297\n",
      "Epoch 835/1000\n",
      "302/302 [==============================] - 0s 969us/step - loss: 341.7413 - val_loss: 674.9680\n",
      "Epoch 836/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 341.7411 - val_loss: 674.9775\n",
      "Epoch 837/1000\n",
      "302/302 [==============================] - 0s 887us/step - loss: 341.7409 - val_loss: 675.0190\n",
      "Epoch 838/1000\n",
      "302/302 [==============================] - 0s 979us/step - loss: 341.7396 - val_loss: 674.9819\n",
      "Epoch 839/1000\n",
      "302/302 [==============================] - 0s 931us/step - loss: 341.7395 - val_loss: 674.9969\n",
      "Epoch 840/1000\n",
      "302/302 [==============================] - 0s 977us/step - loss: 341.7403 - val_loss: 674.9617\n",
      "Epoch 841/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7403 - val_loss: 674.9716\n",
      "Epoch 842/1000\n",
      "302/302 [==============================] - 0s 913us/step - loss: 341.7411 - val_loss: 674.9739\n",
      "Epoch 843/1000\n",
      "302/302 [==============================] - 0s 889us/step - loss: 341.7393 - val_loss: 674.9529\n",
      "Epoch 844/1000\n",
      "302/302 [==============================] - 0s 927us/step - loss: 341.7401 - val_loss: 675.0092\n",
      "Epoch 845/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 341.7398 - val_loss: 674.9945\n",
      "Epoch 846/1000\n",
      "302/302 [==============================] - 0s 894us/step - loss: 341.7419 - val_loss: 674.9839\n",
      "Epoch 847/1000\n",
      "302/302 [==============================] - 0s 867us/step - loss: 341.7411 - val_loss: 674.9933\n",
      "Epoch 848/1000\n",
      "302/302 [==============================] - 0s 937us/step - loss: 341.7398 - val_loss: 674.9985\n",
      "Epoch 849/1000\n",
      "302/302 [==============================] - 0s 957us/step - loss: 341.7396 - val_loss: 674.9847\n",
      "Epoch 850/1000\n",
      "302/302 [==============================] - 0s 926us/step - loss: 341.7403 - val_loss: 675.0612\n",
      "Epoch 851/1000\n",
      "302/302 [==============================] - 0s 986us/step - loss: 341.7418 - val_loss: 675.0414\n",
      "Epoch 852/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 341.7405 - val_loss: 675.0049\n",
      "Epoch 853/1000\n",
      "302/302 [==============================] - 0s 904us/step - loss: 341.7393 - val_loss: 675.0283\n",
      "Epoch 854/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7420 - val_loss: 675.0057\n",
      "Epoch 855/1000\n",
      "302/302 [==============================] - 0s 1000us/step - loss: 341.7393 - val_loss: 674.9673\n",
      "Epoch 856/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7404 - val_loss: 675.0554\n",
      "Epoch 857/1000\n",
      "302/302 [==============================] - 0s 862us/step - loss: 341.7408 - val_loss: 674.9281\n",
      "Epoch 858/1000\n",
      "302/302 [==============================] - 0s 912us/step - loss: 341.7407 - val_loss: 674.9261\n",
      "Epoch 859/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7411 - val_loss: 674.9449\n",
      "Epoch 860/1000\n",
      "302/302 [==============================] - 0s 878us/step - loss: 341.7395 - val_loss: 675.0483\n",
      "Epoch 861/1000\n",
      "302/302 [==============================] - 0s 889us/step - loss: 341.7401 - val_loss: 675.0092\n",
      "Epoch 862/1000\n",
      "302/302 [==============================] - 0s 894us/step - loss: 341.7405 - val_loss: 674.9584\n",
      "Epoch 863/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 341.7429 - val_loss: 675.0166\n",
      "Epoch 864/1000\n",
      "302/302 [==============================] - 0s 908us/step - loss: 341.7407 - val_loss: 675.0057\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 896us/step - loss: 341.7407 - val_loss: 675.0195\n",
      "Epoch 866/1000\n",
      "302/302 [==============================] - 0s 988us/step - loss: 341.7408 - val_loss: 674.9819\n",
      "Epoch 867/1000\n",
      "302/302 [==============================] - 0s 931us/step - loss: 341.7398 - val_loss: 675.0898\n",
      "Epoch 868/1000\n",
      "302/302 [==============================] - 0s 951us/step - loss: 341.7400 - val_loss: 674.9997\n",
      "Epoch 869/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 674.9960\n",
      "Epoch 870/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 675.0129\n",
      "Epoch 871/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 674.9835\n",
      "Epoch 872/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.0146\n",
      "Epoch 873/1000\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 341.7403 - val_loss: 674.9784\n",
      "Epoch 874/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 675.0378\n",
      "Epoch 875/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7414 - val_loss: 675.0673\n",
      "Epoch 876/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7388 - val_loss: 675.0146\n",
      "Epoch 877/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7411 - val_loss: 674.9998\n",
      "Epoch 878/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0402\n",
      "Epoch 879/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7397 - val_loss: 675.0325\n",
      "Epoch 880/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7407 - val_loss: 675.0542\n",
      "Epoch 881/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7410 - val_loss: 675.0070\n",
      "Epoch 882/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7409 - val_loss: 674.9628\n",
      "Epoch 883/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7422 - val_loss: 675.0001\n",
      "Epoch 884/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7393 - val_loss: 674.9996\n",
      "Epoch 885/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7401 - val_loss: 675.0172\n",
      "Epoch 886/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 675.0231\n",
      "Epoch 887/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7407 - val_loss: 674.9899\n",
      "Epoch 888/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 674.8962\n",
      "Epoch 889/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 674.9836\n",
      "Epoch 890/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7413 - val_loss: 675.0291\n",
      "Epoch 891/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7393 - val_loss: 675.0035\n",
      "Epoch 892/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7396 - val_loss: 674.9235\n",
      "Epoch 893/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7393 - val_loss: 674.9356\n",
      "Epoch 894/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 674.8872\n",
      "Epoch 895/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7401 - val_loss: 674.9471\n",
      "Epoch 896/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9543\n",
      "Epoch 897/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 675.0159\n",
      "Epoch 898/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7400 - val_loss: 674.9820\n",
      "Epoch 899/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7408 - val_loss: 674.9258\n",
      "Epoch 900/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 674.9342\n",
      "Epoch 901/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7413 - val_loss: 674.9340\n",
      "Epoch 902/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9570\n",
      "Epoch 903/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9453\n",
      "Epoch 904/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 674.9894\n",
      "Epoch 905/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7395 - val_loss: 674.9927\n",
      "Epoch 906/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7417 - val_loss: 674.9739\n",
      "Epoch 907/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7395 - val_loss: 675.0481\n",
      "Epoch 908/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7403 - val_loss: 675.0156\n",
      "Epoch 909/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 675.0281\n",
      "Epoch 910/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7412 - val_loss: 674.9960\n",
      "Epoch 911/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7417 - val_loss: 674.9827\n",
      "Epoch 912/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7438 - val_loss: 674.9822\n",
      "Epoch 913/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 675.0515\n",
      "Epoch 914/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9786\n",
      "Epoch 915/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7403 - val_loss: 674.9700\n",
      "Epoch 916/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7402 - val_loss: 674.9825\n",
      "Epoch 917/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7420 - val_loss: 674.9714\n",
      "Epoch 918/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7410 - val_loss: 674.9889\n",
      "Epoch 919/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9542\n",
      "Epoch 920/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7402 - val_loss: 674.9156\n",
      "Epoch 921/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 674.9925\n",
      "Epoch 922/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9228\n",
      "Epoch 923/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9506\n",
      "Epoch 924/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 674.9105\n",
      "Epoch 925/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9124\n",
      "Epoch 926/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7397 - val_loss: 674.8957\n",
      "Epoch 927/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7409 - val_loss: 674.9440\n",
      "Epoch 928/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7397 - val_loss: 674.9466\n",
      "Epoch 929/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7415 - val_loss: 674.9252\n",
      "Epoch 930/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7412 - val_loss: 674.9801\n",
      "Epoch 931/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7418 - val_loss: 674.9500\n",
      "Epoch 932/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9591\n",
      "Epoch 933/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7402 - val_loss: 674.9960\n",
      "Epoch 934/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7396 - val_loss: 674.9520\n",
      "Epoch 935/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 674.9395\n",
      "Epoch 936/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.9114\n",
      "Epoch 937/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.8978\n",
      "Epoch 938/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 674.9814\n",
      "Epoch 939/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7394 - val_loss: 674.9944\n",
      "Epoch 940/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7409 - val_loss: 674.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 941/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9807\n",
      "Epoch 942/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7403 - val_loss: 674.9454\n",
      "Epoch 943/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7403 - val_loss: 674.9802\n",
      "Epoch 944/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7408 - val_loss: 674.9549\n",
      "Epoch 945/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9987\n",
      "Epoch 946/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7410 - val_loss: 674.9877\n",
      "Epoch 947/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9902\n",
      "Epoch 948/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7411 - val_loss: 674.9695\n",
      "Epoch 949/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7392 - val_loss: 674.9700\n",
      "Epoch 950/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 674.9724\n",
      "Epoch 951/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9749\n",
      "Epoch 952/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7408 - val_loss: 674.9399\n",
      "Epoch 953/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9799\n",
      "Epoch 954/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9993\n",
      "Epoch 955/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7411 - val_loss: 674.9677\n",
      "Epoch 956/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7397 - val_loss: 675.0259\n",
      "Epoch 957/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9661\n",
      "Epoch 958/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9714\n",
      "Epoch 959/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7396 - val_loss: 674.9741\n",
      "Epoch 960/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9553\n",
      "Epoch 961/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7406 - val_loss: 675.0341\n",
      "Epoch 962/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9053\n",
      "Epoch 963/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9539\n",
      "Epoch 964/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7393 - val_loss: 674.9464\n",
      "Epoch 965/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7404 - val_loss: 674.9438\n",
      "Epoch 966/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7401 - val_loss: 675.0334\n",
      "Epoch 967/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7403 - val_loss: 675.0402\n",
      "Epoch 968/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9705\n",
      "Epoch 969/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9554\n",
      "Epoch 970/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7411 - val_loss: 674.9492\n",
      "Epoch 971/1000\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 341.7414 - val_loss: 674.9882\n",
      "Epoch 972/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7429 - val_loss: 674.9234\n",
      "Epoch 973/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7413 - val_loss: 675.0229\n",
      "Epoch 974/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 341.7407 - val_loss: 674.9858\n",
      "Epoch 975/1000\n",
      "302/302 [==============================] - 0s 974us/step - loss: 341.7404 - val_loss: 674.9985\n",
      "Epoch 976/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7391 - val_loss: 675.0289\n",
      "Epoch 977/1000\n",
      "302/302 [==============================] - 0s 961us/step - loss: 341.7397 - val_loss: 675.0516\n",
      "Epoch 978/1000\n",
      "302/302 [==============================] - 0s 973us/step - loss: 341.7409 - val_loss: 674.9810\n",
      "Epoch 979/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7405 - val_loss: 675.0224\n",
      "Epoch 980/1000\n",
      "302/302 [==============================] - 0s 822us/step - loss: 341.7403 - val_loss: 675.0116\n",
      "Epoch 981/1000\n",
      "302/302 [==============================] - 0s 955us/step - loss: 341.7403 - val_loss: 675.0138\n",
      "Epoch 982/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9989\n",
      "Epoch 983/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 341.7390 - val_loss: 675.0238\n",
      "Epoch 984/1000\n",
      "302/302 [==============================] - 0s 921us/step - loss: 341.7402 - val_loss: 674.9596\n",
      "Epoch 985/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7433 - val_loss: 674.9947\n",
      "Epoch 986/1000\n",
      "302/302 [==============================] - 0s 977us/step - loss: 341.7395 - val_loss: 674.9846\n",
      "Epoch 987/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7396 - val_loss: 674.9877\n",
      "Epoch 988/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7401 - val_loss: 674.9702\n",
      "Epoch 989/1000\n",
      "302/302 [==============================] - 0s 958us/step - loss: 341.7404 - val_loss: 674.9983\n",
      "Epoch 990/1000\n",
      "302/302 [==============================] - 0s 982us/step - loss: 341.7398 - val_loss: 674.9889\n",
      "Epoch 991/1000\n",
      "302/302 [==============================] - 0s 945us/step - loss: 341.7401 - val_loss: 674.9938\n",
      "Epoch 992/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 341.7401 - val_loss: 674.9636\n",
      "Epoch 993/1000\n",
      "302/302 [==============================] - 0s 1000us/step - loss: 341.7402 - val_loss: 674.9910\n",
      "Epoch 994/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.0606\n",
      "Epoch 995/1000\n",
      "302/302 [==============================] - 0s 994us/step - loss: 341.7415 - val_loss: 674.9966\n",
      "Epoch 996/1000\n",
      "302/302 [==============================] - 0s 834us/step - loss: 341.7400 - val_loss: 675.0055\n",
      "Epoch 997/1000\n",
      "302/302 [==============================] - 0s 949us/step - loss: 341.7410 - val_loss: 675.0687\n",
      "Epoch 998/1000\n",
      "302/302 [==============================] - 0s 967us/step - loss: 341.7402 - val_loss: 675.0338\n",
      "Epoch 999/1000\n",
      "302/302 [==============================] - 0s 918us/step - loss: 341.7398 - val_loss: 675.0262\n",
      "Epoch 1000/1000\n",
      "302/302 [==============================] - 0s 907us/step - loss: 341.7397 - val_loss: 675.0486\n",
      "50/50 [==============================] - 0s 475us/step\n",
      "1014697 successful\n",
      "Epoch 1/1000\n",
      "308/308 [==============================] - 1s 1ms/step - loss: 649978.5625 - val_loss: 1036.9358\n",
      "Epoch 2/1000\n",
      "308/308 [==============================] - 0s 955us/step - loss: 655.8464 - val_loss: 645.7344\n",
      "Epoch 3/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 778.3404 - val_loss: 1210.3651\n",
      "Epoch 4/1000\n",
      "308/308 [==============================] - 0s 976us/step - loss: 1055.6810 - val_loss: 2217.4739\n",
      "Epoch 5/1000\n",
      "308/308 [==============================] - 0s 892us/step - loss: 21623.5801 - val_loss: 15299.8184\n",
      "Epoch 6/1000\n",
      "308/308 [==============================] - 0s 873us/step - loss: 54832.8828 - val_loss: 7596.8555\n",
      "Epoch 7/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 51881.9922 - val_loss: 3688.7329\n",
      "Epoch 8/1000\n",
      "308/308 [==============================] - 0s 940us/step - loss: 53463.8203 - val_loss: 100153.8672\n",
      "Epoch 9/1000\n",
      "308/308 [==============================] - 0s 953us/step - loss: 55763.3164 - val_loss: 157674.4531\n",
      "Epoch 10/1000\n",
      "308/308 [==============================] - 0s 903us/step - loss: 44113.5195 - val_loss: 12923.2402\n",
      "Epoch 11/1000\n",
      "308/308 [==============================] - 0s 840us/step - loss: 44449.7227 - val_loss: 5529.9292\n",
      "Epoch 12/1000\n",
      "308/308 [==============================] - 0s 946us/step - loss: 46997.0273 - val_loss: 90895.4766\n",
      "Epoch 13/1000\n",
      "308/308 [==============================] - 0s 897us/step - loss: 44027.7930 - val_loss: 3965.7446\n",
      "Epoch 14/1000\n",
      "308/308 [==============================] - 0s 931us/step - loss: 42125.4219 - val_loss: 32461.9473\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 946us/step - loss: 56404.7422 - val_loss: 28837.7266\n",
      "Epoch 16/1000\n",
      "308/308 [==============================] - 0s 981us/step - loss: 30937.6934 - val_loss: 40691.5430\n",
      "Epoch 17/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 39550.6328 - val_loss: 8810.3535\n",
      "Epoch 18/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 35487.3555 - val_loss: 3213.9392\n",
      "Epoch 19/1000\n",
      "308/308 [==============================] - 0s 841us/step - loss: 33154.7148 - val_loss: 1153.0387\n",
      "Epoch 20/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 41174.3125 - val_loss: 33134.3516\n",
      "Epoch 21/1000\n",
      "308/308 [==============================] - 0s 968us/step - loss: 32486.6953 - val_loss: 608.4377\n",
      "Epoch 22/1000\n",
      "308/308 [==============================] - 0s 843us/step - loss: 38792.8164 - val_loss: 17435.9004\n",
      "Epoch 23/1000\n",
      "308/308 [==============================] - 0s 843us/step - loss: 2352865.0000 - val_loss: 686.6620\n",
      "Epoch 24/1000\n",
      "308/308 [==============================] - 0s 982us/step - loss: 439.0532 - val_loss: 628.5326\n",
      "Epoch 25/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 449.9188 - val_loss: 785.1375\n",
      "Epoch 26/1000\n",
      "308/308 [==============================] - 0s 949us/step - loss: 458.9730 - val_loss: 996.8371\n",
      "Epoch 27/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 443.1615 - val_loss: 1308.1935\n",
      "Epoch 28/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 472.7801 - val_loss: 635.9392\n",
      "Epoch 29/1000\n",
      "308/308 [==============================] - 0s 839us/step - loss: 534.2890 - val_loss: 743.1175\n",
      "Epoch 30/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 517.5455 - val_loss: 628.2613\n",
      "Epoch 31/1000\n",
      "308/308 [==============================] - 0s 977us/step - loss: 665.9529 - val_loss: 723.3432\n",
      "Epoch 32/1000\n",
      "308/308 [==============================] - 0s 849us/step - loss: 628.8541 - val_loss: 2025.4395\n",
      "Epoch 33/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 935.2996 - val_loss: 1111.5063\n",
      "Epoch 34/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 943.2170 - val_loss: 1867.9471\n",
      "Epoch 35/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 3683.5830 - val_loss: 2347.8506\n",
      "Epoch 36/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 11685.7949 - val_loss: 1023.8840\n",
      "Epoch 37/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 18488.8848 - val_loss: 2821.2483\n",
      "Epoch 38/1000\n",
      "308/308 [==============================] - 0s 941us/step - loss: 15828.1465 - val_loss: 8304.9346\n",
      "Epoch 39/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 16149.6553 - val_loss: 77207.8359\n",
      "Epoch 40/1000\n",
      "308/308 [==============================] - 0s 856us/step - loss: 16186.5264 - val_loss: 13046.6016\n",
      "Epoch 41/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 16921.8965 - val_loss: 7607.0400\n",
      "Epoch 42/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 15628.1045 - val_loss: 62916.8984\n",
      "Epoch 43/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 14516.8750 - val_loss: 15302.1982\n",
      "Epoch 44/1000\n",
      "308/308 [==============================] - 0s 861us/step - loss: 14607.9434 - val_loss: 20995.5078\n",
      "Epoch 45/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 12096.3262 - val_loss: 7134.9121\n",
      "Epoch 46/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 14229.2939 - val_loss: 698.7062\n",
      "Epoch 47/1000\n",
      "308/308 [==============================] - 0s 835us/step - loss: 14760.7773 - val_loss: 47095.6602\n",
      "Epoch 48/1000\n",
      "308/308 [==============================] - 0s 818us/step - loss: 11781.1855 - val_loss: 1214.1558\n",
      "Epoch 49/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 13433.3994 - val_loss: 659.8860\n",
      "Epoch 50/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 13686.5693 - val_loss: 1431.1013\n",
      "Epoch 51/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 12828.8066 - val_loss: 2604.8447\n",
      "Epoch 52/1000\n",
      "308/308 [==============================] - 0s 907us/step - loss: 11418.0488 - val_loss: 15357.2646\n",
      "Epoch 53/1000\n",
      "308/308 [==============================] - 0s 817us/step - loss: 10126.8242 - val_loss: 16632.5508\n",
      "Epoch 54/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 12912.3281 - val_loss: 712.9030\n",
      "Epoch 55/1000\n",
      "308/308 [==============================] - 0s 864us/step - loss: 11170.8809 - val_loss: 1042.3783\n",
      "Epoch 56/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 13075.6143 - val_loss: 755.8066\n",
      "Epoch 57/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 9952.0996 - val_loss: 9262.8057\n",
      "Epoch 58/1000\n",
      "308/308 [==============================] - 0s 837us/step - loss: 11281.8467 - val_loss: 18185.7266\n",
      "Epoch 59/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 10740.7676 - val_loss: 1056.7914\n",
      "Epoch 60/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 10880.8281 - val_loss: 10122.8047\n",
      "Epoch 61/1000\n",
      "308/308 [==============================] - 0s 944us/step - loss: 9031.4473 - val_loss: 23657.6094\n",
      "Epoch 62/1000\n",
      "308/308 [==============================] - 0s 945us/step - loss: 9987.0186 - val_loss: 1182.4968\n",
      "Epoch 63/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 895128.1250 - val_loss: 679.0684\n",
      "Epoch 64/1000\n",
      "308/308 [==============================] - 0s 897us/step - loss: 412.6048 - val_loss: 628.4509\n",
      "Epoch 65/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 474.2574 - val_loss: 720.0009\n",
      "Epoch 66/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 451.4618 - val_loss: 611.1515\n",
      "Epoch 67/1000\n",
      "308/308 [==============================] - 0s 890us/step - loss: 462.7640 - val_loss: 911.6779\n",
      "Epoch 68/1000\n",
      "308/308 [==============================] - 0s 846us/step - loss: 532.6002 - val_loss: 613.3378\n",
      "Epoch 69/1000\n",
      "308/308 [==============================] - 0s 847us/step - loss: 545.7051 - val_loss: 928.5342\n",
      "Epoch 70/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 510.3193 - val_loss: 928.2132\n",
      "Epoch 71/1000\n",
      "308/308 [==============================] - 0s 865us/step - loss: 674.9479 - val_loss: 605.7847\n",
      "Epoch 72/1000\n",
      "308/308 [==============================] - 0s 970us/step - loss: 656.6193 - val_loss: 730.4720\n",
      "Epoch 73/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 813.1751 - val_loss: 904.4444\n",
      "Epoch 74/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 1351.1168 - val_loss: 621.7832\n",
      "Epoch 75/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 1348.5659 - val_loss: 1013.2495\n",
      "Epoch 76/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 6029.1084 - val_loss: 604.4085\n",
      "Epoch 77/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 5702.2119 - val_loss: 10845.4111\n",
      "Epoch 78/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 7495.9893 - val_loss: 6936.5859\n",
      "Epoch 79/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 5237.6812 - val_loss: 2536.4683\n",
      "Epoch 80/1000\n",
      "308/308 [==============================] - 0s 955us/step - loss: 6687.4722 - val_loss: 969.3508\n",
      "Epoch 81/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 6386.2559 - val_loss: 10467.8135\n",
      "Epoch 82/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 6447.2446 - val_loss: 28398.5078\n",
      "Epoch 83/1000\n",
      "308/308 [==============================] - 0s 942us/step - loss: 5794.1665 - val_loss: 1202.7656\n",
      "Epoch 84/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 5388.5850 - val_loss: 604.3884\n",
      "Epoch 85/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 4868.1182 - val_loss: 7952.4009\n",
      "Epoch 86/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 5929.2607 - val_loss: 789.9273\n",
      "Epoch 87/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 5093.4985 - val_loss: 1434.4700\n",
      "Epoch 88/1000\n",
      "308/308 [==============================] - 0s 871us/step - loss: 5115.0889 - val_loss: 15023.1514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000\n",
      "308/308 [==============================] - 0s 892us/step - loss: 5625.9429 - val_loss: 2905.2300\n",
      "Epoch 90/1000\n",
      "308/308 [==============================] - 0s 902us/step - loss: 6017.1958 - val_loss: 604.6592\n",
      "Epoch 91/1000\n",
      "308/308 [==============================] - 0s 954us/step - loss: 3652.3489 - val_loss: 4612.9004\n",
      "Epoch 92/1000\n",
      "308/308 [==============================] - 0s 967us/step - loss: 4157.8218 - val_loss: 8455.3604\n",
      "Epoch 93/1000\n",
      "308/308 [==============================] - 0s 883us/step - loss: 5177.1606 - val_loss: 984.9551\n",
      "Epoch 94/1000\n",
      "308/308 [==============================] - 0s 867us/step - loss: 4836.0874 - val_loss: 965.3740\n",
      "Epoch 95/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 4584.2310 - val_loss: 947.5366\n",
      "Epoch 96/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 3950.4182 - val_loss: 1535.4160\n",
      "Epoch 97/1000\n",
      "308/308 [==============================] - 0s 942us/step - loss: 5114.0171 - val_loss: 4361.3335\n",
      "Epoch 98/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 4339.3262 - val_loss: 718.2676\n",
      "Epoch 99/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 3802.1975 - val_loss: 6650.7607\n",
      "Epoch 100/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 4899.2837 - val_loss: 778.4590\n",
      "Epoch 101/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 2964.0422 - val_loss: 19651.7559\n",
      "Epoch 102/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 3798.5781 - val_loss: 3523.2053\n",
      "Epoch 103/1000\n",
      "308/308 [==============================] - 0s 939us/step - loss: 4355.5879 - val_loss: 853.1735\n",
      "Epoch 104/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 4247.8496 - val_loss: 1119.4189\n",
      "Epoch 105/1000\n",
      "308/308 [==============================] - 0s 979us/step - loss: 3062.8296 - val_loss: 772.3049\n",
      "Epoch 106/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 3404.9634 - val_loss: 1113.2054\n",
      "Epoch 107/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 4112.8262 - val_loss: 616.7375\n",
      "Epoch 108/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 3469.2651 - val_loss: 1402.3508\n",
      "Epoch 109/1000\n",
      "308/308 [==============================] - 0s 919us/step - loss: 3097.7625 - val_loss: 810.4759\n",
      "Epoch 110/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 3130.7690 - val_loss: 3635.5183\n",
      "Epoch 111/1000\n",
      "308/308 [==============================] - 0s 978us/step - loss: 3773.0508 - val_loss: 5632.7271\n",
      "Epoch 112/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 3527.1021 - val_loss: 640.5759\n",
      "Epoch 113/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 3003.6409 - val_loss: 6326.6719\n",
      "Epoch 114/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 3589.9788 - val_loss: 2182.5090\n",
      "Epoch 115/1000\n",
      "308/308 [==============================] - 0s 966us/step - loss: 3077.8511 - val_loss: 677.1130\n",
      "Epoch 116/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 3262.7913 - val_loss: 636.6133\n",
      "Epoch 117/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 2479.7944 - val_loss: 1008.5809\n",
      "Epoch 118/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 3547.2288 - val_loss: 849.9292\n",
      "Epoch 119/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 2601.5371 - val_loss: 620.4323\n",
      "Epoch 120/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 3050.4158 - val_loss: 5294.0327\n",
      "Epoch 121/1000\n",
      "308/308 [==============================] - 0s 985us/step - loss: 2687.8904 - val_loss: 918.6356\n",
      "Epoch 122/1000\n",
      "308/308 [==============================] - 0s 946us/step - loss: 3025.4924 - val_loss: 2644.9856\n",
      "Epoch 123/1000\n",
      "308/308 [==============================] - 0s 921us/step - loss: 2735.1528 - val_loss: 2558.7021\n",
      "Epoch 124/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 1819.8049 - val_loss: 2064.6768\n",
      "Epoch 125/1000\n",
      "308/308 [==============================] - 0s 961us/step - loss: 2793.3403 - val_loss: 608.7010\n",
      "Epoch 126/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 2768.9951 - val_loss: 17608.3340\n",
      "Epoch 127/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 2122.6729 - val_loss: 1150.1027\n",
      "Epoch 128/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 223384.1094 - val_loss: 869.9398\n",
      "Epoch 129/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 417.5418 - val_loss: 607.0294\n",
      "Epoch 130/1000\n",
      "308/308 [==============================] - 0s 898us/step - loss: 434.4387 - val_loss: 708.5915\n",
      "Epoch 131/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 440.4980 - val_loss: 605.0048\n",
      "Epoch 132/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 442.6288 - val_loss: 631.3013\n",
      "Epoch 133/1000\n",
      "308/308 [==============================] - 0s 948us/step - loss: 492.7846 - val_loss: 605.3469\n",
      "Epoch 134/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 496.7766 - val_loss: 734.3815\n",
      "Epoch 135/1000\n",
      "308/308 [==============================] - 0s 976us/step - loss: 538.6027 - val_loss: 1624.9843\n",
      "Epoch 136/1000\n",
      "308/308 [==============================] - 0s 861us/step - loss: 734.0311 - val_loss: 709.4450\n",
      "Epoch 137/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 574.0132 - val_loss: 729.7942\n",
      "Epoch 138/1000\n",
      "308/308 [==============================] - 0s 914us/step - loss: 737.5569 - val_loss: 625.1440\n",
      "Epoch 139/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 793.4789 - val_loss: 7515.8545\n",
      "Epoch 140/1000\n",
      "308/308 [==============================] - 0s 871us/step - loss: 1105.1135 - val_loss: 703.3163\n",
      "Epoch 141/1000\n",
      "308/308 [==============================] - 0s 902us/step - loss: 952.2550 - val_loss: 708.5806\n",
      "Epoch 142/1000\n",
      "308/308 [==============================] - 0s 906us/step - loss: 1753.0482 - val_loss: 1676.9330\n",
      "Epoch 143/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 1677.2645 - val_loss: 1420.3931\n",
      "Epoch 144/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 1558.5714 - val_loss: 3341.8364\n",
      "Epoch 145/1000\n",
      "308/308 [==============================] - 0s 914us/step - loss: 1660.4261 - val_loss: 17430.9570\n",
      "Epoch 146/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1940.3414 - val_loss: 661.8782\n",
      "Epoch 147/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1112.4100 - val_loss: 4214.1660\n",
      "Epoch 148/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1628.5649 - val_loss: 651.5772\n",
      "Epoch 149/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1406.0111 - val_loss: 974.6302\n",
      "Epoch 150/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1636.2339 - val_loss: 4177.4521\n",
      "Epoch 151/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1452.6289 - val_loss: 7121.7886\n",
      "Epoch 152/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1214.2493 - val_loss: 1269.6671\n",
      "Epoch 153/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1645.0140 - val_loss: 975.7736\n",
      "Epoch 154/1000\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 1237.7426 - val_loss: 983.4656\n",
      "Epoch 155/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1074.2042 - val_loss: 617.3303\n",
      "Epoch 156/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1140.2551 - val_loss: 606.6882\n",
      "Epoch 157/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1042.0658 - val_loss: 1449.6901\n",
      "Epoch 158/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1205.4698 - val_loss: 604.6376\n",
      "Epoch 159/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 932.1937 - val_loss: 1108.1763\n",
      "Epoch 160/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 1036.0759 - val_loss: 620.9600\n",
      "Epoch 161/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 1055.1033 - val_loss: 3608.1172\n",
      "Epoch 162/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 941.2295 - val_loss: 604.4510\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 1s 3ms/step - loss: 1014.3054 - val_loss: 642.2847\n",
      "Epoch 164/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 773.8700 - val_loss: 4029.1025\n",
      "Epoch 165/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 818.0311 - val_loss: 1383.5043\n",
      "Epoch 166/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 755.9995 - val_loss: 608.2174\n",
      "Epoch 167/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 827.8535 - val_loss: 2244.0610\n",
      "Epoch 168/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 703.6675 - val_loss: 818.6582\n",
      "Epoch 169/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 626.4495 - val_loss: 635.1669\n",
      "Epoch 170/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 780.1111 - val_loss: 1667.7629\n",
      "Epoch 171/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 535.5732 - val_loss: 1355.8979\n",
      "Epoch 172/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 687.5743 - val_loss: 890.1470\n",
      "Epoch 173/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 609.8471 - val_loss: 790.5563\n",
      "Epoch 174/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 481.8032 - val_loss: 616.3074\n",
      "Epoch 175/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 458.6715 - val_loss: 672.8271\n",
      "Epoch 176/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 480.9867 - val_loss: 943.2640\n",
      "Epoch 177/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 462.7061 - val_loss: 685.5237\n",
      "Epoch 178/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 433.1450 - val_loss: 688.4183\n",
      "Epoch 179/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 408.7296 - val_loss: 679.0992\n",
      "Epoch 180/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.5914 - val_loss: 669.4427\n",
      "Epoch 181/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 393.0366 - val_loss: 628.4251\n",
      "Epoch 182/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.3434 - val_loss: 643.3666\n",
      "Epoch 183/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 396.6788 - val_loss: 707.2410\n",
      "Epoch 184/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 391.9267 - val_loss: 639.0633\n",
      "Epoch 185/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.2396 - val_loss: 627.9684\n",
      "Epoch 186/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.1860 - val_loss: 652.1780\n",
      "Epoch 187/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 396.4176 - val_loss: 604.5690\n",
      "Epoch 188/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.9176 - val_loss: 673.8997\n",
      "Epoch 189/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.2676 - val_loss: 809.5928\n",
      "Epoch 190/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 395.3818 - val_loss: 627.0992\n",
      "Epoch 191/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 395.7607 - val_loss: 646.7567\n",
      "Epoch 192/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 396.7039 - val_loss: 736.7892\n",
      "Epoch 193/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.5956 - val_loss: 664.3818\n",
      "Epoch 194/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 400.4670 - val_loss: 617.0279\n",
      "Epoch 195/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.6631 - val_loss: 748.8724\n",
      "Epoch 196/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 398.4645 - val_loss: 614.9403\n",
      "Epoch 197/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 401.5168 - val_loss: 666.3303\n",
      "Epoch 198/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 398.1216 - val_loss: 657.6788\n",
      "Epoch 199/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 410.1325 - val_loss: 608.0609\n",
      "Epoch 200/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 408.1585 - val_loss: 693.7601\n",
      "Epoch 201/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 401.3816 - val_loss: 748.7923\n",
      "Epoch 202/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 403.2649 - val_loss: 628.6121\n",
      "Epoch 203/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 408.6700 - val_loss: 643.1306\n",
      "Epoch 204/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 404.7090 - val_loss: 714.8572\n",
      "Epoch 205/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 577.4419 - val_loss: 663.4313\n",
      "Epoch 206/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 403.4269 - val_loss: 676.2881\n",
      "Epoch 207/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 397.2176 - val_loss: 627.7756\n",
      "Epoch 208/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.9590 - val_loss: 729.8436\n",
      "Epoch 209/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.2847 - val_loss: 654.4701\n",
      "Epoch 210/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.5530 - val_loss: 641.1614\n",
      "Epoch 211/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 404.9722 - val_loss: 618.8962\n",
      "Epoch 212/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 403.2505 - val_loss: 645.3804\n",
      "Epoch 213/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 401.6036 - val_loss: 708.1967\n",
      "Epoch 214/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 405.5475 - val_loss: 609.1147\n",
      "Epoch 215/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 402.2238 - val_loss: 704.4553\n",
      "Epoch 216/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 409.3515 - val_loss: 629.9377\n",
      "Epoch 217/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 404.1661 - val_loss: 607.3821\n",
      "Epoch 218/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.9767 - val_loss: 612.7410\n",
      "Epoch 219/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 396.3903 - val_loss: 679.9630\n",
      "Epoch 220/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 404.3572 - val_loss: 736.5999\n",
      "Epoch 221/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 403.8308 - val_loss: 725.3124\n",
      "Epoch 222/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.4297 - val_loss: 613.3812\n",
      "Epoch 223/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 405.7064 - val_loss: 604.4836\n",
      "Epoch 224/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 402.3832 - val_loss: 732.9480\n",
      "Epoch 225/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 400.5804 - val_loss: 611.5752\n",
      "Epoch 226/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 406.9961 - val_loss: 678.7026\n",
      "Epoch 227/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 407.9660 - val_loss: 610.7953\n",
      "Epoch 228/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 408.8287 - val_loss: 679.7277\n",
      "Epoch 229/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 400.9136 - val_loss: 604.8259\n",
      "Epoch 230/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 414.9931 - val_loss: 622.0115\n",
      "Epoch 231/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 409.9508 - val_loss: 714.0629\n",
      "Epoch 232/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 398.6944 - val_loss: 606.0228\n",
      "Epoch 233/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 400.1774 - val_loss: 738.9425\n",
      "Epoch 234/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 412.7834 - val_loss: 771.1822\n",
      "Epoch 235/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 401.8212 - val_loss: 715.7161\n",
      "Epoch 236/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.4796 - val_loss: 646.5739\n",
      "Epoch 237/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 420.3926 - val_loss: 627.2095\n",
      "Epoch 238/1000\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 398.0651 - val_loss: 711.2902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 401.1481 - val_loss: 621.7477\n",
      "Epoch 240/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 24859.2852 - val_loss: 1457.0447\n",
      "Epoch 241/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 895.8212 - val_loss: 1451.6077\n",
      "Epoch 242/1000\n",
      "308/308 [==============================] - 0s 936us/step - loss: 891.3326 - val_loss: 1445.4298\n",
      "Epoch 243/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 886.2418 - val_loss: 1438.4210\n",
      "Epoch 244/1000\n",
      "308/308 [==============================] - 0s 978us/step - loss: 880.5101 - val_loss: 1430.5682\n",
      "Epoch 245/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 874.1097 - val_loss: 1421.8141\n",
      "Epoch 246/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 867.0261 - val_loss: 1412.1667\n",
      "Epoch 247/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 859.2723 - val_loss: 1401.6283\n",
      "Epoch 248/1000\n",
      "308/308 [==============================] - 0s 907us/step - loss: 850.8786 - val_loss: 1390.2706\n",
      "Epoch 249/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 841.9003 - val_loss: 1378.1599\n",
      "Epoch 250/1000\n",
      "308/308 [==============================] - 0s 914us/step - loss: 832.4008 - val_loss: 1365.3885\n",
      "Epoch 251/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 822.4786 - val_loss: 1352.0946\n",
      "Epoch 252/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 812.2153 - val_loss: 1338.4023\n",
      "Epoch 253/1000\n",
      "308/308 [==============================] - 0s 850us/step - loss: 801.6942 - val_loss: 1324.3705\n",
      "Epoch 254/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 791.0193 - val_loss: 1310.1125\n",
      "Epoch 255/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 780.2664 - val_loss: 1295.7734\n",
      "Epoch 256/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 769.4674 - val_loss: 1281.3319\n",
      "Epoch 257/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 758.6909 - val_loss: 1266.8911\n",
      "Epoch 258/1000\n",
      "308/308 [==============================] - 0s 956us/step - loss: 747.9637 - val_loss: 1252.5128\n",
      "Epoch 259/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 737.3132 - val_loss: 1238.1780\n",
      "Epoch 260/1000\n",
      "308/308 [==============================] - 0s 974us/step - loss: 726.7717 - val_loss: 1223.9874\n",
      "Epoch 261/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 716.3562 - val_loss: 1209.8567\n",
      "Epoch 262/1000\n",
      "308/308 [==============================] - 0s 967us/step - loss: 706.0848 - val_loss: 1195.9384\n",
      "Epoch 263/1000\n",
      "308/308 [==============================] - 0s 955us/step - loss: 695.9741 - val_loss: 1182.1548\n",
      "Epoch 264/1000\n",
      "308/308 [==============================] - 0s 833us/step - loss: 686.0300 - val_loss: 1168.5118\n",
      "Epoch 265/1000\n",
      "308/308 [==============================] - 0s 893us/step - loss: 676.2380 - val_loss: 1155.0472\n",
      "Epoch 266/1000\n",
      "308/308 [==============================] - 0s 933us/step - loss: 666.6064 - val_loss: 1141.7567\n",
      "Epoch 267/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 657.1438 - val_loss: 1128.6561\n",
      "Epoch 268/1000\n",
      "308/308 [==============================] - 0s 907us/step - loss: 647.8381 - val_loss: 1115.6526\n",
      "Epoch 269/1000\n",
      "308/308 [==============================] - 0s 859us/step - loss: 638.7029 - val_loss: 1102.8729\n",
      "Epoch 270/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 629.7560 - val_loss: 1090.2655\n",
      "Epoch 271/1000\n",
      "308/308 [==============================] - 0s 835us/step - loss: 620.9805 - val_loss: 1077.8346\n",
      "Epoch 272/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 612.3897 - val_loss: 1065.6399\n",
      "Epoch 273/1000\n",
      "308/308 [==============================] - 0s 819us/step - loss: 603.9571 - val_loss: 1053.5636\n",
      "Epoch 274/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 595.7019 - val_loss: 1041.6593\n",
      "Epoch 275/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 587.6263 - val_loss: 1029.9818\n",
      "Epoch 276/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 579.7280 - val_loss: 1018.4692\n",
      "Epoch 277/1000\n",
      "308/308 [==============================] - 0s 909us/step - loss: 571.9990 - val_loss: 1007.1442\n",
      "Epoch 278/1000\n",
      "308/308 [==============================] - 0s 922us/step - loss: 564.4428 - val_loss: 995.9795\n",
      "Epoch 279/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 557.0575 - val_loss: 984.9968\n",
      "Epoch 280/1000\n",
      "308/308 [==============================] - 0s 947us/step - loss: 549.8466 - val_loss: 974.1979\n",
      "Epoch 281/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 542.8072 - val_loss: 963.6089\n",
      "Epoch 282/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 535.9370 - val_loss: 953.1561\n",
      "Epoch 283/1000\n",
      "308/308 [==============================] - 0s 965us/step - loss: 529.2408 - val_loss: 942.8811\n",
      "Epoch 284/1000\n",
      "308/308 [==============================] - 0s 986us/step - loss: 522.7307 - val_loss: 932.8412\n",
      "Epoch 285/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 516.3904 - val_loss: 922.9973\n",
      "Epoch 286/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 510.2222 - val_loss: 913.3186\n",
      "Epoch 287/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 504.2223 - val_loss: 903.8123\n",
      "Epoch 288/1000\n",
      "308/308 [==============================] - 0s 951us/step - loss: 498.3844 - val_loss: 894.4745\n",
      "Epoch 289/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 492.7235 - val_loss: 885.3232\n",
      "Epoch 290/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 487.2301 - val_loss: 876.3926\n",
      "Epoch 291/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 481.9039 - val_loss: 867.6027\n",
      "Epoch 292/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 476.7469 - val_loss: 858.9982\n",
      "Epoch 293/1000\n",
      "308/308 [==============================] - 0s 948us/step - loss: 471.7471 - val_loss: 850.6102\n",
      "Epoch 294/1000\n",
      "308/308 [==============================] - 0s 817us/step - loss: 466.9121 - val_loss: 842.3671\n",
      "Epoch 295/1000\n",
      "308/308 [==============================] - 0s 978us/step - loss: 462.2527 - val_loss: 834.3599\n",
      "Epoch 296/1000\n",
      "308/308 [==============================] - 0s 876us/step - loss: 457.7704 - val_loss: 826.5166\n",
      "Epoch 297/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 453.4492 - val_loss: 818.8575\n",
      "Epoch 298/1000\n",
      "308/308 [==============================] - 0s 936us/step - loss: 449.2785 - val_loss: 811.4106\n",
      "Epoch 299/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 445.2690 - val_loss: 804.1120\n",
      "Epoch 300/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 441.4194 - val_loss: 797.0051\n",
      "Epoch 301/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 437.7322 - val_loss: 790.0803\n",
      "Epoch 302/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 434.2099 - val_loss: 783.3150\n",
      "Epoch 303/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 430.8349 - val_loss: 776.7902\n",
      "Epoch 304/1000\n",
      "308/308 [==============================] - 0s 861us/step - loss: 427.6086 - val_loss: 770.4188\n",
      "Epoch 305/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 424.5405 - val_loss: 764.2527\n",
      "Epoch 306/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 421.6222 - val_loss: 758.2319\n",
      "Epoch 307/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 418.8456 - val_loss: 752.4064\n",
      "Epoch 308/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 416.2120 - val_loss: 746.7496\n",
      "Epoch 309/1000\n",
      "308/308 [==============================] - 0s 894us/step - loss: 413.7158 - val_loss: 741.2922\n",
      "Epoch 310/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 411.3627 - val_loss: 735.9929\n",
      "Epoch 311/1000\n",
      "308/308 [==============================] - 0s 985us/step - loss: 409.1463 - val_loss: 730.8781\n",
      "Epoch 312/1000\n",
      "308/308 [==============================] - 0s 999us/step - loss: 407.0707 - val_loss: 725.9719\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 955us/step - loss: 405.1264 - val_loss: 721.2705\n",
      "Epoch 314/1000\n",
      "308/308 [==============================] - 0s 987us/step - loss: 403.3050 - val_loss: 716.7036\n",
      "Epoch 315/1000\n",
      "308/308 [==============================] - 0s 935us/step - loss: 401.6209 - val_loss: 712.3529\n",
      "Epoch 316/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 400.0564 - val_loss: 708.1414\n",
      "Epoch 317/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 398.6054 - val_loss: 704.1463\n",
      "Epoch 318/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 397.2650 - val_loss: 700.3107\n",
      "Epoch 319/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 396.0431 - val_loss: 696.6428\n",
      "Epoch 320/1000\n",
      "308/308 [==============================] - 0s 890us/step - loss: 394.9310 - val_loss: 693.2081\n",
      "Epoch 321/1000\n",
      "308/308 [==============================] - 0s 992us/step - loss: 393.9159 - val_loss: 689.9711\n",
      "Epoch 322/1000\n",
      "308/308 [==============================] - 0s 854us/step - loss: 392.9940 - val_loss: 686.8039\n",
      "Epoch 323/1000\n",
      "308/308 [==============================] - 0s 880us/step - loss: 392.1577 - val_loss: 683.8987\n",
      "Epoch 324/1000\n",
      "308/308 [==============================] - 0s 865us/step - loss: 391.4247 - val_loss: 681.1637\n",
      "Epoch 325/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 390.7733 - val_loss: 678.5992\n",
      "Epoch 326/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 390.1875 - val_loss: 676.2068\n",
      "Epoch 327/1000\n",
      "308/308 [==============================] - 0s 845us/step - loss: 389.6662 - val_loss: 673.9935\n",
      "Epoch 328/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 389.2113 - val_loss: 671.9369\n",
      "Epoch 329/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 388.8131 - val_loss: 669.9343\n",
      "Epoch 330/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 388.4654 - val_loss: 668.1761\n",
      "Epoch 331/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 388.1573 - val_loss: 666.4798\n",
      "Epoch 332/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 387.8907 - val_loss: 664.9451\n",
      "Epoch 333/1000\n",
      "308/308 [==============================] - 0s 873us/step - loss: 387.6613 - val_loss: 663.5080\n",
      "Epoch 334/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 387.4617 - val_loss: 662.1606\n",
      "Epoch 335/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 387.2894 - val_loss: 660.9445\n",
      "Epoch 336/1000\n",
      "308/308 [==============================] - 0s 871us/step - loss: 387.1422 - val_loss: 659.8630\n",
      "Epoch 337/1000\n",
      "308/308 [==============================] - 0s 849us/step - loss: 387.0166 - val_loss: 658.7813\n",
      "Epoch 338/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 386.9109 - val_loss: 657.8430\n",
      "Epoch 339/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 386.8214 - val_loss: 656.9910\n",
      "Epoch 340/1000\n",
      "308/308 [==============================] - 0s 849us/step - loss: 386.7435 - val_loss: 656.1689\n",
      "Epoch 341/1000\n",
      "308/308 [==============================] - 0s 962us/step - loss: 386.6776 - val_loss: 655.4274\n",
      "Epoch 342/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.6226 - val_loss: 654.7474\n",
      "Epoch 343/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 386.5765 - val_loss: 654.1378\n",
      "Epoch 344/1000\n",
      "308/308 [==============================] - 0s 903us/step - loss: 386.5388 - val_loss: 653.6242\n",
      "Epoch 345/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 386.5050 - val_loss: 653.0532\n",
      "Epoch 346/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.4792 - val_loss: 652.6379\n",
      "Epoch 347/1000\n",
      "308/308 [==============================] - 0s 828us/step - loss: 386.4562 - val_loss: 652.2339\n",
      "Epoch 348/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 386.4384 - val_loss: 651.8073\n",
      "Epoch 349/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 386.4217 - val_loss: 651.4486\n",
      "Epoch 350/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 386.4093 - val_loss: 651.1729\n",
      "Epoch 351/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 386.3952 - val_loss: 650.8109\n",
      "Epoch 352/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 386.3855 - val_loss: 650.5881\n",
      "Epoch 353/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 386.3793 - val_loss: 650.3046\n",
      "Epoch 354/1000\n",
      "308/308 [==============================] - 0s 954us/step - loss: 386.3730 - val_loss: 650.0585\n",
      "Epoch 355/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 386.3666 - val_loss: 649.8812\n",
      "Epoch 356/1000\n",
      "308/308 [==============================] - 0s 922us/step - loss: 386.3623 - val_loss: 649.6969\n",
      "Epoch 357/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 386.3568 - val_loss: 649.5389\n",
      "Epoch 358/1000\n",
      "308/308 [==============================] - 0s 882us/step - loss: 386.3555 - val_loss: 649.3946\n",
      "Epoch 359/1000\n",
      "308/308 [==============================] - 0s 864us/step - loss: 386.3531 - val_loss: 649.2773\n",
      "Epoch 360/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3487 - val_loss: 649.1235\n",
      "Epoch 361/1000\n",
      "308/308 [==============================] - 0s 882us/step - loss: 386.3482 - val_loss: 649.0038\n",
      "Epoch 362/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 386.3456 - val_loss: 648.9407\n",
      "Epoch 363/1000\n",
      "308/308 [==============================] - 0s 940us/step - loss: 386.3453 - val_loss: 648.7958\n",
      "Epoch 364/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 386.3437 - val_loss: 648.6570\n",
      "Epoch 365/1000\n",
      "308/308 [==============================] - 0s 883us/step - loss: 386.3441 - val_loss: 648.6761\n",
      "Epoch 366/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 386.3420 - val_loss: 648.5907\n",
      "Epoch 367/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 386.3411 - val_loss: 648.5211\n",
      "Epoch 368/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 386.3404 - val_loss: 648.4589\n",
      "Epoch 369/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 386.3405 - val_loss: 648.3760\n",
      "Epoch 370/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 386.3409 - val_loss: 648.3136\n",
      "Epoch 371/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 386.3392 - val_loss: 648.2891\n",
      "Epoch 372/1000\n",
      "308/308 [==============================] - 0s 942us/step - loss: 386.3390 - val_loss: 648.2073\n",
      "Epoch 373/1000\n",
      "308/308 [==============================] - 0s 894us/step - loss: 386.3396 - val_loss: 648.2463\n",
      "Epoch 374/1000\n",
      "308/308 [==============================] - 0s 846us/step - loss: 386.3393 - val_loss: 648.1888\n",
      "Epoch 375/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 386.3382 - val_loss: 648.1371\n",
      "Epoch 376/1000\n",
      "308/308 [==============================] - 0s 874us/step - loss: 386.3398 - val_loss: 648.1446\n",
      "Epoch 377/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 386.3388 - val_loss: 648.1108\n",
      "Epoch 378/1000\n",
      "308/308 [==============================] - 0s 868us/step - loss: 386.3378 - val_loss: 648.0638\n",
      "Epoch 379/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 386.3378 - val_loss: 648.0684\n",
      "Epoch 380/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.3379 - val_loss: 647.9950\n",
      "Epoch 381/1000\n",
      "308/308 [==============================] - 0s 868us/step - loss: 386.3389 - val_loss: 647.9856\n",
      "Epoch 382/1000\n",
      "308/308 [==============================] - 0s 919us/step - loss: 386.3386 - val_loss: 647.9369\n",
      "Epoch 383/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 386.3379 - val_loss: 647.9312\n",
      "Epoch 384/1000\n",
      "308/308 [==============================] - 0s 830us/step - loss: 386.3380 - val_loss: 647.9932\n",
      "Epoch 385/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 386.3383 - val_loss: 647.8427\n",
      "Epoch 386/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 386.3392 - val_loss: 647.8962\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 902us/step - loss: 386.3377 - val_loss: 647.8806\n",
      "Epoch 388/1000\n",
      "308/308 [==============================] - 0s 927us/step - loss: 386.3386 - val_loss: 647.8703\n",
      "Epoch 389/1000\n",
      "308/308 [==============================] - 0s 906us/step - loss: 386.3371 - val_loss: 647.8506\n",
      "Epoch 390/1000\n",
      "308/308 [==============================] - 0s 851us/step - loss: 386.3382 - val_loss: 647.8423\n",
      "Epoch 391/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 386.3382 - val_loss: 647.8008\n",
      "Epoch 392/1000\n",
      "308/308 [==============================] - 0s 887us/step - loss: 386.3367 - val_loss: 647.8260\n",
      "Epoch 393/1000\n",
      "308/308 [==============================] - 0s 938us/step - loss: 386.3377 - val_loss: 647.8298\n",
      "Epoch 394/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3388 - val_loss: 647.8204\n",
      "Epoch 395/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 386.3382 - val_loss: 647.7878\n",
      "Epoch 396/1000\n",
      "308/308 [==============================] - 0s 959us/step - loss: 386.3387 - val_loss: 647.7972\n",
      "Epoch 397/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3383 - val_loss: 647.7845\n",
      "Epoch 398/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3379 - val_loss: 647.7925\n",
      "Epoch 399/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3372 - val_loss: 647.7682\n",
      "Epoch 400/1000\n",
      "308/308 [==============================] - 0s 974us/step - loss: 386.3370 - val_loss: 647.7634\n",
      "Epoch 401/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 386.3382 - val_loss: 647.8132\n",
      "Epoch 402/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 386.3378 - val_loss: 647.8293\n",
      "Epoch 403/1000\n",
      "308/308 [==============================] - 0s 938us/step - loss: 386.3371 - val_loss: 647.7977\n",
      "Epoch 404/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 386.3377 - val_loss: 647.8029\n",
      "Epoch 405/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3379 - val_loss: 647.7794\n",
      "Epoch 406/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 386.3383 - val_loss: 647.7772\n",
      "Epoch 407/1000\n",
      "308/308 [==============================] - 0s 976us/step - loss: 386.3366 - val_loss: 647.8118\n",
      "Epoch 408/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 386.3379 - val_loss: 647.7740\n",
      "Epoch 409/1000\n",
      "308/308 [==============================] - 0s 965us/step - loss: 386.3374 - val_loss: 647.7772\n",
      "Epoch 410/1000\n",
      "308/308 [==============================] - 0s 834us/step - loss: 386.3388 - val_loss: 647.7952\n",
      "Epoch 411/1000\n",
      "308/308 [==============================] - 0s 961us/step - loss: 386.3379 - val_loss: 647.7598\n",
      "Epoch 412/1000\n",
      "308/308 [==============================] - 0s 860us/step - loss: 386.3376 - val_loss: 647.8206\n",
      "Epoch 413/1000\n",
      "308/308 [==============================] - 0s 977us/step - loss: 386.3390 - val_loss: 647.8209\n",
      "Epoch 414/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 386.3375 - val_loss: 647.7884\n",
      "Epoch 415/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3373 - val_loss: 647.7527\n",
      "Epoch 416/1000\n",
      "308/308 [==============================] - 0s 883us/step - loss: 386.3365 - val_loss: 647.7923\n",
      "Epoch 417/1000\n",
      "308/308 [==============================] - 0s 902us/step - loss: 386.3376 - val_loss: 647.7429\n",
      "Epoch 418/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 386.3387 - val_loss: 647.7398\n",
      "Epoch 419/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 386.3377 - val_loss: 647.7749\n",
      "Epoch 420/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 386.3373 - val_loss: 647.7972\n",
      "Epoch 421/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3377 - val_loss: 647.8057\n",
      "Epoch 422/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3373 - val_loss: 647.7945\n",
      "Epoch 423/1000\n",
      "308/308 [==============================] - 0s 954us/step - loss: 386.3376 - val_loss: 647.7966\n",
      "Epoch 424/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 386.3376 - val_loss: 647.8453\n",
      "Epoch 425/1000\n",
      "308/308 [==============================] - 0s 984us/step - loss: 386.3382 - val_loss: 647.7238\n",
      "Epoch 426/1000\n",
      "308/308 [==============================] - 0s 946us/step - loss: 386.3369 - val_loss: 647.7725\n",
      "Epoch 427/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3396 - val_loss: 647.7581\n",
      "Epoch 428/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3381 - val_loss: 647.7521\n",
      "Epoch 429/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3376 - val_loss: 647.7391\n",
      "Epoch 430/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3372 - val_loss: 647.7711\n",
      "Epoch 431/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3373 - val_loss: 647.7435\n",
      "Epoch 432/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3391 - val_loss: 647.7842\n",
      "Epoch 433/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3376 - val_loss: 647.7589\n",
      "Epoch 434/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3381 - val_loss: 647.7213\n",
      "Epoch 435/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3376 - val_loss: 647.7460\n",
      "Epoch 436/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3384 - val_loss: 647.7506\n",
      "Epoch 437/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3365 - val_loss: 647.7419\n",
      "Epoch 438/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3387 - val_loss: 647.7107\n",
      "Epoch 439/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3388 - val_loss: 647.7503\n",
      "Epoch 440/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3372 - val_loss: 647.7304\n",
      "Epoch 441/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3369 - val_loss: 647.7767\n",
      "Epoch 442/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3381 - val_loss: 647.7251\n",
      "Epoch 443/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3392 - val_loss: 647.7269\n",
      "Epoch 444/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3367 - val_loss: 647.7736\n",
      "Epoch 445/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7107\n",
      "Epoch 446/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7006\n",
      "Epoch 447/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7557\n",
      "Epoch 448/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3377 - val_loss: 647.7190\n",
      "Epoch 449/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3375 - val_loss: 647.7234\n",
      "Epoch 450/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7151\n",
      "Epoch 451/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3385 - val_loss: 647.7246\n",
      "Epoch 452/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3382 - val_loss: 647.7280\n",
      "Epoch 453/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3370 - val_loss: 647.7729\n",
      "Epoch 454/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3372 - val_loss: 647.7407\n",
      "Epoch 455/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7657\n",
      "Epoch 456/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3372 - val_loss: 647.7468\n",
      "Epoch 457/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7740\n",
      "Epoch 458/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3374 - val_loss: 647.8083\n",
      "Epoch 459/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.8124\n",
      "Epoch 460/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3370 - val_loss: 647.7422\n",
      "Epoch 461/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3375 - val_loss: 647.7263\n",
      "Epoch 462/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3386 - val_loss: 647.7328\n",
      "Epoch 463/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3387 - val_loss: 647.7565\n",
      "Epoch 464/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7122\n",
      "Epoch 465/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7210\n",
      "Epoch 466/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7333\n",
      "Epoch 467/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3383 - val_loss: 647.7828\n",
      "Epoch 468/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3382 - val_loss: 647.7970\n",
      "Epoch 469/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3382 - val_loss: 647.7615\n",
      "Epoch 470/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3386 - val_loss: 647.7338\n",
      "Epoch 471/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3398 - val_loss: 647.7841\n",
      "Epoch 472/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3371 - val_loss: 647.8151\n",
      "Epoch 473/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.7561\n",
      "Epoch 474/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7626\n",
      "Epoch 475/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3368 - val_loss: 647.7363\n",
      "Epoch 476/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3390 - val_loss: 647.7762\n",
      "Epoch 477/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3372 - val_loss: 647.7411\n",
      "Epoch 478/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7814\n",
      "Epoch 479/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3367 - val_loss: 647.7196\n",
      "Epoch 480/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3362 - val_loss: 647.7452\n",
      "Epoch 481/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7010\n",
      "Epoch 482/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3382 - val_loss: 647.7130\n",
      "Epoch 483/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3374 - val_loss: 647.7419\n",
      "Epoch 484/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3372 - val_loss: 647.7818\n",
      "Epoch 485/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3379 - val_loss: 647.7059\n",
      "Epoch 486/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7280\n",
      "Epoch 487/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3379 - val_loss: 647.7659\n",
      "Epoch 488/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3385 - val_loss: 647.6981\n",
      "Epoch 489/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3387 - val_loss: 647.7300\n",
      "Epoch 490/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3383 - val_loss: 647.7286\n",
      "Epoch 491/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3376 - val_loss: 647.7300\n",
      "Epoch 492/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3366 - val_loss: 647.7366\n",
      "Epoch 493/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7245\n",
      "Epoch 494/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7123\n",
      "Epoch 495/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3385 - val_loss: 647.7429\n",
      "Epoch 496/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7473\n",
      "Epoch 497/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.6900\n",
      "Epoch 498/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.7418\n",
      "Epoch 499/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7290\n",
      "Epoch 500/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3381 - val_loss: 647.7179\n",
      "Epoch 501/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3382 - val_loss: 647.7347\n",
      "Epoch 502/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3387 - val_loss: 647.7609\n",
      "Epoch 503/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3374 - val_loss: 647.7851\n",
      "Epoch 504/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3371 - val_loss: 647.7145\n",
      "Epoch 505/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3377 - val_loss: 647.7482\n",
      "Epoch 506/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7601\n",
      "Epoch 507/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7269\n",
      "Epoch 508/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3390 - val_loss: 647.6780\n",
      "Epoch 509/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3390 - val_loss: 647.7394\n",
      "Epoch 510/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3389 - val_loss: 647.6894\n",
      "Epoch 511/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3387 - val_loss: 647.6666\n",
      "Epoch 512/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3391 - val_loss: 647.6935\n",
      "Epoch 513/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3369 - val_loss: 647.7253\n",
      "Epoch 514/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7152\n",
      "Epoch 515/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3380 - val_loss: 647.7297\n",
      "Epoch 516/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3373 - val_loss: 647.7040\n",
      "Epoch 517/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3366 - val_loss: 647.7388\n",
      "Epoch 518/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3372 - val_loss: 647.6996\n",
      "Epoch 519/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3394 - val_loss: 647.6966\n",
      "Epoch 520/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3383 - val_loss: 647.7311\n",
      "Epoch 521/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7697\n",
      "Epoch 522/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3370 - val_loss: 647.7059\n",
      "Epoch 523/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3389 - val_loss: 647.7367\n",
      "Epoch 524/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7322\n",
      "Epoch 525/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3373 - val_loss: 647.7375\n",
      "Epoch 526/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3383 - val_loss: 647.6891\n",
      "Epoch 527/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.6863\n",
      "Epoch 528/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3376 - val_loss: 647.7160\n",
      "Epoch 529/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3381 - val_loss: 647.7053\n",
      "Epoch 530/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3384 - val_loss: 647.7396\n",
      "Epoch 531/1000\n",
      "308/308 [==============================] - 0s 951us/step - loss: 386.3383 - val_loss: 647.7800\n",
      "Epoch 532/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 386.3373 - val_loss: 647.7375\n",
      "Epoch 533/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3366 - val_loss: 647.7655\n",
      "Epoch 534/1000\n",
      "308/308 [==============================] - 0s 890us/step - loss: 386.3373 - val_loss: 647.7160\n",
      "Epoch 535/1000\n",
      "308/308 [==============================] - 0s 856us/step - loss: 386.3376 - val_loss: 647.6801\n",
      "Epoch 536/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3380 - val_loss: 647.7293\n",
      "Epoch 537/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3388 - val_loss: 647.7223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 386.3375 - val_loss: 647.6793\n",
      "Epoch 539/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.3388 - val_loss: 647.7281\n",
      "Epoch 540/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 386.3381 - val_loss: 647.7426\n",
      "Epoch 541/1000\n",
      "308/308 [==============================] - 0s 874us/step - loss: 386.3378 - val_loss: 647.7473\n",
      "Epoch 542/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 386.3376 - val_loss: 647.7162\n",
      "Epoch 543/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 386.3385 - val_loss: 647.7086\n",
      "Epoch 544/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 386.3387 - val_loss: 647.7117\n",
      "Epoch 545/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3375 - val_loss: 647.7095\n",
      "Epoch 546/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 386.3379 - val_loss: 647.7032\n",
      "Epoch 547/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3372 - val_loss: 647.6707\n",
      "Epoch 548/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3380 - val_loss: 647.7391\n",
      "Epoch 549/1000\n",
      "308/308 [==============================] - 0s 823us/step - loss: 386.3370 - val_loss: 647.7430\n",
      "Epoch 550/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 386.3374 - val_loss: 647.7561\n",
      "Epoch 551/1000\n",
      "308/308 [==============================] - 0s 968us/step - loss: 386.3380 - val_loss: 647.7225\n",
      "Epoch 552/1000\n",
      "308/308 [==============================] - 0s 868us/step - loss: 386.3366 - val_loss: 647.7448\n",
      "Epoch 553/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 386.3378 - val_loss: 647.7533\n",
      "Epoch 554/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 386.3376 - val_loss: 647.7721\n",
      "Epoch 555/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.3367 - val_loss: 647.7520\n",
      "Epoch 556/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 386.3373 - val_loss: 647.7694\n",
      "Epoch 557/1000\n",
      "308/308 [==============================] - 0s 848us/step - loss: 386.3372 - val_loss: 647.7988\n",
      "Epoch 558/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3370 - val_loss: 647.7404\n",
      "Epoch 559/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 386.3385 - val_loss: 647.7656\n",
      "Epoch 560/1000\n",
      "308/308 [==============================] - 0s 949us/step - loss: 386.3394 - val_loss: 647.7531\n",
      "Epoch 561/1000\n",
      "308/308 [==============================] - 0s 842us/step - loss: 386.3382 - val_loss: 647.7519\n",
      "Epoch 562/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3381 - val_loss: 647.7465\n",
      "Epoch 563/1000\n",
      "308/308 [==============================] - 0s 851us/step - loss: 386.3391 - val_loss: 647.7584\n",
      "Epoch 564/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3391 - val_loss: 647.7344\n",
      "Epoch 565/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 386.3368 - val_loss: 647.7817\n",
      "Epoch 566/1000\n",
      "308/308 [==============================] - 0s 949us/step - loss: 386.3384 - val_loss: 647.7473\n",
      "Epoch 567/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3365 - val_loss: 647.7482\n",
      "Epoch 568/1000\n",
      "308/308 [==============================] - 0s 984us/step - loss: 386.3390 - val_loss: 647.6807\n",
      "Epoch 569/1000\n",
      "308/308 [==============================] - 0s 859us/step - loss: 386.3388 - val_loss: 647.7252\n",
      "Epoch 570/1000\n",
      "308/308 [==============================] - 0s 882us/step - loss: 386.3373 - val_loss: 647.7499\n",
      "Epoch 571/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 386.3388 - val_loss: 647.7584\n",
      "Epoch 572/1000\n",
      "308/308 [==============================] - 0s 891us/step - loss: 386.3394 - val_loss: 647.7450\n",
      "Epoch 573/1000\n",
      "308/308 [==============================] - 0s 843us/step - loss: 386.3387 - val_loss: 647.7248\n",
      "Epoch 574/1000\n",
      "308/308 [==============================] - 0s 982us/step - loss: 386.3382 - val_loss: 647.7507\n",
      "Epoch 575/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 386.3377 - val_loss: 647.6898\n",
      "Epoch 576/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3390 - val_loss: 647.6993\n",
      "Epoch 577/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3376 - val_loss: 647.7106\n",
      "Epoch 578/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 386.3369 - val_loss: 647.6810\n",
      "Epoch 579/1000\n",
      "308/308 [==============================] - 0s 908us/step - loss: 386.3383 - val_loss: 647.7886\n",
      "Epoch 580/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 386.3385 - val_loss: 647.7111\n",
      "Epoch 581/1000\n",
      "308/308 [==============================] - 0s 898us/step - loss: 386.3386 - val_loss: 647.7284\n",
      "Epoch 582/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 386.3375 - val_loss: 647.7596\n",
      "Epoch 583/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 386.3378 - val_loss: 647.7511\n",
      "Epoch 584/1000\n",
      "308/308 [==============================] - 0s 854us/step - loss: 386.3378 - val_loss: 647.7501\n",
      "Epoch 585/1000\n",
      "308/308 [==============================] - 0s 894us/step - loss: 386.3379 - val_loss: 647.7759\n",
      "Epoch 586/1000\n",
      "  1/308 [..............................] - ETA: 0s - loss: 164.7677"
     ]
    }
   ],
   "source": [
    "rmse_list, mape_list = [], []\n",
    "for i in range(len(latitudes)):\n",
    "    rmse, mape = cross_validation(final_df, i)\n",
    "    rmse_list.append(rmse)\n",
    "    mape_list.append(mape)\n",
    "    print(f'{device_ids[i]} successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmse = np.mean(rmse_list)          \n",
    "mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f77fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65808b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
