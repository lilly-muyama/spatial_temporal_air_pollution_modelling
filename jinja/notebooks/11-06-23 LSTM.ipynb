{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148a9670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:53:47.031365: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 21:53:47.124115: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-06 21:53:47.126923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:53:47.126935: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-06 21:53:47.625075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:53:47.625128: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:53:47.625133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import sqrt\n",
    "sys.path.append('../..')\n",
    "from modules import utils\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9fb4a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0afe661",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c1406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pm2_5_calibrated_value</th>\n",
       "      <th>pm2_5_raw_value</th>\n",
       "      <th>pm10_raw_value</th>\n",
       "      <th>pm10_calibrated_value</th>\n",
       "      <th>site_id</th>\n",
       "      <th>device_number</th>\n",
       "      <th>device_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 01:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 03:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 04:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  site_name  latitude  longitude   city  \\\n",
       "0  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "1  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "2  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "3  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "4  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "\n",
       "                  timestamp  pm2_5_calibrated_value  pm2_5_raw_value  \\\n",
       "0 2021-09-01 00:00:00+00:00                     NaN              NaN   \n",
       "1 2021-09-01 01:00:00+00:00                     NaN              NaN   \n",
       "2 2021-09-01 02:00:00+00:00                     NaN              NaN   \n",
       "3 2021-09-01 03:00:00+00:00                     NaN              NaN   \n",
       "4 2021-09-01 04:00:00+00:00                     NaN              NaN   \n",
       "\n",
       "   pm10_raw_value  pm10_calibrated_value                   site_id  \\\n",
       "0             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "1             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "2             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "3             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "4             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "\n",
       "   device_number device_name  \n",
       "0         689753       aq_23  \n",
       "1         689753       aq_23  \n",
       "2         689753       aq_23  \n",
       "3         689753       aq_23  \n",
       "4         689753       aq_23  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jinja_df = pd.read_csv('../data/jinja_data.csv', parse_dates=['timestamp'])\n",
    "jinja_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8a2954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitudes = jinja_df['latitude'].unique()\n",
    "longitudes = jinja_df['longitude'].unique()\n",
    "device_ids = jinja_df['device_number'].unique()\n",
    "len(latitudes), len(longitudes), len(device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07dea145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452909.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>12.2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452910.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>11.6507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452911.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>22.3980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>452912.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>17.4937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452913.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>25.1622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  latitude  longitude    pm2_5\n",
       "0  452909.0  0.437337  33.211051  12.2844\n",
       "1  452910.0  0.437337  33.211051  11.6507\n",
       "2  452911.0  0.437337  33.211051  22.3980\n",
       "3  452912.0  0.437337  33.211051  17.4937\n",
       "4  452913.0  0.437337  33.211051  25.1622"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "cols = ['timestamp', 'latitude', 'longitude', 'pm2_5_calibrated_value']\n",
    "for i, device_id in enumerate(device_ids):\n",
    "    device_df = utils.get_device_data(jinja_df, device_id, cols)\n",
    "    processed_df = utils.preprocessing(device_df)\n",
    "    final_df = pd.concat([final_df, processed_df])\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593969e",
   "metadata": {},
   "source": [
    "#### Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbae94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(X_train, y_train, epochs=1000, optimizer='RMSProp', dropout=0.2):\n",
    "#     model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "#     tf.keras.layers.LSTM(50),\n",
    "#     tf.keras.layers.Dense(1)\n",
    "# ])\n",
    "    \n",
    "    input_layer = Input(shape=(X_train.shape[1],))\n",
    "    reshaped_input = tf.expand_dims(input_layer, axis=1)\n",
    "    \n",
    "    lstm_layer1 = LSTM(units=50, return_sequences=True)(reshaped_input)\n",
    "#     dropout_layer1 = Dropout(dropout)(lstm_layer1)\n",
    "\n",
    "    lstm_layer2 = LSTM(units=50)(lstm_layer1)\n",
    "#     dropout_layer2 = Dropout(dropout)(lstm_layer2)\n",
    "    \n",
    "    output_layer = Dense(units=1)(lstm_layer2)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer) \n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_split=0.2)\n",
    "    \n",
    "#     model = keras.Sequential()\n",
    "#     model.add(Input(shape=(X_train.shape[1],), name='Input-Layer')) \n",
    "#     model.add(LSTM(50, return_sequences=True, input_shape=(window_size, x_train.shape[-1])))\n",
    "#     model.add(Dropout(rate=dropout))\n",
    "\n",
    "#     model.add(Bidirectional(LSTM((window_size * 2), return_sequences=True))) \n",
    "#     model.add(Dropout(rate=dropout))\n",
    "\n",
    "#     model.add(Bidirectional(LSTM(window_size, return_sequences=False))) \n",
    "#     model.add(Dense(units=1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b30825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_data(X):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     X_scaled = X.copy()\n",
    "#     X_scaled[:, 0] = scaler.fit_transform(X[:, 0].reshape(-1, 1)).flatten()\n",
    "#     return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d0392e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(final_df, idx):\n",
    "    device_indices = final_df[final_df.latitude==latitudes[idx]].index\n",
    "    device_df = jinja_df[jinja_df.device_number == device_ids[idx]]\n",
    "    assert(len(device_indices) == len(device_df)-device_df.pm2_5_calibrated_value.isna().sum())\n",
    "    \n",
    "    test_df = final_df.loc[device_indices]\n",
    "    assert(len(test_df.longitude.unique()) == 1)\n",
    "    \n",
    "    train_df = pd.concat([final_df, test_df]).drop_duplicates(keep=False)\n",
    "    assert(len(train_df.longitude.unique()) == len(longitudes)-1)\n",
    "    assert len(final_df) == len(test_df) + len(train_df)\n",
    "    \n",
    "    X_train = train_df.iloc[:, 0:-1]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)#.reshape(-1, 1)\n",
    "#     X_train_scaled = scale_data(X_train)\n",
    "    \n",
    "    X_test = test_df.iloc[:, 0:-1]\n",
    "    y_test = test_df.iloc[:, -1]\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)#.reshape(-1, 1)\n",
    "#     X_test_scaled = scale_data(X_test)\n",
    "    \n",
    "    model = lstm(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    return rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fe7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:53:49.952106: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-06 21:53:49.952164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: PL1207-PRO.paris.inria.fr\n",
      "2023-07-06 21:53:49.952172: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: PL1207-PRO.paris.inria.fr\n",
      "2023-07-06 21:53:49.952283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.125.6\n",
      "2023-07-06 21:53:49.952310: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  525.116.04  Release Build  (dvs-builder@U16-I3-A16-3-3)  Thu Apr 27 18:11:06 UTC 2023\n",
      "GCC version:  gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) \n",
      "\"\n",
      "2023-07-06 21:53:49.952564: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "289/289 [==============================] - 3s 4ms/step - loss: 691.4634 - val_loss: 849.1053\n",
      "Epoch 2/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 428.9437 - val_loss: 679.4831\n",
      "Epoch 3/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5818 - val_loss: 671.8967\n",
      "Epoch 4/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5261 - val_loss: 669.4630\n",
      "Epoch 5/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5259 - val_loss: 672.7383\n",
      "Epoch 6/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5331 - val_loss: 672.2908\n",
      "Epoch 7/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5234 - val_loss: 667.7997\n",
      "Epoch 8/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5292 - val_loss: 671.6800\n",
      "Epoch 9/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5433 - val_loss: 671.0722\n",
      "Epoch 10/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5562 - val_loss: 668.9001\n",
      "Epoch 11/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5009 - val_loss: 672.8552\n",
      "Epoch 12/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5170 - val_loss: 671.1691\n",
      "Epoch 13/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5554 - val_loss: 671.7174\n",
      "Epoch 14/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.3806 - val_loss: 665.4755\n",
      "Epoch 15/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5314 - val_loss: 665.3175\n",
      "Epoch 16/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5031 - val_loss: 673.9764\n",
      "Epoch 17/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5523 - val_loss: 673.2267\n",
      "Epoch 18/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5312 - val_loss: 673.3050\n",
      "Epoch 19/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4485 - val_loss: 665.1625\n",
      "Epoch 20/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5174 - val_loss: 667.2107\n",
      "Epoch 21/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5091 - val_loss: 672.9827\n",
      "Epoch 22/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4775 - val_loss: 673.1464\n",
      "Epoch 23/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5602 - val_loss: 670.4473\n",
      "Epoch 24/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5010 - val_loss: 673.8493\n",
      "Epoch 25/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5497 - val_loss: 673.1069\n",
      "Epoch 26/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5620 - val_loss: 670.6788\n",
      "Epoch 27/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5456 - val_loss: 669.7853\n",
      "Epoch 28/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5526 - val_loss: 671.1050\n",
      "Epoch 29/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5244 - val_loss: 669.8962\n",
      "Epoch 30/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5320 - val_loss: 671.7776\n",
      "Epoch 31/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5146 - val_loss: 669.8322\n",
      "Epoch 32/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5246 - val_loss: 671.2783\n",
      "Epoch 33/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5073 - val_loss: 672.5369\n",
      "Epoch 34/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5427 - val_loss: 670.8002\n",
      "Epoch 35/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4953 - val_loss: 671.1620\n",
      "Epoch 36/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5026 - val_loss: 667.3275\n",
      "Epoch 37/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5255 - val_loss: 671.8500\n",
      "Epoch 38/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5555 - val_loss: 672.5624\n",
      "Epoch 39/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5407 - val_loss: 670.9512\n",
      "Epoch 40/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5505 - val_loss: 669.2228\n",
      "Epoch 41/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5195 - val_loss: 674.3144\n",
      "Epoch 42/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4697 - val_loss: 676.8533\n",
      "Epoch 43/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5994 - val_loss: 671.9670\n",
      "Epoch 44/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5290 - val_loss: 672.3804\n",
      "Epoch 45/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5170 - val_loss: 669.1991\n",
      "Epoch 46/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5520 - val_loss: 669.1575\n",
      "Epoch 47/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5179 - val_loss: 669.5344\n",
      "Epoch 48/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5159 - val_loss: 666.8099\n",
      "Epoch 49/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5314 - val_loss: 666.9269\n",
      "Epoch 50/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4880 - val_loss: 669.9489\n",
      "Epoch 51/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5307 - val_loss: 670.3927\n",
      "Epoch 52/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5228 - val_loss: 671.3049\n",
      "Epoch 53/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5390 - val_loss: 670.8566\n",
      "Epoch 54/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5377 - val_loss: 669.8345\n",
      "Epoch 55/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4783 - val_loss: 671.7821\n",
      "Epoch 56/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4975 - val_loss: 672.6901\n",
      "Epoch 57/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5547 - val_loss: 672.9152\n",
      "Epoch 58/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5219 - val_loss: 672.5507\n",
      "Epoch 59/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4715 - val_loss: 669.8259\n",
      "Epoch 60/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5198 - val_loss: 672.6380\n",
      "Epoch 61/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5266 - val_loss: 671.1838\n",
      "Epoch 62/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5127 - val_loss: 669.0775\n",
      "Epoch 63/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5334 - val_loss: 669.2587\n",
      "Epoch 64/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4879 - val_loss: 670.6813\n",
      "Epoch 65/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5081 - val_loss: 671.7024\n",
      "Epoch 66/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5061 - val_loss: 673.0803\n",
      "Epoch 67/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5437 - val_loss: 669.3071\n",
      "Epoch 68/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5172 - val_loss: 673.8134\n",
      "Epoch 69/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4908 - val_loss: 672.7572\n",
      "Epoch 70/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5234 - val_loss: 667.8805\n",
      "Epoch 71/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4573 - val_loss: 671.3658\n",
      "Epoch 72/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5530 - val_loss: 672.3046\n",
      "Epoch 73/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5160 - val_loss: 672.4406\n",
      "Epoch 74/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5116 - val_loss: 669.0195\n",
      "Epoch 75/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4962 - val_loss: 673.8788\n",
      "Epoch 76/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5136 - val_loss: 674.1650\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5303 - val_loss: 671.3726\n",
      "Epoch 78/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5838 - val_loss: 670.8093\n",
      "Epoch 79/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5074 - val_loss: 670.6758\n",
      "Epoch 80/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5101 - val_loss: 673.9629\n",
      "Epoch 81/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5388 - val_loss: 669.9647\n",
      "Epoch 82/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5453 - val_loss: 667.8781\n",
      "Epoch 83/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5504 - val_loss: 671.0720\n",
      "Epoch 84/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5455 - val_loss: 671.1788\n",
      "Epoch 85/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5218 - val_loss: 669.3261\n",
      "Epoch 86/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5462 - val_loss: 669.3015\n",
      "Epoch 87/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5273 - val_loss: 670.6776\n",
      "Epoch 88/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5244 - val_loss: 671.4222\n",
      "Epoch 89/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4924 - val_loss: 674.3622\n",
      "Epoch 90/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5662 - val_loss: 671.9713\n",
      "Epoch 91/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4557 - val_loss: 665.8846\n",
      "Epoch 92/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4297 - val_loss: 675.7847\n",
      "Epoch 93/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5061 - val_loss: 667.7369\n",
      "Epoch 94/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5562 - val_loss: 670.6430\n",
      "Epoch 95/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5305 - val_loss: 673.6104\n",
      "Epoch 96/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5128 - val_loss: 674.6064\n",
      "Epoch 97/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5015 - val_loss: 668.5046\n",
      "Epoch 98/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5150 - val_loss: 672.8962\n",
      "Epoch 99/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5610 - val_loss: 670.2763\n",
      "Epoch 100/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4980 - val_loss: 672.7074\n",
      "Epoch 101/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5495 - val_loss: 670.9796\n",
      "Epoch 102/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5081 - val_loss: 674.1192\n",
      "Epoch 103/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5705 - val_loss: 669.9702\n",
      "Epoch 104/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5323 - val_loss: 669.5529\n",
      "Epoch 105/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5043 - val_loss: 669.2034\n",
      "Epoch 106/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5227 - val_loss: 669.0305\n",
      "Epoch 107/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5201 - val_loss: 674.1290\n",
      "Epoch 108/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5396 - val_loss: 671.9445\n",
      "Epoch 109/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4770 - val_loss: 674.6359\n",
      "Epoch 110/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5096 - val_loss: 676.0798\n",
      "Epoch 111/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5644 - val_loss: 672.7552\n",
      "Epoch 112/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5589 - val_loss: 671.5131\n",
      "Epoch 113/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4871 - val_loss: 672.6257\n",
      "Epoch 114/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5269 - val_loss: 671.1362\n",
      "Epoch 115/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5146 - val_loss: 668.6995\n",
      "Epoch 116/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5571 - val_loss: 670.9763\n",
      "Epoch 117/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5098 - val_loss: 673.4620\n",
      "Epoch 118/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5123 - val_loss: 668.3474\n",
      "Epoch 119/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4985 - val_loss: 667.0577\n",
      "Epoch 120/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5433 - val_loss: 672.3224\n",
      "Epoch 121/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4961 - val_loss: 674.2054\n",
      "Epoch 122/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5716 - val_loss: 671.5319\n",
      "Epoch 123/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5348 - val_loss: 669.1346\n",
      "Epoch 124/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5329 - val_loss: 669.4191\n",
      "Epoch 125/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5572 - val_loss: 672.2968\n",
      "Epoch 126/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5371 - val_loss: 669.6025\n",
      "Epoch 127/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4879 - val_loss: 673.9947\n",
      "Epoch 128/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5496 - val_loss: 670.7457\n",
      "Epoch 129/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5465 - val_loss: 670.6446\n",
      "Epoch 130/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5253 - val_loss: 671.6292\n",
      "Epoch 131/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5341 - val_loss: 668.7234\n",
      "Epoch 132/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4353 - val_loss: 675.7660\n",
      "Epoch 133/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5764 - val_loss: 671.5231\n",
      "Epoch 134/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5413 - val_loss: 672.4840\n",
      "Epoch 135/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5124 - val_loss: 674.1987\n",
      "Epoch 136/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5406 - val_loss: 670.2084\n",
      "Epoch 137/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5583 - val_loss: 671.8234\n",
      "Epoch 138/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5157 - val_loss: 667.2769\n",
      "Epoch 139/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5200 - val_loss: 670.0676\n",
      "Epoch 140/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4989 - val_loss: 674.1276\n",
      "Epoch 141/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5003 - val_loss: 667.1669\n",
      "Epoch 142/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5028 - val_loss: 671.3889\n",
      "Epoch 143/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5289 - val_loss: 671.3671\n",
      "Epoch 144/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5592 - val_loss: 669.2889\n",
      "Epoch 145/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5161 - val_loss: 674.4749\n",
      "Epoch 146/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5323 - val_loss: 671.7903\n",
      "Epoch 147/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5458 - val_loss: 669.6385\n",
      "Epoch 148/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5003 - val_loss: 675.2386\n",
      "Epoch 149/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5302 - val_loss: 675.8928\n",
      "Epoch 150/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5483 - val_loss: 675.0307\n",
      "Epoch 151/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5746 - val_loss: 670.0418\n",
      "Epoch 152/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5180 - val_loss: 673.0334\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5492 - val_loss: 670.2642\n",
      "Epoch 154/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5495 - val_loss: 671.0743\n",
      "Epoch 155/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5438 - val_loss: 671.3777\n",
      "Epoch 156/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5329 - val_loss: 671.3700\n",
      "Epoch 157/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5119 - val_loss: 673.3416\n",
      "Epoch 158/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5418 - val_loss: 672.3607\n",
      "Epoch 159/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5349 - val_loss: 672.9725\n",
      "Epoch 160/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5642 - val_loss: 671.9335\n",
      "Epoch 161/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5358 - val_loss: 670.4097\n",
      "Epoch 162/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4775 - val_loss: 673.2176\n",
      "Epoch 163/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5472 - val_loss: 670.5417\n",
      "Epoch 164/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5202 - val_loss: 670.0726\n",
      "Epoch 165/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5313 - val_loss: 667.4528\n",
      "Epoch 166/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5413 - val_loss: 668.4813\n",
      "Epoch 167/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5011 - val_loss: 673.1200\n",
      "Epoch 168/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5556 - val_loss: 669.3399\n",
      "Epoch 169/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5185 - val_loss: 672.8524\n",
      "Epoch 170/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5179 - val_loss: 670.0046\n",
      "Epoch 171/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5399 - val_loss: 670.9736\n",
      "Epoch 172/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4777 - val_loss: 671.0186\n",
      "Epoch 173/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5200 - val_loss: 669.3812\n",
      "Epoch 174/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5489 - val_loss: 671.5127\n",
      "Epoch 175/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5197 - val_loss: 673.3863\n",
      "Epoch 176/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5443 - val_loss: 670.2056\n",
      "Epoch 177/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5288 - val_loss: 671.3657\n",
      "Epoch 178/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4913 - val_loss: 668.5470\n",
      "Epoch 179/1000\n",
      "289/289 [==============================] - 2s 7ms/step - loss: 411.3994 - val_loss: 675.5837\n",
      "Epoch 180/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5567 - val_loss: 668.5167\n",
      "Epoch 181/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4964 - val_loss: 672.4583\n",
      "Epoch 182/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5258 - val_loss: 668.0265\n",
      "Epoch 183/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5263 - val_loss: 672.6573\n",
      "Epoch 184/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5406 - val_loss: 669.2459\n",
      "Epoch 185/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4817 - val_loss: 667.8641\n",
      "Epoch 186/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5363 - val_loss: 669.1313\n",
      "Epoch 187/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5438 - val_loss: 670.3439\n",
      "Epoch 188/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4879 - val_loss: 668.3233\n",
      "Epoch 189/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5050 - val_loss: 669.3062\n",
      "Epoch 190/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4271 - val_loss: 668.0239\n",
      "Epoch 191/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5472 - val_loss: 671.7124\n",
      "Epoch 192/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5163 - val_loss: 668.2467\n",
      "Epoch 193/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5388 - val_loss: 669.9957\n",
      "Epoch 194/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4629 - val_loss: 671.7087\n",
      "Epoch 195/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5595 - val_loss: 670.7307\n",
      "Epoch 196/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5472 - val_loss: 673.0803\n",
      "Epoch 197/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5468 - val_loss: 669.6605\n",
      "Epoch 198/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5270 - val_loss: 669.8581\n",
      "Epoch 199/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4921 - val_loss: 674.4562\n",
      "Epoch 200/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5564 - val_loss: 668.5807\n",
      "Epoch 201/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5259 - val_loss: 669.1882\n",
      "Epoch 202/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5312 - val_loss: 668.9412\n",
      "Epoch 203/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5057 - val_loss: 668.9524\n",
      "Epoch 204/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5628 - val_loss: 670.7802\n",
      "Epoch 205/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5103 - val_loss: 671.5350\n",
      "Epoch 206/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4817 - val_loss: 669.0537\n",
      "Epoch 207/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4951 - val_loss: 666.7625\n",
      "Epoch 208/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5602 - val_loss: 669.5246\n",
      "Epoch 209/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5118 - val_loss: 671.2658\n",
      "Epoch 210/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5099 - val_loss: 675.0903\n",
      "Epoch 211/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5587 - val_loss: 669.9925\n",
      "Epoch 212/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4901 - val_loss: 673.2736\n",
      "Epoch 213/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5419 - val_loss: 672.7527\n",
      "Epoch 214/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5405 - val_loss: 672.6597\n",
      "Epoch 215/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5303 - val_loss: 671.5562\n",
      "Epoch 216/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5209 - val_loss: 672.0175\n",
      "Epoch 217/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5065 - val_loss: 674.8016\n",
      "Epoch 218/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5182 - val_loss: 675.1873\n",
      "Epoch 219/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5555 - val_loss: 669.7966\n",
      "Epoch 220/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5107 - val_loss: 671.2260\n",
      "Epoch 221/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4898 - val_loss: 672.6095\n",
      "Epoch 222/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5388 - val_loss: 669.9774\n",
      "Epoch 223/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5484 - val_loss: 670.6827\n",
      "Epoch 224/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5423 - val_loss: 672.3417\n",
      "Epoch 225/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5742 - val_loss: 671.5138\n",
      "Epoch 226/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5349 - val_loss: 669.8974\n",
      "Epoch 227/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5067 - val_loss: 673.1009\n",
      "Epoch 228/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4810 - val_loss: 667.4245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5269 - val_loss: 671.5192\n",
      "Epoch 230/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5443 - val_loss: 669.0494\n",
      "Epoch 231/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5166 - val_loss: 670.7081\n",
      "Epoch 232/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4613 - val_loss: 666.5757\n",
      "Epoch 233/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5116 - val_loss: 671.4974\n",
      "Epoch 234/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5695 - val_loss: 671.4645\n",
      "Epoch 235/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5358 - val_loss: 672.6835\n",
      "Epoch 236/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5022 - val_loss: 670.4443\n",
      "Epoch 237/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4574 - val_loss: 672.4921\n",
      "Epoch 238/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4854 - val_loss: 670.8384\n",
      "Epoch 239/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5045 - val_loss: 668.5992\n",
      "Epoch 240/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5389 - val_loss: 670.6665\n",
      "Epoch 241/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4912 - val_loss: 674.0004\n",
      "Epoch 242/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5419 - val_loss: 672.1208\n",
      "Epoch 243/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4905 - val_loss: 669.8036\n",
      "Epoch 244/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5106 - val_loss: 672.6144\n",
      "Epoch 245/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5547 - val_loss: 670.8438\n",
      "Epoch 246/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5191 - val_loss: 670.1316\n",
      "Epoch 247/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5188 - val_loss: 669.1039\n",
      "Epoch 248/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4704 - val_loss: 676.0489\n",
      "Epoch 249/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5552 - val_loss: 674.8627\n",
      "Epoch 250/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5068 - val_loss: 670.7579\n",
      "Epoch 251/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5245 - val_loss: 668.9383\n",
      "Epoch 252/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5253 - val_loss: 672.1463\n",
      "Epoch 253/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5346 - val_loss: 671.5594\n",
      "Epoch 254/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5078 - val_loss: 673.1393\n",
      "Epoch 255/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5153 - val_loss: 668.9247\n",
      "Epoch 256/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5087 - val_loss: 667.7415\n",
      "Epoch 257/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4684 - val_loss: 673.8266\n",
      "Epoch 258/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5502 - val_loss: 672.6649\n",
      "Epoch 259/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5585 - val_loss: 673.3661\n",
      "Epoch 260/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5196 - val_loss: 668.2831\n",
      "Epoch 261/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4616 - val_loss: 675.3186\n",
      "Epoch 262/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5378 - val_loss: 668.8808\n",
      "Epoch 263/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4062 - val_loss: 666.5481\n",
      "Epoch 264/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5549 - val_loss: 669.6592\n",
      "Epoch 265/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5029 - val_loss: 673.5699\n",
      "Epoch 266/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4593 - val_loss: 667.3557\n",
      "Epoch 267/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5098 - val_loss: 672.0664\n",
      "Epoch 268/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5165 - val_loss: 673.3478\n",
      "Epoch 269/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5184 - val_loss: 671.7194\n",
      "Epoch 270/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5633 - val_loss: 669.3981\n",
      "Epoch 271/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5211 - val_loss: 671.3314\n",
      "Epoch 272/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5612 - val_loss: 671.3463\n",
      "Epoch 273/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5464 - val_loss: 669.9129\n",
      "Epoch 274/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5047 - val_loss: 673.9252\n",
      "Epoch 275/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5574 - val_loss: 670.5736\n",
      "Epoch 276/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5310 - val_loss: 670.2253\n",
      "Epoch 277/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4586 - val_loss: 674.1155\n",
      "Epoch 278/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5650 - val_loss: 669.7711\n",
      "Epoch 279/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4318 - val_loss: 673.4945\n",
      "Epoch 280/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4741 - val_loss: 674.5998\n",
      "Epoch 281/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4679 - val_loss: 675.4581\n",
      "Epoch 282/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5483 - val_loss: 675.1041\n",
      "Epoch 283/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5711 - val_loss: 671.3575\n",
      "Epoch 284/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5228 - val_loss: 672.5218\n",
      "Epoch 285/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5470 - val_loss: 673.4621\n",
      "Epoch 286/1000\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 411.5746 - val_loss: 670.6010\n",
      "Epoch 287/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.4844 - val_loss: 669.8099\n",
      "Epoch 288/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5023 - val_loss: 672.5219\n",
      "Epoch 289/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5373 - val_loss: 671.0627\n",
      "Epoch 290/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5208 - val_loss: 672.7790\n",
      "Epoch 291/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5648 - val_loss: 671.1479\n",
      "Epoch 292/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5441 - val_loss: 671.3201\n",
      "Epoch 293/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4440 - val_loss: 674.3585\n",
      "Epoch 294/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5560 - val_loss: 671.3911\n",
      "Epoch 295/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5208 - val_loss: 669.4816\n",
      "Epoch 296/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4900 - val_loss: 667.7836\n",
      "Epoch 297/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5542 - val_loss: 670.7169\n",
      "Epoch 298/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5563 - val_loss: 670.6769\n",
      "Epoch 299/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4989 - val_loss: 674.2812\n",
      "Epoch 300/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5453 - val_loss: 672.6752\n",
      "Epoch 301/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5573 - val_loss: 672.8129\n",
      "Epoch 302/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5320 - val_loss: 673.0538\n",
      "Epoch 303/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5722 - val_loss: 671.7612\n",
      "Epoch 304/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4637 - val_loss: 667.2314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5103 - val_loss: 673.2497\n",
      "Epoch 306/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5226 - val_loss: 670.2274\n",
      "Epoch 307/1000\n",
      "289/289 [==============================] - 2s 5ms/step - loss: 411.5186 - val_loss: 673.4577\n",
      "Epoch 308/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5524 - val_loss: 670.2390\n",
      "Epoch 309/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5553 - val_loss: 672.5005\n",
      "Epoch 310/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5403 - val_loss: 672.9831\n",
      "Epoch 311/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5522 - val_loss: 671.6510\n",
      "Epoch 312/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5381 - val_loss: 668.1166\n",
      "Epoch 313/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5298 - val_loss: 670.3782\n",
      "Epoch 314/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5086 - val_loss: 670.9065\n",
      "Epoch 315/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4935 - val_loss: 673.0399\n",
      "Epoch 316/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5227 - val_loss: 674.7001\n",
      "Epoch 317/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4944 - val_loss: 668.7141\n",
      "Epoch 318/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4978 - val_loss: 673.1905\n",
      "Epoch 319/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5060 - val_loss: 669.1105\n",
      "Epoch 320/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5231 - val_loss: 670.1190\n",
      "Epoch 321/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5300 - val_loss: 670.0125\n",
      "Epoch 322/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5313 - val_loss: 673.7441\n",
      "Epoch 323/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5464 - val_loss: 672.9166\n",
      "Epoch 324/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4709 - val_loss: 666.9297\n",
      "Epoch 325/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5061 - val_loss: 673.3724\n",
      "Epoch 326/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5496 - val_loss: 671.0844\n",
      "Epoch 327/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5153 - val_loss: 670.0312\n",
      "Epoch 328/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4994 - val_loss: 667.2910\n",
      "Epoch 329/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5295 - val_loss: 670.0253\n",
      "Epoch 330/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5417 - val_loss: 671.4021\n",
      "Epoch 331/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5409 - val_loss: 669.6923\n",
      "Epoch 332/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5131 - val_loss: 673.3272\n",
      "Epoch 333/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5150 - val_loss: 671.9453\n",
      "Epoch 334/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5529 - val_loss: 669.8802\n",
      "Epoch 335/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5591 - val_loss: 670.1788\n",
      "Epoch 336/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4773 - val_loss: 672.6593\n",
      "Epoch 337/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5432 - val_loss: 669.5274\n",
      "Epoch 338/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5263 - val_loss: 668.4767\n",
      "Epoch 339/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5254 - val_loss: 673.9380\n",
      "Epoch 340/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5305 - val_loss: 674.0125\n",
      "Epoch 341/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5422 - val_loss: 670.5419\n",
      "Epoch 342/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5619 - val_loss: 670.0020\n",
      "Epoch 343/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4868 - val_loss: 670.9096\n",
      "Epoch 344/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5116 - val_loss: 671.5396\n",
      "Epoch 345/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5164 - val_loss: 669.4244\n",
      "Epoch 346/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5135 - val_loss: 673.3761\n",
      "Epoch 347/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5080 - val_loss: 668.8561\n",
      "Epoch 348/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5496 - val_loss: 672.1772\n",
      "Epoch 349/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5488 - val_loss: 671.9489\n",
      "Epoch 350/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5208 - val_loss: 669.9893\n",
      "Epoch 351/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5420 - val_loss: 671.6666\n",
      "Epoch 352/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5198 - val_loss: 669.2252\n",
      "Epoch 353/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5439 - val_loss: 669.9608\n",
      "Epoch 354/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5521 - val_loss: 668.2010\n",
      "Epoch 355/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5321 - val_loss: 669.9139\n",
      "Epoch 356/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5042 - val_loss: 674.1031\n",
      "Epoch 357/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5563 - val_loss: 668.9040\n",
      "Epoch 358/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5603 - val_loss: 668.3168\n",
      "Epoch 359/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5027 - val_loss: 668.3552\n",
      "Epoch 360/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5043 - val_loss: 673.9172\n",
      "Epoch 361/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5735 - val_loss: 670.7584\n",
      "Epoch 362/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5206 - val_loss: 669.7884\n",
      "Epoch 363/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5269 - val_loss: 671.2148\n",
      "Epoch 364/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5366 - val_loss: 671.9249\n",
      "Epoch 365/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4941 - val_loss: 666.8989\n",
      "Epoch 366/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5374 - val_loss: 670.3475\n",
      "Epoch 367/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5200 - val_loss: 671.6111\n",
      "Epoch 368/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5796 - val_loss: 670.7995\n",
      "Epoch 369/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5357 - val_loss: 669.7407\n",
      "Epoch 370/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5014 - val_loss: 671.5632\n",
      "Epoch 371/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4566 - val_loss: 676.0455\n",
      "Epoch 372/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5820 - val_loss: 671.6022\n",
      "Epoch 373/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5247 - val_loss: 673.8170\n",
      "Epoch 374/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5558 - val_loss: 670.7135\n",
      "Epoch 375/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5051 - val_loss: 675.7406\n",
      "Epoch 376/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5365 - val_loss: 669.7817\n",
      "Epoch 377/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5266 - val_loss: 671.6093\n",
      "Epoch 378/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5280 - val_loss: 670.0960\n",
      "Epoch 379/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4792 - val_loss: 666.7121\n",
      "Epoch 380/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5282 - val_loss: 669.4309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4993 - val_loss: 673.2119\n",
      "Epoch 382/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5441 - val_loss: 671.5834\n",
      "Epoch 383/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4747 - val_loss: 675.1639\n",
      "Epoch 384/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5809 - val_loss: 672.2635\n",
      "Epoch 385/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5669 - val_loss: 670.3874\n",
      "Epoch 386/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4949 - val_loss: 673.8565\n",
      "Epoch 387/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4878 - val_loss: 667.6887\n",
      "Epoch 388/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5618 - val_loss: 670.1162\n",
      "Epoch 389/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5290 - val_loss: 669.1378\n",
      "Epoch 390/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4901 - val_loss: 666.8209\n",
      "Epoch 391/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5555 - val_loss: 671.0751\n",
      "Epoch 392/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5209 - val_loss: 670.9654\n",
      "Epoch 393/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4908 - val_loss: 674.8656\n",
      "Epoch 394/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5569 - val_loss: 673.2662\n",
      "Epoch 395/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5495 - val_loss: 668.4002\n",
      "Epoch 396/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5297 - val_loss: 667.4728\n",
      "Epoch 397/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5327 - val_loss: 670.2415\n",
      "Epoch 398/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4929 - val_loss: 672.6600\n",
      "Epoch 399/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5147 - val_loss: 672.9924\n",
      "Epoch 400/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5720 - val_loss: 672.5760\n",
      "Epoch 401/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5039 - val_loss: 669.0253\n",
      "Epoch 402/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5298 - val_loss: 670.6160\n",
      "Epoch 403/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4810 - val_loss: 674.4630\n",
      "Epoch 404/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4706 - val_loss: 676.4501\n",
      "Epoch 405/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5665 - val_loss: 672.8734\n",
      "Epoch 406/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5139 - val_loss: 668.5899\n",
      "Epoch 407/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5400 - val_loss: 671.4846\n",
      "Epoch 408/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4344 - val_loss: 665.5623\n",
      "Epoch 409/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5721 - val_loss: 670.4651\n",
      "Epoch 410/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5439 - val_loss: 670.9987\n",
      "Epoch 411/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5334 - val_loss: 669.9490\n",
      "Epoch 412/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5523 - val_loss: 669.4121\n",
      "Epoch 413/1000\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 411.5249 - val_loss: 671.5729\n",
      "Epoch 414/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5219 - val_loss: 670.1276\n",
      "Epoch 415/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5040 - val_loss: 670.6054\n",
      "Epoch 416/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5150 - val_loss: 668.1198\n",
      "Epoch 417/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5109 - val_loss: 669.1528\n",
      "Epoch 418/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5539 - val_loss: 671.2946\n",
      "Epoch 419/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5225 - val_loss: 667.9893\n",
      "Epoch 420/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5151 - val_loss: 672.2744\n",
      "Epoch 421/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5254 - val_loss: 667.5815\n",
      "Epoch 422/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5522 - val_loss: 670.2488\n",
      "Epoch 423/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5190 - val_loss: 670.2597\n",
      "Epoch 424/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5064 - val_loss: 673.3603\n",
      "Epoch 425/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5398 - val_loss: 673.4384\n",
      "Epoch 426/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5004 - val_loss: 673.6737\n",
      "Epoch 427/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5479 - val_loss: 672.2116\n",
      "Epoch 428/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5381 - val_loss: 670.6677\n",
      "Epoch 429/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5211 - val_loss: 669.3570\n",
      "Epoch 430/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5097 - val_loss: 673.7865\n",
      "Epoch 431/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5381 - val_loss: 672.2509\n",
      "Epoch 432/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4904 - val_loss: 674.6758\n",
      "Epoch 433/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5776 - val_loss: 670.7418\n",
      "Epoch 434/1000\n",
      "289/289 [==============================] - 1s 5ms/step - loss: 411.4191 - val_loss: 676.9529\n",
      "Epoch 435/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5448 - val_loss: 668.4523\n",
      "Epoch 436/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5364 - val_loss: 668.3765\n",
      "Epoch 437/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5493 - val_loss: 671.5379\n",
      "Epoch 438/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5378 - val_loss: 670.9036\n",
      "Epoch 439/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4630 - val_loss: 674.8716\n",
      "Epoch 440/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5125 - val_loss: 673.8840\n",
      "Epoch 441/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4792 - val_loss: 666.2796\n",
      "Epoch 442/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5701 - val_loss: 668.7198\n",
      "Epoch 443/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4256 - val_loss: 674.5372\n",
      "Epoch 444/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5038 - val_loss: 669.1691\n",
      "Epoch 445/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5261 - val_loss: 668.6040\n",
      "Epoch 446/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5269 - val_loss: 672.7800\n",
      "Epoch 447/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5161 - val_loss: 671.3351\n",
      "Epoch 448/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4763 - val_loss: 666.4297\n",
      "Epoch 449/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4841 - val_loss: 672.8204\n",
      "Epoch 450/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5074 - val_loss: 672.4266\n",
      "Epoch 451/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5338 - val_loss: 670.8395\n",
      "Epoch 452/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5477 - val_loss: 670.7808\n",
      "Epoch 453/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5099 - val_loss: 674.1767\n",
      "Epoch 454/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5490 - val_loss: 671.4757\n",
      "Epoch 455/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5430 - val_loss: 670.2901\n",
      "Epoch 456/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5097 - val_loss: 671.4146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4826 - val_loss: 675.1313\n",
      "Epoch 458/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5635 - val_loss: 671.9899\n",
      "Epoch 459/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5265 - val_loss: 670.2952\n",
      "Epoch 460/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4876 - val_loss: 667.0733\n",
      "Epoch 461/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5135 - val_loss: 671.2905\n",
      "Epoch 462/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5201 - val_loss: 672.2866\n",
      "Epoch 463/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5294 - val_loss: 670.6942\n",
      "Epoch 464/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5345 - val_loss: 668.7523\n",
      "Epoch 465/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5630 - val_loss: 670.2621\n",
      "Epoch 466/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5515 - val_loss: 669.8877\n",
      "Epoch 467/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5128 - val_loss: 674.2610\n",
      "Epoch 468/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5188 - val_loss: 665.9703\n",
      "Epoch 469/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5577 - val_loss: 668.6216\n",
      "Epoch 470/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5087 - val_loss: 671.2286\n",
      "Epoch 471/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5068 - val_loss: 673.7101\n",
      "Epoch 472/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5316 - val_loss: 669.4147\n",
      "Epoch 473/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5177 - val_loss: 667.1141\n",
      "Epoch 474/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5494 - val_loss: 671.0858\n",
      "Epoch 475/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4822 - val_loss: 671.9100\n",
      "Epoch 476/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4679 - val_loss: 668.2913\n",
      "Epoch 477/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5061 - val_loss: 671.9874\n",
      "Epoch 478/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5180 - val_loss: 669.0439\n",
      "Epoch 479/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5216 - val_loss: 669.5160\n",
      "Epoch 480/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5603 - val_loss: 670.6758\n",
      "Epoch 481/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5075 - val_loss: 669.0770\n",
      "Epoch 482/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5014 - val_loss: 673.2397\n",
      "Epoch 483/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5285 - val_loss: 669.3012\n",
      "Epoch 484/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5007 - val_loss: 667.5140\n",
      "Epoch 485/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5682 - val_loss: 671.0395\n",
      "Epoch 486/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5290 - val_loss: 670.1672\n",
      "Epoch 487/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5373 - val_loss: 669.9674\n",
      "Epoch 488/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4442 - val_loss: 672.8558\n",
      "Epoch 489/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4122 - val_loss: 675.9984\n",
      "Epoch 490/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5443 - val_loss: 675.3521\n",
      "Epoch 491/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5437 - val_loss: 669.6096\n",
      "Epoch 492/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4355 - val_loss: 666.6329\n",
      "Epoch 493/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5475 - val_loss: 669.1034\n",
      "Epoch 494/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5015 - val_loss: 671.3200\n",
      "Epoch 495/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.3979 - val_loss: 677.8542\n",
      "Epoch 496/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5560 - val_loss: 674.7871\n",
      "Epoch 497/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5550 - val_loss: 669.6531\n",
      "Epoch 498/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5526 - val_loss: 670.1421\n",
      "Epoch 499/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5518 - val_loss: 668.1847\n",
      "Epoch 500/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5255 - val_loss: 668.5227\n",
      "Epoch 501/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5101 - val_loss: 673.0096\n",
      "Epoch 502/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5492 - val_loss: 673.0352\n",
      "Epoch 503/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4731 - val_loss: 675.5341\n",
      "Epoch 504/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5429 - val_loss: 668.4116\n",
      "Epoch 505/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.3393 - val_loss: 676.8546\n",
      "Epoch 506/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5344 - val_loss: 674.6917\n",
      "Epoch 507/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5953 - val_loss: 671.4365\n",
      "Epoch 508/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5419 - val_loss: 669.8397\n",
      "Epoch 509/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4962 - val_loss: 672.7742\n",
      "Epoch 510/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5297 - val_loss: 672.3160\n",
      "Epoch 511/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5132 - val_loss: 674.7639\n",
      "Epoch 512/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5273 - val_loss: 670.4755\n",
      "Epoch 513/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5310 - val_loss: 669.7985\n",
      "Epoch 514/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5266 - val_loss: 671.8015\n",
      "Epoch 515/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5421 - val_loss: 668.5609\n",
      "Epoch 516/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5150 - val_loss: 670.7399\n",
      "Epoch 517/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5663 - val_loss: 670.1575\n",
      "Epoch 518/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4485 - val_loss: 670.4926\n",
      "Epoch 519/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4949 - val_loss: 667.2885\n",
      "Epoch 520/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4562 - val_loss: 675.4924\n",
      "Epoch 521/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4958 - val_loss: 670.5464\n",
      "Epoch 522/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5079 - val_loss: 669.6270\n",
      "Epoch 523/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5185 - val_loss: 667.0992\n",
      "Epoch 524/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5260 - val_loss: 670.2865\n",
      "Epoch 525/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5362 - val_loss: 672.8846\n",
      "Epoch 526/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4654 - val_loss: 667.4529\n",
      "Epoch 527/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4951 - val_loss: 672.5295\n",
      "Epoch 528/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5130 - val_loss: 669.9914\n",
      "Epoch 529/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5259 - val_loss: 672.7542\n",
      "Epoch 530/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5290 - val_loss: 667.9081\n",
      "Epoch 531/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5170 - val_loss: 670.8401\n",
      "Epoch 532/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4989 - val_loss: 669.1306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5009 - val_loss: 672.4611\n",
      "Epoch 534/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5032 - val_loss: 672.6423\n",
      "Epoch 535/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5272 - val_loss: 671.5565\n",
      "Epoch 536/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5288 - val_loss: 668.5496\n",
      "Epoch 537/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5462 - val_loss: 671.8786\n",
      "Epoch 538/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5231 - val_loss: 673.1542\n",
      "Epoch 539/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5577 - val_loss: 669.7914\n",
      "Epoch 540/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5032 - val_loss: 672.4036\n",
      "Epoch 541/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5433 - val_loss: 672.5167\n",
      "Epoch 542/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5468 - val_loss: 671.1288\n",
      "Epoch 543/1000\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 411.4909 - val_loss: 669.4517\n",
      "Epoch 544/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5372 - val_loss: 670.7371\n",
      "Epoch 545/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5128 - val_loss: 668.9180\n",
      "Epoch 546/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5190 - val_loss: 669.9969\n",
      "Epoch 547/1000\n",
      "289/289 [==============================] - 2s 8ms/step - loss: 411.5034 - val_loss: 671.8689\n",
      "Epoch 548/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4782 - val_loss: 667.5676\n",
      "Epoch 549/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5406 - val_loss: 668.9263\n",
      "Epoch 550/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5612 - val_loss: 670.9143\n",
      "Epoch 551/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5435 - val_loss: 671.3893\n",
      "Epoch 552/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5253 - val_loss: 670.2748\n",
      "Epoch 553/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4941 - val_loss: 673.0071\n",
      "Epoch 554/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5187 - val_loss: 672.9513\n",
      "Epoch 555/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5494 - val_loss: 670.4875\n",
      "Epoch 556/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5433 - val_loss: 670.0386\n",
      "Epoch 557/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5552 - val_loss: 670.8369\n",
      "Epoch 558/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4601 - val_loss: 674.4807\n",
      "Epoch 559/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5043 - val_loss: 675.1752\n",
      "Epoch 560/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5895 - val_loss: 674.9888\n",
      "Epoch 561/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5653 - val_loss: 671.3378\n",
      "Epoch 562/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5174 - val_loss: 670.1878\n",
      "Epoch 563/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5457 - val_loss: 670.7950\n",
      "Epoch 564/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4621 - val_loss: 676.2949\n",
      "Epoch 565/1000\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 411.5762 - val_loss: 669.2593\n",
      "Epoch 566/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5001 - val_loss: 672.3399\n",
      "Epoch 567/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5514 - val_loss: 674.1605\n",
      "Epoch 568/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5376 - val_loss: 669.0785\n",
      "Epoch 569/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4561 - val_loss: 676.0928\n",
      "Epoch 570/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5529 - val_loss: 672.9230\n",
      "Epoch 571/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5780 - val_loss: 670.6796\n",
      "Epoch 572/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5402 - val_loss: 671.3734\n",
      "Epoch 573/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5258 - val_loss: 670.5391\n",
      "Epoch 574/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4991 - val_loss: 665.9887\n",
      "Epoch 575/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5655 - val_loss: 668.5111\n",
      "Epoch 576/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.3930 - val_loss: 675.7632\n",
      "Epoch 577/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5719 - val_loss: 670.3400\n",
      "Epoch 578/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4885 - val_loss: 667.8113\n",
      "Epoch 579/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5313 - val_loss: 668.6502\n",
      "Epoch 580/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5216 - val_loss: 667.7416\n",
      "Epoch 581/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5233 - val_loss: 671.8049\n",
      "Epoch 582/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5120 - val_loss: 672.1627\n",
      "Epoch 583/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5245 - val_loss: 672.6658\n",
      "Epoch 584/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5159 - val_loss: 673.7189\n",
      "Epoch 585/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5574 - val_loss: 671.8948\n",
      "Epoch 586/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5152 - val_loss: 667.9180\n",
      "Epoch 587/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5440 - val_loss: 668.2679\n",
      "Epoch 588/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4355 - val_loss: 672.7945\n",
      "Epoch 589/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4854 - val_loss: 672.3220\n",
      "Epoch 590/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4704 - val_loss: 666.7043\n",
      "Epoch 591/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5587 - val_loss: 670.5980\n",
      "Epoch 592/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5405 - val_loss: 670.1324\n",
      "Epoch 593/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5171 - val_loss: 672.3184\n",
      "Epoch 594/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.3912 - val_loss: 664.9739\n",
      "Epoch 595/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5493 - val_loss: 671.8352\n",
      "Epoch 596/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5391 - val_loss: 672.5195\n",
      "Epoch 597/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5469 - val_loss: 670.7354\n",
      "Epoch 598/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5514 - val_loss: 668.7398\n",
      "Epoch 599/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5327 - val_loss: 669.3605\n",
      "Epoch 600/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4663 - val_loss: 667.5662\n",
      "Epoch 601/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5364 - val_loss: 671.3337\n",
      "Epoch 602/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5218 - val_loss: 669.4905\n",
      "Epoch 603/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5205 - val_loss: 670.6955\n",
      "Epoch 604/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5548 - val_loss: 670.1703\n",
      "Epoch 605/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5556 - val_loss: 670.8160\n",
      "Epoch 606/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5305 - val_loss: 670.8655\n",
      "Epoch 607/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4964 - val_loss: 673.2469\n",
      "Epoch 608/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5595 - val_loss: 669.9481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 609/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5009 - val_loss: 673.8660\n",
      "Epoch 610/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5605 - val_loss: 671.0702\n",
      "Epoch 611/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4909 - val_loss: 667.7821\n",
      "Epoch 612/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.3513 - val_loss: 676.1262\n",
      "Epoch 613/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5720 - val_loss: 672.2934\n",
      "Epoch 614/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5227 - val_loss: 672.6943\n",
      "Epoch 615/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5395 - val_loss: 669.9478\n",
      "Epoch 616/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5348 - val_loss: 670.3585\n",
      "Epoch 617/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5080 - val_loss: 672.5635\n",
      "Epoch 618/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5279 - val_loss: 673.3131\n",
      "Epoch 619/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5456 - val_loss: 671.2300\n",
      "Epoch 620/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5181 - val_loss: 672.7557\n",
      "Epoch 621/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5632 - val_loss: 671.0119\n",
      "Epoch 622/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5331 - val_loss: 672.8474\n",
      "Epoch 623/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4948 - val_loss: 675.3563\n",
      "Epoch 624/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5780 - val_loss: 670.9332\n",
      "Epoch 625/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5258 - val_loss: 671.4264\n",
      "Epoch 626/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5045 - val_loss: 671.0591\n",
      "Epoch 627/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4740 - val_loss: 674.4005\n",
      "Epoch 628/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5429 - val_loss: 671.7158\n",
      "Epoch 629/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4608 - val_loss: 676.4925\n",
      "Epoch 630/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5628 - val_loss: 668.8140\n",
      "Epoch 631/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5159 - val_loss: 669.3424\n",
      "Epoch 632/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5355 - val_loss: 668.9431\n",
      "Epoch 633/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5130 - val_loss: 671.5460\n",
      "Epoch 634/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5144 - val_loss: 672.4215\n",
      "Epoch 635/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5189 - val_loss: 671.2783\n",
      "Epoch 636/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5180 - val_loss: 672.7741\n",
      "Epoch 637/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4551 - val_loss: 668.8345\n",
      "Epoch 638/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5121 - val_loss: 671.5833\n",
      "Epoch 639/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5218 - val_loss: 670.7375\n",
      "Epoch 640/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5565 - val_loss: 670.9824\n",
      "Epoch 641/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4805 - val_loss: 672.6672\n",
      "Epoch 642/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5429 - val_loss: 672.7333\n",
      "Epoch 643/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5280 - val_loss: 667.8286\n",
      "Epoch 644/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5362 - val_loss: 668.7221\n",
      "Epoch 645/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5415 - val_loss: 670.7209\n",
      "Epoch 646/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4920 - val_loss: 669.6758\n",
      "Epoch 647/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4693 - val_loss: 668.8358\n",
      "Epoch 648/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5305 - val_loss: 672.0293\n",
      "Epoch 649/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5579 - val_loss: 669.9372\n",
      "Epoch 650/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4425 - val_loss: 676.3192\n",
      "Epoch 651/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.6018 - val_loss: 672.6824\n",
      "Epoch 652/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5284 - val_loss: 673.3425\n",
      "Epoch 653/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5510 - val_loss: 672.8104\n",
      "Epoch 654/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5652 - val_loss: 670.4741\n",
      "Epoch 655/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5362 - val_loss: 667.9393\n",
      "Epoch 656/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5055 - val_loss: 672.9636\n",
      "Epoch 657/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5318 - val_loss: 672.2151\n",
      "Epoch 658/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5456 - val_loss: 671.0389\n",
      "Epoch 659/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4918 - val_loss: 674.8613\n",
      "Epoch 660/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5480 - val_loss: 671.4656\n",
      "Epoch 661/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5046 - val_loss: 668.6015\n",
      "Epoch 662/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4846 - val_loss: 670.7787\n",
      "Epoch 663/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5429 - val_loss: 672.6882\n",
      "Epoch 664/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5429 - val_loss: 669.5186\n",
      "Epoch 665/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5104 - val_loss: 670.3668\n",
      "Epoch 666/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4791 - val_loss: 668.0735\n",
      "Epoch 667/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5237 - val_loss: 671.8483\n",
      "Epoch 668/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5163 - val_loss: 667.9921\n",
      "Epoch 669/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5076 - val_loss: 671.1641\n",
      "Epoch 670/1000\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 411.4956 - val_loss: 675.5856\n",
      "Epoch 671/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5565 - val_loss: 671.1578\n",
      "Epoch 672/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4724 - val_loss: 672.1154\n",
      "Epoch 673/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4588 - val_loss: 673.8815\n",
      "Epoch 674/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5388 - val_loss: 671.3407\n",
      "Epoch 675/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5284 - val_loss: 672.1599\n",
      "Epoch 676/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5160 - val_loss: 668.4002\n",
      "Epoch 677/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4911 - val_loss: 669.6679\n",
      "Epoch 678/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5148 - val_loss: 668.6254\n",
      "Epoch 679/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4532 - val_loss: 673.6865\n",
      "Epoch 680/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5400 - val_loss: 670.5768\n",
      "Epoch 681/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5314 - val_loss: 672.8847\n",
      "Epoch 682/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5398 - val_loss: 671.8214\n",
      "Epoch 683/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5154 - val_loss: 667.4886\n",
      "Epoch 684/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5156 - val_loss: 666.8102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5402 - val_loss: 672.1633\n",
      "Epoch 686/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5429 - val_loss: 671.5931\n",
      "Epoch 687/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5346 - val_loss: 671.6535\n",
      "Epoch 688/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5508 - val_loss: 672.6123\n",
      "Epoch 689/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5490 - val_loss: 669.8882\n",
      "Epoch 690/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4849 - val_loss: 674.4456\n",
      "Epoch 691/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5085 - val_loss: 672.4662\n",
      "Epoch 692/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5029 - val_loss: 666.7715\n",
      "Epoch 693/1000\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 411.5343 - val_loss: 670.8273\n",
      "Epoch 694/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5444 - val_loss: 673.5577\n",
      "Epoch 695/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5410 - val_loss: 668.2140\n",
      "Epoch 696/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5461 - val_loss: 671.2612\n",
      "Epoch 697/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5112 - val_loss: 667.7348\n",
      "Epoch 698/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5324 - val_loss: 669.4977\n",
      "Epoch 699/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4975 - val_loss: 673.1996\n",
      "Epoch 700/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5388 - val_loss: 669.6550\n",
      "Epoch 701/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5395 - val_loss: 670.5828\n",
      "Epoch 702/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4884 - val_loss: 667.8895\n",
      "Epoch 703/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4111 - val_loss: 673.8767\n",
      "Epoch 704/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5030 - val_loss: 674.9815\n",
      "Epoch 705/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5788 - val_loss: 670.1581\n",
      "Epoch 706/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5187 - val_loss: 671.7959\n",
      "Epoch 707/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4722 - val_loss: 668.0201\n",
      "Epoch 708/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5197 - val_loss: 671.4594\n",
      "Epoch 709/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5190 - val_loss: 672.8622\n",
      "Epoch 710/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5402 - val_loss: 672.6080\n",
      "Epoch 711/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5383 - val_loss: 671.7111\n",
      "Epoch 712/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5398 - val_loss: 671.4254\n",
      "Epoch 713/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4756 - val_loss: 672.7748\n",
      "Epoch 714/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5300 - val_loss: 673.3313\n",
      "Epoch 715/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4945 - val_loss: 673.5223\n",
      "Epoch 716/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5258 - val_loss: 673.6484\n",
      "Epoch 717/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5301 - val_loss: 671.0905\n",
      "Epoch 718/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4934 - val_loss: 667.0527\n",
      "Epoch 719/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5410 - val_loss: 671.0975\n",
      "Epoch 720/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5360 - val_loss: 669.3306\n",
      "Epoch 721/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5192 - val_loss: 671.5756\n",
      "Epoch 722/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5572 - val_loss: 670.9420\n",
      "Epoch 723/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4086 - val_loss: 673.4666\n",
      "Epoch 724/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5213 - val_loss: 674.4454\n",
      "Epoch 725/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5491 - val_loss: 670.7120\n",
      "Epoch 726/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5329 - val_loss: 672.6944\n",
      "Epoch 727/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5406 - val_loss: 670.9142\n",
      "Epoch 728/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5455 - val_loss: 671.0107\n",
      "Epoch 729/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5190 - val_loss: 674.6846\n",
      "Epoch 730/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5572 - val_loss: 671.9885\n",
      "Epoch 731/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4934 - val_loss: 672.7307\n",
      "Epoch 732/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5063 - val_loss: 670.1332\n",
      "Epoch 733/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5168 - val_loss: 668.1835\n",
      "Epoch 734/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5441 - val_loss: 671.2842\n",
      "Epoch 735/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5455 - val_loss: 670.5163\n",
      "Epoch 736/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4612 - val_loss: 675.3216\n",
      "Epoch 737/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5660 - val_loss: 673.2014\n",
      "Epoch 738/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5167 - val_loss: 668.9395\n",
      "Epoch 739/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.3979 - val_loss: 664.7983\n",
      "Epoch 740/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5671 - val_loss: 669.4772\n",
      "Epoch 741/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5080 - val_loss: 673.4284\n",
      "Epoch 742/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5334 - val_loss: 671.9706\n",
      "Epoch 743/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5386 - val_loss: 672.1063\n",
      "Epoch 744/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5011 - val_loss: 671.4226\n",
      "Epoch 745/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5153 - val_loss: 670.8558\n",
      "Epoch 746/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5419 - val_loss: 672.4120\n",
      "Epoch 747/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5227 - val_loss: 674.0889\n",
      "Epoch 748/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5045 - val_loss: 675.4658\n",
      "Epoch 749/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5871 - val_loss: 669.5416\n",
      "Epoch 750/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4786 - val_loss: 666.2889\n",
      "Epoch 751/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5008 - val_loss: 674.0036\n",
      "Epoch 752/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5560 - val_loss: 670.4367\n",
      "Epoch 753/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5738 - val_loss: 672.8469\n",
      "Epoch 754/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5318 - val_loss: 670.4208\n",
      "Epoch 755/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5305 - val_loss: 669.3265\n",
      "Epoch 756/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4519 - val_loss: 674.8041\n",
      "Epoch 757/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5505 - val_loss: 668.3156\n",
      "Epoch 758/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5530 - val_loss: 671.7867\n",
      "Epoch 759/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5072 - val_loss: 672.2529\n",
      "Epoch 760/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5395 - val_loss: 673.9343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5428 - val_loss: 672.0525\n",
      "Epoch 762/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5225 - val_loss: 670.5266\n",
      "Epoch 763/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5406 - val_loss: 671.5809\n",
      "Epoch 764/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5238 - val_loss: 668.3142\n",
      "Epoch 765/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5166 - val_loss: 672.3429\n",
      "Epoch 766/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5455 - val_loss: 671.4683\n",
      "Epoch 767/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5164 - val_loss: 669.1150\n",
      "Epoch 768/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4259 - val_loss: 674.4518\n",
      "Epoch 769/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4996 - val_loss: 668.5933\n",
      "Epoch 770/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.3646 - val_loss: 677.2944\n",
      "Epoch 771/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4619 - val_loss: 665.4010\n",
      "Epoch 772/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5339 - val_loss: 671.7339\n",
      "Epoch 773/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5272 - val_loss: 668.3536\n",
      "Epoch 774/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5401 - val_loss: 673.2221\n",
      "Epoch 775/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5510 - val_loss: 671.3387\n",
      "Epoch 776/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4889 - val_loss: 673.9865\n",
      "Epoch 777/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5211 - val_loss: 670.1028\n",
      "Epoch 778/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5276 - val_loss: 671.2224\n",
      "Epoch 779/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5554 - val_loss: 670.7745\n",
      "Epoch 780/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5250 - val_loss: 671.1044\n",
      "Epoch 781/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4918 - val_loss: 667.0784\n",
      "Epoch 782/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4791 - val_loss: 670.7117\n",
      "Epoch 783/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5364 - val_loss: 670.0710\n",
      "Epoch 784/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5233 - val_loss: 671.5159\n",
      "Epoch 785/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5143 - val_loss: 668.9501\n",
      "Epoch 786/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5573 - val_loss: 667.5007\n",
      "Epoch 787/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5562 - val_loss: 670.0530\n",
      "Epoch 788/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5615 - val_loss: 671.3626\n",
      "Epoch 789/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5242 - val_loss: 667.4392\n",
      "Epoch 790/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4643 - val_loss: 674.9396\n",
      "Epoch 791/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5411 - val_loss: 669.9642\n",
      "Epoch 792/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4223 - val_loss: 673.2278\n",
      "Epoch 793/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5277 - val_loss: 671.3638\n",
      "Epoch 794/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5593 - val_loss: 670.1197\n",
      "Epoch 795/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4789 - val_loss: 669.7611\n",
      "Epoch 796/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4164 - val_loss: 676.2113\n",
      "Epoch 797/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5259 - val_loss: 670.5674\n",
      "Epoch 798/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4281 - val_loss: 676.6490\n",
      "Epoch 799/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5561 - val_loss: 669.3830\n",
      "Epoch 800/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4963 - val_loss: 673.4367\n",
      "Epoch 801/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4836 - val_loss: 667.2532\n",
      "Epoch 802/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5403 - val_loss: 671.1326\n",
      "Epoch 803/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5445 - val_loss: 670.6088\n",
      "Epoch 804/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5225 - val_loss: 671.2703\n",
      "Epoch 805/1000\n",
      "289/289 [==============================] - 2s 7ms/step - loss: 411.5399 - val_loss: 668.9879\n",
      "Epoch 806/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5178 - val_loss: 668.0894\n",
      "Epoch 807/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5782 - val_loss: 669.6224\n",
      "Epoch 808/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5498 - val_loss: 669.9873\n",
      "Epoch 809/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5129 - val_loss: 668.5260\n",
      "Epoch 810/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5484 - val_loss: 670.0755\n",
      "Epoch 811/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5146 - val_loss: 669.2090\n",
      "Epoch 812/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4848 - val_loss: 673.3829\n",
      "Epoch 813/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5262 - val_loss: 671.3552\n",
      "Epoch 814/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5026 - val_loss: 671.8741\n",
      "Epoch 815/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5450 - val_loss: 671.7312\n",
      "Epoch 816/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4698 - val_loss: 667.3019\n",
      "Epoch 817/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5414 - val_loss: 667.8304\n",
      "Epoch 818/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5547 - val_loss: 670.2302\n",
      "Epoch 819/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5101 - val_loss: 671.6034\n",
      "Epoch 820/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5486 - val_loss: 671.2037\n",
      "Epoch 821/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5697 - val_loss: 671.0954\n",
      "Epoch 822/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4250 - val_loss: 674.5439\n",
      "Epoch 823/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.4102 - val_loss: 676.2958\n",
      "Epoch 824/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5379 - val_loss: 676.8444\n",
      "Epoch 825/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5533 - val_loss: 671.7714\n",
      "Epoch 826/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5228 - val_loss: 671.6792\n",
      "Epoch 827/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5308 - val_loss: 671.9973\n",
      "Epoch 828/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.4960 - val_loss: 668.3866\n",
      "Epoch 829/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4981 - val_loss: 668.3188\n",
      "Epoch 830/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5408 - val_loss: 671.0026\n",
      "Epoch 831/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5189 - val_loss: 673.1802\n",
      "Epoch 832/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5198 - val_loss: 668.9467\n",
      "Epoch 833/1000\n",
      "289/289 [==============================] - 2s 6ms/step - loss: 411.5493 - val_loss: 670.4426\n",
      "Epoch 834/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5333 - val_loss: 672.3956\n",
      "Epoch 835/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5417 - val_loss: 672.0329\n",
      "Epoch 836/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5435 - val_loss: 671.7789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 837/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5369 - val_loss: 670.1948\n",
      "Epoch 838/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5442 - val_loss: 670.0798\n",
      "Epoch 839/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4495 - val_loss: 674.8400\n",
      "Epoch 840/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4112 - val_loss: 675.8308\n",
      "Epoch 841/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5023 - val_loss: 667.6492\n",
      "Epoch 842/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4936 - val_loss: 671.3037\n",
      "Epoch 843/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5472 - val_loss: 671.2405\n",
      "Epoch 844/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5170 - val_loss: 668.2457\n",
      "Epoch 845/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5139 - val_loss: 672.9326\n",
      "Epoch 846/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5046 - val_loss: 667.4526\n",
      "Epoch 847/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4647 - val_loss: 671.3876\n",
      "Epoch 848/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5437 - val_loss: 669.1940\n",
      "Epoch 849/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5093 - val_loss: 672.5095\n",
      "Epoch 850/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5262 - val_loss: 669.0375\n",
      "Epoch 851/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4774 - val_loss: 665.4360\n",
      "Epoch 852/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5564 - val_loss: 672.1091\n",
      "Epoch 853/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5346 - val_loss: 668.7496\n",
      "Epoch 854/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4708 - val_loss: 673.2034\n",
      "Epoch 855/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4927 - val_loss: 667.5279\n",
      "Epoch 856/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5302 - val_loss: 670.0325\n",
      "Epoch 857/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5210 - val_loss: 670.9731\n",
      "Epoch 858/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5247 - val_loss: 671.8883\n",
      "Epoch 859/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5227 - val_loss: 672.4138\n",
      "Epoch 860/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5574 - val_loss: 670.5134\n",
      "Epoch 861/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5198 - val_loss: 669.6185\n",
      "Epoch 862/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5338 - val_loss: 671.8069\n",
      "Epoch 863/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5301 - val_loss: 674.3899\n",
      "Epoch 864/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5498 - val_loss: 674.2418\n",
      "Epoch 865/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5095 - val_loss: 676.3051\n",
      "Epoch 866/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5474 - val_loss: 671.9544\n",
      "Epoch 867/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5329 - val_loss: 668.3323\n",
      "Epoch 868/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4707 - val_loss: 674.9683\n",
      "Epoch 869/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5380 - val_loss: 669.5633\n",
      "Epoch 870/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5232 - val_loss: 670.6552\n",
      "Epoch 871/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5163 - val_loss: 672.7606\n",
      "Epoch 872/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5310 - val_loss: 672.7787\n",
      "Epoch 873/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5074 - val_loss: 667.7192\n",
      "Epoch 874/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5252 - val_loss: 669.7475\n",
      "Epoch 875/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5323 - val_loss: 667.6011\n",
      "Epoch 876/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5316 - val_loss: 669.7076\n",
      "Epoch 877/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4811 - val_loss: 671.6625\n",
      "Epoch 878/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4957 - val_loss: 672.7086\n",
      "Epoch 879/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5307 - val_loss: 671.6126\n",
      "Epoch 880/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5285 - val_loss: 669.4133\n",
      "Epoch 881/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5236 - val_loss: 667.9757\n",
      "Epoch 882/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4968 - val_loss: 671.1175\n",
      "Epoch 883/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5284 - val_loss: 671.7082\n",
      "Epoch 884/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5269 - val_loss: 672.0508\n",
      "Epoch 885/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4643 - val_loss: 674.1674\n",
      "Epoch 886/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5378 - val_loss: 672.4410\n",
      "Epoch 887/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5239 - val_loss: 668.7693\n",
      "Epoch 888/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4483 - val_loss: 672.7236\n",
      "Epoch 889/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5569 - val_loss: 672.3294\n",
      "Epoch 890/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5442 - val_loss: 669.0003\n",
      "Epoch 891/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4029 - val_loss: 676.8339\n",
      "Epoch 892/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5592 - val_loss: 671.5274\n",
      "Epoch 893/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5469 - val_loss: 668.9758\n",
      "Epoch 894/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5286 - val_loss: 670.7870\n",
      "Epoch 895/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5231 - val_loss: 670.2653\n",
      "Epoch 896/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4946 - val_loss: 672.6232\n",
      "Epoch 897/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5359 - val_loss: 673.1038\n",
      "Epoch 898/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5382 - val_loss: 673.9855\n",
      "Epoch 899/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5157 - val_loss: 668.8511\n",
      "Epoch 900/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.3844 - val_loss: 678.1121\n",
      "Epoch 901/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5799 - val_loss: 674.9735\n",
      "Epoch 902/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5479 - val_loss: 668.8444\n",
      "Epoch 903/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5464 - val_loss: 670.5111\n",
      "Epoch 904/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5150 - val_loss: 668.1818\n",
      "Epoch 905/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5366 - val_loss: 671.2792\n",
      "Epoch 906/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5157 - val_loss: 669.8924\n",
      "Epoch 907/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5199 - val_loss: 668.0136\n",
      "Epoch 908/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5143 - val_loss: 670.6838\n",
      "Epoch 909/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5169 - val_loss: 669.0451\n",
      "Epoch 910/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5555 - val_loss: 670.5674\n",
      "Epoch 911/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5367 - val_loss: 670.8150\n",
      "Epoch 912/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5197 - val_loss: 669.5869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4950 - val_loss: 672.8406\n",
      "Epoch 914/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5108 - val_loss: 670.4717\n",
      "Epoch 915/1000\n",
      "289/289 [==============================] - 2s 7ms/step - loss: 411.5128 - val_loss: 673.0449\n",
      "Epoch 916/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5365 - val_loss: 672.3726\n",
      "Epoch 917/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4920 - val_loss: 673.1735\n",
      "Epoch 918/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5143 - val_loss: 669.3957\n",
      "Epoch 919/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4325 - val_loss: 665.8217\n",
      "Epoch 920/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5305 - val_loss: 671.8267\n",
      "Epoch 921/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5062 - val_loss: 672.6944\n",
      "Epoch 922/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4710 - val_loss: 666.0635\n",
      "Epoch 923/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4878 - val_loss: 672.6526\n",
      "Epoch 924/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5266 - val_loss: 673.5630\n",
      "Epoch 925/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5491 - val_loss: 669.0260\n",
      "Epoch 926/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5308 - val_loss: 668.3919\n",
      "Epoch 927/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4977 - val_loss: 669.6550\n",
      "Epoch 928/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5086 - val_loss: 671.2150\n",
      "Epoch 929/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4950 - val_loss: 668.5120\n",
      "Epoch 930/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4811 - val_loss: 673.9379\n",
      "Epoch 931/1000\n",
      "289/289 [==============================] - 3s 10ms/step - loss: 411.5587 - val_loss: 669.8024\n",
      "Epoch 932/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5363 - val_loss: 669.0160\n",
      "Epoch 933/1000\n",
      "289/289 [==============================] - 2s 9ms/step - loss: 411.5184 - val_loss: 667.2029\n",
      "Epoch 934/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5395 - val_loss: 671.5916\n",
      "Epoch 935/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5385 - val_loss: 669.9225\n",
      "Epoch 936/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5504 - val_loss: 672.5468\n",
      "Epoch 937/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5197 - val_loss: 673.8177\n",
      "Epoch 938/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5132 - val_loss: 668.7713\n",
      "Epoch 939/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4922 - val_loss: 671.0007\n",
      "Epoch 940/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4576 - val_loss: 675.1157\n",
      "Epoch 941/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5612 - val_loss: 670.5461\n",
      "Epoch 942/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.3678 - val_loss: 677.1998\n",
      "Epoch 943/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.6202 - val_loss: 671.7311\n",
      "Epoch 944/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.5483 - val_loss: 669.3381\n",
      "Epoch 945/1000\n",
      "289/289 [==============================] - 3s 9ms/step - loss: 411.4779 - val_loss: 675.2877\n",
      "Epoch 946/1000\n",
      "289/289 [==============================] - 1s 4ms/step - loss: 411.5131 - val_loss: 669.3740\n",
      "Epoch 947/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5056 - val_loss: 670.7424\n",
      "Epoch 948/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4953 - val_loss: 672.8251\n",
      "Epoch 949/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4973 - val_loss: 670.9215\n",
      "Epoch 950/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5034 - val_loss: 674.2662\n",
      "Epoch 951/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5743 - val_loss: 672.2746\n",
      "Epoch 952/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5117 - val_loss: 669.2792\n",
      "Epoch 953/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4892 - val_loss: 667.9037\n",
      "Epoch 954/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5136 - val_loss: 669.1901\n",
      "Epoch 955/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5566 - val_loss: 669.7080\n",
      "Epoch 956/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5293 - val_loss: 669.6180\n",
      "Epoch 957/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5303 - val_loss: 673.3355\n",
      "Epoch 958/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5048 - val_loss: 672.5165\n",
      "Epoch 959/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5082 - val_loss: 671.0121\n",
      "Epoch 960/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5186 - val_loss: 667.4993\n",
      "Epoch 961/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5243 - val_loss: 671.6487\n",
      "Epoch 962/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5344 - val_loss: 670.9940\n",
      "Epoch 963/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5047 - val_loss: 670.8506\n",
      "Epoch 964/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5059 - val_loss: 668.1711\n",
      "Epoch 965/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5308 - val_loss: 671.2106\n",
      "Epoch 966/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5398 - val_loss: 670.3103\n",
      "Epoch 967/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5225 - val_loss: 672.6063\n",
      "Epoch 968/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5338 - val_loss: 669.8206\n",
      "Epoch 969/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.5353 - val_loss: 670.7770\n",
      "Epoch 970/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4821 - val_loss: 673.8061\n",
      "Epoch 971/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5305 - val_loss: 673.9982\n",
      "Epoch 972/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5493 - val_loss: 669.2228\n",
      "Epoch 973/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4919 - val_loss: 672.0746\n",
      "Epoch 974/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5222 - val_loss: 670.6371\n",
      "Epoch 975/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5271 - val_loss: 670.7154\n",
      "Epoch 976/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5130 - val_loss: 671.2640\n",
      "Epoch 977/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5161 - val_loss: 668.4375\n",
      "Epoch 978/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5321 - val_loss: 671.5448\n",
      "Epoch 979/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5577 - val_loss: 671.0082\n",
      "Epoch 980/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5125 - val_loss: 672.7291\n",
      "Epoch 981/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5295 - val_loss: 671.7026\n",
      "Epoch 982/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4478 - val_loss: 668.9373\n",
      "Epoch 983/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4784 - val_loss: 673.5944\n",
      "Epoch 984/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5370 - val_loss: 671.1276\n",
      "Epoch 985/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5375 - val_loss: 671.9089\n",
      "Epoch 986/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5412 - val_loss: 670.3490\n",
      "Epoch 987/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4873 - val_loss: 671.8327\n",
      "Epoch 988/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4206 - val_loss: 674.5466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5595 - val_loss: 671.9141\n",
      "Epoch 990/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5332 - val_loss: 671.9057\n",
      "Epoch 991/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5351 - val_loss: 668.3004\n",
      "Epoch 992/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5142 - val_loss: 671.3259\n",
      "Epoch 993/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5167 - val_loss: 674.4212\n",
      "Epoch 994/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5746 - val_loss: 672.9188\n",
      "Epoch 995/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5143 - val_loss: 671.7219\n",
      "Epoch 996/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5078 - val_loss: 668.2654\n",
      "Epoch 997/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4622 - val_loss: 674.8352\n",
      "Epoch 998/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5141 - val_loss: 675.1530\n",
      "Epoch 999/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5839 - val_loss: 670.9964\n",
      "Epoch 1000/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.5263 - val_loss: 671.3151\n",
      "66/66 [==============================] - 1s 894us/step\n",
      "689753 successful\n",
      "Epoch 1/1000\n",
      "320/320 [==============================] - 3s 3ms/step - loss: 516.0021 - val_loss: 752.3578\n",
      "Epoch 2/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 330.3408 - val_loss: 649.6578\n",
      "Epoch 3/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0827 - val_loss: 646.9163\n",
      "Epoch 4/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0450 - val_loss: 643.0040\n",
      "Epoch 5/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1324 - val_loss: 646.2241\n",
      "Epoch 6/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0746 - val_loss: 648.4924\n",
      "Epoch 7/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1230 - val_loss: 646.3678\n",
      "Epoch 8/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0852 - val_loss: 650.4668\n",
      "Epoch 9/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1252 - val_loss: 645.3242\n",
      "Epoch 10/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0924 - val_loss: 645.3700\n",
      "Epoch 11/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1112 - val_loss: 648.7318\n",
      "Epoch 12/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0826 - val_loss: 648.9845\n",
      "Epoch 13/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1024 - val_loss: 647.1646\n",
      "Epoch 14/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0950 - val_loss: 650.4691\n",
      "Epoch 15/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0809 - val_loss: 642.8771\n",
      "Epoch 16/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1324 - val_loss: 646.0983\n",
      "Epoch 17/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1103 - val_loss: 648.2128\n",
      "Epoch 18/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0903 - val_loss: 647.6522\n",
      "Epoch 19/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1127 - val_loss: 649.1494\n",
      "Epoch 20/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0837 - val_loss: 650.4423\n",
      "Epoch 21/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0989 - val_loss: 645.4534\n",
      "Epoch 22/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1180 - val_loss: 645.8037\n",
      "Epoch 23/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0925 - val_loss: 642.7471\n",
      "Epoch 24/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.1080 - val_loss: 642.0012\n",
      "Epoch 25/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0959 - val_loss: 646.9960\n",
      "Epoch 26/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0938 - val_loss: 644.1440\n",
      "Epoch 27/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1163 - val_loss: 647.4731\n",
      "Epoch 28/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1122 - val_loss: 649.1088\n",
      "Epoch 29/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0973 - val_loss: 647.9515\n",
      "Epoch 30/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0853 - val_loss: 646.6312\n",
      "Epoch 31/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0688 - val_loss: 652.0862\n",
      "Epoch 32/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1192 - val_loss: 647.6582\n",
      "Epoch 33/1000\n",
      "320/320 [==============================] - 3s 9ms/step - loss: 325.0931 - val_loss: 644.0269\n",
      "Epoch 34/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0899 - val_loss: 648.8909\n",
      "Epoch 35/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0996 - val_loss: 648.8597\n",
      "Epoch 36/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0948 - val_loss: 650.4319\n",
      "Epoch 37/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1156 - val_loss: 647.9451\n",
      "Epoch 38/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0997 - val_loss: 644.1340\n",
      "Epoch 39/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1275 - val_loss: 647.7686\n",
      "Epoch 40/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1223 - val_loss: 648.4189\n",
      "Epoch 41/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1132 - val_loss: 647.8950\n",
      "Epoch 42/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0797 - val_loss: 645.9008\n",
      "Epoch 43/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1208 - val_loss: 647.2587\n",
      "Epoch 44/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1014 - val_loss: 643.2381\n",
      "Epoch 45/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0766 - val_loss: 649.8527\n",
      "Epoch 46/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0970 - val_loss: 648.2462\n",
      "Epoch 47/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0586 - val_loss: 644.4029\n",
      "Epoch 48/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0761 - val_loss: 642.6358\n",
      "Epoch 49/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1196 - val_loss: 644.6669\n",
      "Epoch 50/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1266 - val_loss: 646.8809\n",
      "Epoch 51/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1136 - val_loss: 648.4597\n",
      "Epoch 52/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1168 - val_loss: 646.4120\n",
      "Epoch 53/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0959 - val_loss: 648.5966\n",
      "Epoch 54/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0925 - val_loss: 647.3121\n",
      "Epoch 55/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0869 - val_loss: 650.9623\n",
      "Epoch 56/1000\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 325.0951 - val_loss: 647.4749\n",
      "Epoch 57/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0473 - val_loss: 651.2787\n",
      "Epoch 58/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1203 - val_loss: 646.5271\n",
      "Epoch 59/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0748 - val_loss: 646.0108\n",
      "Epoch 60/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0783 - val_loss: 643.8353\n",
      "Epoch 61/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1415 - val_loss: 647.1879\n",
      "Epoch 62/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0969 - val_loss: 644.7731\n",
      "Epoch 63/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0938 - val_loss: 648.7144\n",
      "Epoch 64/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1129 - val_loss: 645.5576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0872 - val_loss: 647.0229\n",
      "Epoch 66/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1069 - val_loss: 646.8654\n",
      "Epoch 67/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1123 - val_loss: 649.7751\n",
      "Epoch 68/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0818 - val_loss: 646.3648\n",
      "Epoch 69/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1196 - val_loss: 646.8790\n",
      "Epoch 70/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0379 - val_loss: 640.8393\n",
      "Epoch 71/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1174 - val_loss: 649.2597\n",
      "Epoch 72/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0856 - val_loss: 651.4796\n",
      "Epoch 73/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1429 - val_loss: 647.3975\n",
      "Epoch 74/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0870 - val_loss: 650.9141\n",
      "Epoch 75/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0995 - val_loss: 645.9281\n",
      "Epoch 76/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1049 - val_loss: 646.7148\n",
      "Epoch 77/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0716 - val_loss: 644.9691\n",
      "Epoch 78/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1151 - val_loss: 645.1379\n",
      "Epoch 79/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0654 - val_loss: 645.8103\n",
      "Epoch 80/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1150 - val_loss: 645.1744\n",
      "Epoch 81/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0839 - val_loss: 649.9299\n",
      "Epoch 82/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1161 - val_loss: 646.6193\n",
      "Epoch 83/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0915 - val_loss: 644.8044\n",
      "Epoch 84/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1128 - val_loss: 645.0280\n",
      "Epoch 85/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1025 - val_loss: 650.3342\n",
      "Epoch 86/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0743 - val_loss: 652.6086\n",
      "Epoch 87/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1699 - val_loss: 647.3394\n",
      "Epoch 88/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0368 - val_loss: 652.2372\n",
      "Epoch 89/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1566 - val_loss: 648.1953\n",
      "Epoch 90/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 324.9929 - val_loss: 654.5640\n",
      "Epoch 91/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1437 - val_loss: 646.8191\n",
      "Epoch 92/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1271 - val_loss: 648.6747\n",
      "Epoch 93/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1232 - val_loss: 645.6110\n",
      "Epoch 94/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1230 - val_loss: 648.0472\n",
      "Epoch 95/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0319 - val_loss: 653.2872\n",
      "Epoch 96/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1501 - val_loss: 647.7606\n",
      "Epoch 97/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1065 - val_loss: 648.1931\n",
      "Epoch 98/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1338 - val_loss: 646.9653\n",
      "Epoch 99/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0967 - val_loss: 647.5583\n",
      "Epoch 100/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1198 - val_loss: 648.5367\n",
      "Epoch 101/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0974 - val_loss: 643.8383\n",
      "Epoch 102/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1035 - val_loss: 645.0901\n",
      "Epoch 103/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1016 - val_loss: 648.1968\n",
      "Epoch 104/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 324.9998 - val_loss: 652.9071\n",
      "Epoch 105/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1247 - val_loss: 650.8479\n",
      "Epoch 106/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1142 - val_loss: 650.2027\n",
      "Epoch 107/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0997 - val_loss: 646.4422\n",
      "Epoch 108/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1160 - val_loss: 645.8583\n",
      "Epoch 109/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0733 - val_loss: 646.5394\n",
      "Epoch 110/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.1068 - val_loss: 645.1341\n",
      "Epoch 111/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0644 - val_loss: 651.9548\n",
      "Epoch 112/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1439 - val_loss: 647.9794\n",
      "Epoch 113/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0693 - val_loss: 652.0056\n",
      "Epoch 114/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0672 - val_loss: 652.5898\n",
      "Epoch 115/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1057 - val_loss: 645.6892\n",
      "Epoch 116/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0875 - val_loss: 649.2014\n",
      "Epoch 117/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1236 - val_loss: 646.4464\n",
      "Epoch 118/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1139 - val_loss: 644.7014\n",
      "Epoch 119/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 324.9502 - val_loss: 652.0677\n",
      "Epoch 120/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1343 - val_loss: 647.8273\n",
      "Epoch 121/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0761 - val_loss: 652.8969\n",
      "Epoch 122/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1466 - val_loss: 647.7313\n",
      "Epoch 123/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1092 - val_loss: 647.2605\n",
      "Epoch 124/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1041 - val_loss: 645.7265\n",
      "Epoch 125/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0633 - val_loss: 651.6097\n",
      "Epoch 126/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1104 - val_loss: 643.9976\n",
      "Epoch 127/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0931 - val_loss: 643.4487\n",
      "Epoch 128/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1208 - val_loss: 647.0198\n",
      "Epoch 129/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0995 - val_loss: 647.3911\n",
      "Epoch 130/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1038 - val_loss: 647.4191\n",
      "Epoch 131/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1060 - val_loss: 650.2841\n",
      "Epoch 132/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0457 - val_loss: 642.3438\n",
      "Epoch 133/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0499 - val_loss: 649.4297\n",
      "Epoch 134/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0756 - val_loss: 650.4656\n",
      "Epoch 135/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0814 - val_loss: 643.8812\n",
      "Epoch 136/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0612 - val_loss: 650.1653\n",
      "Epoch 137/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1111 - val_loss: 647.3425\n",
      "Epoch 138/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0580 - val_loss: 643.0262\n",
      "Epoch 139/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0802 - val_loss: 648.4789\n",
      "Epoch 140/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1201 - val_loss: 648.9014\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0921 - val_loss: 646.1320\n",
      "Epoch 142/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1106 - val_loss: 646.6246\n",
      "Epoch 143/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1253 - val_loss: 647.8837\n",
      "Epoch 144/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1227 - val_loss: 645.4751\n",
      "Epoch 145/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0912 - val_loss: 648.1488\n",
      "Epoch 146/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0941 - val_loss: 646.1117\n",
      "Epoch 147/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0814 - val_loss: 645.6294\n",
      "Epoch 148/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1249 - val_loss: 647.3774\n",
      "Epoch 149/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1194 - val_loss: 649.0387\n",
      "Epoch 150/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1138 - val_loss: 649.4880\n",
      "Epoch 151/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0622 - val_loss: 649.3208\n",
      "Epoch 152/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1215 - val_loss: 647.9899\n",
      "Epoch 153/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1041 - val_loss: 645.9202\n",
      "Epoch 154/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1154 - val_loss: 647.3098\n",
      "Epoch 155/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0806 - val_loss: 648.6342\n",
      "Epoch 156/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0664 - val_loss: 652.7136\n",
      "Epoch 157/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1109 - val_loss: 651.0505\n",
      "Epoch 158/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1413 - val_loss: 649.2412\n",
      "Epoch 159/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1094 - val_loss: 646.2913\n",
      "Epoch 160/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1161 - val_loss: 645.3626\n",
      "Epoch 161/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1267 - val_loss: 647.5650\n",
      "Epoch 162/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0826 - val_loss: 645.6578\n",
      "Epoch 163/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0084 - val_loss: 653.2388\n",
      "Epoch 164/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1357 - val_loss: 647.5247\n",
      "Epoch 165/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1032 - val_loss: 646.5524\n",
      "Epoch 166/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0786 - val_loss: 650.7988\n",
      "Epoch 167/1000\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 325.1299 - val_loss: 644.7516\n",
      "Epoch 168/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1160 - val_loss: 647.7555\n",
      "Epoch 169/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1060 - val_loss: 646.0795\n",
      "Epoch 170/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0561 - val_loss: 651.7346\n",
      "Epoch 171/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0710 - val_loss: 653.2928\n",
      "Epoch 172/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1131 - val_loss: 642.8657\n",
      "Epoch 173/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1070 - val_loss: 648.6219\n",
      "Epoch 174/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0542 - val_loss: 652.8843\n",
      "Epoch 175/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0520 - val_loss: 643.0905\n",
      "Epoch 176/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1187 - val_loss: 646.1266\n",
      "Epoch 177/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0990 - val_loss: 648.7585\n",
      "Epoch 178/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0952 - val_loss: 645.0430\n",
      "Epoch 179/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0218 - val_loss: 652.3786\n",
      "Epoch 180/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1430 - val_loss: 649.5389\n",
      "Epoch 181/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0856 - val_loss: 652.6458\n",
      "Epoch 182/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1091 - val_loss: 648.7389\n",
      "Epoch 183/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0746 - val_loss: 645.6791\n",
      "Epoch 184/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0673 - val_loss: 652.8314\n",
      "Epoch 185/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0903 - val_loss: 651.4409\n",
      "Epoch 186/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1334 - val_loss: 645.5598\n",
      "Epoch 187/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1082 - val_loss: 644.9514\n",
      "Epoch 188/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0902 - val_loss: 646.2380\n",
      "Epoch 189/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1057 - val_loss: 647.5182\n",
      "Epoch 190/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1120 - val_loss: 648.8310\n",
      "Epoch 191/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0950 - val_loss: 647.2194\n",
      "Epoch 192/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0832 - val_loss: 648.3803\n",
      "Epoch 193/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0547 - val_loss: 653.6226\n",
      "Epoch 194/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0894 - val_loss: 646.6906\n",
      "Epoch 195/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1093 - val_loss: 647.3580\n",
      "Epoch 196/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1203 - val_loss: 646.8432\n",
      "Epoch 197/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0500 - val_loss: 650.3967\n",
      "Epoch 198/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1088 - val_loss: 645.9992\n",
      "Epoch 199/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1181 - val_loss: 646.4596\n",
      "Epoch 200/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0300 - val_loss: 649.1634\n",
      "Epoch 201/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1240 - val_loss: 648.4780\n",
      "Epoch 202/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1166 - val_loss: 648.3457\n",
      "Epoch 203/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0741 - val_loss: 648.5397\n",
      "Epoch 204/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1110 - val_loss: 644.8196\n",
      "Epoch 205/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0572 - val_loss: 651.0862\n",
      "Epoch 206/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1231 - val_loss: 646.0011\n",
      "Epoch 207/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0961 - val_loss: 645.9976\n",
      "Epoch 208/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0223 - val_loss: 641.8282\n",
      "Epoch 209/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1240 - val_loss: 646.7899\n",
      "Epoch 210/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0638 - val_loss: 644.6418\n",
      "Epoch 211/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 324.9892 - val_loss: 639.0377\n",
      "Epoch 212/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1333 - val_loss: 648.7543\n",
      "Epoch 213/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1158 - val_loss: 648.5557\n",
      "Epoch 214/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1095 - val_loss: 645.6695\n",
      "Epoch 215/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 324.9312 - val_loss: 658.1896\n",
      "Epoch 216/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1327 - val_loss: 648.8303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1114 - val_loss: 648.6529\n",
      "Epoch 218/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0921 - val_loss: 646.0129\n",
      "Epoch 219/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1280 - val_loss: 646.5862\n",
      "Epoch 220/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0981 - val_loss: 643.4684\n",
      "Epoch 221/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1105 - val_loss: 644.7087\n",
      "Epoch 222/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1183 - val_loss: 648.2383\n",
      "Epoch 223/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1029 - val_loss: 643.7049\n",
      "Epoch 224/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0969 - val_loss: 645.4950\n",
      "Epoch 225/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1073 - val_loss: 647.3925\n",
      "Epoch 226/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0939 - val_loss: 645.8339\n",
      "Epoch 227/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1251 - val_loss: 647.3416\n",
      "Epoch 228/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 324.9550 - val_loss: 654.3279\n",
      "Epoch 229/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1387 - val_loss: 646.8391\n",
      "Epoch 230/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1103 - val_loss: 646.3393\n",
      "Epoch 231/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0782 - val_loss: 642.5466\n",
      "Epoch 232/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0983 - val_loss: 649.5527\n",
      "Epoch 233/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1234 - val_loss: 647.6870\n",
      "Epoch 234/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0601 - val_loss: 652.6405\n",
      "Epoch 235/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1040 - val_loss: 649.2689\n",
      "Epoch 236/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0804 - val_loss: 648.7619\n",
      "Epoch 237/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0900 - val_loss: 646.2040\n",
      "Epoch 238/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0927 - val_loss: 644.7285\n",
      "Epoch 239/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1183 - val_loss: 648.0822\n",
      "Epoch 240/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0886 - val_loss: 649.5435\n",
      "Epoch 241/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1085 - val_loss: 644.2691\n",
      "Epoch 242/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1151 - val_loss: 646.4436\n",
      "Epoch 243/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0629 - val_loss: 651.2979\n",
      "Epoch 244/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1030 - val_loss: 651.7126\n",
      "Epoch 245/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0971 - val_loss: 650.2682\n",
      "Epoch 246/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1110 - val_loss: 646.4544\n",
      "Epoch 247/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1094 - val_loss: 647.1901\n",
      "Epoch 248/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0984 - val_loss: 646.7686\n",
      "Epoch 249/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0599 - val_loss: 647.6351\n",
      "Epoch 250/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1028 - val_loss: 648.2073\n",
      "Epoch 251/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0996 - val_loss: 646.9259\n",
      "Epoch 252/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0972 - val_loss: 645.1434\n",
      "Epoch 253/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1088 - val_loss: 646.8312\n",
      "Epoch 254/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1044 - val_loss: 646.7556\n",
      "Epoch 255/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1049 - val_loss: 646.3269\n",
      "Epoch 256/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0399 - val_loss: 641.1544\n",
      "Epoch 257/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0838 - val_loss: 649.9308\n",
      "Epoch 258/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0460 - val_loss: 643.2706\n",
      "Epoch 259/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1078 - val_loss: 646.6288\n",
      "Epoch 260/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0992 - val_loss: 644.5839\n",
      "Epoch 261/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0711 - val_loss: 645.9180\n",
      "Epoch 262/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1090 - val_loss: 648.6826\n",
      "Epoch 263/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1324 - val_loss: 648.3469\n",
      "Epoch 264/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.1100 - val_loss: 647.5010\n",
      "Epoch 265/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0816 - val_loss: 646.8828\n",
      "Epoch 266/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1072 - val_loss: 647.9044\n",
      "Epoch 267/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1106 - val_loss: 646.7971\n",
      "Epoch 268/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1097 - val_loss: 647.5354\n",
      "Epoch 269/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0961 - val_loss: 644.7305\n",
      "Epoch 270/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0835 - val_loss: 644.9973\n",
      "Epoch 271/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0520 - val_loss: 651.8846\n",
      "Epoch 272/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0773 - val_loss: 648.1014\n",
      "Epoch 273/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1054 - val_loss: 646.0142\n",
      "Epoch 274/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0969 - val_loss: 650.9619\n",
      "Epoch 275/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1104 - val_loss: 649.8780\n",
      "Epoch 276/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0970 - val_loss: 648.3955\n",
      "Epoch 277/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1228 - val_loss: 648.7757\n",
      "Epoch 278/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0927 - val_loss: 649.3715\n",
      "Epoch 279/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0909 - val_loss: 645.7760\n",
      "Epoch 280/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0736 - val_loss: 651.4080\n",
      "Epoch 281/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0542 - val_loss: 652.3571\n",
      "Epoch 282/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1167 - val_loss: 646.9606\n",
      "Epoch 283/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0574 - val_loss: 645.5515\n",
      "Epoch 284/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1212 - val_loss: 646.8458\n",
      "Epoch 285/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1213 - val_loss: 646.0251\n",
      "Epoch 286/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0112 - val_loss: 652.9426\n",
      "Epoch 287/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1378 - val_loss: 646.4865\n",
      "Epoch 288/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0984 - val_loss: 645.3286\n",
      "Epoch 289/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1245 - val_loss: 646.3553\n",
      "Epoch 290/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1176 - val_loss: 646.2024\n",
      "Epoch 291/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0435 - val_loss: 651.0808\n",
      "Epoch 292/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1316 - val_loss: 646.2022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1254 - val_loss: 647.5383\n",
      "Epoch 294/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0551 - val_loss: 643.2222\n",
      "Epoch 295/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1209 - val_loss: 643.6933\n",
      "Epoch 296/1000\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 325.0733 - val_loss: 642.0524\n",
      "Epoch 297/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0832 - val_loss: 649.4487\n",
      "Epoch 298/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0907 - val_loss: 648.6370\n",
      "Epoch 299/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0887 - val_loss: 649.4803\n",
      "Epoch 300/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0999 - val_loss: 649.2362\n",
      "Epoch 301/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1198 - val_loss: 647.3040\n",
      "Epoch 302/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0807 - val_loss: 646.1413\n",
      "Epoch 303/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0802 - val_loss: 649.2927\n",
      "Epoch 304/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1002 - val_loss: 647.0554\n",
      "Epoch 305/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1124 - val_loss: 646.1313\n",
      "Epoch 306/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1106 - val_loss: 647.5593\n",
      "Epoch 307/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0810 - val_loss: 648.4670\n",
      "Epoch 308/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0479 - val_loss: 642.2372\n",
      "Epoch 309/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0948 - val_loss: 649.7300\n",
      "Epoch 310/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1149 - val_loss: 647.4731\n",
      "Epoch 311/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0910 - val_loss: 649.9960\n",
      "Epoch 312/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1227 - val_loss: 648.8557\n",
      "Epoch 313/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1203 - val_loss: 646.2341\n",
      "Epoch 314/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0631 - val_loss: 651.3418\n",
      "Epoch 315/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1429 - val_loss: 649.0682\n",
      "Epoch 316/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0981 - val_loss: 649.4800\n",
      "Epoch 317/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1097 - val_loss: 649.1393\n",
      "Epoch 318/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0985 - val_loss: 650.4695\n",
      "Epoch 319/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1070 - val_loss: 644.6828\n",
      "Epoch 320/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1237 - val_loss: 646.2394\n",
      "Epoch 321/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1104 - val_loss: 647.3241\n",
      "Epoch 322/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0897 - val_loss: 646.7039\n",
      "Epoch 323/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1066 - val_loss: 644.7537\n",
      "Epoch 324/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1150 - val_loss: 644.5006\n",
      "Epoch 325/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1194 - val_loss: 648.5783\n",
      "Epoch 326/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1006 - val_loss: 648.7482\n",
      "Epoch 327/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1039 - val_loss: 649.5353\n",
      "Epoch 328/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1337 - val_loss: 648.3292\n",
      "Epoch 329/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0609 - val_loss: 650.8620\n",
      "Epoch 330/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0900 - val_loss: 652.2176\n",
      "Epoch 331/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1237 - val_loss: 645.8535\n",
      "Epoch 332/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1103 - val_loss: 648.3644\n",
      "Epoch 333/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1175 - val_loss: 647.9683\n",
      "Epoch 334/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0688 - val_loss: 643.5668\n",
      "Epoch 335/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0204 - val_loss: 643.8500\n",
      "Epoch 336/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1123 - val_loss: 644.2722\n",
      "Epoch 337/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1140 - val_loss: 649.0078\n",
      "Epoch 338/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1234 - val_loss: 647.6179\n",
      "Epoch 339/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0676 - val_loss: 651.3687\n",
      "Epoch 340/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0886 - val_loss: 645.1187\n",
      "Epoch 341/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1075 - val_loss: 645.8597\n",
      "Epoch 342/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0978 - val_loss: 645.2119\n",
      "Epoch 343/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0623 - val_loss: 646.6000\n",
      "Epoch 344/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0979 - val_loss: 643.9134\n",
      "Epoch 345/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1084 - val_loss: 646.6498\n",
      "Epoch 346/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0833 - val_loss: 647.7658\n",
      "Epoch 347/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0947 - val_loss: 649.1659\n",
      "Epoch 348/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0933 - val_loss: 649.8866\n",
      "Epoch 349/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1063 - val_loss: 645.2645\n",
      "Epoch 350/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1071 - val_loss: 648.7578\n",
      "Epoch 351/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0742 - val_loss: 650.4269\n",
      "Epoch 352/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1163 - val_loss: 649.8998\n",
      "Epoch 353/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0633 - val_loss: 652.1299\n",
      "Epoch 354/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0147 - val_loss: 654.8075\n",
      "Epoch 355/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0401 - val_loss: 642.2471\n",
      "Epoch 356/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1182 - val_loss: 644.6848\n",
      "Epoch 357/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1133 - val_loss: 647.3583\n",
      "Epoch 358/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0730 - val_loss: 645.1434\n",
      "Epoch 359/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0852 - val_loss: 644.0844\n",
      "Epoch 360/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0563 - val_loss: 651.7014\n",
      "Epoch 361/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1168 - val_loss: 647.1125\n",
      "Epoch 362/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 324.9692 - val_loss: 639.0227\n",
      "Epoch 363/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1041 - val_loss: 648.1310\n",
      "Epoch 364/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0967 - val_loss: 647.4525\n",
      "Epoch 365/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1121 - val_loss: 650.0795\n",
      "Epoch 366/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1300 - val_loss: 648.2005\n",
      "Epoch 367/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1103 - val_loss: 644.1673\n",
      "Epoch 368/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0691 - val_loss: 649.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0795 - val_loss: 643.3533\n",
      "Epoch 370/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0207 - val_loss: 653.9026\n",
      "Epoch 371/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1211 - val_loss: 647.4648\n",
      "Epoch 372/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1484 - val_loss: 646.7005\n",
      "Epoch 373/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0887 - val_loss: 649.5605\n",
      "Epoch 374/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0999 - val_loss: 644.2115\n",
      "Epoch 375/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0773 - val_loss: 650.4990\n",
      "Epoch 376/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1265 - val_loss: 646.5914\n",
      "Epoch 377/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0536 - val_loss: 643.0016\n",
      "Epoch 378/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1053 - val_loss: 646.6868\n",
      "Epoch 379/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1034 - val_loss: 646.5867\n",
      "Epoch 380/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0547 - val_loss: 651.0704\n",
      "Epoch 381/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0612 - val_loss: 644.6513\n",
      "Epoch 382/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1062 - val_loss: 648.3083\n",
      "Epoch 383/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.1096 - val_loss: 646.5825\n",
      "Epoch 384/1000\n",
      "320/320 [==============================] - 2s 5ms/step - loss: 325.1273 - val_loss: 649.0975\n",
      "Epoch 385/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1305 - val_loss: 647.0359\n",
      "Epoch 386/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0960 - val_loss: 647.5134\n",
      "Epoch 387/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1141 - val_loss: 647.8928\n",
      "Epoch 388/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0724 - val_loss: 648.8373\n",
      "Epoch 389/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0120 - val_loss: 641.5319\n",
      "Epoch 390/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1246 - val_loss: 648.2828\n",
      "Epoch 391/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0652 - val_loss: 651.1146\n",
      "Epoch 392/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1080 - val_loss: 646.9850\n",
      "Epoch 393/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1037 - val_loss: 646.6717\n",
      "Epoch 394/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1215 - val_loss: 645.8342\n",
      "Epoch 395/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1090 - val_loss: 646.3062\n",
      "Epoch 396/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0525 - val_loss: 651.0021\n",
      "Epoch 397/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1270 - val_loss: 646.5364\n",
      "Epoch 398/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0939 - val_loss: 649.1553\n",
      "Epoch 399/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0863 - val_loss: 652.6797\n",
      "Epoch 400/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1107 - val_loss: 649.6086\n",
      "Epoch 401/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0433 - val_loss: 653.9695\n",
      "Epoch 402/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1114 - val_loss: 646.7760\n",
      "Epoch 403/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0964 - val_loss: 649.5073\n",
      "Epoch 404/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0948 - val_loss: 651.4813\n",
      "Epoch 405/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1014 - val_loss: 645.1595\n",
      "Epoch 406/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1200 - val_loss: 643.9638\n",
      "Epoch 407/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0988 - val_loss: 647.7121\n",
      "Epoch 408/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1077 - val_loss: 646.4111\n",
      "Epoch 409/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1027 - val_loss: 649.0490\n",
      "Epoch 410/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1091 - val_loss: 645.5810\n",
      "Epoch 411/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1024 - val_loss: 649.3081\n",
      "Epoch 412/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1138 - val_loss: 646.4505\n",
      "Epoch 413/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0423 - val_loss: 652.7900\n",
      "Epoch 414/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.1164 - val_loss: 647.9288\n",
      "Epoch 415/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0940 - val_loss: 646.0165\n",
      "Epoch 416/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1288 - val_loss: 645.9755\n",
      "Epoch 417/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0027 - val_loss: 654.7584\n",
      "Epoch 418/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0851 - val_loss: 643.2324\n",
      "Epoch 419/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0475 - val_loss: 651.9653\n",
      "Epoch 420/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0613 - val_loss: 653.3247\n",
      "Epoch 421/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1508 - val_loss: 648.3548\n",
      "Epoch 422/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0629 - val_loss: 649.2344\n",
      "Epoch 423/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0820 - val_loss: 643.8669\n",
      "Epoch 424/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1194 - val_loss: 647.7693\n",
      "Epoch 425/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1011 - val_loss: 650.0590\n",
      "Epoch 426/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1353 - val_loss: 647.5352\n",
      "Epoch 427/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0671 - val_loss: 643.4926\n",
      "Epoch 428/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0569 - val_loss: 646.6935\n",
      "Epoch 429/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0875 - val_loss: 644.6234\n",
      "Epoch 430/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0835 - val_loss: 643.2830\n",
      "Epoch 431/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1200 - val_loss: 646.8359\n",
      "Epoch 432/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1354 - val_loss: 648.3454\n",
      "Epoch 433/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1137 - val_loss: 647.9211\n",
      "Epoch 434/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1343 - val_loss: 646.6661\n",
      "Epoch 435/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0797 - val_loss: 651.0308\n",
      "Epoch 436/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1096 - val_loss: 650.1485\n",
      "Epoch 437/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1251 - val_loss: 648.4620\n",
      "Epoch 438/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0973 - val_loss: 650.0051\n",
      "Epoch 439/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1046 - val_loss: 650.1920\n",
      "Epoch 440/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0325 - val_loss: 649.0950\n",
      "Epoch 441/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0988 - val_loss: 648.0728\n",
      "Epoch 442/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1074 - val_loss: 649.0321\n",
      "Epoch 443/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0893 - val_loss: 646.2087\n",
      "Epoch 444/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1213 - val_loss: 645.7052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1064 - val_loss: 649.6287\n",
      "Epoch 446/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0823 - val_loss: 651.2388\n",
      "Epoch 447/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1235 - val_loss: 647.8687\n",
      "Epoch 448/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0960 - val_loss: 648.4977\n",
      "Epoch 449/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0833 - val_loss: 643.6844\n",
      "Epoch 450/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0832 - val_loss: 645.5978\n",
      "Epoch 451/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1188 - val_loss: 649.2823\n",
      "Epoch 452/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1077 - val_loss: 646.3214\n",
      "Epoch 453/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0697 - val_loss: 650.9755\n",
      "Epoch 454/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1083 - val_loss: 646.9042\n",
      "Epoch 455/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0526 - val_loss: 644.3501\n",
      "Epoch 456/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1255 - val_loss: 647.4473\n",
      "Epoch 457/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1124 - val_loss: 646.7526\n",
      "Epoch 458/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1057 - val_loss: 648.6064\n",
      "Epoch 459/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0715 - val_loss: 644.1310\n",
      "Epoch 460/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1109 - val_loss: 644.0971\n",
      "Epoch 461/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1295 - val_loss: 646.2346\n",
      "Epoch 462/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1036 - val_loss: 645.9797\n",
      "Epoch 463/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1105 - val_loss: 648.9360\n",
      "Epoch 464/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1044 - val_loss: 647.7184\n",
      "Epoch 465/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0567 - val_loss: 652.5706\n",
      "Epoch 466/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1505 - val_loss: 645.8931\n",
      "Epoch 467/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1077 - val_loss: 644.8970\n",
      "Epoch 468/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0110 - val_loss: 653.4719\n",
      "Epoch 469/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1207 - val_loss: 648.9545\n",
      "Epoch 470/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0608 - val_loss: 645.8876\n",
      "Epoch 471/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0919 - val_loss: 648.6830\n",
      "Epoch 472/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0553 - val_loss: 646.2761\n",
      "Epoch 473/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1038 - val_loss: 644.9257\n",
      "Epoch 474/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1006 - val_loss: 646.6517\n",
      "Epoch 475/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0543 - val_loss: 643.4577\n",
      "Epoch 476/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1012 - val_loss: 645.5871\n",
      "Epoch 477/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0895 - val_loss: 649.7930\n",
      "Epoch 478/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0646 - val_loss: 646.1658\n",
      "Epoch 479/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0820 - val_loss: 651.0590\n",
      "Epoch 480/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1258 - val_loss: 647.6274\n",
      "Epoch 481/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0903 - val_loss: 647.9002\n",
      "Epoch 482/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0016 - val_loss: 643.4006\n",
      "Epoch 483/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1151 - val_loss: 646.3525\n",
      "Epoch 484/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0677 - val_loss: 648.9625\n",
      "Epoch 485/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1154 - val_loss: 648.9482\n",
      "Epoch 486/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0902 - val_loss: 651.4433\n",
      "Epoch 487/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1414 - val_loss: 647.3943\n",
      "Epoch 488/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0893 - val_loss: 649.8931\n",
      "Epoch 489/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1305 - val_loss: 647.0881\n",
      "Epoch 490/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1038 - val_loss: 644.7340\n",
      "Epoch 491/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0366 - val_loss: 642.2644\n",
      "Epoch 492/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1126 - val_loss: 643.4809\n",
      "Epoch 493/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0725 - val_loss: 649.8832\n",
      "Epoch 494/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1279 - val_loss: 647.4565\n",
      "Epoch 495/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1144 - val_loss: 647.5464\n",
      "Epoch 496/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0678 - val_loss: 648.8848\n",
      "Epoch 497/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0989 - val_loss: 647.4319\n",
      "Epoch 498/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1095 - val_loss: 644.7616\n",
      "Epoch 499/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1178 - val_loss: 646.2389\n",
      "Epoch 500/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0494 - val_loss: 643.7895\n",
      "Epoch 501/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0852 - val_loss: 650.1391\n",
      "Epoch 502/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1201 - val_loss: 645.7962\n",
      "Epoch 503/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1032 - val_loss: 646.8613\n",
      "Epoch 504/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0838 - val_loss: 648.7677\n",
      "Epoch 505/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1029 - val_loss: 644.8837\n",
      "Epoch 506/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1078 - val_loss: 643.9336\n",
      "Epoch 507/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1084 - val_loss: 648.5321\n",
      "Epoch 508/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1345 - val_loss: 643.3640\n",
      "Epoch 509/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.1191 - val_loss: 646.6477\n",
      "Epoch 510/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 324.9444 - val_loss: 640.8051\n",
      "Epoch 511/1000\n",
      "320/320 [==============================] - 1s 4ms/step - loss: 325.1155 - val_loss: 646.9587\n",
      "Epoch 512/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1067 - val_loss: 647.4780\n",
      "Epoch 513/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0802 - val_loss: 648.5309\n",
      "Epoch 514/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1277 - val_loss: 645.4084\n",
      "Epoch 515/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1007 - val_loss: 648.5789\n",
      "Epoch 516/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0437 - val_loss: 652.5035\n",
      "Epoch 517/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0631 - val_loss: 648.0788\n",
      "Epoch 518/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.1018 - val_loss: 644.8863\n",
      "Epoch 519/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0994 - val_loss: 646.0751\n",
      "Epoch 520/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 324.9876 - val_loss: 653.8995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1306 - val_loss: 646.0298\n",
      "Epoch 522/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0797 - val_loss: 650.6956\n",
      "Epoch 523/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0793 - val_loss: 650.8806\n",
      "Epoch 524/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1220 - val_loss: 647.7037\n",
      "Epoch 525/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0740 - val_loss: 649.4999\n",
      "Epoch 526/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0870 - val_loss: 650.9057\n",
      "Epoch 527/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0547 - val_loss: 653.7485\n",
      "Epoch 528/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.1580 - val_loss: 648.5605\n",
      "Epoch 529/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0264 - val_loss: 653.7524\n",
      "Epoch 530/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0977 - val_loss: 648.0948\n",
      "Epoch 531/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0488 - val_loss: 648.8332\n",
      "Epoch 532/1000\n",
      "320/320 [==============================] - 3s 8ms/step - loss: 325.0510 - val_loss: 651.0038\n",
      "Epoch 533/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.0903 - val_loss: 645.3660\n",
      "Epoch 534/1000\n",
      "320/320 [==============================] - 2s 7ms/step - loss: 325.0452 - val_loss: 642.7829\n",
      "Epoch 535/1000\n",
      "320/320 [==============================] - 2s 8ms/step - loss: 325.1213 - val_loss: 648.5363\n",
      "Epoch 536/1000\n",
      "245/320 [=====================>........] - ETA: 0s - loss: 332.1351"
     ]
    }
   ],
   "source": [
    "rmse_list, mape_list = [], []\n",
    "for i in range(len(latitudes)):\n",
    "    rmse, mape = cross_validation(final_df, i)\n",
    "    rmse_list.append(rmse)\n",
    "    mape_list.append(mape)\n",
    "    print(f'{device_ids[i]} successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rmse, mean_mape = np.mean(rmse_list), np.mean(mape_list)          \n",
    "mean_rmse, mean_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712091c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05bdbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d89af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
