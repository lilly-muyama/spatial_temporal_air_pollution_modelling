{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148a9670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:50:48.416038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 21:50:48.485158: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-06 21:50:48.487163: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:50:48.487172: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-06 21:50:48.827077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:50:48.827106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-06 21:50:48.827109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from math import sqrt\n",
    "sys.path.append('../..')\n",
    "from modules import utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62b979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0afe661",
   "metadata": {},
   "source": [
    "#### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c1406a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pm2_5_calibrated_value</th>\n",
       "      <th>pm2_5_raw_value</th>\n",
       "      <th>pm10_raw_value</th>\n",
       "      <th>pm10_calibrated_value</th>\n",
       "      <th>site_id</th>\n",
       "      <th>device_number</th>\n",
       "      <th>device_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 01:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 03:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jinja Main Street, Jinja</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>Jinja</td>\n",
       "      <td>2021-09-01 04:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60d058c8048305120d2d6142</td>\n",
       "      <td>689753</td>\n",
       "      <td>aq_23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  site_name  latitude  longitude   city  \\\n",
       "0  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "1  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "2  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "3  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "4  Jinja Main Street, Jinja  0.437337  33.211051  Jinja   \n",
       "\n",
       "                  timestamp  pm2_5_calibrated_value  pm2_5_raw_value  \\\n",
       "0 2021-09-01 00:00:00+00:00                     NaN              NaN   \n",
       "1 2021-09-01 01:00:00+00:00                     NaN              NaN   \n",
       "2 2021-09-01 02:00:00+00:00                     NaN              NaN   \n",
       "3 2021-09-01 03:00:00+00:00                     NaN              NaN   \n",
       "4 2021-09-01 04:00:00+00:00                     NaN              NaN   \n",
       "\n",
       "   pm10_raw_value  pm10_calibrated_value                   site_id  \\\n",
       "0             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "1             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "2             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "3             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "4             NaN                    NaN  60d058c8048305120d2d6142   \n",
       "\n",
       "   device_number device_name  \n",
       "0         689753       aq_23  \n",
       "1         689753       aq_23  \n",
       "2         689753       aq_23  \n",
       "3         689753       aq_23  \n",
       "4         689753       aq_23  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jinja_df = pd.read_csv('../data/jinja_data.csv', parse_dates=['timestamp'])\n",
    "jinja_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8a2954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latitudes = jinja_df['latitude'].unique()\n",
    "longitudes = jinja_df['longitude'].unique()\n",
    "device_ids = jinja_df['device_number'].unique()\n",
    "len(latitudes), len(longitudes), len(device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07dea145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>pm2_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452909.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>12.2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452910.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>11.6507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452911.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>22.3980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>452912.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>17.4937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452913.0</td>\n",
       "      <td>0.437337</td>\n",
       "      <td>33.211051</td>\n",
       "      <td>25.1622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  latitude  longitude    pm2_5\n",
       "0  452909.0  0.437337  33.211051  12.2844\n",
       "1  452910.0  0.437337  33.211051  11.6507\n",
       "2  452911.0  0.437337  33.211051  22.3980\n",
       "3  452912.0  0.437337  33.211051  17.4937\n",
       "4  452913.0  0.437337  33.211051  25.1622"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "cols = ['timestamp', 'latitude', 'longitude', 'pm2_5_calibrated_value']\n",
    "for i, device_id in enumerate(device_ids):\n",
    "    device_df = utils.get_device_data(jinja_df, device_id, cols)\n",
    "    processed_df = utils.preprocessing(device_df)\n",
    "    final_df = pd.concat([final_df, processed_df])\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593969e",
   "metadata": {},
   "source": [
    "#### Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbae94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffnn(X_train, y_train, epochs=1000, optimizer='RMSProp', dropout=0.2):\n",
    "    model = tf.keras.Sequential() \n",
    "    model.add(Input(shape=(X_train.shape[1],), name='Input-Layer')) \n",
    "#     model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(128, activation='relu', name='Hidden-Layer1'))\n",
    "#     model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(32, activation='relu', name='Hidden-Layer2'))\n",
    "#     model.add(Dropout(rate=dropout))\n",
    "    model.add(Dense(1, activation='linear', name='Output-Layer')) \n",
    "\n",
    "    model.compile(optimizer=optimizer, # default='rmsprop', an algorithm to be used in backpropagation\n",
    "                  loss=tf.keras.losses.MeanSquaredError(),\n",
    "                 )\n",
    "    model.fit(X_train, \n",
    "          y_train,\n",
    "          batch_size=32,\n",
    "          epochs=epochs, # default=1, Number of epochs to train the model\n",
    "          callbacks=None,\n",
    "          validation_split=0.2, \n",
    "         )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "484a957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_data(X):\n",
    "#     scaler = MinMaxScaler()\n",
    "#     X_scaled = X.copy()\n",
    "#     X_scaled[:, 0] = scaler.fit_transform(X[:, 0].reshape(-1, 1)).flatten()\n",
    "#     return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2795c0b",
   "metadata": {},
   "source": [
    "#### delete from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b246fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# device_indices = final_df[final_df.latitude==latitudes[idx]].index\n",
    "# device_df = jinja_df[jinja_df.device_number == device_ids[idx]]\n",
    "# assert(len(device_indices) == len(device_df)-device_df.pm2_5_calibrated_value.isna().sum())\n",
    "# test_df = final_df.loc[device_indices]\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "113bbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([final_df, test_df]).drop_duplicates(keep=False)\n",
    "# assert(len(train_df.longitude.unique()) == len(longitudes)-1)\n",
    "# assert len(final_df) == len(test_df) + len(train_df)\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c4dae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train_df.iloc[:, 0:-1]\n",
    "# y_train = train_df.iloc[:, -1]\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)#.reshape(-1, 1)\n",
    "\n",
    "# X_test = test_df.iloc[:, 0:-1]\n",
    "# y_test = test_df.iloc[:, -1]\n",
    "# X_test, y_test = np.array(X_test), np.array(y_test)#.reshape(-1, 1)\n",
    "# X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b81083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98e539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = scale_data(X_train)\n",
    "# X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c01784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ffnn(X_train, y_train, 500, 'RMSProp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38805ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test) \n",
    "# y_pred.shape, y_test.reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46a83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(y_pred), np.mean(y_pred), np.max(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0aaefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b5965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = model.predict(X_train)\n",
    "# mean_squared_error(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03798db5",
   "metadata": {},
   "source": [
    "#### end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d0392e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(final_df, idx):\n",
    "    device_indices = final_df[final_df.latitude==latitudes[idx]].index\n",
    "    device_df = jinja_df[jinja_df.device_number == device_ids[idx]]\n",
    "    assert(len(device_indices) == len(device_df)-device_df.pm2_5_calibrated_value.isna().sum())\n",
    "    \n",
    "    test_df = final_df.loc[device_indices]\n",
    "    assert(len(test_df.longitude.unique()) == 1)\n",
    "    \n",
    "    train_df = pd.concat([final_df, test_df]).drop_duplicates(keep=False)\n",
    "    assert(len(train_df.longitude.unique()) == len(longitudes)-1)\n",
    "    assert len(final_df) == len(test_df) + len(train_df)\n",
    "    \n",
    "    X_train = train_df.iloc[:, 0:-1]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)#.reshape(-1, 1)\n",
    "#     X_train_scaled = scale_data(X_train)\n",
    "    \n",
    "    X_test = test_df.iloc[:, 0:-1]\n",
    "    y_test = test_df.iloc[:, -1]\n",
    "    X_test, y_test = np.array(X_test), np.array(y_test)#.reshape(-1, 1)\n",
    "#     X_test_scaled = scale_data(X_test)\n",
    "    \n",
    "    model = ffnn(X_train, y_train, optimizer='Adam', dropout=0.8)\n",
    "    y_pred = model.predict(X_test) \n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    return rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "945fe7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 21:50:50.523981: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-07-06 21:50:50.524003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: PL1207-PRO.paris.inria.fr\n",
      "2023-07-06 21:50:50.524006: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: PL1207-PRO.paris.inria.fr\n",
      "2023-07-06 21:50:50.524087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 525.125.6\n",
      "2023-07-06 21:50:50.524099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  525.116.04  Release Build  (dvs-builder@U16-I3-A16-3-3)  Thu Apr 27 18:11:06 UTC 2023\n",
      "GCC version:  gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) \n",
      "\"\n",
      "2023-07-06 21:50:50.524307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 1ms/step - loss: 14429381.0000 - val_loss: 695.1968\n",
      "Epoch 2/1000\n",
      "289/289 [==============================] - 0s 934us/step - loss: 440.1732 - val_loss: 630.7939\n",
      "Epoch 3/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 448.7069 - val_loss: 714.0650\n",
      "Epoch 4/1000\n",
      "289/289 [==============================] - 0s 837us/step - loss: 488.5003 - val_loss: 635.2147\n",
      "Epoch 5/1000\n",
      "289/289 [==============================] - 0s 710us/step - loss: 472.7919 - val_loss: 844.3975\n",
      "Epoch 6/1000\n",
      "289/289 [==============================] - 0s 750us/step - loss: 530.0157 - val_loss: 988.3795\n",
      "Epoch 7/1000\n",
      "289/289 [==============================] - 0s 806us/step - loss: 563.4109 - val_loss: 709.6088\n",
      "Epoch 8/1000\n",
      "289/289 [==============================] - 0s 752us/step - loss: 611.3159 - val_loss: 692.2584\n",
      "Epoch 9/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 601.9983 - val_loss: 868.5683\n",
      "Epoch 10/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 705.1030 - val_loss: 981.1019\n",
      "Epoch 11/1000\n",
      "289/289 [==============================] - 0s 915us/step - loss: 808.4721 - val_loss: 697.9484\n",
      "Epoch 12/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 1144.2581 - val_loss: 1022.1990\n",
      "Epoch 13/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 2490.0598 - val_loss: 808.0933\n",
      "Epoch 14/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 74505.6953 - val_loss: 11405.3447\n",
      "Epoch 15/1000\n",
      "289/289 [==============================] - 0s 894us/step - loss: 47751.2852 - val_loss: 117543.3125\n",
      "Epoch 16/1000\n",
      "289/289 [==============================] - 0s 801us/step - loss: 76324.4766 - val_loss: 1310.5264\n",
      "Epoch 17/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 70443.5000 - val_loss: 113783.6328\n",
      "Epoch 18/1000\n",
      "289/289 [==============================] - 0s 864us/step - loss: 80953.0547 - val_loss: 500102.0938\n",
      "Epoch 19/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 71139.7969 - val_loss: 75553.6172\n",
      "Epoch 20/1000\n",
      "289/289 [==============================] - 0s 722us/step - loss: 90546.3594 - val_loss: 4641.3789\n",
      "Epoch 21/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 54724.6953 - val_loss: 5784.8301\n",
      "Epoch 22/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 72941.5625 - val_loss: 111178.1953\n",
      "Epoch 23/1000\n",
      "289/289 [==============================] - 0s 897us/step - loss: 62827.7656 - val_loss: 67516.3750\n",
      "Epoch 24/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 61900.6836 - val_loss: 42756.0430\n",
      "Epoch 25/1000\n",
      "289/289 [==============================] - 0s 826us/step - loss: 79563.5547 - val_loss: 20054.3418\n",
      "Epoch 26/1000\n",
      "289/289 [==============================] - 0s 774us/step - loss: 49606.1602 - val_loss: 61311.2305\n",
      "Epoch 27/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 66096.2891 - val_loss: 12731.3359\n",
      "Epoch 28/1000\n",
      "289/289 [==============================] - 0s 714us/step - loss: 56882.0117 - val_loss: 13783.2480\n",
      "Epoch 29/1000\n",
      "289/289 [==============================] - 0s 718us/step - loss: 61552.6133 - val_loss: 2308.1270\n",
      "Epoch 30/1000\n",
      "289/289 [==============================] - 0s 833us/step - loss: 57075.8984 - val_loss: 64459.0820\n",
      "Epoch 31/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 54958.4688 - val_loss: 2845.2720\n",
      "Epoch 32/1000\n",
      "289/289 [==============================] - 0s 753us/step - loss: 58808.4922 - val_loss: 9741.8008\n",
      "Epoch 33/1000\n",
      "289/289 [==============================] - 0s 822us/step - loss: 57395.2930 - val_loss: 76011.7969\n",
      "Epoch 34/1000\n",
      "289/289 [==============================] - 0s 909us/step - loss: 52567.5430 - val_loss: 108511.1875\n",
      "Epoch 35/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 47095.0430 - val_loss: 354744.7188\n",
      "Epoch 36/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 52989.9766 - val_loss: 8545.5010\n",
      "Epoch 37/1000\n",
      "289/289 [==============================] - 0s 908us/step - loss: 49882.7266 - val_loss: 6441.6079\n",
      "Epoch 38/1000\n",
      "289/289 [==============================] - 0s 754us/step - loss: 63054.7812 - val_loss: 22087.3047\n",
      "Epoch 39/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 43396.4141 - val_loss: 8534.8389\n",
      "Epoch 40/1000\n",
      "289/289 [==============================] - 0s 868us/step - loss: 41881.6602 - val_loss: 25334.4570\n",
      "Epoch 41/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 47077.5508 - val_loss: 3260.0962\n",
      "Epoch 42/1000\n",
      "289/289 [==============================] - 0s 868us/step - loss: 42653.2109 - val_loss: 20690.6113\n",
      "Epoch 43/1000\n",
      "289/289 [==============================] - 0s 902us/step - loss: 47697.0547 - val_loss: 346152.2188\n",
      "Epoch 44/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 41923.2188 - val_loss: 3254.2708\n",
      "Epoch 45/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 46498.2461 - val_loss: 2663.4854\n",
      "Epoch 46/1000\n",
      "289/289 [==============================] - 0s 834us/step - loss: 48771.7734 - val_loss: 5141.3281\n",
      "Epoch 47/1000\n",
      "289/289 [==============================] - 0s 763us/step - loss: 38141.8750 - val_loss: 6778.6655\n",
      "Epoch 48/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 42505.3555 - val_loss: 13931.0830\n",
      "Epoch 49/1000\n",
      "289/289 [==============================] - 0s 768us/step - loss: 39894.1133 - val_loss: 629.4484\n",
      "Epoch 50/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 43764.2578 - val_loss: 116547.9453\n",
      "Epoch 51/1000\n",
      "289/289 [==============================] - 0s 928us/step - loss: 35626.6172 - val_loss: 786.7567\n",
      "Epoch 52/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 39673.8516 - val_loss: 10213.2041\n",
      "Epoch 53/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 46590.2969 - val_loss: 120400.5547\n",
      "Epoch 54/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 26357.2539 - val_loss: 24916.4414\n",
      "Epoch 55/1000\n",
      "289/289 [==============================] - 0s 728us/step - loss: 36485.2188 - val_loss: 5713.6343\n",
      "Epoch 56/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 37228.9219 - val_loss: 22822.1953\n",
      "Epoch 57/1000\n",
      "289/289 [==============================] - 0s 730us/step - loss: 32850.2344 - val_loss: 8399.8643\n",
      "Epoch 58/1000\n",
      "289/289 [==============================] - 0s 806us/step - loss: 37318.2461 - val_loss: 4092.3789\n",
      "Epoch 59/1000\n",
      "289/289 [==============================] - 0s 857us/step - loss: 36345.2656 - val_loss: 857.6076\n",
      "Epoch 60/1000\n",
      "289/289 [==============================] - 0s 872us/step - loss: 29007.9688 - val_loss: 1099.2152\n",
      "Epoch 61/1000\n",
      "289/289 [==============================] - 0s 742us/step - loss: 29352.6934 - val_loss: 18364.3281\n",
      "Epoch 62/1000\n",
      "289/289 [==============================] - 0s 918us/step - loss: 35835.1953 - val_loss: 13292.7627\n",
      "Epoch 63/1000\n",
      "289/289 [==============================] - 0s 868us/step - loss: 33978.9805 - val_loss: 18122.8320\n",
      "Epoch 64/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 27152.2148 - val_loss: 19118.4766\n",
      "Epoch 65/1000\n",
      "289/289 [==============================] - 0s 806us/step - loss: 30068.7910 - val_loss: 5682.9067\n",
      "Epoch 66/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 29515.3184 - val_loss: 30463.4668\n",
      "Epoch 67/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 28131.9004 - val_loss: 10897.0195\n",
      "Epoch 68/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 24979.8496 - val_loss: 17022.5762\n",
      "Epoch 69/1000\n",
      "289/289 [==============================] - 0s 892us/step - loss: 28325.3965 - val_loss: 6316.6279\n",
      "Epoch 70/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 36345.1250 - val_loss: 5356.5703\n",
      "Epoch 71/1000\n",
      "289/289 [==============================] - 0s 819us/step - loss: 16493.0840 - val_loss: 21999.4727\n",
      "Epoch 72/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 24698.9141 - val_loss: 3406.2654\n",
      "Epoch 73/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 25065.3672 - val_loss: 7819.0483\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 743us/step - loss: 27155.5254 - val_loss: 637.7709\n",
      "Epoch 75/1000\n",
      "289/289 [==============================] - 0s 798us/step - loss: 21555.9746 - val_loss: 15788.6992\n",
      "Epoch 76/1000\n",
      "289/289 [==============================] - 0s 724us/step - loss: 23540.2852 - val_loss: 2550.6472\n",
      "Epoch 77/1000\n",
      "289/289 [==============================] - 0s 916us/step - loss: 22780.8262 - val_loss: 31565.1992\n",
      "Epoch 78/1000\n",
      "289/289 [==============================] - 0s 747us/step - loss: 19399.4590 - val_loss: 18866.4238\n",
      "Epoch 79/1000\n",
      "289/289 [==============================] - 0s 720us/step - loss: 17685.8828 - val_loss: 89440.0781\n",
      "Epoch 80/1000\n",
      "289/289 [==============================] - 0s 716us/step - loss: 21029.6035 - val_loss: 6868.3315\n",
      "Epoch 81/1000\n",
      "289/289 [==============================] - 0s 777us/step - loss: 19354.2363 - val_loss: 22005.6074\n",
      "Epoch 82/1000\n",
      "289/289 [==============================] - 0s 939us/step - loss: 24778.8652 - val_loss: 9825.4619\n",
      "Epoch 83/1000\n",
      "289/289 [==============================] - 0s 812us/step - loss: 19229.8477 - val_loss: 1214.1903\n",
      "Epoch 84/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 16838.9902 - val_loss: 5804.4404\n",
      "Epoch 85/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 13456.3418 - val_loss: 1889.8245\n",
      "Epoch 86/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 19290.1973 - val_loss: 667.0338\n",
      "Epoch 87/1000\n",
      "289/289 [==============================] - 0s 847us/step - loss: 19740.2637 - val_loss: 925.1835\n",
      "Epoch 88/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 13800.5049 - val_loss: 18091.7344\n",
      "Epoch 89/1000\n",
      "289/289 [==============================] - 0s 956us/step - loss: 18569.2480 - val_loss: 1534.2593\n",
      "Epoch 90/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 14522.0205 - val_loss: 3397.7046\n",
      "Epoch 91/1000\n",
      "289/289 [==============================] - 0s 850us/step - loss: 15979.5479 - val_loss: 6669.3872\n",
      "Epoch 92/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 14755.2109 - val_loss: 1661.5638\n",
      "Epoch 93/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 16454.9609 - val_loss: 22579.3398\n",
      "Epoch 94/1000\n",
      "289/289 [==============================] - 0s 822us/step - loss: 15608.4404 - val_loss: 632.0159\n",
      "Epoch 95/1000\n",
      "289/289 [==============================] - 0s 874us/step - loss: 12956.2070 - val_loss: 13116.0566\n",
      "Epoch 96/1000\n",
      "289/289 [==============================] - 0s 900us/step - loss: 18400.3672 - val_loss: 16840.5801\n",
      "Epoch 97/1000\n",
      "289/289 [==============================] - 0s 779us/step - loss: 10848.3154 - val_loss: 3554.2395\n",
      "Epoch 98/1000\n",
      "289/289 [==============================] - 0s 873us/step - loss: 14963.9160 - val_loss: 16544.3340\n",
      "Epoch 99/1000\n",
      "289/289 [==============================] - 0s 874us/step - loss: 12446.3242 - val_loss: 8580.5068\n",
      "Epoch 100/1000\n",
      "289/289 [==============================] - 0s 823us/step - loss: 15531.3828 - val_loss: 32120.1250\n",
      "Epoch 101/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 12347.2627 - val_loss: 12053.9199\n",
      "Epoch 102/1000\n",
      "289/289 [==============================] - 0s 919us/step - loss: 13504.0049 - val_loss: 686.4132\n",
      "Epoch 103/1000\n",
      "289/289 [==============================] - 0s 781us/step - loss: 12822.9570 - val_loss: 13112.1562\n",
      "Epoch 104/1000\n",
      "289/289 [==============================] - 0s 844us/step - loss: 13366.5107 - val_loss: 5802.1216\n",
      "Epoch 105/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 11351.2363 - val_loss: 8522.1797\n",
      "Epoch 106/1000\n",
      "289/289 [==============================] - 0s 882us/step - loss: 12374.2871 - val_loss: 7569.2104\n",
      "Epoch 107/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 11801.4092 - val_loss: 1097.1799\n",
      "Epoch 108/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 11005.7871 - val_loss: 634.6411\n",
      "Epoch 109/1000\n",
      "289/289 [==============================] - 0s 811us/step - loss: 11666.7852 - val_loss: 9427.8760\n",
      "Epoch 110/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 10352.2695 - val_loss: 7755.4067\n",
      "Epoch 111/1000\n",
      "289/289 [==============================] - 0s 774us/step - loss: 8501.0098 - val_loss: 1162.0011\n",
      "Epoch 112/1000\n",
      "289/289 [==============================] - 0s 846us/step - loss: 9965.0430 - val_loss: 2985.7300\n",
      "Epoch 113/1000\n",
      "289/289 [==============================] - 0s 950us/step - loss: 10763.8408 - val_loss: 27251.4941\n",
      "Epoch 114/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 9976.5850 - val_loss: 9203.4951\n",
      "Epoch 115/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 205802.2344 - val_loss: 659.8383\n",
      "Epoch 116/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 526.6123 - val_loss: 782.1684\n",
      "Epoch 117/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 659.3121 - val_loss: 955.7882\n",
      "Epoch 118/1000\n",
      "289/289 [==============================] - 0s 768us/step - loss: 768.3956 - val_loss: 1011.3933\n",
      "Epoch 119/1000\n",
      "289/289 [==============================] - 0s 672us/step - loss: 738.2620 - val_loss: 764.6636\n",
      "Epoch 120/1000\n",
      "289/289 [==============================] - 0s 755us/step - loss: 1007.4005 - val_loss: 687.3673\n",
      "Epoch 121/1000\n",
      "289/289 [==============================] - 0s 925us/step - loss: 1177.5083 - val_loss: 723.0703\n",
      "Epoch 122/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 1801.5879 - val_loss: 1108.0465\n",
      "Epoch 123/1000\n",
      "289/289 [==============================] - 0s 805us/step - loss: 5966.6616 - val_loss: 29604.4355\n",
      "Epoch 124/1000\n",
      "289/289 [==============================] - 0s 930us/step - loss: 8858.5918 - val_loss: 1966.4344\n",
      "Epoch 125/1000\n",
      "289/289 [==============================] - 0s 737us/step - loss: 9408.1240 - val_loss: 12415.9492\n",
      "Epoch 126/1000\n",
      "289/289 [==============================] - 0s 869us/step - loss: 6766.6177 - val_loss: 61249.7656\n",
      "Epoch 127/1000\n",
      "289/289 [==============================] - 0s 983us/step - loss: 8001.3926 - val_loss: 24715.9473\n",
      "Epoch 128/1000\n",
      "289/289 [==============================] - 0s 726us/step - loss: 6449.3140 - val_loss: 851.1068\n",
      "Epoch 129/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 9729.3701 - val_loss: 4266.0332\n",
      "Epoch 130/1000\n",
      "289/289 [==============================] - 0s 848us/step - loss: 5263.5361 - val_loss: 4491.6245\n",
      "Epoch 131/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 8479.2256 - val_loss: 1066.4250\n",
      "Epoch 132/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 6634.7100 - val_loss: 7581.9482\n",
      "Epoch 133/1000\n",
      "289/289 [==============================] - 0s 856us/step - loss: 7908.7563 - val_loss: 5808.6562\n",
      "Epoch 134/1000\n",
      "289/289 [==============================] - 0s 711us/step - loss: 5960.8052 - val_loss: 1700.6864\n",
      "Epoch 135/1000\n",
      "289/289 [==============================] - 0s 852us/step - loss: 7799.7974 - val_loss: 1837.8749\n",
      "Epoch 136/1000\n",
      "289/289 [==============================] - 0s 641us/step - loss: 6958.9604 - val_loss: 2789.8167\n",
      "Epoch 137/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 5796.7812 - val_loss: 2276.7036\n",
      "Epoch 138/1000\n",
      "289/289 [==============================] - 0s 787us/step - loss: 7163.6787 - val_loss: 635.1801\n",
      "Epoch 139/1000\n",
      "289/289 [==============================] - 0s 899us/step - loss: 5381.9761 - val_loss: 833.0428\n",
      "Epoch 140/1000\n",
      "289/289 [==============================] - 0s 781us/step - loss: 6521.8477 - val_loss: 12816.9736\n",
      "Epoch 141/1000\n",
      "289/289 [==============================] - 0s 853us/step - loss: 6974.7246 - val_loss: 1764.3971\n",
      "Epoch 142/1000\n",
      "289/289 [==============================] - 0s 838us/step - loss: 5318.8086 - val_loss: 1802.9662\n",
      "Epoch 143/1000\n",
      "289/289 [==============================] - 0s 747us/step - loss: 6340.3345 - val_loss: 1847.8029\n",
      "Epoch 144/1000\n",
      "289/289 [==============================] - 0s 658us/step - loss: 5888.7026 - val_loss: 2199.2083\n",
      "Epoch 145/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 5517.2026 - val_loss: 3810.1360\n",
      "Epoch 146/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 7121.8442 - val_loss: 974.3615\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 699us/step - loss: 4607.2720 - val_loss: 6634.4575\n",
      "Epoch 148/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 5595.3608 - val_loss: 5961.6587\n",
      "Epoch 149/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 27815.9180 - val_loss: 2171.8884\n",
      "Epoch 150/1000\n",
      "289/289 [==============================] - 0s 908us/step - loss: 839.6008 - val_loss: 649.4758\n",
      "Epoch 151/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 1331.8673 - val_loss: 626.0139\n",
      "Epoch 152/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 1933.7330 - val_loss: 15161.0801\n",
      "Epoch 153/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 5215.1392 - val_loss: 759.6946\n",
      "Epoch 154/1000\n",
      "289/289 [==============================] - 0s 734us/step - loss: 3638.9631 - val_loss: 25198.9844\n",
      "Epoch 155/1000\n",
      "289/289 [==============================] - 0s 725us/step - loss: 5058.0923 - val_loss: 7355.1499\n",
      "Epoch 156/1000\n",
      "289/289 [==============================] - 0s 950us/step - loss: 5500.6260 - val_loss: 13223.8018\n",
      "Epoch 157/1000\n",
      "289/289 [==============================] - 0s 835us/step - loss: 3822.2932 - val_loss: 11422.1523\n",
      "Epoch 158/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 5734.4897 - val_loss: 13565.1875\n",
      "Epoch 159/1000\n",
      "289/289 [==============================] - 0s 855us/step - loss: 3890.5271 - val_loss: 7782.5933\n",
      "Epoch 160/1000\n",
      "289/289 [==============================] - 0s 780us/step - loss: 3833.1265 - val_loss: 968.7737\n",
      "Epoch 161/1000\n",
      "289/289 [==============================] - 0s 715us/step - loss: 4258.2983 - val_loss: 3439.8135\n",
      "Epoch 162/1000\n",
      "289/289 [==============================] - 0s 742us/step - loss: 4717.7119 - val_loss: 7388.3262\n",
      "Epoch 163/1000\n",
      "289/289 [==============================] - 0s 808us/step - loss: 3201.7993 - val_loss: 723.6771\n",
      "Epoch 164/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 319432.1250 - val_loss: 662.0074\n",
      "Epoch 165/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 486.6591 - val_loss: 856.8799\n",
      "Epoch 166/1000\n",
      "289/289 [==============================] - 0s 682us/step - loss: 454.0922 - val_loss: 715.4400\n",
      "Epoch 167/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 484.9881 - val_loss: 626.3362\n",
      "Epoch 168/1000\n",
      "289/289 [==============================] - 0s 688us/step - loss: 494.8929 - val_loss: 727.5046\n",
      "Epoch 169/1000\n",
      "289/289 [==============================] - 0s 711us/step - loss: 510.0639 - val_loss: 647.9034\n",
      "Epoch 170/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 567.0624 - val_loss: 987.8080\n",
      "Epoch 171/1000\n",
      "289/289 [==============================] - 0s 725us/step - loss: 640.7410 - val_loss: 637.3008\n",
      "Epoch 172/1000\n",
      "289/289 [==============================] - 0s 652us/step - loss: 647.9424 - val_loss: 1081.8591\n",
      "Epoch 173/1000\n",
      "289/289 [==============================] - 0s 707us/step - loss: 717.8513 - val_loss: 1027.8352\n",
      "Epoch 174/1000\n",
      "289/289 [==============================] - 0s 783us/step - loss: 729.6785 - val_loss: 2109.3105\n",
      "Epoch 175/1000\n",
      "289/289 [==============================] - 0s 764us/step - loss: 1046.4950 - val_loss: 641.6901\n",
      "Epoch 176/1000\n",
      "289/289 [==============================] - 0s 721us/step - loss: 1306.7750 - val_loss: 2736.7793\n",
      "Epoch 177/1000\n",
      "289/289 [==============================] - 0s 704us/step - loss: 2422.7402 - val_loss: 12184.5625\n",
      "Epoch 178/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 2789.6692 - val_loss: 1401.9751\n",
      "Epoch 179/1000\n",
      "289/289 [==============================] - 0s 856us/step - loss: 3081.2991 - val_loss: 16128.1035\n",
      "Epoch 180/1000\n",
      "289/289 [==============================] - 0s 933us/step - loss: 2782.6672 - val_loss: 2336.3420\n",
      "Epoch 181/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 3029.5330 - val_loss: 789.5815\n",
      "Epoch 182/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 2758.0022 - val_loss: 4595.3052\n",
      "Epoch 183/1000\n",
      "289/289 [==============================] - 0s 953us/step - loss: 3287.2996 - val_loss: 1170.6085\n",
      "Epoch 184/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 2466.3440 - val_loss: 918.4912\n",
      "Epoch 185/1000\n",
      "289/289 [==============================] - 0s 1000us/step - loss: 2382.6750 - val_loss: 11088.9199\n",
      "Epoch 186/1000\n",
      "289/289 [==============================] - 0s 688us/step - loss: 3075.1511 - val_loss: 628.1213\n",
      "Epoch 187/1000\n",
      "289/289 [==============================] - 0s 670us/step - loss: 2249.0886 - val_loss: 729.5115\n",
      "Epoch 188/1000\n",
      "289/289 [==============================] - 0s 658us/step - loss: 2262.7891 - val_loss: 2691.2214\n",
      "Epoch 189/1000\n",
      "289/289 [==============================] - 0s 950us/step - loss: 3154.5134 - val_loss: 3239.0242\n",
      "Epoch 190/1000\n",
      "289/289 [==============================] - 0s 754us/step - loss: 2024.5139 - val_loss: 2450.3860\n",
      "Epoch 191/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 2085.7241 - val_loss: 6169.8560\n",
      "Epoch 192/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 2626.7334 - val_loss: 1037.4155\n",
      "Epoch 193/1000\n",
      "289/289 [==============================] - 0s 712us/step - loss: 3424.0081 - val_loss: 1963.6089\n",
      "Epoch 194/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 1422.6210 - val_loss: 671.5779\n",
      "Epoch 195/1000\n",
      "289/289 [==============================] - 0s 883us/step - loss: 2072.5027 - val_loss: 663.9141\n",
      "Epoch 196/1000\n",
      "289/289 [==============================] - 0s 765us/step - loss: 1791.4026 - val_loss: 3372.6021\n",
      "Epoch 197/1000\n",
      "289/289 [==============================] - 0s 674us/step - loss: 2814.0461 - val_loss: 9269.4023\n",
      "Epoch 198/1000\n",
      "289/289 [==============================] - 0s 752us/step - loss: 1440.1306 - val_loss: 1095.5104\n",
      "Epoch 199/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 1989.1941 - val_loss: 6599.1094\n",
      "Epoch 200/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 2584.7402 - val_loss: 743.7076\n",
      "Epoch 201/1000\n",
      "289/289 [==============================] - 0s 943us/step - loss: 2209.3242 - val_loss: 682.1219\n",
      "Epoch 202/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 2148.8347 - val_loss: 750.8138\n",
      "Epoch 203/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 1356.2491 - val_loss: 693.8826\n",
      "Epoch 204/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 2193.7817 - val_loss: 5956.0605\n",
      "Epoch 205/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 1691.9762 - val_loss: 814.1996\n",
      "Epoch 206/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 2310.0303 - val_loss: 1677.8016\n",
      "Epoch 207/1000\n",
      "289/289 [==============================] - 0s 822us/step - loss: 1572.9890 - val_loss: 4363.8511\n",
      "Epoch 208/1000\n",
      "289/289 [==============================] - 0s 677us/step - loss: 2265.9888 - val_loss: 2598.6096\n",
      "Epoch 209/1000\n",
      "289/289 [==============================] - 0s 666us/step - loss: 1127.4602 - val_loss: 1328.5835\n",
      "Epoch 210/1000\n",
      "289/289 [==============================] - 0s 684us/step - loss: 1480.2236 - val_loss: 1049.8015\n",
      "Epoch 211/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 90262.2109 - val_loss: 730.3693\n",
      "Epoch 212/1000\n",
      "289/289 [==============================] - 0s 684us/step - loss: 463.7682 - val_loss: 628.5188\n",
      "Epoch 213/1000\n",
      "289/289 [==============================] - 0s 650us/step - loss: 515.5731 - val_loss: 627.4954\n",
      "Epoch 214/1000\n",
      "289/289 [==============================] - 0s 642us/step - loss: 501.5655 - val_loss: 714.9620\n",
      "Epoch 215/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 482.8663 - val_loss: 764.7521\n",
      "Epoch 216/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 554.0499 - val_loss: 712.6649\n",
      "Epoch 217/1000\n",
      "289/289 [==============================] - 0s 798us/step - loss: 536.1084 - val_loss: 936.6159\n",
      "Epoch 218/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 581.5566 - val_loss: 946.0728\n",
      "Epoch 219/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 697.6838 - val_loss: 1046.1262\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 704us/step - loss: 797.3736 - val_loss: 653.6112\n",
      "Epoch 221/1000\n",
      "289/289 [==============================] - 0s 710us/step - loss: 826.3627 - val_loss: 722.7275\n",
      "Epoch 222/1000\n",
      "289/289 [==============================] - 0s 833us/step - loss: 921.1188 - val_loss: 628.2672\n",
      "Epoch 223/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 1260.9399 - val_loss: 816.9923\n",
      "Epoch 224/1000\n",
      "289/289 [==============================] - 0s 726us/step - loss: 1004.6031 - val_loss: 691.4389\n",
      "Epoch 225/1000\n",
      "289/289 [==============================] - 0s 839us/step - loss: 1516.5729 - val_loss: 1369.9880\n",
      "Epoch 226/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 1474.6846 - val_loss: 2639.3694\n",
      "Epoch 227/1000\n",
      "289/289 [==============================] - 0s 854us/step - loss: 1296.6978 - val_loss: 1385.8105\n",
      "Epoch 228/1000\n",
      "289/289 [==============================] - 0s 714us/step - loss: 1455.3848 - val_loss: 848.1095\n",
      "Epoch 229/1000\n",
      "289/289 [==============================] - 0s 746us/step - loss: 1445.4028 - val_loss: 3342.3835\n",
      "Epoch 230/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 1110.9386 - val_loss: 804.9417\n",
      "Epoch 231/1000\n",
      "289/289 [==============================] - 0s 698us/step - loss: 1590.5616 - val_loss: 970.9254\n",
      "Epoch 232/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 1220.9230 - val_loss: 630.1780\n",
      "Epoch 233/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 993.7370 - val_loss: 698.1259\n",
      "Epoch 234/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 19415.4355 - val_loss: 751.4908\n",
      "Epoch 235/1000\n",
      "289/289 [==============================] - 0s 991us/step - loss: 538.3055 - val_loss: 627.1092\n",
      "Epoch 236/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 489.0285 - val_loss: 625.9850\n",
      "Epoch 237/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 580.5547 - val_loss: 936.7304\n",
      "Epoch 238/1000\n",
      "289/289 [==============================] - 0s 731us/step - loss: 576.5883 - val_loss: 639.2263\n",
      "Epoch 239/1000\n",
      "289/289 [==============================] - 0s 712us/step - loss: 606.5898 - val_loss: 651.0336\n",
      "Epoch 240/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 764.3332 - val_loss: 1072.5043\n",
      "Epoch 241/1000\n",
      "289/289 [==============================] - 0s 903us/step - loss: 928.3985 - val_loss: 1455.1682\n",
      "Epoch 242/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 1303.5258 - val_loss: 2023.7212\n",
      "Epoch 243/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 930.8627 - val_loss: 630.5566\n",
      "Epoch 244/1000\n",
      "289/289 [==============================] - 0s 665us/step - loss: 1209.6506 - val_loss: 626.3677\n",
      "Epoch 245/1000\n",
      "289/289 [==============================] - 0s 684us/step - loss: 1065.8179 - val_loss: 647.7884\n",
      "Epoch 246/1000\n",
      "289/289 [==============================] - 0s 791us/step - loss: 873.9150 - val_loss: 1453.0632\n",
      "Epoch 247/1000\n",
      "289/289 [==============================] - 0s 845us/step - loss: 1250.0240 - val_loss: 703.0228\n",
      "Epoch 248/1000\n",
      "289/289 [==============================] - 0s 723us/step - loss: 1027.1035 - val_loss: 1051.8665\n",
      "Epoch 249/1000\n",
      "289/289 [==============================] - 0s 719us/step - loss: 1180.2604 - val_loss: 2087.1594\n",
      "Epoch 250/1000\n",
      "289/289 [==============================] - 0s 765us/step - loss: 925.0219 - val_loss: 1396.1322\n",
      "Epoch 251/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 1150.6279 - val_loss: 882.3874\n",
      "Epoch 252/1000\n",
      "289/289 [==============================] - 0s 921us/step - loss: 946.8242 - val_loss: 937.5350\n",
      "Epoch 253/1000\n",
      "289/289 [==============================] - 0s 852us/step - loss: 933.8223 - val_loss: 1349.0618\n",
      "Epoch 254/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 1026.5598 - val_loss: 766.4175\n",
      "Epoch 255/1000\n",
      "289/289 [==============================] - 0s 786us/step - loss: 1070.5458 - val_loss: 635.8525\n",
      "Epoch 256/1000\n",
      "289/289 [==============================] - 0s 790us/step - loss: 841.2557 - val_loss: 1611.0062\n",
      "Epoch 257/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 11947.2158 - val_loss: 1048.5710\n",
      "Epoch 258/1000\n",
      "289/289 [==============================] - 0s 923us/step - loss: 523.7990 - val_loss: 635.1567\n",
      "Epoch 259/1000\n",
      "289/289 [==============================] - 0s 884us/step - loss: 562.2890 - val_loss: 1467.8320\n",
      "Epoch 260/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 569.3179 - val_loss: 699.0903\n",
      "Epoch 261/1000\n",
      "289/289 [==============================] - 0s 834us/step - loss: 627.6619 - val_loss: 793.6158\n",
      "Epoch 262/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 561.8879 - val_loss: 701.9414\n",
      "Epoch 263/1000\n",
      "289/289 [==============================] - 0s 819us/step - loss: 579.1851 - val_loss: 1096.3195\n",
      "Epoch 264/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 728.4243 - val_loss: 637.6469\n",
      "Epoch 265/1000\n",
      "289/289 [==============================] - 0s 825us/step - loss: 686.6098 - val_loss: 751.2037\n",
      "Epoch 266/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 613.9811 - val_loss: 734.7488\n",
      "Epoch 267/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 763.9233 - val_loss: 1373.5946\n",
      "Epoch 268/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 1056.2992 - val_loss: 1031.4291\n",
      "Epoch 269/1000\n",
      "289/289 [==============================] - 0s 888us/step - loss: 832.7785 - val_loss: 2155.7961\n",
      "Epoch 270/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 741.3344 - val_loss: 1459.2554\n",
      "Epoch 271/1000\n",
      "289/289 [==============================] - 0s 723us/step - loss: 678.6208 - val_loss: 627.2473\n",
      "Epoch 272/1000\n",
      "289/289 [==============================] - 0s 708us/step - loss: 882.6956 - val_loss: 628.4012\n",
      "Epoch 273/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 672.1538 - val_loss: 655.5146\n",
      "Epoch 274/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 808.7679 - val_loss: 1265.4246\n",
      "Epoch 275/1000\n",
      "289/289 [==============================] - 0s 714us/step - loss: 665.7128 - val_loss: 2134.9622\n",
      "Epoch 276/1000\n",
      "289/289 [==============================] - 0s 780us/step - loss: 772.8752 - val_loss: 626.5994\n",
      "Epoch 277/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 660.1489 - val_loss: 648.3877\n",
      "Epoch 278/1000\n",
      "289/289 [==============================] - 0s 753us/step - loss: 723.5007 - val_loss: 2128.4775\n",
      "Epoch 279/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 704.1440 - val_loss: 995.6459\n",
      "Epoch 280/1000\n",
      "289/289 [==============================] - 0s 896us/step - loss: 749.4648 - val_loss: 692.4886\n",
      "Epoch 281/1000\n",
      "289/289 [==============================] - 0s 711us/step - loss: 674.7089 - val_loss: 698.4285\n",
      "Epoch 282/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 747.7440 - val_loss: 676.6039\n",
      "Epoch 283/1000\n",
      "289/289 [==============================] - 0s 823us/step - loss: 695.2889 - val_loss: 628.4849\n",
      "Epoch 284/1000\n",
      "289/289 [==============================] - 0s 799us/step - loss: 643.8119 - val_loss: 794.2885\n",
      "Epoch 285/1000\n",
      "289/289 [==============================] - 0s 718us/step - loss: 620.1610 - val_loss: 949.3607\n",
      "Epoch 286/1000\n",
      "289/289 [==============================] - 0s 778us/step - loss: 590.6560 - val_loss: 644.7144\n",
      "Epoch 287/1000\n",
      "289/289 [==============================] - 0s 763us/step - loss: 567.2565 - val_loss: 665.0885\n",
      "Epoch 288/1000\n",
      "289/289 [==============================] - 0s 737us/step - loss: 610.5109 - val_loss: 637.0743\n",
      "Epoch 289/1000\n",
      "289/289 [==============================] - 0s 694us/step - loss: 598.8334 - val_loss: 663.2125\n",
      "Epoch 290/1000\n",
      "289/289 [==============================] - 0s 931us/step - loss: 609.8301 - val_loss: 1094.1990\n",
      "Epoch 291/1000\n",
      "289/289 [==============================] - 0s 859us/step - loss: 655.9387 - val_loss: 1977.1400\n",
      "Epoch 292/1000\n",
      "289/289 [==============================] - 0s 840us/step - loss: 592.7953 - val_loss: 1196.2814\n",
      "Epoch 293/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 566.0752 - val_loss: 633.8699\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 999us/step - loss: 584.2621 - val_loss: 763.5949\n",
      "Epoch 295/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 601.5676 - val_loss: 827.7820\n",
      "Epoch 296/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 540.7006 - val_loss: 900.6365\n",
      "Epoch 297/1000\n",
      "289/289 [==============================] - 0s 663us/step - loss: 535.7651 - val_loss: 695.6960\n",
      "Epoch 298/1000\n",
      "289/289 [==============================] - 0s 744us/step - loss: 572.5806 - val_loss: 666.0480\n",
      "Epoch 299/1000\n",
      "289/289 [==============================] - 0s 801us/step - loss: 541.1354 - val_loss: 914.0098\n",
      "Epoch 300/1000\n",
      "289/289 [==============================] - 0s 750us/step - loss: 572.5159 - val_loss: 1093.4408\n",
      "Epoch 301/1000\n",
      "289/289 [==============================] - 0s 929us/step - loss: 502.4918 - val_loss: 633.9722\n",
      "Epoch 302/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 528.7831 - val_loss: 692.1944\n",
      "Epoch 303/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 543.3134 - val_loss: 897.0604\n",
      "Epoch 304/1000\n",
      "289/289 [==============================] - 0s 900us/step - loss: 528.5704 - val_loss: 646.5724\n",
      "Epoch 305/1000\n",
      "289/289 [==============================] - 0s 846us/step - loss: 510.6233 - val_loss: 629.6414\n",
      "Epoch 306/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 483.6013 - val_loss: 1112.0542\n",
      "Epoch 307/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 480.2064 - val_loss: 646.9201\n",
      "Epoch 308/1000\n",
      "289/289 [==============================] - 0s 786us/step - loss: 486.2819 - val_loss: 671.2645\n",
      "Epoch 309/1000\n",
      "289/289 [==============================] - 0s 691us/step - loss: 442.7406 - val_loss: 625.9915\n",
      "Epoch 310/1000\n",
      "289/289 [==============================] - 0s 878us/step - loss: 427.7765 - val_loss: 710.5262\n",
      "Epoch 311/1000\n",
      "289/289 [==============================] - 0s 953us/step - loss: 424.2244 - val_loss: 636.9248\n",
      "Epoch 312/1000\n",
      "289/289 [==============================] - 0s 914us/step - loss: 422.1671 - val_loss: 659.7159\n",
      "Epoch 313/1000\n",
      "289/289 [==============================] - 0s 808us/step - loss: 420.1449 - val_loss: 684.1742\n",
      "Epoch 314/1000\n",
      "289/289 [==============================] - 0s 734us/step - loss: 415.4941 - val_loss: 655.7723\n",
      "Epoch 315/1000\n",
      "289/289 [==============================] - 0s 886us/step - loss: 416.8199 - val_loss: 734.8694\n",
      "Epoch 316/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 419.9964 - val_loss: 657.9692\n",
      "Epoch 317/1000\n",
      "289/289 [==============================] - 0s 880us/step - loss: 420.2707 - val_loss: 650.3890\n",
      "Epoch 318/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 417.0378 - val_loss: 697.0886\n",
      "Epoch 319/1000\n",
      "289/289 [==============================] - 0s 717us/step - loss: 415.5810 - val_loss: 677.5389\n",
      "Epoch 320/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 417.5772 - val_loss: 663.2696\n",
      "Epoch 321/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 419.2898 - val_loss: 635.2271\n",
      "Epoch 322/1000\n",
      "289/289 [==============================] - 0s 696us/step - loss: 421.7946 - val_loss: 748.9282\n",
      "Epoch 323/1000\n",
      "289/289 [==============================] - 0s 898us/step - loss: 420.8654 - val_loss: 632.5295\n",
      "Epoch 324/1000\n",
      "289/289 [==============================] - 0s 808us/step - loss: 418.6751 - val_loss: 685.3156\n",
      "Epoch 325/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 426.1541 - val_loss: 722.3234\n",
      "Epoch 326/1000\n",
      "289/289 [==============================] - 0s 904us/step - loss: 423.3481 - val_loss: 728.6723\n",
      "Epoch 327/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 420.7589 - val_loss: 686.1328\n",
      "Epoch 328/1000\n",
      "289/289 [==============================] - 0s 683us/step - loss: 422.2628 - val_loss: 633.7113\n",
      "Epoch 329/1000\n",
      "289/289 [==============================] - 0s 749us/step - loss: 421.6031 - val_loss: 754.4042\n",
      "Epoch 330/1000\n",
      "289/289 [==============================] - 0s 685us/step - loss: 423.9356 - val_loss: 693.6908\n",
      "Epoch 331/1000\n",
      "289/289 [==============================] - 0s 889us/step - loss: 418.6871 - val_loss: 632.3323\n",
      "Epoch 332/1000\n",
      "289/289 [==============================] - 0s 713us/step - loss: 424.5051 - val_loss: 651.7319\n",
      "Epoch 333/1000\n",
      "289/289 [==============================] - 0s 810us/step - loss: 423.8818 - val_loss: 638.1367\n",
      "Epoch 334/1000\n",
      "289/289 [==============================] - 0s 786us/step - loss: 427.7045 - val_loss: 635.3998\n",
      "Epoch 335/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 421.8907 - val_loss: 695.5735\n",
      "Epoch 336/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 422.0265 - val_loss: 677.8118\n",
      "Epoch 337/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 429.0346 - val_loss: 793.9335\n",
      "Epoch 338/1000\n",
      "289/289 [==============================] - 0s 869us/step - loss: 422.1884 - val_loss: 733.7055\n",
      "Epoch 339/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 427.6880 - val_loss: 712.7523\n",
      "Epoch 340/1000\n",
      "289/289 [==============================] - 0s 682us/step - loss: 426.3867 - val_loss: 705.3251\n",
      "Epoch 341/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 426.9856 - val_loss: 642.4064\n",
      "Epoch 342/1000\n",
      "289/289 [==============================] - 0s 730us/step - loss: 421.8125 - val_loss: 669.8204\n",
      "Epoch 343/1000\n",
      "289/289 [==============================] - 0s 835us/step - loss: 420.1212 - val_loss: 635.7054\n",
      "Epoch 344/1000\n",
      "289/289 [==============================] - 0s 864us/step - loss: 423.8971 - val_loss: 685.8328\n",
      "Epoch 345/1000\n",
      "289/289 [==============================] - 0s 746us/step - loss: 422.0726 - val_loss: 796.3979\n",
      "Epoch 346/1000\n",
      "289/289 [==============================] - 0s 783us/step - loss: 428.6273 - val_loss: 713.5790\n",
      "Epoch 347/1000\n",
      "289/289 [==============================] - 0s 691us/step - loss: 424.4275 - val_loss: 674.9881\n",
      "Epoch 348/1000\n",
      "289/289 [==============================] - 0s 876us/step - loss: 423.3898 - val_loss: 727.4349\n",
      "Epoch 349/1000\n",
      "289/289 [==============================] - 0s 731us/step - loss: 426.4102 - val_loss: 724.7068\n",
      "Epoch 350/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 418.6174 - val_loss: 735.1177\n",
      "Epoch 351/1000\n",
      "289/289 [==============================] - 0s 720us/step - loss: 419.7708 - val_loss: 689.8670\n",
      "Epoch 352/1000\n",
      "289/289 [==============================] - 0s 892us/step - loss: 422.7110 - val_loss: 641.6008\n",
      "Epoch 353/1000\n",
      "289/289 [==============================] - 0s 830us/step - loss: 425.6685 - val_loss: 739.2458\n",
      "Epoch 354/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 419.8000 - val_loss: 665.7795\n",
      "Epoch 355/1000\n",
      "289/289 [==============================] - 0s 654us/step - loss: 418.7082 - val_loss: 660.7458\n",
      "Epoch 356/1000\n",
      "289/289 [==============================] - 0s 752us/step - loss: 420.9299 - val_loss: 659.9781\n",
      "Epoch 357/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 427.4442 - val_loss: 630.9954\n",
      "Epoch 358/1000\n",
      "289/289 [==============================] - 0s 750us/step - loss: 428.8425 - val_loss: 720.7338\n",
      "Epoch 359/1000\n",
      "289/289 [==============================] - 0s 948us/step - loss: 427.2635 - val_loss: 792.6577\n",
      "Epoch 360/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 426.3459 - val_loss: 677.6953\n",
      "Epoch 361/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 5268.3882 - val_loss: 1540.2955\n",
      "Epoch 362/1000\n",
      "289/289 [==============================] - 0s 682us/step - loss: 963.7295 - val_loss: 1528.6041\n",
      "Epoch 363/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 954.3454 - val_loss: 1516.2135\n",
      "Epoch 364/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 944.4683 - val_loss: 1503.1975\n",
      "Epoch 365/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 934.1706 - val_loss: 1489.6932\n",
      "Epoch 366/1000\n",
      "289/289 [==============================] - 0s 722us/step - loss: 923.5442 - val_loss: 1475.7611\n",
      "Epoch 367/1000\n",
      "289/289 [==============================] - 0s 871us/step - loss: 912.6686 - val_loss: 1461.5330\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 752us/step - loss: 901.6155 - val_loss: 1447.0682\n",
      "Epoch 369/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 890.4498 - val_loss: 1432.4662\n",
      "Epoch 370/1000\n",
      "289/289 [==============================] - 0s 732us/step - loss: 879.2330 - val_loss: 1417.8032\n",
      "Epoch 371/1000\n",
      "289/289 [==============================] - 0s 888us/step - loss: 868.0050 - val_loss: 1403.0726\n",
      "Epoch 372/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 856.8105 - val_loss: 1388.4003\n",
      "Epoch 373/1000\n",
      "289/289 [==============================] - 0s 741us/step - loss: 845.6729 - val_loss: 1373.7759\n",
      "Epoch 374/1000\n",
      "289/289 [==============================] - 0s 753us/step - loss: 834.6174 - val_loss: 1359.2156\n",
      "Epoch 375/1000\n",
      "289/289 [==============================] - 0s 812us/step - loss: 823.6627 - val_loss: 1344.7247\n",
      "Epoch 376/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 812.8220 - val_loss: 1330.4139\n",
      "Epoch 377/1000\n",
      "289/289 [==============================] - 0s 752us/step - loss: 802.1012 - val_loss: 1316.1361\n",
      "Epoch 378/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 791.5120 - val_loss: 1302.0515\n",
      "Epoch 379/1000\n",
      "289/289 [==============================] - 0s 719us/step - loss: 781.0583 - val_loss: 1288.0645\n",
      "Epoch 380/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 770.7538 - val_loss: 1274.2755\n",
      "Epoch 381/1000\n",
      "289/289 [==============================] - 0s 906us/step - loss: 760.6092 - val_loss: 1260.6121\n",
      "Epoch 382/1000\n",
      "289/289 [==============================] - 0s 742us/step - loss: 750.6079 - val_loss: 1247.1171\n",
      "Epoch 383/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 740.7555 - val_loss: 1233.7468\n",
      "Epoch 384/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 731.0537 - val_loss: 1220.5586\n",
      "Epoch 385/1000\n",
      "289/289 [==============================] - 0s 738us/step - loss: 721.4941 - val_loss: 1207.5331\n",
      "Epoch 386/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 712.0993 - val_loss: 1194.6219\n",
      "Epoch 387/1000\n",
      "289/289 [==============================] - 0s 683us/step - loss: 702.8581 - val_loss: 1181.9098\n",
      "Epoch 388/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 693.7707 - val_loss: 1169.3217\n",
      "Epoch 389/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 684.8482 - val_loss: 1156.9177\n",
      "Epoch 390/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 676.0712 - val_loss: 1144.6973\n",
      "Epoch 391/1000\n",
      "289/289 [==============================] - 0s 842us/step - loss: 667.4465 - val_loss: 1132.5912\n",
      "Epoch 392/1000\n",
      "289/289 [==============================] - 0s 785us/step - loss: 658.9901 - val_loss: 1120.6570\n",
      "Epoch 393/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 650.6968 - val_loss: 1108.9203\n",
      "Epoch 394/1000\n",
      "289/289 [==============================] - 0s 844us/step - loss: 642.5588 - val_loss: 1097.3538\n",
      "Epoch 395/1000\n",
      "289/289 [==============================] - 0s 879us/step - loss: 634.5612 - val_loss: 1085.9015\n",
      "Epoch 396/1000\n",
      "289/289 [==============================] - 0s 772us/step - loss: 626.7099 - val_loss: 1074.6587\n",
      "Epoch 397/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 619.0138 - val_loss: 1063.4763\n",
      "Epoch 398/1000\n",
      "289/289 [==============================] - 0s 956us/step - loss: 611.4780 - val_loss: 1052.5229\n",
      "Epoch 399/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 604.1043 - val_loss: 1041.7701\n",
      "Epoch 400/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 596.8902 - val_loss: 1031.1294\n",
      "Epoch 401/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 589.8222 - val_loss: 1020.6653\n",
      "Epoch 402/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 582.8972 - val_loss: 1010.3008\n",
      "Epoch 403/1000\n",
      "289/289 [==============================] - 0s 798us/step - loss: 576.1328 - val_loss: 1000.1737\n",
      "Epoch 404/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 569.5217 - val_loss: 990.1671\n",
      "Epoch 405/1000\n",
      "289/289 [==============================] - 0s 690us/step - loss: 563.0642 - val_loss: 980.3648\n",
      "Epoch 406/1000\n",
      "289/289 [==============================] - 0s 761us/step - loss: 556.7410 - val_loss: 970.6562\n",
      "Epoch 407/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 550.5607 - val_loss: 961.1157\n",
      "Epoch 408/1000\n",
      "289/289 [==============================] - 0s 694us/step - loss: 544.5408 - val_loss: 951.7870\n",
      "Epoch 409/1000\n",
      "289/289 [==============================] - 0s 732us/step - loss: 538.6774 - val_loss: 942.5579\n",
      "Epoch 410/1000\n",
      "289/289 [==============================] - 0s 907us/step - loss: 532.9789 - val_loss: 933.5728\n",
      "Epoch 411/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 527.4316 - val_loss: 924.7340\n",
      "Epoch 412/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 522.0278 - val_loss: 916.0676\n",
      "Epoch 413/1000\n",
      "289/289 [==============================] - 0s 778us/step - loss: 516.7745 - val_loss: 907.4942\n",
      "Epoch 414/1000\n",
      "289/289 [==============================] - 0s 843us/step - loss: 511.6696 - val_loss: 899.1639\n",
      "Epoch 415/1000\n",
      "289/289 [==============================] - 0s 783us/step - loss: 506.7094 - val_loss: 890.9142\n",
      "Epoch 416/1000\n",
      "289/289 [==============================] - 0s 744us/step - loss: 501.8824 - val_loss: 882.8506\n",
      "Epoch 417/1000\n",
      "289/289 [==============================] - 0s 623us/step - loss: 497.1973 - val_loss: 874.9091\n",
      "Epoch 418/1000\n",
      "289/289 [==============================] - 0s 632us/step - loss: 492.6592 - val_loss: 867.2041\n",
      "Epoch 419/1000\n",
      "289/289 [==============================] - 0s 649us/step - loss: 488.2676 - val_loss: 859.5886\n",
      "Epoch 420/1000\n",
      "289/289 [==============================] - 0s 653us/step - loss: 484.0248 - val_loss: 852.1530\n",
      "Epoch 421/1000\n",
      "289/289 [==============================] - 0s 823us/step - loss: 479.9273 - val_loss: 844.9321\n",
      "Epoch 422/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 475.9681 - val_loss: 837.7836\n",
      "Epoch 423/1000\n",
      "289/289 [==============================] - 0s 725us/step - loss: 472.1610 - val_loss: 830.9133\n",
      "Epoch 424/1000\n",
      "289/289 [==============================] - 0s 714us/step - loss: 468.4949 - val_loss: 824.1309\n",
      "Epoch 425/1000\n",
      "289/289 [==============================] - 0s 699us/step - loss: 464.9648 - val_loss: 817.5089\n",
      "Epoch 426/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 461.5790 - val_loss: 811.1057\n",
      "Epoch 427/1000\n",
      "289/289 [==============================] - 0s 760us/step - loss: 458.3306 - val_loss: 804.8292\n",
      "Epoch 428/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 455.2032 - val_loss: 798.6995\n",
      "Epoch 429/1000\n",
      "289/289 [==============================] - 0s 753us/step - loss: 452.2035 - val_loss: 792.7124\n",
      "Epoch 430/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 449.3433 - val_loss: 786.9062\n",
      "Epoch 431/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 446.6223 - val_loss: 781.2672\n",
      "Epoch 432/1000\n",
      "289/289 [==============================] - 0s 754us/step - loss: 444.0300 - val_loss: 775.8035\n",
      "Epoch 433/1000\n",
      "289/289 [==============================] - 0s 687us/step - loss: 441.5589 - val_loss: 770.5173\n",
      "Epoch 434/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 439.2159 - val_loss: 765.3242\n",
      "Epoch 435/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 436.9906 - val_loss: 760.3224\n",
      "Epoch 436/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 434.8853 - val_loss: 755.5062\n",
      "Epoch 437/1000\n",
      "289/289 [==============================] - 0s 876us/step - loss: 432.9015 - val_loss: 750.8182\n",
      "Epoch 438/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 431.0439 - val_loss: 746.3034\n",
      "Epoch 439/1000\n",
      "289/289 [==============================] - 0s 724us/step - loss: 429.3182 - val_loss: 742.0221\n",
      "Epoch 440/1000\n",
      "289/289 [==============================] - 0s 774us/step - loss: 427.7021 - val_loss: 737.8970\n",
      "Epoch 441/1000\n",
      "289/289 [==============================] - 0s 838us/step - loss: 426.1851 - val_loss: 733.9360\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 880us/step - loss: 424.7650 - val_loss: 730.0643\n",
      "Epoch 443/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 423.4584 - val_loss: 726.3736\n",
      "Epoch 444/1000\n",
      "289/289 [==============================] - 0s 917us/step - loss: 422.2421 - val_loss: 722.8353\n",
      "Epoch 445/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 421.1097 - val_loss: 719.4846\n",
      "Epoch 446/1000\n",
      "289/289 [==============================] - 0s 895us/step - loss: 420.0730 - val_loss: 716.1963\n",
      "Epoch 447/1000\n",
      "289/289 [==============================] - 0s 770us/step - loss: 419.1306 - val_loss: 713.1639\n",
      "Epoch 448/1000\n",
      "289/289 [==============================] - 0s 787us/step - loss: 418.2687 - val_loss: 710.2592\n",
      "Epoch 449/1000\n",
      "289/289 [==============================] - 0s 794us/step - loss: 417.4916 - val_loss: 707.5453\n",
      "Epoch 450/1000\n",
      "289/289 [==============================] - 0s 662us/step - loss: 416.7965 - val_loss: 704.9751\n",
      "Epoch 451/1000\n",
      "289/289 [==============================] - 0s 777us/step - loss: 416.1632 - val_loss: 702.5335\n",
      "Epoch 452/1000\n",
      "289/289 [==============================] - 0s 899us/step - loss: 415.5915 - val_loss: 700.2852\n",
      "Epoch 453/1000\n",
      "289/289 [==============================] - 0s 896us/step - loss: 415.0860 - val_loss: 698.0682\n",
      "Epoch 454/1000\n",
      "289/289 [==============================] - 0s 803us/step - loss: 414.6293 - val_loss: 696.1418\n",
      "Epoch 455/1000\n",
      "289/289 [==============================] - 0s 780us/step - loss: 414.2218 - val_loss: 694.2109\n",
      "Epoch 456/1000\n",
      "289/289 [==============================] - 0s 759us/step - loss: 413.8589 - val_loss: 692.3970\n",
      "Epoch 457/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 413.5387 - val_loss: 690.7013\n",
      "Epoch 458/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 413.2538 - val_loss: 689.1252\n",
      "Epoch 459/1000\n",
      "289/289 [==============================] - 0s 799us/step - loss: 412.9997 - val_loss: 687.6309\n",
      "Epoch 460/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 412.7771 - val_loss: 686.2736\n",
      "Epoch 461/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 412.5886 - val_loss: 685.0144\n",
      "Epoch 462/1000\n",
      "289/289 [==============================] - 0s 872us/step - loss: 412.4247 - val_loss: 683.8804\n",
      "Epoch 463/1000\n",
      "289/289 [==============================] - 0s 729us/step - loss: 412.2834 - val_loss: 682.8195\n",
      "Epoch 464/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 412.1616 - val_loss: 681.8345\n",
      "Epoch 465/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 412.0571 - val_loss: 680.9553\n",
      "Epoch 466/1000\n",
      "289/289 [==============================] - 0s 755us/step - loss: 411.9648 - val_loss: 680.0511\n",
      "Epoch 467/1000\n",
      "289/289 [==============================] - 0s 703us/step - loss: 411.8881 - val_loss: 679.2479\n",
      "Epoch 468/1000\n",
      "289/289 [==============================] - 0s 759us/step - loss: 411.8210 - val_loss: 678.6545\n",
      "Epoch 469/1000\n",
      "289/289 [==============================] - 0s 764us/step - loss: 411.7632 - val_loss: 677.9735\n",
      "Epoch 470/1000\n",
      "289/289 [==============================] - 0s 766us/step - loss: 411.7144 - val_loss: 677.3445\n",
      "Epoch 471/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.6724 - val_loss: 676.8066\n",
      "Epoch 472/1000\n",
      "289/289 [==============================] - 0s 917us/step - loss: 411.6357 - val_loss: 676.2379\n",
      "Epoch 473/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.6025 - val_loss: 675.7881\n",
      "Epoch 474/1000\n",
      "289/289 [==============================] - 0s 945us/step - loss: 411.5755 - val_loss: 675.3098\n",
      "Epoch 475/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 411.5532 - val_loss: 674.9222\n",
      "Epoch 476/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 411.5329 - val_loss: 674.5718\n",
      "Epoch 477/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 411.5148 - val_loss: 674.2147\n",
      "Epoch 478/1000\n",
      "289/289 [==============================] - 0s 694us/step - loss: 411.5005 - val_loss: 673.8947\n",
      "Epoch 479/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 411.4887 - val_loss: 673.5889\n",
      "Epoch 480/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 411.4772 - val_loss: 673.2717\n",
      "Epoch 481/1000\n",
      "289/289 [==============================] - 0s 691us/step - loss: 411.4692 - val_loss: 673.0504\n",
      "Epoch 482/1000\n",
      "289/289 [==============================] - 0s 697us/step - loss: 411.4635 - val_loss: 672.7988\n",
      "Epoch 483/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 411.4549 - val_loss: 672.6254\n",
      "Epoch 484/1000\n",
      "289/289 [==============================] - 0s 988us/step - loss: 411.4488 - val_loss: 672.4450\n",
      "Epoch 485/1000\n",
      "289/289 [==============================] - 0s 850us/step - loss: 411.4437 - val_loss: 672.2215\n",
      "Epoch 486/1000\n",
      "289/289 [==============================] - 0s 824us/step - loss: 411.4394 - val_loss: 672.0576\n",
      "Epoch 487/1000\n",
      "289/289 [==============================] - 0s 852us/step - loss: 411.4378 - val_loss: 671.8903\n",
      "Epoch 488/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4340 - val_loss: 671.7906\n",
      "Epoch 489/1000\n",
      "289/289 [==============================] - 0s 682us/step - loss: 411.4346 - val_loss: 671.6579\n",
      "Epoch 490/1000\n",
      "289/289 [==============================] - 0s 670us/step - loss: 411.4294 - val_loss: 671.5317\n",
      "Epoch 491/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 411.4274 - val_loss: 671.4595\n",
      "Epoch 492/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 411.4272 - val_loss: 671.3337\n",
      "Epoch 493/1000\n",
      "289/289 [==============================] - 0s 863us/step - loss: 411.4241 - val_loss: 671.2626\n",
      "Epoch 494/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 411.4249 - val_loss: 671.1356\n",
      "Epoch 495/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 411.4238 - val_loss: 671.0063\n",
      "Epoch 496/1000\n",
      "289/289 [==============================] - 0s 697us/step - loss: 411.4222 - val_loss: 671.0023\n",
      "Epoch 497/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 411.4201 - val_loss: 670.9504\n",
      "Epoch 498/1000\n",
      "289/289 [==============================] - 0s 696us/step - loss: 411.4201 - val_loss: 670.8622\n",
      "Epoch 499/1000\n",
      "289/289 [==============================] - 0s 702us/step - loss: 411.4213 - val_loss: 670.8438\n",
      "Epoch 500/1000\n",
      "289/289 [==============================] - 0s 772us/step - loss: 411.4180 - val_loss: 670.7476\n",
      "Epoch 501/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 411.4180 - val_loss: 670.6566\n",
      "Epoch 502/1000\n",
      "289/289 [==============================] - 0s 688us/step - loss: 411.4187 - val_loss: 670.6127\n",
      "Epoch 503/1000\n",
      "289/289 [==============================] - 0s 857us/step - loss: 411.4180 - val_loss: 670.6234\n",
      "Epoch 504/1000\n",
      "289/289 [==============================] - 0s 726us/step - loss: 411.4184 - val_loss: 670.6218\n",
      "Epoch 505/1000\n",
      "289/289 [==============================] - 0s 859us/step - loss: 411.4185 - val_loss: 670.5482\n",
      "Epoch 506/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 411.4180 - val_loss: 670.5223\n",
      "Epoch 507/1000\n",
      "289/289 [==============================] - 0s 751us/step - loss: 411.4166 - val_loss: 670.4689\n",
      "Epoch 508/1000\n",
      "289/289 [==============================] - 0s 741us/step - loss: 411.4170 - val_loss: 670.4988\n",
      "Epoch 509/1000\n",
      "289/289 [==============================] - 0s 681us/step - loss: 411.4164 - val_loss: 670.4362\n",
      "Epoch 510/1000\n",
      "289/289 [==============================] - 0s 833us/step - loss: 411.4169 - val_loss: 670.4348\n",
      "Epoch 511/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 411.4163 - val_loss: 670.3936\n",
      "Epoch 512/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 411.4178 - val_loss: 670.3682\n",
      "Epoch 513/1000\n",
      "289/289 [==============================] - 0s 881us/step - loss: 411.4170 - val_loss: 670.3564\n",
      "Epoch 514/1000\n",
      "289/289 [==============================] - 0s 794us/step - loss: 411.4160 - val_loss: 670.3561\n",
      "Epoch 515/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 411.4177 - val_loss: 670.3619\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 926us/step - loss: 411.4165 - val_loss: 670.3693\n",
      "Epoch 517/1000\n",
      "289/289 [==============================] - 0s 739us/step - loss: 411.4161 - val_loss: 670.2386\n",
      "Epoch 518/1000\n",
      "289/289 [==============================] - 0s 799us/step - loss: 411.4171 - val_loss: 670.2278\n",
      "Epoch 519/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 411.4168 - val_loss: 670.2743\n",
      "Epoch 520/1000\n",
      "289/289 [==============================] - 0s 735us/step - loss: 411.4158 - val_loss: 670.1822\n",
      "Epoch 521/1000\n",
      "289/289 [==============================] - 0s 764us/step - loss: 411.4194 - val_loss: 670.2259\n",
      "Epoch 522/1000\n",
      "289/289 [==============================] - 0s 780us/step - loss: 411.4163 - val_loss: 670.2438\n",
      "Epoch 523/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.4167 - val_loss: 670.2831\n",
      "Epoch 524/1000\n",
      "289/289 [==============================] - 0s 693us/step - loss: 411.4160 - val_loss: 670.2075\n",
      "Epoch 525/1000\n",
      "289/289 [==============================] - 0s 981us/step - loss: 411.4159 - val_loss: 670.1902\n",
      "Epoch 526/1000\n",
      "289/289 [==============================] - 0s 923us/step - loss: 411.4169 - val_loss: 670.1907\n",
      "Epoch 527/1000\n",
      "289/289 [==============================] - 0s 785us/step - loss: 411.4165 - val_loss: 670.1736\n",
      "Epoch 528/1000\n",
      "289/289 [==============================] - 0s 895us/step - loss: 411.4174 - val_loss: 670.1602\n",
      "Epoch 529/1000\n",
      "289/289 [==============================] - 0s 888us/step - loss: 411.4173 - val_loss: 670.1720\n",
      "Epoch 530/1000\n",
      "289/289 [==============================] - 0s 798us/step - loss: 411.4173 - val_loss: 670.1758\n",
      "Epoch 531/1000\n",
      "289/289 [==============================] - 0s 886us/step - loss: 411.4164 - val_loss: 670.1561\n",
      "Epoch 532/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 411.4165 - val_loss: 670.1712\n",
      "Epoch 533/1000\n",
      "289/289 [==============================] - 0s 854us/step - loss: 411.4164 - val_loss: 670.1701\n",
      "Epoch 534/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4153 - val_loss: 670.1008\n",
      "Epoch 535/1000\n",
      "289/289 [==============================] - 0s 705us/step - loss: 411.4158 - val_loss: 670.1320\n",
      "Epoch 536/1000\n",
      "289/289 [==============================] - 0s 757us/step - loss: 411.4165 - val_loss: 670.1612\n",
      "Epoch 537/1000\n",
      "289/289 [==============================] - 0s 712us/step - loss: 411.4162 - val_loss: 670.1014\n",
      "Epoch 538/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 411.4169 - val_loss: 670.1041\n",
      "Epoch 539/1000\n",
      "289/289 [==============================] - 0s 758us/step - loss: 411.4168 - val_loss: 670.1700\n",
      "Epoch 540/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.1046\n",
      "Epoch 541/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4155 - val_loss: 670.1433\n",
      "Epoch 542/1000\n",
      "289/289 [==============================] - 0s 708us/step - loss: 411.4159 - val_loss: 670.1170\n",
      "Epoch 543/1000\n",
      "289/289 [==============================] - 0s 676us/step - loss: 411.4162 - val_loss: 670.1157\n",
      "Epoch 544/1000\n",
      "289/289 [==============================] - 0s 775us/step - loss: 411.4166 - val_loss: 670.0753\n",
      "Epoch 545/1000\n",
      "289/289 [==============================] - 0s 686us/step - loss: 411.4169 - val_loss: 670.0667\n",
      "Epoch 546/1000\n",
      "289/289 [==============================] - 0s 773us/step - loss: 411.4178 - val_loss: 670.0953\n",
      "Epoch 547/1000\n",
      "289/289 [==============================] - 0s 740us/step - loss: 411.4181 - val_loss: 670.0952\n",
      "Epoch 548/1000\n",
      "289/289 [==============================] - 0s 950us/step - loss: 411.4174 - val_loss: 670.1458\n",
      "Epoch 549/1000\n",
      "289/289 [==============================] - 0s 849us/step - loss: 411.4175 - val_loss: 670.1074\n",
      "Epoch 550/1000\n",
      "289/289 [==============================] - 0s 855us/step - loss: 411.4147 - val_loss: 670.0959\n",
      "Epoch 551/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4167 - val_loss: 670.0738\n",
      "Epoch 552/1000\n",
      "289/289 [==============================] - 0s 774us/step - loss: 411.4164 - val_loss: 670.0906\n",
      "Epoch 553/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 411.4160 - val_loss: 670.1093\n",
      "Epoch 554/1000\n",
      "289/289 [==============================] - 0s 904us/step - loss: 411.4181 - val_loss: 670.0854\n",
      "Epoch 555/1000\n",
      "289/289 [==============================] - 0s 889us/step - loss: 411.4159 - val_loss: 670.1048\n",
      "Epoch 556/1000\n",
      "289/289 [==============================] - 0s 697us/step - loss: 411.4151 - val_loss: 670.1053\n",
      "Epoch 557/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 411.4163 - val_loss: 670.0504\n",
      "Epoch 558/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 411.4170 - val_loss: 670.1284\n",
      "Epoch 559/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0677\n",
      "Epoch 560/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4169 - val_loss: 670.0766\n",
      "Epoch 561/1000\n",
      "289/289 [==============================] - 0s 802us/step - loss: 411.4158 - val_loss: 670.1071\n",
      "Epoch 562/1000\n",
      "289/289 [==============================] - 0s 751us/step - loss: 411.4167 - val_loss: 670.1335\n",
      "Epoch 563/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 411.4157 - val_loss: 670.1278\n",
      "Epoch 564/1000\n",
      "289/289 [==============================] - 0s 967us/step - loss: 411.4178 - val_loss: 670.0521\n",
      "Epoch 565/1000\n",
      "289/289 [==============================] - 0s 726us/step - loss: 411.4151 - val_loss: 670.1747\n",
      "Epoch 566/1000\n",
      "289/289 [==============================] - 0s 728us/step - loss: 411.4163 - val_loss: 670.1577\n",
      "Epoch 567/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 411.4157 - val_loss: 670.0780\n",
      "Epoch 568/1000\n",
      "289/289 [==============================] - 0s 811us/step - loss: 411.4160 - val_loss: 670.1373\n",
      "Epoch 569/1000\n",
      "289/289 [==============================] - 0s 731us/step - loss: 411.4171 - val_loss: 670.0946\n",
      "Epoch 570/1000\n",
      "289/289 [==============================] - 0s 698us/step - loss: 411.4166 - val_loss: 670.1401\n",
      "Epoch 571/1000\n",
      "289/289 [==============================] - 0s 813us/step - loss: 411.4162 - val_loss: 670.1573\n",
      "Epoch 572/1000\n",
      "289/289 [==============================] - 0s 839us/step - loss: 411.4167 - val_loss: 670.1053\n",
      "Epoch 573/1000\n",
      "289/289 [==============================] - 0s 822us/step - loss: 411.4155 - val_loss: 670.1556\n",
      "Epoch 574/1000\n",
      "289/289 [==============================] - 0s 848us/step - loss: 411.4165 - val_loss: 670.1545\n",
      "Epoch 575/1000\n",
      "289/289 [==============================] - 0s 830us/step - loss: 411.4166 - val_loss: 670.1342\n",
      "Epoch 576/1000\n",
      "289/289 [==============================] - 0s 791us/step - loss: 411.4172 - val_loss: 670.1154\n",
      "Epoch 577/1000\n",
      "289/289 [==============================] - 0s 892us/step - loss: 411.4171 - val_loss: 670.0984\n",
      "Epoch 578/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 411.4165 - val_loss: 670.0995\n",
      "Epoch 579/1000\n",
      "289/289 [==============================] - 0s 941us/step - loss: 411.4155 - val_loss: 670.1007\n",
      "Epoch 580/1000\n",
      "289/289 [==============================] - 0s 683us/step - loss: 411.4149 - val_loss: 670.0968\n",
      "Epoch 581/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 411.4163 - val_loss: 670.0943\n",
      "Epoch 582/1000\n",
      "289/289 [==============================] - 0s 760us/step - loss: 411.4162 - val_loss: 670.0832\n",
      "Epoch 583/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 411.4153 - val_loss: 670.1077\n",
      "Epoch 584/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4156 - val_loss: 670.0908\n",
      "Epoch 585/1000\n",
      "289/289 [==============================] - 0s 762us/step - loss: 411.4154 - val_loss: 670.1307\n",
      "Epoch 586/1000\n",
      "289/289 [==============================] - 0s 755us/step - loss: 411.4165 - val_loss: 670.1265\n",
      "Epoch 587/1000\n",
      "289/289 [==============================] - 0s 880us/step - loss: 411.4157 - val_loss: 670.1032\n",
      "Epoch 588/1000\n",
      "289/289 [==============================] - 0s 840us/step - loss: 411.4174 - val_loss: 670.1379\n",
      "Epoch 589/1000\n",
      "289/289 [==============================] - 0s 859us/step - loss: 411.4165 - val_loss: 670.0931\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 667us/step - loss: 411.4181 - val_loss: 670.0842\n",
      "Epoch 591/1000\n",
      "289/289 [==============================] - 0s 733us/step - loss: 411.4158 - val_loss: 670.0985\n",
      "Epoch 592/1000\n",
      "289/289 [==============================] - 0s 789us/step - loss: 411.4157 - val_loss: 670.0862\n",
      "Epoch 593/1000\n",
      "289/289 [==============================] - 0s 877us/step - loss: 411.4166 - val_loss: 670.0599\n",
      "Epoch 594/1000\n",
      "289/289 [==============================] - 0s 721us/step - loss: 411.4175 - val_loss: 670.1052\n",
      "Epoch 595/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4152 - val_loss: 670.0533\n",
      "Epoch 596/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 411.4154 - val_loss: 670.0704\n",
      "Epoch 597/1000\n",
      "289/289 [==============================] - 0s 748us/step - loss: 411.4169 - val_loss: 670.1282\n",
      "Epoch 598/1000\n",
      "289/289 [==============================] - 0s 855us/step - loss: 411.4169 - val_loss: 670.0961\n",
      "Epoch 599/1000\n",
      "289/289 [==============================] - 0s 732us/step - loss: 411.4165 - val_loss: 670.0959\n",
      "Epoch 600/1000\n",
      "289/289 [==============================] - 0s 906us/step - loss: 411.4164 - val_loss: 670.0951\n",
      "Epoch 601/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4172 - val_loss: 670.1021\n",
      "Epoch 602/1000\n",
      "289/289 [==============================] - 0s 964us/step - loss: 411.4169 - val_loss: 670.0761\n",
      "Epoch 603/1000\n",
      "289/289 [==============================] - 0s 701us/step - loss: 411.4166 - val_loss: 670.0609\n",
      "Epoch 604/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 411.4170 - val_loss: 670.0800\n",
      "Epoch 605/1000\n",
      "289/289 [==============================] - 0s 706us/step - loss: 411.4163 - val_loss: 670.0760\n",
      "Epoch 606/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.4168 - val_loss: 670.0820\n",
      "Epoch 607/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4159 - val_loss: 670.0848\n",
      "Epoch 608/1000\n",
      "289/289 [==============================] - 0s 754us/step - loss: 411.4159 - val_loss: 670.0833\n",
      "Epoch 609/1000\n",
      "289/289 [==============================] - 0s 929us/step - loss: 411.4166 - val_loss: 670.0492\n",
      "Epoch 610/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 411.4161 - val_loss: 670.1379\n",
      "Epoch 611/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 411.4163 - val_loss: 670.1160\n",
      "Epoch 612/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 411.4167 - val_loss: 670.0838\n",
      "Epoch 613/1000\n",
      "289/289 [==============================] - 0s 718us/step - loss: 411.4159 - val_loss: 670.0914\n",
      "Epoch 614/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 411.4169 - val_loss: 670.0858\n",
      "Epoch 615/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4173 - val_loss: 670.1284\n",
      "Epoch 616/1000\n",
      "289/289 [==============================] - 0s 876us/step - loss: 411.4156 - val_loss: 670.0833\n",
      "Epoch 617/1000\n",
      "289/289 [==============================] - 0s 768us/step - loss: 411.4164 - val_loss: 670.0880\n",
      "Epoch 618/1000\n",
      "289/289 [==============================] - 0s 694us/step - loss: 411.4156 - val_loss: 670.1053\n",
      "Epoch 619/1000\n",
      "289/289 [==============================] - 0s 695us/step - loss: 411.4176 - val_loss: 670.1906\n",
      "Epoch 620/1000\n",
      "289/289 [==============================] - 0s 686us/step - loss: 411.4163 - val_loss: 670.1448\n",
      "Epoch 621/1000\n",
      "289/289 [==============================] - 0s 696us/step - loss: 411.4164 - val_loss: 670.1075\n",
      "Epoch 622/1000\n",
      "289/289 [==============================] - 0s 749us/step - loss: 411.4177 - val_loss: 670.1129\n",
      "Epoch 623/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4164 - val_loss: 670.1077\n",
      "Epoch 624/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 411.4150 - val_loss: 670.1366\n",
      "Epoch 625/1000\n",
      "289/289 [==============================] - 0s 933us/step - loss: 411.4166 - val_loss: 670.1562\n",
      "Epoch 626/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 411.4168 - val_loss: 670.1337\n",
      "Epoch 627/1000\n",
      "289/289 [==============================] - 0s 737us/step - loss: 411.4176 - val_loss: 670.0833\n",
      "Epoch 628/1000\n",
      "289/289 [==============================] - 0s 842us/step - loss: 411.4158 - val_loss: 670.1362\n",
      "Epoch 629/1000\n",
      "289/289 [==============================] - 0s 845us/step - loss: 411.4160 - val_loss: 670.1171\n",
      "Epoch 630/1000\n",
      "289/289 [==============================] - 0s 745us/step - loss: 411.4167 - val_loss: 670.1581\n",
      "Epoch 631/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 411.4164 - val_loss: 670.1895\n",
      "Epoch 632/1000\n",
      "289/289 [==============================] - 0s 719us/step - loss: 411.4148 - val_loss: 670.1281\n",
      "Epoch 633/1000\n",
      "289/289 [==============================] - 0s 722us/step - loss: 411.4175 - val_loss: 670.1954\n",
      "Epoch 634/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4162 - val_loss: 670.1173\n",
      "Epoch 635/1000\n",
      "289/289 [==============================] - 0s 812us/step - loss: 411.4199 - val_loss: 670.1182\n",
      "Epoch 636/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 411.4183 - val_loss: 670.0634\n",
      "Epoch 637/1000\n",
      "289/289 [==============================] - 0s 863us/step - loss: 411.4200 - val_loss: 670.1222\n",
      "Epoch 638/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 411.4161 - val_loss: 670.1342\n",
      "Epoch 639/1000\n",
      "289/289 [==============================] - 0s 729us/step - loss: 411.4167 - val_loss: 670.1754\n",
      "Epoch 640/1000\n",
      "289/289 [==============================] - 0s 679us/step - loss: 411.4161 - val_loss: 670.1439\n",
      "Epoch 641/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 411.4177 - val_loss: 670.0969\n",
      "Epoch 642/1000\n",
      "289/289 [==============================] - 0s 710us/step - loss: 411.4158 - val_loss: 670.1053\n",
      "Epoch 643/1000\n",
      "289/289 [==============================] - 0s 687us/step - loss: 411.4155 - val_loss: 670.1429\n",
      "Epoch 644/1000\n",
      "289/289 [==============================] - 0s 729us/step - loss: 411.4192 - val_loss: 670.1320\n",
      "Epoch 645/1000\n",
      "289/289 [==============================] - 0s 736us/step - loss: 411.4153 - val_loss: 670.1208\n",
      "Epoch 646/1000\n",
      "289/289 [==============================] - 0s 927us/step - loss: 411.4174 - val_loss: 670.1210\n",
      "Epoch 647/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 411.4166 - val_loss: 670.0881\n",
      "Epoch 648/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0656\n",
      "Epoch 649/1000\n",
      "289/289 [==============================] - 0s 746us/step - loss: 411.4162 - val_loss: 670.1185\n",
      "Epoch 650/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 411.4176 - val_loss: 670.0283\n",
      "Epoch 651/1000\n",
      "289/289 [==============================] - 0s 883us/step - loss: 411.4169 - val_loss: 670.1114\n",
      "Epoch 652/1000\n",
      "289/289 [==============================] - 0s 859us/step - loss: 411.4161 - val_loss: 670.0863\n",
      "Epoch 653/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.0974\n",
      "Epoch 654/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 411.4162 - val_loss: 670.1193\n",
      "Epoch 655/1000\n",
      "289/289 [==============================] - 0s 747us/step - loss: 411.4171 - val_loss: 670.1612\n",
      "Epoch 656/1000\n",
      "289/289 [==============================] - 0s 900us/step - loss: 411.4156 - val_loss: 670.0521\n",
      "Epoch 657/1000\n",
      "289/289 [==============================] - 0s 939us/step - loss: 411.4160 - val_loss: 670.1171\n",
      "Epoch 658/1000\n",
      "289/289 [==============================] - 0s 875us/step - loss: 411.4163 - val_loss: 670.0733\n",
      "Epoch 659/1000\n",
      "289/289 [==============================] - 0s 786us/step - loss: 411.4180 - val_loss: 670.1094\n",
      "Epoch 660/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 411.4158 - val_loss: 670.1014\n",
      "Epoch 661/1000\n",
      "289/289 [==============================] - 0s 965us/step - loss: 411.4173 - val_loss: 670.1016\n",
      "Epoch 662/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 411.4178 - val_loss: 670.1515\n",
      "Epoch 663/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 411.4168 - val_loss: 670.1271\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 918us/step - loss: 411.4151 - val_loss: 670.1086\n",
      "Epoch 665/1000\n",
      "289/289 [==============================] - 0s 842us/step - loss: 411.4166 - val_loss: 670.1305\n",
      "Epoch 666/1000\n",
      "289/289 [==============================] - 0s 719us/step - loss: 411.4167 - val_loss: 670.1286\n",
      "Epoch 667/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 411.4168 - val_loss: 670.0923\n",
      "Epoch 668/1000\n",
      "289/289 [==============================] - 0s 880us/step - loss: 411.4168 - val_loss: 670.1165\n",
      "Epoch 669/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4183 - val_loss: 670.0670\n",
      "Epoch 670/1000\n",
      "289/289 [==============================] - 0s 882us/step - loss: 411.4159 - val_loss: 670.0553\n",
      "Epoch 671/1000\n",
      "289/289 [==============================] - 0s 927us/step - loss: 411.4153 - val_loss: 670.0914\n",
      "Epoch 672/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4165 - val_loss: 670.1137\n",
      "Epoch 673/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 411.4179 - val_loss: 670.1154\n",
      "Epoch 674/1000\n",
      "289/289 [==============================] - 0s 889us/step - loss: 411.4165 - val_loss: 670.0861\n",
      "Epoch 675/1000\n",
      "289/289 [==============================] - 0s 818us/step - loss: 411.4166 - val_loss: 670.1097\n",
      "Epoch 676/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 411.4171 - val_loss: 670.1180\n",
      "Epoch 677/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 411.4176 - val_loss: 670.1534\n",
      "Epoch 678/1000\n",
      "289/289 [==============================] - 0s 867us/step - loss: 411.4168 - val_loss: 670.1033\n",
      "Epoch 679/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4167 - val_loss: 670.0971\n",
      "Epoch 680/1000\n",
      "289/289 [==============================] - 0s 721us/step - loss: 411.4164 - val_loss: 670.1107\n",
      "Epoch 681/1000\n",
      "289/289 [==============================] - 0s 796us/step - loss: 411.4170 - val_loss: 670.0951\n",
      "Epoch 682/1000\n",
      "289/289 [==============================] - 0s 911us/step - loss: 411.4161 - val_loss: 670.0952\n",
      "Epoch 683/1000\n",
      "289/289 [==============================] - 0s 737us/step - loss: 411.4166 - val_loss: 670.1347\n",
      "Epoch 684/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4166 - val_loss: 670.1415\n",
      "Epoch 685/1000\n",
      "289/289 [==============================] - 0s 717us/step - loss: 411.4164 - val_loss: 670.0681\n",
      "Epoch 686/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 411.4164 - val_loss: 670.1238\n",
      "Epoch 687/1000\n",
      "289/289 [==============================] - 0s 810us/step - loss: 411.4157 - val_loss: 670.0735\n",
      "Epoch 688/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 411.4157 - val_loss: 670.0784\n",
      "Epoch 689/1000\n",
      "289/289 [==============================] - 0s 908us/step - loss: 411.4159 - val_loss: 670.1235\n",
      "Epoch 690/1000\n",
      "289/289 [==============================] - 0s 803us/step - loss: 411.4173 - val_loss: 670.0810\n",
      "Epoch 691/1000\n",
      "289/289 [==============================] - 0s 771us/step - loss: 411.4175 - val_loss: 670.0293\n",
      "Epoch 692/1000\n",
      "289/289 [==============================] - 0s 934us/step - loss: 411.4163 - val_loss: 670.1217\n",
      "Epoch 693/1000\n",
      "289/289 [==============================] - 0s 938us/step - loss: 411.4163 - val_loss: 670.0887\n",
      "Epoch 694/1000\n",
      "289/289 [==============================] - 0s 937us/step - loss: 411.4161 - val_loss: 670.0272\n",
      "Epoch 695/1000\n",
      "289/289 [==============================] - 0s 871us/step - loss: 411.4154 - val_loss: 670.1166\n",
      "Epoch 696/1000\n",
      "289/289 [==============================] - 0s 883us/step - loss: 411.4164 - val_loss: 670.0790\n",
      "Epoch 697/1000\n",
      "289/289 [==============================] - 0s 756us/step - loss: 411.4155 - val_loss: 670.1044\n",
      "Epoch 698/1000\n",
      "289/289 [==============================] - 0s 800us/step - loss: 411.4157 - val_loss: 670.0715\n",
      "Epoch 699/1000\n",
      "289/289 [==============================] - 0s 793us/step - loss: 411.4157 - val_loss: 670.1012\n",
      "Epoch 700/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.4156 - val_loss: 670.1021\n",
      "Epoch 701/1000\n",
      "289/289 [==============================] - 0s 750us/step - loss: 411.4156 - val_loss: 670.0514\n",
      "Epoch 702/1000\n",
      "289/289 [==============================] - 0s 902us/step - loss: 411.4177 - val_loss: 670.0812\n",
      "Epoch 703/1000\n",
      "289/289 [==============================] - 0s 863us/step - loss: 411.4182 - val_loss: 670.0538\n",
      "Epoch 704/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 411.4174 - val_loss: 670.0577\n",
      "Epoch 705/1000\n",
      "289/289 [==============================] - 0s 743us/step - loss: 411.4174 - val_loss: 670.0837\n",
      "Epoch 706/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 411.4167 - val_loss: 670.1001\n",
      "Epoch 707/1000\n",
      "289/289 [==============================] - 0s 875us/step - loss: 411.4164 - val_loss: 670.0804\n",
      "Epoch 708/1000\n",
      "289/289 [==============================] - 0s 903us/step - loss: 411.4165 - val_loss: 670.0635\n",
      "Epoch 709/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4170 - val_loss: 670.0506\n",
      "Epoch 710/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 411.4171 - val_loss: 670.0632\n",
      "Epoch 711/1000\n",
      "289/289 [==============================] - 0s 795us/step - loss: 411.4163 - val_loss: 670.0952\n",
      "Epoch 712/1000\n",
      "289/289 [==============================] - 0s 976us/step - loss: 411.4171 - val_loss: 670.0753\n",
      "Epoch 713/1000\n",
      "289/289 [==============================] - 0s 787us/step - loss: 411.4159 - val_loss: 670.0501\n",
      "Epoch 714/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.0996\n",
      "Epoch 715/1000\n",
      "289/289 [==============================] - 0s 898us/step - loss: 411.4169 - val_loss: 670.1014\n",
      "Epoch 716/1000\n",
      "289/289 [==============================] - 0s 744us/step - loss: 411.4168 - val_loss: 670.1025\n",
      "Epoch 717/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 411.4159 - val_loss: 670.0985\n",
      "Epoch 718/1000\n",
      "289/289 [==============================] - 0s 810us/step - loss: 411.4160 - val_loss: 670.1433\n",
      "Epoch 719/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 411.4165 - val_loss: 670.0712\n",
      "Epoch 720/1000\n",
      "289/289 [==============================] - 0s 915us/step - loss: 411.4153 - val_loss: 670.1198\n",
      "Epoch 721/1000\n",
      "289/289 [==============================] - 0s 967us/step - loss: 411.4169 - val_loss: 670.1380\n",
      "Epoch 722/1000\n",
      "289/289 [==============================] - 0s 919us/step - loss: 411.4167 - val_loss: 670.1145\n",
      "Epoch 723/1000\n",
      "289/289 [==============================] - 0s 944us/step - loss: 411.4174 - val_loss: 670.1033\n",
      "Epoch 724/1000\n",
      "289/289 [==============================] - 0s 803us/step - loss: 411.4195 - val_loss: 670.0375\n",
      "Epoch 725/1000\n",
      "289/289 [==============================] - 0s 906us/step - loss: 411.4158 - val_loss: 670.0991\n",
      "Epoch 726/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0901\n",
      "Epoch 727/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4167 - val_loss: 670.1341\n",
      "Epoch 728/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 411.4171 - val_loss: 670.1344\n",
      "Epoch 729/1000\n",
      "289/289 [==============================] - 0s 954us/step - loss: 411.4171 - val_loss: 670.1118\n",
      "Epoch 730/1000\n",
      "289/289 [==============================] - 0s 959us/step - loss: 411.4161 - val_loss: 670.1124\n",
      "Epoch 731/1000\n",
      "289/289 [==============================] - 0s 914us/step - loss: 411.4192 - val_loss: 670.1338\n",
      "Epoch 732/1000\n",
      "289/289 [==============================] - 0s 992us/step - loss: 411.4163 - val_loss: 670.0989\n",
      "Epoch 733/1000\n",
      "289/289 [==============================] - 0s 902us/step - loss: 411.4165 - val_loss: 670.1277\n",
      "Epoch 734/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 411.4176 - val_loss: 670.0607\n",
      "Epoch 735/1000\n",
      "289/289 [==============================] - 0s 850us/step - loss: 411.4158 - val_loss: 670.1375\n",
      "Epoch 736/1000\n",
      "289/289 [==============================] - 0s 760us/step - loss: 411.4162 - val_loss: 670.1295\n",
      "Epoch 737/1000\n",
      "289/289 [==============================] - 0s 838us/step - loss: 411.4165 - val_loss: 670.0921\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 914us/step - loss: 411.4154 - val_loss: 670.1682\n",
      "Epoch 739/1000\n",
      "289/289 [==============================] - 0s 936us/step - loss: 411.4174 - val_loss: 670.1422\n",
      "Epoch 740/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.1232\n",
      "Epoch 741/1000\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 411.4165 - val_loss: 670.0794\n",
      "Epoch 742/1000\n",
      "289/289 [==============================] - 0s 969us/step - loss: 411.4161 - val_loss: 670.1012\n",
      "Epoch 743/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4154 - val_loss: 670.0814\n",
      "Epoch 744/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.0757\n",
      "Epoch 745/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0917\n",
      "Epoch 746/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.0573\n",
      "Epoch 747/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0902\n",
      "Epoch 748/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4175 - val_loss: 670.0838\n",
      "Epoch 749/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.1390\n",
      "Epoch 750/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.1320\n",
      "Epoch 751/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.0827\n",
      "Epoch 752/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4154 - val_loss: 670.1221\n",
      "Epoch 753/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4174 - val_loss: 670.0870\n",
      "Epoch 754/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.0663\n",
      "Epoch 755/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4153 - val_loss: 670.0919\n",
      "Epoch 756/1000\n",
      "289/289 [==============================] - 0s 982us/step - loss: 411.4162 - val_loss: 670.1155\n",
      "Epoch 757/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.1553\n",
      "Epoch 758/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4156 - val_loss: 670.1166\n",
      "Epoch 759/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.1352\n",
      "Epoch 760/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.1125\n",
      "Epoch 761/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4178 - val_loss: 670.0781\n",
      "Epoch 762/1000\n",
      "289/289 [==============================] - 0s 987us/step - loss: 411.4164 - val_loss: 670.0723\n",
      "Epoch 763/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.1102\n",
      "Epoch 764/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4171 - val_loss: 670.1243\n",
      "Epoch 765/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.0695\n",
      "Epoch 766/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4153 - val_loss: 670.1044\n",
      "Epoch 767/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4157 - val_loss: 670.0928\n",
      "Epoch 768/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4175 - val_loss: 670.1085\n",
      "Epoch 769/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4170 - val_loss: 670.1155\n",
      "Epoch 770/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4170 - val_loss: 670.0675\n",
      "Epoch 771/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.1274\n",
      "Epoch 772/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0947\n",
      "Epoch 773/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.1372\n",
      "Epoch 774/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4172 - val_loss: 670.0668\n",
      "Epoch 775/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.1112\n",
      "Epoch 776/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0560\n",
      "Epoch 777/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4157 - val_loss: 670.1101\n",
      "Epoch 778/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.0635\n",
      "Epoch 779/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4152 - val_loss: 670.0764\n",
      "Epoch 780/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0641\n",
      "Epoch 781/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0770\n",
      "Epoch 782/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4167 - val_loss: 670.0928\n",
      "Epoch 783/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4156 - val_loss: 670.1108\n",
      "Epoch 784/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0869\n",
      "Epoch 785/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4172 - val_loss: 670.0528\n",
      "Epoch 786/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4173 - val_loss: 670.1252\n",
      "Epoch 787/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4162 - val_loss: 670.1003\n",
      "Epoch 788/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.0432\n",
      "Epoch 789/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0840\n",
      "Epoch 790/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4176 - val_loss: 670.0181\n",
      "Epoch 791/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4180 - val_loss: 670.1177\n",
      "Epoch 792/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4201 - val_loss: 670.0465\n",
      "Epoch 793/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4175 - val_loss: 670.0433\n",
      "Epoch 794/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4158 - val_loss: 670.0928\n",
      "Epoch 795/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4174 - val_loss: 670.0857\n",
      "Epoch 796/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4180 - val_loss: 670.0469\n",
      "Epoch 797/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4174 - val_loss: 670.0496\n",
      "Epoch 798/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4175 - val_loss: 670.0513\n",
      "Epoch 799/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.0812\n",
      "Epoch 800/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4169 - val_loss: 670.1266\n",
      "Epoch 801/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.1193\n",
      "Epoch 802/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4155 - val_loss: 670.0671\n",
      "Epoch 803/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.0756\n",
      "Epoch 804/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4158 - val_loss: 670.0856\n",
      "Epoch 805/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.1087\n",
      "Epoch 806/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.1191\n",
      "Epoch 807/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4152 - val_loss: 670.0853\n",
      "Epoch 808/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4153 - val_loss: 670.0818\n",
      "Epoch 809/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.1107\n",
      "Epoch 810/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4150 - val_loss: 670.0663\n",
      "Epoch 811/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.0513\n",
      "Epoch 812/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4166 - val_loss: 670.0708\n",
      "Epoch 813/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.1025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4167 - val_loss: 670.0447\n",
      "Epoch 815/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.0968\n",
      "Epoch 816/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4163 - val_loss: 670.1039\n",
      "Epoch 817/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4156 - val_loss: 670.1099\n",
      "Epoch 818/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4159 - val_loss: 670.0610\n",
      "Epoch 819/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4171 - val_loss: 670.0801\n",
      "Epoch 820/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4172 - val_loss: 670.0998\n",
      "Epoch 821/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4177 - val_loss: 670.1011\n",
      "Epoch 822/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4181 - val_loss: 670.0915\n",
      "Epoch 823/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4182 - val_loss: 670.0723\n",
      "Epoch 824/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4178 - val_loss: 670.0421\n",
      "Epoch 825/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4164 - val_loss: 670.1307\n",
      "Epoch 826/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.0857\n",
      "Epoch 827/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4168 - val_loss: 670.0967\n",
      "Epoch 828/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4174 - val_loss: 670.0895\n",
      "Epoch 829/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4155 - val_loss: 670.1219\n",
      "Epoch 830/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0635\n",
      "Epoch 831/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4161 - val_loss: 670.0821\n",
      "Epoch 832/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4155 - val_loss: 670.1022\n",
      "Epoch 833/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4151 - val_loss: 670.0903\n",
      "Epoch 834/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.0906\n",
      "Epoch 835/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4165 - val_loss: 670.0761\n",
      "Epoch 836/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4160 - val_loss: 670.0923\n",
      "Epoch 837/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4162 - val_loss: 670.1058\n",
      "Epoch 838/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4158 - val_loss: 670.1083\n",
      "Epoch 839/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4182 - val_loss: 670.1053\n",
      "Epoch 840/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4180 - val_loss: 670.1346\n",
      "Epoch 841/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4147 - val_loss: 670.1350\n",
      "Epoch 842/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4171 - val_loss: 670.1388\n",
      "Epoch 843/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4157 - val_loss: 670.1129\n",
      "Epoch 844/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.1119\n",
      "Epoch 845/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4163 - val_loss: 670.0995\n",
      "Epoch 846/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4167 - val_loss: 670.1106\n",
      "Epoch 847/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4172 - val_loss: 670.1022\n",
      "Epoch 848/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4164 - val_loss: 670.1437\n",
      "Epoch 849/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.0798\n",
      "Epoch 850/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4158 - val_loss: 670.1144\n",
      "Epoch 851/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4180 - val_loss: 670.1405\n",
      "Epoch 852/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4153 - val_loss: 670.0785\n",
      "Epoch 853/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4154 - val_loss: 670.1115\n",
      "Epoch 854/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4192 - val_loss: 670.0780\n",
      "Epoch 855/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4185 - val_loss: 670.1057\n",
      "Epoch 856/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.1100\n",
      "Epoch 857/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4179 - val_loss: 670.1033\n",
      "Epoch 858/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4154 - val_loss: 670.0887\n",
      "Epoch 859/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4153 - val_loss: 670.0818\n",
      "Epoch 860/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4153 - val_loss: 670.1124\n",
      "Epoch 861/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4174 - val_loss: 670.1448\n",
      "Epoch 862/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.0539\n",
      "Epoch 863/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4170 - val_loss: 670.0998\n",
      "Epoch 864/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4154 - val_loss: 670.0917\n",
      "Epoch 865/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4181 - val_loss: 670.0934\n",
      "Epoch 866/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4169 - val_loss: 670.1435\n",
      "Epoch 867/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4156 - val_loss: 670.1475\n",
      "Epoch 868/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4161 - val_loss: 670.0659\n",
      "Epoch 869/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.1466\n",
      "Epoch 870/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.1285\n",
      "Epoch 871/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4154 - val_loss: 670.1279\n",
      "Epoch 872/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4152 - val_loss: 670.1218\n",
      "Epoch 873/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4162 - val_loss: 670.1269\n",
      "Epoch 874/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4165 - val_loss: 670.1047\n",
      "Epoch 875/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4167 - val_loss: 670.1454\n",
      "Epoch 876/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4153 - val_loss: 670.1278\n",
      "Epoch 877/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4177 - val_loss: 670.1116\n",
      "Epoch 878/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4166 - val_loss: 670.0936\n",
      "Epoch 879/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4157 - val_loss: 670.1133\n",
      "Epoch 880/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4153 - val_loss: 670.1362\n",
      "Epoch 881/1000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411.4168 - val_loss: 670.1190\n",
      "Epoch 882/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.1056\n",
      "Epoch 883/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4160 - val_loss: 670.0866\n",
      "Epoch 884/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4160 - val_loss: 670.0828\n",
      "Epoch 885/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4170 - val_loss: 670.1070\n",
      "Epoch 886/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.0703\n",
      "Epoch 887/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4161 - val_loss: 670.1100\n",
      "Epoch 888/1000\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 411.4165 - val_loss: 670.1349\n",
      "Epoch 889/1000\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 411.4180 - val_loss: 670.1198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 890/1000\n",
      "289/289 [==============================] - 0s 1ms/step - loss: 411.4154 - val_loss: 670.1390\n",
      "Epoch 891/1000\n",
      "289/289 [==============================] - 0s 934us/step - loss: 411.4161 - val_loss: 670.0742\n",
      "Epoch 892/1000\n",
      "289/289 [==============================] - 0s 949us/step - loss: 411.4160 - val_loss: 670.1237\n",
      "Epoch 893/1000\n",
      "289/289 [==============================] - 0s 891us/step - loss: 411.4159 - val_loss: 670.1760\n",
      "Epoch 894/1000\n",
      "289/289 [==============================] - 0s 932us/step - loss: 411.4163 - val_loss: 670.1296\n",
      "Epoch 895/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 411.4167 - val_loss: 670.1020\n",
      "Epoch 896/1000\n",
      "289/289 [==============================] - 0s 870us/step - loss: 411.4172 - val_loss: 670.1049\n",
      "Epoch 897/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 411.4166 - val_loss: 670.1000\n",
      "Epoch 898/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 411.4162 - val_loss: 670.0969\n",
      "Epoch 899/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4170 - val_loss: 670.1191\n",
      "Epoch 900/1000\n",
      "289/289 [==============================] - 0s 829us/step - loss: 411.4168 - val_loss: 670.0655\n",
      "Epoch 901/1000\n",
      "289/289 [==============================] - 0s 899us/step - loss: 411.4166 - val_loss: 670.0667\n",
      "Epoch 902/1000\n",
      "289/289 [==============================] - 0s 943us/step - loss: 411.4176 - val_loss: 670.1609\n",
      "Epoch 903/1000\n",
      "289/289 [==============================] - 0s 905us/step - loss: 411.4154 - val_loss: 670.1530\n",
      "Epoch 904/1000\n",
      "289/289 [==============================] - 0s 837us/step - loss: 411.4161 - val_loss: 670.1458\n",
      "Epoch 905/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 411.4184 - val_loss: 670.0728\n",
      "Epoch 906/1000\n",
      "289/289 [==============================] - 0s 967us/step - loss: 411.4164 - val_loss: 670.0944\n",
      "Epoch 907/1000\n",
      "289/289 [==============================] - 0s 841us/step - loss: 411.4177 - val_loss: 670.1136\n",
      "Epoch 908/1000\n",
      "289/289 [==============================] - 0s 815us/step - loss: 411.4153 - val_loss: 670.1146\n",
      "Epoch 909/1000\n",
      "289/289 [==============================] - 0s 897us/step - loss: 411.4156 - val_loss: 670.1091\n",
      "Epoch 910/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 411.4157 - val_loss: 670.0980\n",
      "Epoch 911/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 411.4171 - val_loss: 670.1033\n",
      "Epoch 912/1000\n",
      "289/289 [==============================] - 0s 835us/step - loss: 411.4164 - val_loss: 670.0923\n",
      "Epoch 913/1000\n",
      "289/289 [==============================] - 0s 923us/step - loss: 411.4153 - val_loss: 670.1143\n",
      "Epoch 914/1000\n",
      "289/289 [==============================] - 0s 804us/step - loss: 411.4172 - val_loss: 670.0738\n",
      "Epoch 915/1000\n",
      "289/289 [==============================] - 0s 862us/step - loss: 411.4159 - val_loss: 670.0807\n",
      "Epoch 916/1000\n",
      "289/289 [==============================] - 0s 903us/step - loss: 411.4158 - val_loss: 670.0568\n",
      "Epoch 917/1000\n",
      "289/289 [==============================] - 0s 852us/step - loss: 411.4169 - val_loss: 670.0616\n",
      "Epoch 918/1000\n",
      "289/289 [==============================] - 0s 879us/step - loss: 411.4166 - val_loss: 670.0894\n",
      "Epoch 919/1000\n",
      "289/289 [==============================] - 0s 865us/step - loss: 411.4176 - val_loss: 670.1093\n",
      "Epoch 920/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4164 - val_loss: 670.0781\n",
      "Epoch 921/1000\n",
      "289/289 [==============================] - 0s 860us/step - loss: 411.4166 - val_loss: 670.1091\n",
      "Epoch 922/1000\n",
      "289/289 [==============================] - 0s 821us/step - loss: 411.4167 - val_loss: 670.1464\n",
      "Epoch 923/1000\n",
      "289/289 [==============================] - 0s 848us/step - loss: 411.4174 - val_loss: 670.0928\n",
      "Epoch 924/1000\n",
      "289/289 [==============================] - 0s 874us/step - loss: 411.4156 - val_loss: 670.0803\n",
      "Epoch 925/1000\n",
      "289/289 [==============================] - 0s 922us/step - loss: 411.4157 - val_loss: 670.1222\n",
      "Epoch 926/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4171 - val_loss: 670.1672\n",
      "Epoch 927/1000\n",
      "289/289 [==============================] - 0s 876us/step - loss: 411.4169 - val_loss: 670.1382\n",
      "Epoch 928/1000\n",
      "289/289 [==============================] - 0s 813us/step - loss: 411.4152 - val_loss: 670.1060\n",
      "Epoch 929/1000\n",
      "289/289 [==============================] - 0s 869us/step - loss: 411.4165 - val_loss: 670.1046\n",
      "Epoch 930/1000\n",
      "289/289 [==============================] - 0s 875us/step - loss: 411.4161 - val_loss: 670.0798\n",
      "Epoch 931/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4164 - val_loss: 670.1150\n",
      "Epoch 932/1000\n",
      "289/289 [==============================] - 0s 792us/step - loss: 411.4166 - val_loss: 670.1230\n",
      "Epoch 933/1000\n",
      "289/289 [==============================] - 0s 817us/step - loss: 411.4152 - val_loss: 670.1190\n",
      "Epoch 934/1000\n",
      "289/289 [==============================] - 0s 836us/step - loss: 411.4151 - val_loss: 670.0944\n",
      "Epoch 935/1000\n",
      "289/289 [==============================] - 0s 784us/step - loss: 411.4162 - val_loss: 670.1028\n",
      "Epoch 936/1000\n",
      "289/289 [==============================] - 0s 807us/step - loss: 411.4172 - val_loss: 670.1065\n",
      "Epoch 937/1000\n",
      "289/289 [==============================] - 0s 790us/step - loss: 411.4161 - val_loss: 670.1220\n",
      "Epoch 938/1000\n",
      "289/289 [==============================] - 0s 861us/step - loss: 411.4169 - val_loss: 670.0757\n",
      "Epoch 939/1000\n",
      "289/289 [==============================] - 0s 892us/step - loss: 411.4174 - val_loss: 670.0773\n",
      "Epoch 940/1000\n",
      "289/289 [==============================] - 0s 856us/step - loss: 411.4171 - val_loss: 670.0621\n",
      "Epoch 941/1000\n",
      "289/289 [==============================] - 0s 899us/step - loss: 411.4152 - val_loss: 670.0985\n",
      "Epoch 942/1000\n",
      "289/289 [==============================] - 0s 911us/step - loss: 411.4181 - val_loss: 670.1053\n",
      "Epoch 943/1000\n",
      "289/289 [==============================] - 0s 936us/step - loss: 411.4166 - val_loss: 670.0985\n",
      "Epoch 944/1000\n",
      "289/289 [==============================] - 0s 972us/step - loss: 411.4154 - val_loss: 670.1298\n",
      "Epoch 945/1000\n",
      "289/289 [==============================] - 0s 890us/step - loss: 411.4163 - val_loss: 670.0596\n",
      "Epoch 946/1000\n",
      "289/289 [==============================] - 0s 863us/step - loss: 411.4179 - val_loss: 670.1563\n",
      "Epoch 947/1000\n",
      "289/289 [==============================] - 0s 781us/step - loss: 411.4158 - val_loss: 670.1007\n",
      "Epoch 948/1000\n",
      "289/289 [==============================] - 0s 794us/step - loss: 411.4166 - val_loss: 670.0956\n",
      "Epoch 949/1000\n",
      "289/289 [==============================] - 0s 854us/step - loss: 411.4167 - val_loss: 670.0905\n",
      "Epoch 950/1000\n",
      "289/289 [==============================] - 0s 949us/step - loss: 411.4158 - val_loss: 670.0935\n",
      "Epoch 951/1000\n",
      "289/289 [==============================] - 0s 931us/step - loss: 411.4153 - val_loss: 670.1475\n",
      "Epoch 952/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 411.4174 - val_loss: 670.0687\n",
      "Epoch 953/1000\n",
      "289/289 [==============================] - 0s 834us/step - loss: 411.4165 - val_loss: 670.1450\n",
      "Epoch 954/1000\n",
      "289/289 [==============================] - 0s 844us/step - loss: 411.4157 - val_loss: 670.1382\n",
      "Epoch 955/1000\n",
      "289/289 [==============================] - 0s 820us/step - loss: 411.4158 - val_loss: 670.1284\n",
      "Epoch 956/1000\n",
      "289/289 [==============================] - 0s 894us/step - loss: 411.4161 - val_loss: 670.1078\n",
      "Epoch 957/1000\n",
      "289/289 [==============================] - 0s 969us/step - loss: 411.4158 - val_loss: 670.1125\n",
      "Epoch 958/1000\n",
      "289/289 [==============================] - 0s 873us/step - loss: 411.4167 - val_loss: 670.1271\n",
      "Epoch 959/1000\n",
      "289/289 [==============================] - 0s 932us/step - loss: 411.4166 - val_loss: 670.1195\n",
      "Epoch 960/1000\n",
      "289/289 [==============================] - 0s 885us/step - loss: 411.4155 - val_loss: 670.1475\n",
      "Epoch 961/1000\n",
      "289/289 [==============================] - 0s 926us/step - loss: 411.4151 - val_loss: 670.0995\n",
      "Epoch 962/1000\n",
      "289/289 [==============================] - 0s 938us/step - loss: 411.4169 - val_loss: 670.1237\n",
      "Epoch 963/1000\n",
      "289/289 [==============================] - 0s 840us/step - loss: 411.4165 - val_loss: 670.1103\n",
      "Epoch 964/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 779us/step - loss: 411.4156 - val_loss: 670.1448\n",
      "Epoch 965/1000\n",
      "289/289 [==============================] - 0s 805us/step - loss: 411.4160 - val_loss: 670.1233\n",
      "Epoch 966/1000\n",
      "289/289 [==============================] - 0s 785us/step - loss: 411.4156 - val_loss: 670.1265\n",
      "Epoch 967/1000\n",
      "289/289 [==============================] - 0s 856us/step - loss: 411.4169 - val_loss: 670.0591\n",
      "Epoch 968/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4178 - val_loss: 670.1599\n",
      "Epoch 969/1000\n",
      "289/289 [==============================] - 0s 846us/step - loss: 411.4169 - val_loss: 670.1230\n",
      "Epoch 970/1000\n",
      "289/289 [==============================] - 0s 864us/step - loss: 411.4160 - val_loss: 670.1091\n",
      "Epoch 971/1000\n",
      "289/289 [==============================] - 0s 871us/step - loss: 411.4158 - val_loss: 670.0868\n",
      "Epoch 972/1000\n",
      "289/289 [==============================] - 0s 790us/step - loss: 411.4179 - val_loss: 670.1400\n",
      "Epoch 973/1000\n",
      "289/289 [==============================] - 0s 997us/step - loss: 411.4164 - val_loss: 670.1421\n",
      "Epoch 974/1000\n",
      "289/289 [==============================] - 0s 906us/step - loss: 411.4154 - val_loss: 670.1053\n",
      "Epoch 975/1000\n",
      "289/289 [==============================] - 0s 845us/step - loss: 411.4160 - val_loss: 670.1097\n",
      "Epoch 976/1000\n",
      "289/289 [==============================] - 0s 874us/step - loss: 411.4161 - val_loss: 670.0781\n",
      "Epoch 977/1000\n",
      "289/289 [==============================] - 0s 849us/step - loss: 411.4157 - val_loss: 670.0962\n",
      "Epoch 978/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4162 - val_loss: 670.1061\n",
      "Epoch 979/1000\n",
      "289/289 [==============================] - 0s 783us/step - loss: 411.4161 - val_loss: 670.1094\n",
      "Epoch 980/1000\n",
      "289/289 [==============================] - 0s 878us/step - loss: 411.4154 - val_loss: 670.0970\n",
      "Epoch 981/1000\n",
      "289/289 [==============================] - 0s 809us/step - loss: 411.4168 - val_loss: 670.1044\n",
      "Epoch 982/1000\n",
      "289/289 [==============================] - 0s 782us/step - loss: 411.4178 - val_loss: 670.1127\n",
      "Epoch 983/1000\n",
      "289/289 [==============================] - 0s 866us/step - loss: 411.4166 - val_loss: 670.1028\n",
      "Epoch 984/1000\n",
      "289/289 [==============================] - 0s 755us/step - loss: 411.4160 - val_loss: 670.0779\n",
      "Epoch 985/1000\n",
      "289/289 [==============================] - 0s 886us/step - loss: 411.4163 - val_loss: 670.1022\n",
      "Epoch 986/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 411.4153 - val_loss: 670.1055\n",
      "Epoch 987/1000\n",
      "289/289 [==============================] - 0s 857us/step - loss: 411.4174 - val_loss: 670.0914\n",
      "Epoch 988/1000\n",
      "289/289 [==============================] - 0s 811us/step - loss: 411.4189 - val_loss: 670.1273\n",
      "Epoch 989/1000\n",
      "289/289 [==============================] - 0s 843us/step - loss: 411.4162 - val_loss: 670.1108\n",
      "Epoch 990/1000\n",
      "289/289 [==============================] - 0s 799us/step - loss: 411.4176 - val_loss: 670.1033\n",
      "Epoch 991/1000\n",
      "289/289 [==============================] - 0s 828us/step - loss: 411.4196 - val_loss: 670.1602\n",
      "Epoch 992/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 411.4168 - val_loss: 670.1232\n",
      "Epoch 993/1000\n",
      "289/289 [==============================] - 0s 816us/step - loss: 411.4173 - val_loss: 670.1004\n",
      "Epoch 994/1000\n",
      "289/289 [==============================] - 0s 797us/step - loss: 411.4170 - val_loss: 670.1003\n",
      "Epoch 995/1000\n",
      "289/289 [==============================] - 0s 901us/step - loss: 411.4172 - val_loss: 670.1340\n",
      "Epoch 996/1000\n",
      "289/289 [==============================] - 0s 831us/step - loss: 411.4164 - val_loss: 670.1495\n",
      "Epoch 997/1000\n",
      "289/289 [==============================] - 0s 814us/step - loss: 411.4167 - val_loss: 670.0927\n",
      "Epoch 998/1000\n",
      "289/289 [==============================] - 0s 851us/step - loss: 411.4166 - val_loss: 670.1179\n",
      "Epoch 999/1000\n",
      "289/289 [==============================] - 0s 808us/step - loss: 411.4169 - val_loss: 670.1577\n",
      "Epoch 1000/1000\n",
      "289/289 [==============================] - 0s 832us/step - loss: 411.4156 - val_loss: 670.1353\n",
      "66/66 [==============================] - 0s 498us/step\n",
      "689753 successful\n",
      "Epoch 1/1000\n",
      "320/320 [==============================] - 1s 964us/step - loss: 111535896.0000 - val_loss: 640.3176\n",
      "Epoch 2/1000\n",
      "320/320 [==============================] - 0s 780us/step - loss: 332.7872 - val_loss: 759.7542\n",
      "Epoch 3/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 337.0701 - val_loss: 643.9401\n",
      "Epoch 4/1000\n",
      "320/320 [==============================] - 0s 796us/step - loss: 340.0969 - val_loss: 606.8678\n",
      "Epoch 5/1000\n",
      "320/320 [==============================] - 0s 783us/step - loss: 359.2371 - val_loss: 709.3022\n",
      "Epoch 6/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 348.8002 - val_loss: 602.7874\n",
      "Epoch 7/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 363.0086 - val_loss: 608.3472\n",
      "Epoch 8/1000\n",
      "320/320 [==============================] - 0s 849us/step - loss: 365.6725 - val_loss: 611.1189\n",
      "Epoch 9/1000\n",
      "320/320 [==============================] - 0s 824us/step - loss: 377.4344 - val_loss: 636.5237\n",
      "Epoch 10/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 391.7129 - val_loss: 644.8176\n",
      "Epoch 11/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 446.8802 - val_loss: 594.1233\n",
      "Epoch 12/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 468.8480 - val_loss: 835.3882\n",
      "Epoch 13/1000\n",
      "320/320 [==============================] - 0s 906us/step - loss: 439.1221 - val_loss: 823.4122\n",
      "Epoch 14/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 502.9620 - val_loss: 829.5080\n",
      "Epoch 15/1000\n",
      "320/320 [==============================] - 0s 825us/step - loss: 626.8143 - val_loss: 693.1590\n",
      "Epoch 16/1000\n",
      "320/320 [==============================] - 0s 989us/step - loss: 707.0212 - val_loss: 719.4247\n",
      "Epoch 17/1000\n",
      "320/320 [==============================] - 0s 833us/step - loss: 964.4324 - val_loss: 4047.7856\n",
      "Epoch 18/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 4710.1426 - val_loss: 13939.7988\n",
      "Epoch 19/1000\n",
      "320/320 [==============================] - 0s 834us/step - loss: 122056.0625 - val_loss: 95600.8828\n",
      "Epoch 20/1000\n",
      "320/320 [==============================] - 0s 858us/step - loss: 113983.7656 - val_loss: 51025.9648\n",
      "Epoch 21/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 90897.8906 - val_loss: 35428.2344\n",
      "Epoch 22/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 120592.1094 - val_loss: 629.0220\n",
      "Epoch 23/1000\n",
      "320/320 [==============================] - 0s 855us/step - loss: 96530.2656 - val_loss: 146177.4844\n",
      "Epoch 24/1000\n",
      "320/320 [==============================] - 0s 864us/step - loss: 103839.5078 - val_loss: 3778.9016\n",
      "Epoch 25/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 102421.4844 - val_loss: 205933.9688\n",
      "Epoch 26/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 97507.7656 - val_loss: 7170.1528\n",
      "Epoch 27/1000\n",
      "320/320 [==============================] - 0s 978us/step - loss: 107181.2266 - val_loss: 36329.9297\n",
      "Epoch 28/1000\n",
      "320/320 [==============================] - 0s 858us/step - loss: 107798.1719 - val_loss: 25437.8691\n",
      "Epoch 29/1000\n",
      "320/320 [==============================] - 0s 923us/step - loss: 79066.5703 - val_loss: 290590.5312\n",
      "Epoch 30/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 99245.5234 - val_loss: 116076.4922\n",
      "Epoch 31/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 84816.3594 - val_loss: 3784.6028\n",
      "Epoch 32/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 86982.8281 - val_loss: 115493.2266\n",
      "Epoch 33/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 100574.6484 - val_loss: 94704.2656\n",
      "Epoch 34/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 74932.6172 - val_loss: 12584.2744\n",
      "Epoch 35/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 85965.7734 - val_loss: 331455.0312\n",
      "Epoch 36/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 89285.3281 - val_loss: 6123.5977\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 927us/step - loss: 73763.5391 - val_loss: 253816.5000\n",
      "Epoch 38/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 84012.4844 - val_loss: 177123.7812\n",
      "Epoch 39/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 70740.0156 - val_loss: 29936.2285\n",
      "Epoch 40/1000\n",
      "320/320 [==============================] - 0s 833us/step - loss: 94050.2109 - val_loss: 225017.2812\n",
      "Epoch 41/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 52493.7383 - val_loss: 78291.4062\n",
      "Epoch 42/1000\n",
      "320/320 [==============================] - 0s 901us/step - loss: 65702.9297 - val_loss: 14069.8574\n",
      "Epoch 43/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 75191.7969 - val_loss: 33752.6680\n",
      "Epoch 44/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 63027.8320 - val_loss: 2611.3777\n",
      "Epoch 45/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 67584.0000 - val_loss: 78145.3281\n",
      "Epoch 46/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 78494.8047 - val_loss: 36771.9336\n",
      "Epoch 47/1000\n",
      "320/320 [==============================] - 0s 915us/step - loss: 41347.5859 - val_loss: 1888.7761\n",
      "Epoch 48/1000\n",
      "320/320 [==============================] - 0s 928us/step - loss: 61443.5820 - val_loss: 6381.3027\n",
      "Epoch 49/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 61151.0703 - val_loss: 596388.7500\n",
      "Epoch 50/1000\n",
      "320/320 [==============================] - 0s 899us/step - loss: 57952.1758 - val_loss: 635.9000\n",
      "Epoch 51/1000\n",
      "320/320 [==============================] - 0s 937us/step - loss: 2459624.5000 - val_loss: 36427.1719\n",
      "Epoch 52/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 879.1107 - val_loss: 648.3398\n",
      "Epoch 53/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 402.5546 - val_loss: 593.2598\n",
      "Epoch 54/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 439.4899 - val_loss: 921.9290\n",
      "Epoch 55/1000\n",
      "320/320 [==============================] - 0s 936us/step - loss: 403.1886 - val_loss: 598.2621\n",
      "Epoch 56/1000\n",
      "320/320 [==============================] - 0s 864us/step - loss: 504.4069 - val_loss: 677.2372\n",
      "Epoch 57/1000\n",
      "320/320 [==============================] - 0s 861us/step - loss: 641.2565 - val_loss: 1177.2294\n",
      "Epoch 58/1000\n",
      "320/320 [==============================] - 0s 846us/step - loss: 635.5887 - val_loss: 1839.2195\n",
      "Epoch 59/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 944.0381 - val_loss: 764.7851\n",
      "Epoch 60/1000\n",
      "320/320 [==============================] - 0s 902us/step - loss: 2232.1494 - val_loss: 589.4845\n",
      "Epoch 61/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 31492.1094 - val_loss: 39387.5547\n",
      "Epoch 62/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 38487.3008 - val_loss: 33815.2539\n",
      "Epoch 63/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 40615.6094 - val_loss: 1512.9724\n",
      "Epoch 64/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 39006.3750 - val_loss: 26148.9844\n",
      "Epoch 65/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 39684.6836 - val_loss: 31587.7051\n",
      "Epoch 66/1000\n",
      "320/320 [==============================] - 0s 965us/step - loss: 39372.4219 - val_loss: 1873.8206\n",
      "Epoch 67/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 33076.6680 - val_loss: 3091.1904\n",
      "Epoch 68/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 34500.6016 - val_loss: 9270.6729\n",
      "Epoch 69/1000\n",
      "320/320 [==============================] - 0s 862us/step - loss: 36008.6016 - val_loss: 34794.0078\n",
      "Epoch 70/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 32762.1973 - val_loss: 84194.2266\n",
      "Epoch 71/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 32005.6973 - val_loss: 13009.2109\n",
      "Epoch 72/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 30916.7539 - val_loss: 38291.8047\n",
      "Epoch 73/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 35877.2891 - val_loss: 1965.6260\n",
      "Epoch 74/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 24717.5977 - val_loss: 33542.9492\n",
      "Epoch 75/1000\n",
      "320/320 [==============================] - 0s 996us/step - loss: 29964.3320 - val_loss: 14458.3789\n",
      "Epoch 76/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 31034.3867 - val_loss: 2033.5092\n",
      "Epoch 77/1000\n",
      "320/320 [==============================] - 0s 957us/step - loss: 25520.9414 - val_loss: 46447.2852\n",
      "Epoch 78/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 25285.6289 - val_loss: 5610.8550\n",
      "Epoch 79/1000\n",
      "320/320 [==============================] - 0s 915us/step - loss: 26208.7227 - val_loss: 6386.3833\n",
      "Epoch 80/1000\n",
      "320/320 [==============================] - 0s 960us/step - loss: 24893.8867 - val_loss: 10155.7334\n",
      "Epoch 81/1000\n",
      "320/320 [==============================] - 0s 971us/step - loss: 11648.7188 - val_loss: 629.5471\n",
      "Epoch 82/1000\n",
      "320/320 [==============================] - 0s 920us/step - loss: 21687.9141 - val_loss: 5996.8145\n",
      "Epoch 83/1000\n",
      "320/320 [==============================] - 0s 953us/step - loss: 18180.9023 - val_loss: 13612.6309\n",
      "Epoch 84/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 21573.4883 - val_loss: 9600.4365\n",
      "Epoch 85/1000\n",
      "320/320 [==============================] - 0s 839us/step - loss: 20610.0586 - val_loss: 8389.4209\n",
      "Epoch 86/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 22549.9492 - val_loss: 612.2779\n",
      "Epoch 87/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 13322.7324 - val_loss: 7512.8745\n",
      "Epoch 88/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 18929.9512 - val_loss: 3027.9363\n",
      "Epoch 89/1000\n",
      "320/320 [==============================] - 0s 912us/step - loss: 17138.5449 - val_loss: 1031.7833\n",
      "Epoch 90/1000\n",
      "320/320 [==============================] - 0s 946us/step - loss: 20548.0234 - val_loss: 39055.1445\n",
      "Epoch 91/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 19444.4160 - val_loss: 632.8966\n",
      "Epoch 92/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 15115.2080 - val_loss: 12339.5156\n",
      "Epoch 93/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 16186.3643 - val_loss: 27315.0684\n",
      "Epoch 94/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 18493.8086 - val_loss: 1500.2615\n",
      "Epoch 95/1000\n",
      "320/320 [==============================] - 0s 963us/step - loss: 14904.7363 - val_loss: 45243.2461\n",
      "Epoch 96/1000\n",
      "320/320 [==============================] - 0s 982us/step - loss: 18167.3926 - val_loss: 9199.1328\n",
      "Epoch 97/1000\n",
      "320/320 [==============================] - 0s 933us/step - loss: 15663.4424 - val_loss: 12487.2646\n",
      "Epoch 98/1000\n",
      "320/320 [==============================] - 0s 945us/step - loss: 12451.0439 - val_loss: 4183.3950\n",
      "Epoch 99/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 15450.4326 - val_loss: 4216.1938\n",
      "Epoch 100/1000\n",
      "320/320 [==============================] - 0s 998us/step - loss: 14156.4795 - val_loss: 1943.3807\n",
      "Epoch 101/1000\n",
      "320/320 [==============================] - 0s 926us/step - loss: 14415.6250 - val_loss: 11195.5518\n",
      "Epoch 102/1000\n",
      "320/320 [==============================] - 0s 987us/step - loss: 15713.5059 - val_loss: 15710.1133\n",
      "Epoch 103/1000\n",
      "320/320 [==============================] - 0s 920us/step - loss: 11272.7734 - val_loss: 1107.9006\n",
      "Epoch 104/1000\n",
      "320/320 [==============================] - 0s 911us/step - loss: 13694.4160 - val_loss: 5218.4941\n",
      "Epoch 105/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 11483.5654 - val_loss: 56510.3945\n",
      "Epoch 106/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 11842.3691 - val_loss: 12369.9932\n",
      "Epoch 107/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 12392.9854 - val_loss: 11867.6318\n",
      "Epoch 108/1000\n",
      "320/320 [==============================] - 0s 890us/step - loss: 14149.5801 - val_loss: 19568.8066\n",
      "Epoch 109/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 11427.4014 - val_loss: 10732.9043\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 924us/step - loss: 10819.1387 - val_loss: 26304.9902\n",
      "Epoch 111/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 9891.5967 - val_loss: 5403.6021\n",
      "Epoch 112/1000\n",
      "320/320 [==============================] - 0s 941us/step - loss: 13282.6699 - val_loss: 6493.7319\n",
      "Epoch 113/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 10188.6396 - val_loss: 8528.5840\n",
      "Epoch 114/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 11782.3730 - val_loss: 4550.8315\n",
      "Epoch 115/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 10246.4297 - val_loss: 20693.4395\n",
      "Epoch 116/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 7990.0781 - val_loss: 15884.6387\n",
      "Epoch 117/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 10516.5762 - val_loss: 1265.8334\n",
      "Epoch 118/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 8287.7979 - val_loss: 11263.4141\n",
      "Epoch 119/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 10185.2061 - val_loss: 2170.3523\n",
      "Epoch 120/1000\n",
      "320/320 [==============================] - 0s 912us/step - loss: 9114.1699 - val_loss: 7832.9839\n",
      "Epoch 121/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 8795.2480 - val_loss: 4258.9185\n",
      "Epoch 122/1000\n",
      "320/320 [==============================] - 0s 913us/step - loss: 8640.2061 - val_loss: 36354.5820\n",
      "Epoch 123/1000\n",
      "320/320 [==============================] - 0s 970us/step - loss: 8971.0938 - val_loss: 36947.1328\n",
      "Epoch 124/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 163952.0469 - val_loss: 80639.4219\n",
      "Epoch 125/1000\n",
      "320/320 [==============================] - 0s 990us/step - loss: 2332.4482 - val_loss: 592.0613\n",
      "Epoch 126/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 448.3381 - val_loss: 1501.6346\n",
      "Epoch 127/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 439.1208 - val_loss: 590.7931\n",
      "Epoch 128/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 668.2992 - val_loss: 589.7318\n",
      "Epoch 129/1000\n",
      "320/320 [==============================] - 0s 936us/step - loss: 724.6893 - val_loss: 705.9939\n",
      "Epoch 130/1000\n",
      "320/320 [==============================] - 0s 963us/step - loss: 847.5073 - val_loss: 958.8857\n",
      "Epoch 131/1000\n",
      "320/320 [==============================] - 0s 880us/step - loss: 1376.7562 - val_loss: 1016.0143\n",
      "Epoch 132/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 3775.0984 - val_loss: 2632.0427\n",
      "Epoch 133/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 7064.1084 - val_loss: 8154.5225\n",
      "Epoch 134/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 5767.5923 - val_loss: 18927.3457\n",
      "Epoch 135/1000\n",
      "320/320 [==============================] - 0s 818us/step - loss: 6883.9570 - val_loss: 3206.7715\n",
      "Epoch 136/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 4447.4082 - val_loss: 11481.7891\n",
      "Epoch 137/1000\n",
      "320/320 [==============================] - 0s 789us/step - loss: 5223.0029 - val_loss: 12821.7676\n",
      "Epoch 138/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 6504.2349 - val_loss: 17650.4121\n",
      "Epoch 139/1000\n",
      "320/320 [==============================] - 0s 794us/step - loss: 3389.5562 - val_loss: 7268.3467\n",
      "Epoch 140/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 4593.4834 - val_loss: 4095.7881\n",
      "Epoch 141/1000\n",
      "320/320 [==============================] - 0s 963us/step - loss: 4829.8462 - val_loss: 4501.0088\n",
      "Epoch 142/1000\n",
      "320/320 [==============================] - 0s 909us/step - loss: 4168.4092 - val_loss: 689.0182\n",
      "Epoch 143/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 4103.7891 - val_loss: 11642.6357\n",
      "Epoch 144/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 4016.0591 - val_loss: 824.8760\n",
      "Epoch 145/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 4548.6748 - val_loss: 626.5961\n",
      "Epoch 146/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 4236.5381 - val_loss: 9303.2236\n",
      "Epoch 147/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 3820.5833 - val_loss: 9328.3428\n",
      "Epoch 148/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 3239.8403 - val_loss: 6340.3628\n",
      "Epoch 149/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 4495.5752 - val_loss: 12346.8652\n",
      "Epoch 150/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3347.6987 - val_loss: 7350.7686\n",
      "Epoch 151/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3496.1531 - val_loss: 2901.2969\n",
      "Epoch 152/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3844.0344 - val_loss: 8391.6074\n",
      "Epoch 153/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3375.6050 - val_loss: 829.9620\n",
      "Epoch 154/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2789.4951 - val_loss: 3018.2510\n",
      "Epoch 155/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2824.9685 - val_loss: 6661.4902\n",
      "Epoch 156/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2762.0515 - val_loss: 1133.9625\n",
      "Epoch 157/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3148.8772 - val_loss: 3523.0610\n",
      "Epoch 158/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2427.6909 - val_loss: 1356.2817\n",
      "Epoch 159/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 3432.5996 - val_loss: 7648.3477\n",
      "Epoch 160/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1986.1270 - val_loss: 2155.3171\n",
      "Epoch 161/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 3678.0417 - val_loss: 7228.7339\n",
      "Epoch 162/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2433.2131 - val_loss: 673.5927\n",
      "Epoch 163/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2354.3623 - val_loss: 3310.1838\n",
      "Epoch 164/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2557.2300 - val_loss: 4512.3936\n",
      "Epoch 165/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1841.4293 - val_loss: 1333.2294\n",
      "Epoch 166/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2601.9868 - val_loss: 8206.4707\n",
      "Epoch 167/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2196.8462 - val_loss: 4639.4355\n",
      "Epoch 168/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2764.2358 - val_loss: 608.7726\n",
      "Epoch 169/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1268.6272 - val_loss: 1793.0309\n",
      "Epoch 170/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2707.3999 - val_loss: 1225.0868\n",
      "Epoch 171/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2344.7090 - val_loss: 1197.7177\n",
      "Epoch 172/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 2235.7246 - val_loss: 6014.0513\n",
      "Epoch 173/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1786.3037 - val_loss: 5441.7593\n",
      "Epoch 174/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1331.0573 - val_loss: 2490.3894\n",
      "Epoch 175/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1733.6804 - val_loss: 889.3549\n",
      "Epoch 176/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1758.3684 - val_loss: 1065.9503\n",
      "Epoch 177/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1249.8020 - val_loss: 601.2772\n",
      "Epoch 178/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1593.4691 - val_loss: 598.1956\n",
      "Epoch 179/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1757.3699 - val_loss: 1880.5890\n",
      "Epoch 180/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1720.9958 - val_loss: 642.5709\n",
      "Epoch 181/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1429.2734 - val_loss: 1104.9778\n",
      "Epoch 182/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1357.0785 - val_loss: 1130.6514\n",
      "Epoch 183/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1169.6610 - val_loss: 593.5399\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 1444.0652 - val_loss: 3728.7727\n",
      "Epoch 185/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1860.0912 - val_loss: 8329.9756\n",
      "Epoch 186/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1559.2400 - val_loss: 7738.4731\n",
      "Epoch 187/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1086.0531 - val_loss: 1706.9159\n",
      "Epoch 188/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1186.5870 - val_loss: 666.9517\n",
      "Epoch 189/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1229.9197 - val_loss: 970.7610\n",
      "Epoch 190/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1611.2795 - val_loss: 4487.0342\n",
      "Epoch 191/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 1072.9838 - val_loss: 2911.9983\n",
      "Epoch 192/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1096.4703 - val_loss: 965.1544\n",
      "Epoch 193/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1170.2819 - val_loss: 605.7997\n",
      "Epoch 194/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 857.6546 - val_loss: 4091.7966\n",
      "Epoch 195/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 963.6538 - val_loss: 673.4782\n",
      "Epoch 196/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 1006.8353 - val_loss: 1791.4691\n",
      "Epoch 197/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 943.9095 - val_loss: 801.2745\n",
      "Epoch 198/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 5720.2534 - val_loss: 2073.6465\n",
      "Epoch 199/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 415.7636 - val_loss: 708.1495\n",
      "Epoch 200/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 350.5342 - val_loss: 824.0825\n",
      "Epoch 201/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 352.5003 - val_loss: 589.5018\n",
      "Epoch 202/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 359.4178 - val_loss: 652.9088\n",
      "Epoch 203/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 358.4810 - val_loss: 669.0707\n",
      "Epoch 204/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 360.5936 - val_loss: 590.0331\n",
      "Epoch 205/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 381.3539 - val_loss: 880.7217\n",
      "Epoch 206/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 361.2071 - val_loss: 837.4938\n",
      "Epoch 207/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 363.8390 - val_loss: 602.4195\n",
      "Epoch 208/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 369.5933 - val_loss: 628.5784\n",
      "Epoch 209/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 400.6934 - val_loss: 911.0521\n",
      "Epoch 210/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 383.8371 - val_loss: 623.4597\n",
      "Epoch 211/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 347.3307 - val_loss: 820.2615\n",
      "Epoch 212/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 360.2651 - val_loss: 631.4154\n",
      "Epoch 213/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 364.2320 - val_loss: 658.2905\n",
      "Epoch 214/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 350.2792 - val_loss: 652.2092\n",
      "Epoch 215/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 335.7984 - val_loss: 655.1741\n",
      "Epoch 216/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 335.9904 - val_loss: 686.4881\n",
      "Epoch 217/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 328.9955 - val_loss: 601.0240\n",
      "Epoch 218/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 328.8202 - val_loss: 632.2189\n",
      "Epoch 219/1000\n",
      "320/320 [==============================] - 0s 967us/step - loss: 329.7919 - val_loss: 595.7990\n",
      "Epoch 220/1000\n",
      "320/320 [==============================] - 0s 968us/step - loss: 332.0870 - val_loss: 637.3690\n",
      "Epoch 221/1000\n",
      "320/320 [==============================] - 0s 916us/step - loss: 329.5620 - val_loss: 632.7009\n",
      "Epoch 222/1000\n",
      "320/320 [==============================] - 0s 939us/step - loss: 332.5515 - val_loss: 606.2673\n",
      "Epoch 223/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 331.0345 - val_loss: 615.7585\n",
      "Epoch 224/1000\n",
      "320/320 [==============================] - 0s 926us/step - loss: 331.7344 - val_loss: 657.5681\n",
      "Epoch 225/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 331.7802 - val_loss: 739.3727\n",
      "Epoch 226/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 337.7395 - val_loss: 652.1851\n",
      "Epoch 227/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 335.5361 - val_loss: 726.7637\n",
      "Epoch 228/1000\n",
      "320/320 [==============================] - 0s 865us/step - loss: 334.5543 - val_loss: 620.6514\n",
      "Epoch 229/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 331.6520 - val_loss: 624.2010\n",
      "Epoch 230/1000\n",
      "320/320 [==============================] - 0s 970us/step - loss: 333.6514 - val_loss: 656.2820\n",
      "Epoch 231/1000\n",
      "320/320 [==============================] - 0s 991us/step - loss: 335.4269 - val_loss: 664.7892\n",
      "Epoch 232/1000\n",
      "320/320 [==============================] - 0s 952us/step - loss: 334.7498 - val_loss: 640.5403\n",
      "Epoch 233/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 337.8496 - val_loss: 670.7089\n",
      "Epoch 234/1000\n",
      "320/320 [==============================] - 0s 909us/step - loss: 336.7692 - val_loss: 615.4728\n",
      "Epoch 235/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 334.9412 - val_loss: 622.5452\n",
      "Epoch 236/1000\n",
      "320/320 [==============================] - 0s 924us/step - loss: 338.9909 - val_loss: 618.0469\n",
      "Epoch 237/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 337.9772 - val_loss: 672.7003\n",
      "Epoch 238/1000\n",
      "320/320 [==============================] - 0s 799us/step - loss: 337.5945 - val_loss: 696.3571\n",
      "Epoch 239/1000\n",
      "320/320 [==============================] - 0s 832us/step - loss: 337.3258 - val_loss: 723.1598\n",
      "Epoch 240/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 335.3924 - val_loss: 655.2231\n",
      "Epoch 241/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 337.8311 - val_loss: 622.8802\n",
      "Epoch 242/1000\n",
      "320/320 [==============================] - 0s 841us/step - loss: 335.8850 - val_loss: 651.6843\n",
      "Epoch 243/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 344.4521 - val_loss: 689.7322\n",
      "Epoch 244/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 336.7702 - val_loss: 778.8967\n",
      "Epoch 245/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 341.4091 - val_loss: 695.3396\n",
      "Epoch 246/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 334.6245 - val_loss: 759.8997\n",
      "Epoch 247/1000\n",
      "320/320 [==============================] - 0s 923us/step - loss: 338.5300 - val_loss: 590.6391\n",
      "Epoch 248/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 7960.1484 - val_loss: 624.5074\n",
      "Epoch 249/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 344.1604 - val_loss: 604.4495\n",
      "Epoch 250/1000\n",
      "320/320 [==============================] - 0s 801us/step - loss: 341.3057 - val_loss: 673.7933\n",
      "Epoch 251/1000\n",
      "320/320 [==============================] - 0s 758us/step - loss: 338.4102 - val_loss: 610.8992\n",
      "Epoch 252/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 332.7134 - val_loss: 601.0540\n",
      "Epoch 253/1000\n",
      "320/320 [==============================] - 0s 819us/step - loss: 334.5418 - val_loss: 666.6968\n",
      "Epoch 254/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 338.4431 - val_loss: 733.8336\n",
      "Epoch 255/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 333.8182 - val_loss: 678.7823\n",
      "Epoch 256/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 339.9483 - val_loss: 591.2063\n",
      "Epoch 257/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 335.1353 - val_loss: 695.3058\n",
      "Epoch 258/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 332.2640 - val_loss: 685.8441\n",
      "Epoch 259/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 880us/step - loss: 341.2778 - val_loss: 666.9804\n",
      "Epoch 260/1000\n",
      "320/320 [==============================] - 0s 789us/step - loss: 340.0689 - val_loss: 612.8167\n",
      "Epoch 261/1000\n",
      "320/320 [==============================] - 0s 766us/step - loss: 331.3000 - val_loss: 624.4341\n",
      "Epoch 262/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 336.1635 - val_loss: 648.4045\n",
      "Epoch 263/1000\n",
      "320/320 [==============================] - 0s 799us/step - loss: 339.5234 - val_loss: 663.9865\n",
      "Epoch 264/1000\n",
      "320/320 [==============================] - 0s 765us/step - loss: 335.1804 - val_loss: 718.9734\n",
      "Epoch 265/1000\n",
      "320/320 [==============================] - 0s 773us/step - loss: 333.5516 - val_loss: 674.4270\n",
      "Epoch 266/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 337.7031 - val_loss: 710.6555\n",
      "Epoch 267/1000\n",
      "320/320 [==============================] - 0s 767us/step - loss: 331.5582 - val_loss: 644.6478\n",
      "Epoch 268/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 341.6313 - val_loss: 636.8036\n",
      "Epoch 269/1000\n",
      "320/320 [==============================] - 0s 743us/step - loss: 338.8976 - val_loss: 709.5805\n",
      "Epoch 270/1000\n",
      "320/320 [==============================] - 0s 773us/step - loss: 339.1920 - val_loss: 651.0745\n",
      "Epoch 271/1000\n",
      "320/320 [==============================] - 0s 757us/step - loss: 336.6129 - val_loss: 613.4219\n",
      "Epoch 272/1000\n",
      "320/320 [==============================] - 0s 734us/step - loss: 333.5384 - val_loss: 730.5641\n",
      "Epoch 273/1000\n",
      "320/320 [==============================] - 0s 751us/step - loss: 333.8183 - val_loss: 659.4632\n",
      "Epoch 274/1000\n",
      "320/320 [==============================] - 0s 790us/step - loss: 335.8391 - val_loss: 631.8227\n",
      "Epoch 275/1000\n",
      "320/320 [==============================] - 0s 816us/step - loss: 334.0124 - val_loss: 663.9093\n",
      "Epoch 276/1000\n",
      "320/320 [==============================] - 0s 782us/step - loss: 340.5954 - val_loss: 652.5684\n",
      "Epoch 277/1000\n",
      "320/320 [==============================] - 0s 804us/step - loss: 334.9527 - val_loss: 741.4293\n",
      "Epoch 278/1000\n",
      "320/320 [==============================] - 0s 807us/step - loss: 340.7457 - val_loss: 726.3693\n",
      "Epoch 279/1000\n",
      "320/320 [==============================] - 0s 752us/step - loss: 336.0462 - val_loss: 764.0065\n",
      "Epoch 280/1000\n",
      "320/320 [==============================] - 0s 751us/step - loss: 341.7364 - val_loss: 652.5726\n",
      "Epoch 281/1000\n",
      "320/320 [==============================] - 0s 762us/step - loss: 336.2031 - val_loss: 598.7698\n",
      "Epoch 282/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 331.5094 - val_loss: 612.5153\n",
      "Epoch 283/1000\n",
      "320/320 [==============================] - 0s 770us/step - loss: 340.2734 - val_loss: 598.6920\n",
      "Epoch 284/1000\n",
      "320/320 [==============================] - 0s 784us/step - loss: 337.1873 - val_loss: 612.1788\n",
      "Epoch 285/1000\n",
      "320/320 [==============================] - 0s 783us/step - loss: 342.5469 - val_loss: 667.2615\n",
      "Epoch 286/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 333.7826 - val_loss: 647.6529\n",
      "Epoch 287/1000\n",
      "320/320 [==============================] - 0s 801us/step - loss: 341.0157 - val_loss: 743.1490\n",
      "Epoch 288/1000\n",
      "320/320 [==============================] - 0s 800us/step - loss: 333.7637 - val_loss: 592.1100\n",
      "Epoch 289/1000\n",
      "320/320 [==============================] - 0s 738us/step - loss: 346.9576 - val_loss: 656.1846\n",
      "Epoch 290/1000\n",
      "320/320 [==============================] - 0s 792us/step - loss: 341.1361 - val_loss: 708.0442\n",
      "Epoch 291/1000\n",
      "320/320 [==============================] - 0s 771us/step - loss: 334.8825 - val_loss: 621.5423\n",
      "Epoch 292/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 337.4381 - val_loss: 691.4001\n",
      "Epoch 293/1000\n",
      "320/320 [==============================] - 0s 765us/step - loss: 334.4780 - val_loss: 801.2275\n",
      "Epoch 294/1000\n",
      "320/320 [==============================] - 0s 758us/step - loss: 338.2146 - val_loss: 805.4738\n",
      "Epoch 295/1000\n",
      "320/320 [==============================] - 0s 752us/step - loss: 2315.9524 - val_loss: 1417.3929\n",
      "Epoch 296/1000\n",
      "320/320 [==============================] - 0s 809us/step - loss: 769.0316 - val_loss: 1400.8101\n",
      "Epoch 297/1000\n",
      "320/320 [==============================] - 0s 773us/step - loss: 756.8670 - val_loss: 1384.2457\n",
      "Epoch 298/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 744.7597 - val_loss: 1367.7341\n",
      "Epoch 299/1000\n",
      "320/320 [==============================] - 0s 785us/step - loss: 732.7420 - val_loss: 1351.2850\n",
      "Epoch 300/1000\n",
      "320/320 [==============================] - 0s 811us/step - loss: 720.8444 - val_loss: 1334.9696\n",
      "Epoch 301/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 709.0762 - val_loss: 1318.7894\n",
      "Epoch 302/1000\n",
      "320/320 [==============================] - 0s 798us/step - loss: 697.4609 - val_loss: 1302.7236\n",
      "Epoch 303/1000\n",
      "320/320 [==============================] - 0s 803us/step - loss: 686.0041 - val_loss: 1286.8014\n",
      "Epoch 304/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 674.7203 - val_loss: 1271.0717\n",
      "Epoch 305/1000\n",
      "320/320 [==============================] - 0s 758us/step - loss: 663.6036 - val_loss: 1255.5477\n",
      "Epoch 306/1000\n",
      "320/320 [==============================] - 0s 759us/step - loss: 652.6796 - val_loss: 1240.1942\n",
      "Epoch 307/1000\n",
      "320/320 [==============================] - 0s 779us/step - loss: 641.9438 - val_loss: 1225.0323\n",
      "Epoch 308/1000\n",
      "320/320 [==============================] - 0s 805us/step - loss: 631.3861 - val_loss: 1210.0736\n",
      "Epoch 309/1000\n",
      "320/320 [==============================] - 0s 820us/step - loss: 621.0184 - val_loss: 1195.2546\n",
      "Epoch 310/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 610.8493 - val_loss: 1180.6869\n",
      "Epoch 311/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 600.8657 - val_loss: 1166.3029\n",
      "Epoch 312/1000\n",
      "320/320 [==============================] - 0s 757us/step - loss: 591.0756 - val_loss: 1152.0913\n",
      "Epoch 313/1000\n",
      "320/320 [==============================] - 0s 814us/step - loss: 581.4631 - val_loss: 1138.1104\n",
      "Epoch 314/1000\n",
      "320/320 [==============================] - 0s 803us/step - loss: 572.0529 - val_loss: 1124.3024\n",
      "Epoch 315/1000\n",
      "320/320 [==============================] - 0s 807us/step - loss: 562.8356 - val_loss: 1110.7170\n",
      "Epoch 316/1000\n",
      "320/320 [==============================] - 0s 807us/step - loss: 553.8033 - val_loss: 1097.3087\n",
      "Epoch 317/1000\n",
      "320/320 [==============================] - 0s 778us/step - loss: 544.9673 - val_loss: 1084.1128\n",
      "Epoch 318/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 536.3248 - val_loss: 1071.1445\n",
      "Epoch 319/1000\n",
      "320/320 [==============================] - 0s 942us/step - loss: 527.8650 - val_loss: 1058.3361\n",
      "Epoch 320/1000\n",
      "320/320 [==============================] - 0s 816us/step - loss: 519.5870 - val_loss: 1045.7538\n",
      "Epoch 321/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 511.5098 - val_loss: 1033.3231\n",
      "Epoch 322/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 503.6185 - val_loss: 1021.0959\n",
      "Epoch 323/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 495.9098 - val_loss: 1009.0975\n",
      "Epoch 324/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 488.3832 - val_loss: 997.2766\n",
      "Epoch 325/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 481.0502 - val_loss: 985.6351\n",
      "Epoch 326/1000\n",
      "320/320 [==============================] - 0s 805us/step - loss: 473.9164 - val_loss: 974.2772\n",
      "Epoch 327/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 466.9705 - val_loss: 963.0391\n",
      "Epoch 328/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 460.2042 - val_loss: 952.0376\n",
      "Epoch 329/1000\n",
      "320/320 [==============================] - 0s 794us/step - loss: 453.6192 - val_loss: 941.2007\n",
      "Epoch 330/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 447.2304 - val_loss: 930.5833\n",
      "Epoch 331/1000\n",
      "320/320 [==============================] - 0s 825us/step - loss: 441.0193 - val_loss: 920.2011\n",
      "Epoch 332/1000\n",
      "320/320 [==============================] - 0s 817us/step - loss: 434.9904 - val_loss: 909.9905\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 818us/step - loss: 429.1426 - val_loss: 900.0040\n",
      "Epoch 334/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 423.4613 - val_loss: 890.1267\n",
      "Epoch 335/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 417.9692 - val_loss: 880.4914\n",
      "Epoch 336/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 412.6581 - val_loss: 871.1049\n",
      "Epoch 337/1000\n",
      "320/320 [==============================] - 0s 799us/step - loss: 407.5475 - val_loss: 861.8760\n",
      "Epoch 338/1000\n",
      "320/320 [==============================] - 0s 867us/step - loss: 402.6212 - val_loss: 852.8680\n",
      "Epoch 339/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 397.8746 - val_loss: 844.0757\n",
      "Epoch 340/1000\n",
      "320/320 [==============================] - 0s 794us/step - loss: 393.2881 - val_loss: 835.4984\n",
      "Epoch 341/1000\n",
      "320/320 [==============================] - 0s 830us/step - loss: 388.8649 - val_loss: 827.0215\n",
      "Epoch 342/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 384.6203 - val_loss: 818.8168\n",
      "Epoch 343/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 380.5569 - val_loss: 810.8242\n",
      "Epoch 344/1000\n",
      "320/320 [==============================] - 0s 880us/step - loss: 376.6484 - val_loss: 802.9667\n",
      "Epoch 345/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 372.9142 - val_loss: 795.3369\n",
      "Epoch 346/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 369.3538 - val_loss: 787.9129\n",
      "Epoch 347/1000\n",
      "320/320 [==============================] - 0s 986us/step - loss: 365.9630 - val_loss: 780.6855\n",
      "Epoch 348/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 362.7423 - val_loss: 773.6825\n",
      "Epoch 349/1000\n",
      "320/320 [==============================] - 0s 964us/step - loss: 359.6826 - val_loss: 766.9023\n",
      "Epoch 350/1000\n",
      "320/320 [==============================] - 0s 992us/step - loss: 356.7815 - val_loss: 760.2788\n",
      "Epoch 351/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 354.0446 - val_loss: 753.9075\n",
      "Epoch 352/1000\n",
      "320/320 [==============================] - 0s 938us/step - loss: 351.4676 - val_loss: 747.6991\n",
      "Epoch 353/1000\n",
      "320/320 [==============================] - 0s 991us/step - loss: 349.0428 - val_loss: 741.7527\n",
      "Epoch 354/1000\n",
      "320/320 [==============================] - 0s 911us/step - loss: 346.7803 - val_loss: 736.0235\n",
      "Epoch 355/1000\n",
      "320/320 [==============================] - 0s 840us/step - loss: 344.6532 - val_loss: 730.4784\n",
      "Epoch 356/1000\n",
      "320/320 [==============================] - 0s 951us/step - loss: 342.6672 - val_loss: 725.1301\n",
      "Epoch 357/1000\n",
      "320/320 [==============================] - 0s 880us/step - loss: 340.8319 - val_loss: 719.9789\n",
      "Epoch 358/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 339.1291 - val_loss: 715.0721\n",
      "Epoch 359/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 337.5536 - val_loss: 710.3615\n",
      "Epoch 360/1000\n",
      "320/320 [==============================] - 0s 832us/step - loss: 336.1064 - val_loss: 705.8225\n",
      "Epoch 361/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 334.7910 - val_loss: 701.5505\n",
      "Epoch 362/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 333.5918 - val_loss: 697.4749\n",
      "Epoch 363/1000\n",
      "320/320 [==============================] - 0s 906us/step - loss: 332.5064 - val_loss: 693.6035\n",
      "Epoch 364/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 331.5351 - val_loss: 689.9266\n",
      "Epoch 365/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 330.6663 - val_loss: 686.4974\n",
      "Epoch 366/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 329.8936 - val_loss: 683.3168\n",
      "Epoch 367/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 329.2131 - val_loss: 680.3561\n",
      "Epoch 368/1000\n",
      "320/320 [==============================] - 0s 802us/step - loss: 328.6146 - val_loss: 677.5914\n",
      "Epoch 369/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 328.0837 - val_loss: 674.9276\n",
      "Epoch 370/1000\n",
      "320/320 [==============================] - 0s 792us/step - loss: 327.6191 - val_loss: 672.3552\n",
      "Epoch 371/1000\n",
      "320/320 [==============================] - 0s 982us/step - loss: 327.2130 - val_loss: 670.0965\n",
      "Epoch 372/1000\n",
      "320/320 [==============================] - 0s 995us/step - loss: 326.8664 - val_loss: 668.1315\n",
      "Epoch 373/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 326.5744 - val_loss: 666.1100\n",
      "Epoch 374/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 326.3195 - val_loss: 664.3990\n",
      "Epoch 375/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 326.1036 - val_loss: 662.7023\n",
      "Epoch 376/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.9173 - val_loss: 661.2145\n",
      "Epoch 377/1000\n",
      "320/320 [==============================] - 0s 968us/step - loss: 325.7636 - val_loss: 659.8500\n",
      "Epoch 378/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 325.6319 - val_loss: 658.5614\n",
      "Epoch 379/1000\n",
      "320/320 [==============================] - 0s 969us/step - loss: 325.5213 - val_loss: 657.4262\n",
      "Epoch 380/1000\n",
      "320/320 [==============================] - 0s 933us/step - loss: 325.4326 - val_loss: 656.3706\n",
      "Epoch 381/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.3563 - val_loss: 655.4301\n",
      "Epoch 382/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 325.2934 - val_loss: 654.5856\n",
      "Epoch 383/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.2421 - val_loss: 653.7664\n",
      "Epoch 384/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 325.1996 - val_loss: 653.0896\n",
      "Epoch 385/1000\n",
      "320/320 [==============================] - 0s 960us/step - loss: 325.1650 - val_loss: 652.4886\n",
      "Epoch 386/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.1388 - val_loss: 651.8929\n",
      "Epoch 387/1000\n",
      "320/320 [==============================] - 0s 897us/step - loss: 325.1139 - val_loss: 651.4310\n",
      "Epoch 388/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 325.0967 - val_loss: 650.9178\n",
      "Epoch 389/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0795 - val_loss: 650.5784\n",
      "Epoch 390/1000\n",
      "320/320 [==============================] - 0s 890us/step - loss: 325.0665 - val_loss: 650.1493\n",
      "Epoch 391/1000\n",
      "320/320 [==============================] - 0s 902us/step - loss: 325.0558 - val_loss: 649.8331\n",
      "Epoch 392/1000\n",
      "320/320 [==============================] - 0s 937us/step - loss: 325.0472 - val_loss: 649.5815\n",
      "Epoch 393/1000\n",
      "320/320 [==============================] - 0s 901us/step - loss: 325.0390 - val_loss: 649.2650\n",
      "Epoch 394/1000\n",
      "320/320 [==============================] - 0s 947us/step - loss: 325.0344 - val_loss: 648.9648\n",
      "Epoch 395/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 325.0287 - val_loss: 648.7714\n",
      "Epoch 396/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0260 - val_loss: 648.5693\n",
      "Epoch 397/1000\n",
      "320/320 [==============================] - 0s 827us/step - loss: 325.0217 - val_loss: 648.3726\n",
      "Epoch 398/1000\n",
      "320/320 [==============================] - 0s 945us/step - loss: 325.0193 - val_loss: 648.2145\n",
      "Epoch 399/1000\n",
      "320/320 [==============================] - 0s 978us/step - loss: 325.0176 - val_loss: 647.9843\n",
      "Epoch 400/1000\n",
      "320/320 [==============================] - 0s 941us/step - loss: 325.0152 - val_loss: 647.9611\n",
      "Epoch 401/1000\n",
      "320/320 [==============================] - 0s 839us/step - loss: 325.0143 - val_loss: 647.7676\n",
      "Epoch 402/1000\n",
      "320/320 [==============================] - 0s 899us/step - loss: 325.0128 - val_loss: 647.6938\n",
      "Epoch 403/1000\n",
      "320/320 [==============================] - 0s 841us/step - loss: 325.0116 - val_loss: 647.5877\n",
      "Epoch 404/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 325.0118 - val_loss: 647.4882\n",
      "Epoch 405/1000\n",
      "320/320 [==============================] - 0s 904us/step - loss: 325.0110 - val_loss: 647.4407\n",
      "Epoch 406/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 325.0096 - val_loss: 647.4166\n",
      "Epoch 407/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 871us/step - loss: 325.0092 - val_loss: 647.2628\n",
      "Epoch 408/1000\n",
      "320/320 [==============================] - 0s 901us/step - loss: 325.0084 - val_loss: 647.1929\n",
      "Epoch 409/1000\n",
      "320/320 [==============================] - 0s 811us/step - loss: 325.0081 - val_loss: 647.1346\n",
      "Epoch 410/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0080 - val_loss: 647.1158\n",
      "Epoch 411/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0076 - val_loss: 647.0607\n",
      "Epoch 412/1000\n",
      "320/320 [==============================] - 0s 882us/step - loss: 325.0078 - val_loss: 646.9792\n",
      "Epoch 413/1000\n",
      "320/320 [==============================] - 0s 836us/step - loss: 325.0091 - val_loss: 646.9435\n",
      "Epoch 414/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0084 - val_loss: 646.8931\n",
      "Epoch 415/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0069 - val_loss: 646.9078\n",
      "Epoch 416/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 325.0084 - val_loss: 646.8712\n",
      "Epoch 417/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0081 - val_loss: 646.8270\n",
      "Epoch 418/1000\n",
      "320/320 [==============================] - 0s 825us/step - loss: 325.0073 - val_loss: 646.8552\n",
      "Epoch 419/1000\n",
      "320/320 [==============================] - 0s 884us/step - loss: 325.0074 - val_loss: 646.8122\n",
      "Epoch 420/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0078 - val_loss: 646.7816\n",
      "Epoch 421/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0075 - val_loss: 646.8069\n",
      "Epoch 422/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0076 - val_loss: 646.8064\n",
      "Epoch 423/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0067 - val_loss: 646.7541\n",
      "Epoch 424/1000\n",
      "320/320 [==============================] - 0s 858us/step - loss: 325.0072 - val_loss: 646.7852\n",
      "Epoch 425/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0069 - val_loss: 646.7269\n",
      "Epoch 426/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 325.0069 - val_loss: 646.7467\n",
      "Epoch 427/1000\n",
      "320/320 [==============================] - 0s 846us/step - loss: 325.0074 - val_loss: 646.7607\n",
      "Epoch 428/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 325.0081 - val_loss: 646.6677\n",
      "Epoch 429/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 325.0066 - val_loss: 646.6697\n",
      "Epoch 430/1000\n",
      "320/320 [==============================] - 0s 945us/step - loss: 325.0076 - val_loss: 646.6805\n",
      "Epoch 431/1000\n",
      "320/320 [==============================] - 0s 978us/step - loss: 325.0068 - val_loss: 646.6500\n",
      "Epoch 432/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0066 - val_loss: 646.6443\n",
      "Epoch 433/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0069 - val_loss: 646.6244\n",
      "Epoch 434/1000\n",
      "320/320 [==============================] - 0s 965us/step - loss: 325.0069 - val_loss: 646.6509\n",
      "Epoch 435/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0074 - val_loss: 646.6238\n",
      "Epoch 436/1000\n",
      "320/320 [==============================] - 0s 968us/step - loss: 325.0077 - val_loss: 646.6475\n",
      "Epoch 437/1000\n",
      "320/320 [==============================] - 0s 963us/step - loss: 325.0071 - val_loss: 646.6715\n",
      "Epoch 438/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0064 - val_loss: 646.6382\n",
      "Epoch 439/1000\n",
      "320/320 [==============================] - 0s 933us/step - loss: 325.0066 - val_loss: 646.6390\n",
      "Epoch 440/1000\n",
      "320/320 [==============================] - 0s 934us/step - loss: 325.0074 - val_loss: 646.6700\n",
      "Epoch 441/1000\n",
      "320/320 [==============================] - 0s 957us/step - loss: 325.0069 - val_loss: 646.6378\n",
      "Epoch 442/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0073 - val_loss: 646.6358\n",
      "Epoch 443/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0071 - val_loss: 646.7020\n",
      "Epoch 444/1000\n",
      "320/320 [==============================] - 0s 937us/step - loss: 325.0065 - val_loss: 646.6555\n",
      "Epoch 445/1000\n",
      "320/320 [==============================] - 0s 924us/step - loss: 325.0064 - val_loss: 646.6097\n",
      "Epoch 446/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0096 - val_loss: 646.6586\n",
      "Epoch 447/1000\n",
      "320/320 [==============================] - 0s 942us/step - loss: 325.0061 - val_loss: 646.6257\n",
      "Epoch 448/1000\n",
      "320/320 [==============================] - 0s 929us/step - loss: 325.0073 - val_loss: 646.6517\n",
      "Epoch 449/1000\n",
      "320/320 [==============================] - 0s 915us/step - loss: 325.0085 - val_loss: 646.6656\n",
      "Epoch 450/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0079 - val_loss: 646.6627\n",
      "Epoch 451/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 325.0070 - val_loss: 646.6545\n",
      "Epoch 452/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0069 - val_loss: 646.6369\n",
      "Epoch 453/1000\n",
      "320/320 [==============================] - 0s 913us/step - loss: 325.0077 - val_loss: 646.5905\n",
      "Epoch 454/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0072 - val_loss: 646.6112\n",
      "Epoch 455/1000\n",
      "320/320 [==============================] - 0s 936us/step - loss: 325.0077 - val_loss: 646.6509\n",
      "Epoch 456/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0064 - val_loss: 646.5800\n",
      "Epoch 457/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0076 - val_loss: 646.6161\n",
      "Epoch 458/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0074 - val_loss: 646.6234\n",
      "Epoch 459/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0075 - val_loss: 646.6166\n",
      "Epoch 460/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0071 - val_loss: 646.6408\n",
      "Epoch 461/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0070 - val_loss: 646.6262\n",
      "Epoch 462/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0068 - val_loss: 646.6121\n",
      "Epoch 463/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0077 - val_loss: 646.5797\n",
      "Epoch 464/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0080 - val_loss: 646.6233\n",
      "Epoch 465/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.5628\n",
      "Epoch 466/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0069 - val_loss: 646.6268\n",
      "Epoch 467/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0074 - val_loss: 646.6412\n",
      "Epoch 468/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0082 - val_loss: 646.5942\n",
      "Epoch 469/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0090 - val_loss: 646.6135\n",
      "Epoch 470/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0078 - val_loss: 646.5944\n",
      "Epoch 471/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0077 - val_loss: 646.5784\n",
      "Epoch 472/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0079 - val_loss: 646.5975\n",
      "Epoch 473/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0072 - val_loss: 646.6254\n",
      "Epoch 474/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0071 - val_loss: 646.6216\n",
      "Epoch 475/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.5809\n",
      "Epoch 476/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0068 - val_loss: 646.6046\n",
      "Epoch 477/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.5983\n",
      "Epoch 478/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0077 - val_loss: 646.5854\n",
      "Epoch 479/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.5786\n",
      "Epoch 480/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0085 - val_loss: 646.6046\n",
      "Epoch 481/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0072 - val_loss: 646.5563\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0088 - val_loss: 646.6315\n",
      "Epoch 483/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0070 - val_loss: 646.5771\n",
      "Epoch 484/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0065 - val_loss: 646.6141\n",
      "Epoch 485/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0071 - val_loss: 646.5793\n",
      "Epoch 486/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0071 - val_loss: 646.5801\n",
      "Epoch 487/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6308\n",
      "Epoch 488/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0066 - val_loss: 646.6221\n",
      "Epoch 489/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0067 - val_loss: 646.6292\n",
      "Epoch 490/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.6467\n",
      "Epoch 491/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.6610\n",
      "Epoch 492/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0073 - val_loss: 646.6350\n",
      "Epoch 493/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0079 - val_loss: 646.6074\n",
      "Epoch 494/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0082 - val_loss: 646.6404\n",
      "Epoch 495/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0063 - val_loss: 646.5998\n",
      "Epoch 496/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0071 - val_loss: 646.6300\n",
      "Epoch 497/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.6339\n",
      "Epoch 498/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.6475\n",
      "Epoch 499/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0072 - val_loss: 646.5945\n",
      "Epoch 500/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0077 - val_loss: 646.5895\n",
      "Epoch 501/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0069 - val_loss: 646.5937\n",
      "Epoch 502/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0064 - val_loss: 646.6146\n",
      "Epoch 503/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0063 - val_loss: 646.6417\n",
      "Epoch 504/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0076 - val_loss: 646.6387\n",
      "Epoch 505/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0066 - val_loss: 646.5908\n",
      "Epoch 506/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0070 - val_loss: 646.6772\n",
      "Epoch 507/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0077 - val_loss: 646.5610\n",
      "Epoch 508/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0077 - val_loss: 646.6104\n",
      "Epoch 509/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0072 - val_loss: 646.6193\n",
      "Epoch 510/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0078 - val_loss: 646.5903\n",
      "Epoch 511/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0075 - val_loss: 646.6013\n",
      "Epoch 512/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0066 - val_loss: 646.5389\n",
      "Epoch 513/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0082 - val_loss: 646.5774\n",
      "Epoch 514/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6107\n",
      "Epoch 515/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0080 - val_loss: 646.5940\n",
      "Epoch 516/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0073 - val_loss: 646.5878\n",
      "Epoch 517/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0081 - val_loss: 646.5731\n",
      "Epoch 518/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6346\n",
      "Epoch 519/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0069 - val_loss: 646.5782\n",
      "Epoch 520/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0089 - val_loss: 646.5546\n",
      "Epoch 521/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0076 - val_loss: 646.6122\n",
      "Epoch 522/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0062 - val_loss: 646.6100\n",
      "Epoch 523/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0093 - val_loss: 646.5944\n",
      "Epoch 524/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0061 - val_loss: 646.6265\n",
      "Epoch 525/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0074 - val_loss: 646.5895\n",
      "Epoch 526/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0076 - val_loss: 646.6059\n",
      "Epoch 527/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0088 - val_loss: 646.5752\n",
      "Epoch 528/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0061 - val_loss: 646.6132\n",
      "Epoch 529/1000\n",
      "320/320 [==============================] - 0s 964us/step - loss: 325.0074 - val_loss: 646.6249\n",
      "Epoch 530/1000\n",
      "320/320 [==============================] - 0s 897us/step - loss: 325.0076 - val_loss: 646.6254\n",
      "Epoch 531/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0079 - val_loss: 646.6456\n",
      "Epoch 532/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0077 - val_loss: 646.6610\n",
      "Epoch 533/1000\n",
      "320/320 [==============================] - 0s 938us/step - loss: 325.0074 - val_loss: 646.6281\n",
      "Epoch 534/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0073 - val_loss: 646.6446\n",
      "Epoch 535/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0074 - val_loss: 646.5811\n",
      "Epoch 536/1000\n",
      "320/320 [==============================] - 0s 980us/step - loss: 325.0076 - val_loss: 646.6249\n",
      "Epoch 537/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0069 - val_loss: 646.6418\n",
      "Epoch 538/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0066 - val_loss: 646.6047\n",
      "Epoch 539/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0069 - val_loss: 646.6182\n",
      "Epoch 540/1000\n",
      "320/320 [==============================] - 0s 946us/step - loss: 325.0067 - val_loss: 646.6190\n",
      "Epoch 541/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0074 - val_loss: 646.5776\n",
      "Epoch 542/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 325.0066 - val_loss: 646.6399\n",
      "Epoch 543/1000\n",
      "320/320 [==============================] - 0s 970us/step - loss: 325.0076 - val_loss: 646.6013\n",
      "Epoch 544/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0065 - val_loss: 646.6071\n",
      "Epoch 545/1000\n",
      "320/320 [==============================] - 0s 926us/step - loss: 325.0081 - val_loss: 646.6356\n",
      "Epoch 546/1000\n",
      "320/320 [==============================] - 0s 944us/step - loss: 325.0067 - val_loss: 646.5847\n",
      "Epoch 547/1000\n",
      "320/320 [==============================] - 0s 923us/step - loss: 325.0071 - val_loss: 646.5351\n",
      "Epoch 548/1000\n",
      "320/320 [==============================] - 0s 829us/step - loss: 325.0065 - val_loss: 646.6060\n",
      "Epoch 549/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0068 - val_loss: 646.6205\n",
      "Epoch 550/1000\n",
      "320/320 [==============================] - 0s 927us/step - loss: 325.0075 - val_loss: 646.5921\n",
      "Epoch 551/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0073 - val_loss: 646.5952\n",
      "Epoch 552/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0074 - val_loss: 646.6091\n",
      "Epoch 553/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 325.0070 - val_loss: 646.5932\n",
      "Epoch 554/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 325.0071 - val_loss: 646.6188\n",
      "Epoch 555/1000\n",
      "320/320 [==============================] - 0s 788us/step - loss: 325.0065 - val_loss: 646.6225\n",
      "Epoch 556/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0081 - val_loss: 646.5987\n",
      "Epoch 557/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 835us/step - loss: 325.0091 - val_loss: 646.5652\n",
      "Epoch 558/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 325.0094 - val_loss: 646.6236\n",
      "Epoch 559/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0074 - val_loss: 646.5471\n",
      "Epoch 560/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0072 - val_loss: 646.6533\n",
      "Epoch 561/1000\n",
      "320/320 [==============================] - 0s 788us/step - loss: 325.0078 - val_loss: 646.6245\n",
      "Epoch 562/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 325.0079 - val_loss: 646.5875\n",
      "Epoch 563/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 325.0065 - val_loss: 646.5970\n",
      "Epoch 564/1000\n",
      "320/320 [==============================] - 0s 944us/step - loss: 325.0074 - val_loss: 646.6144\n",
      "Epoch 565/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 325.0068 - val_loss: 646.6111\n",
      "Epoch 566/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0070 - val_loss: 646.6059\n",
      "Epoch 567/1000\n",
      "320/320 [==============================] - 0s 812us/step - loss: 325.0073 - val_loss: 646.6530\n",
      "Epoch 568/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0078 - val_loss: 646.6487\n",
      "Epoch 569/1000\n",
      "320/320 [==============================] - 0s 899us/step - loss: 325.0085 - val_loss: 646.6035\n",
      "Epoch 570/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0070 - val_loss: 646.6434\n",
      "Epoch 571/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0074 - val_loss: 646.6393\n",
      "Epoch 572/1000\n",
      "320/320 [==============================] - 0s 819us/step - loss: 325.0073 - val_loss: 646.6335\n",
      "Epoch 573/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0074 - val_loss: 646.6133\n",
      "Epoch 574/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0061 - val_loss: 646.6252\n",
      "Epoch 575/1000\n",
      "320/320 [==============================] - 0s 980us/step - loss: 325.0078 - val_loss: 646.6276\n",
      "Epoch 576/1000\n",
      "320/320 [==============================] - 0s 871us/step - loss: 325.0083 - val_loss: 646.6624\n",
      "Epoch 577/1000\n",
      "320/320 [==============================] - 0s 830us/step - loss: 325.0068 - val_loss: 646.6310\n",
      "Epoch 578/1000\n",
      "320/320 [==============================] - 0s 901us/step - loss: 325.0088 - val_loss: 646.6173\n",
      "Epoch 579/1000\n",
      "320/320 [==============================] - 0s 763us/step - loss: 325.0085 - val_loss: 646.6545\n",
      "Epoch 580/1000\n",
      "320/320 [==============================] - 0s 818us/step - loss: 325.0071 - val_loss: 646.6122\n",
      "Epoch 581/1000\n",
      "320/320 [==============================] - 0s 738us/step - loss: 325.0081 - val_loss: 646.6240\n",
      "Epoch 582/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 325.0062 - val_loss: 646.6337\n",
      "Epoch 583/1000\n",
      "320/320 [==============================] - 0s 832us/step - loss: 325.0070 - val_loss: 646.6506\n",
      "Epoch 584/1000\n",
      "320/320 [==============================] - 0s 777us/step - loss: 325.0074 - val_loss: 646.6918\n",
      "Epoch 585/1000\n",
      "320/320 [==============================] - 0s 764us/step - loss: 325.0071 - val_loss: 646.6667\n",
      "Epoch 586/1000\n",
      "320/320 [==============================] - 0s 805us/step - loss: 325.0063 - val_loss: 646.6761\n",
      "Epoch 587/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0063 - val_loss: 646.6629\n",
      "Epoch 588/1000\n",
      "320/320 [==============================] - 0s 821us/step - loss: 325.0079 - val_loss: 646.6476\n",
      "Epoch 589/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0072 - val_loss: 646.6806\n",
      "Epoch 590/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0080 - val_loss: 646.6978\n",
      "Epoch 591/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 325.0071 - val_loss: 646.6483\n",
      "Epoch 592/1000\n",
      "320/320 [==============================] - 0s 847us/step - loss: 325.0070 - val_loss: 646.5962\n",
      "Epoch 593/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0067 - val_loss: 646.6180\n",
      "Epoch 594/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 325.0082 - val_loss: 646.6335\n",
      "Epoch 595/1000\n",
      "320/320 [==============================] - 0s 894us/step - loss: 325.0077 - val_loss: 646.6013\n",
      "Epoch 596/1000\n",
      "320/320 [==============================] - 0s 834us/step - loss: 325.0075 - val_loss: 646.6194\n",
      "Epoch 597/1000\n",
      "320/320 [==============================] - 0s 768us/step - loss: 325.0067 - val_loss: 646.5936\n",
      "Epoch 598/1000\n",
      "320/320 [==============================] - 0s 909us/step - loss: 325.0065 - val_loss: 646.6163\n",
      "Epoch 599/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0080 - val_loss: 646.6100\n",
      "Epoch 600/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0076 - val_loss: 646.6486\n",
      "Epoch 601/1000\n",
      "320/320 [==============================] - 0s 797us/step - loss: 325.0073 - val_loss: 646.6565\n",
      "Epoch 602/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0069 - val_loss: 646.6078\n",
      "Epoch 603/1000\n",
      "320/320 [==============================] - 0s 767us/step - loss: 325.0070 - val_loss: 646.6484\n",
      "Epoch 604/1000\n",
      "320/320 [==============================] - 0s 800us/step - loss: 325.0076 - val_loss: 646.6398\n",
      "Epoch 605/1000\n",
      "320/320 [==============================] - 0s 798us/step - loss: 325.0084 - val_loss: 646.5814\n",
      "Epoch 606/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 325.0067 - val_loss: 646.6393\n",
      "Epoch 607/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0061 - val_loss: 646.6068\n",
      "Epoch 608/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0075 - val_loss: 646.6348\n",
      "Epoch 609/1000\n",
      "320/320 [==============================] - 0s 803us/step - loss: 325.0078 - val_loss: 646.6208\n",
      "Epoch 610/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 325.0073 - val_loss: 646.6325\n",
      "Epoch 611/1000\n",
      "320/320 [==============================] - 0s 910us/step - loss: 325.0074 - val_loss: 646.6544\n",
      "Epoch 612/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 325.0073 - val_loss: 646.6559\n",
      "Epoch 613/1000\n",
      "320/320 [==============================] - 0s 915us/step - loss: 325.0080 - val_loss: 646.6775\n",
      "Epoch 614/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0072 - val_loss: 646.6871\n",
      "Epoch 615/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0087 - val_loss: 646.7166\n",
      "Epoch 616/1000\n",
      "320/320 [==============================] - 0s 919us/step - loss: 325.0074 - val_loss: 646.6653\n",
      "Epoch 617/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0080 - val_loss: 646.6344\n",
      "Epoch 618/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0072 - val_loss: 646.6887\n",
      "Epoch 619/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0090 - val_loss: 646.6340\n",
      "Epoch 620/1000\n",
      "320/320 [==============================] - 0s 836us/step - loss: 325.0066 - val_loss: 646.6287\n",
      "Epoch 621/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 325.0079 - val_loss: 646.6620\n",
      "Epoch 622/1000\n",
      "320/320 [==============================] - 0s 921us/step - loss: 325.0076 - val_loss: 646.6524\n",
      "Epoch 623/1000\n",
      "320/320 [==============================] - 0s 808us/step - loss: 325.0081 - val_loss: 646.6215\n",
      "Epoch 624/1000\n",
      "320/320 [==============================] - 0s 830us/step - loss: 325.0066 - val_loss: 646.6240\n",
      "Epoch 625/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0067 - val_loss: 646.6803\n",
      "Epoch 626/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0085 - val_loss: 646.6325\n",
      "Epoch 627/1000\n",
      "320/320 [==============================] - 0s 824us/step - loss: 325.0067 - val_loss: 646.6429\n",
      "Epoch 628/1000\n",
      "320/320 [==============================] - 0s 899us/step - loss: 325.0070 - val_loss: 646.5822\n",
      "Epoch 629/1000\n",
      "320/320 [==============================] - 0s 820us/step - loss: 325.0102 - val_loss: 646.6248\n",
      "Epoch 630/1000\n",
      "320/320 [==============================] - 0s 861us/step - loss: 325.0081 - val_loss: 646.6347\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 872us/step - loss: 325.0064 - val_loss: 646.6216\n",
      "Epoch 632/1000\n",
      "320/320 [==============================] - 0s 939us/step - loss: 325.0074 - val_loss: 646.6132\n",
      "Epoch 633/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0068 - val_loss: 646.6451\n",
      "Epoch 634/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 325.0072 - val_loss: 646.6358\n",
      "Epoch 635/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 325.0081 - val_loss: 646.6191\n",
      "Epoch 636/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0068 - val_loss: 646.6182\n",
      "Epoch 637/1000\n",
      "320/320 [==============================] - 0s 795us/step - loss: 325.0071 - val_loss: 646.6307\n",
      "Epoch 638/1000\n",
      "320/320 [==============================] - 0s 880us/step - loss: 325.0074 - val_loss: 646.6141\n",
      "Epoch 639/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0084 - val_loss: 646.6434\n",
      "Epoch 640/1000\n",
      "320/320 [==============================] - 0s 882us/step - loss: 325.0075 - val_loss: 646.6101\n",
      "Epoch 641/1000\n",
      "320/320 [==============================] - 0s 834us/step - loss: 325.0069 - val_loss: 646.6581\n",
      "Epoch 642/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 325.0077 - val_loss: 646.6428\n",
      "Epoch 643/1000\n",
      "320/320 [==============================] - 0s 818us/step - loss: 325.0077 - val_loss: 646.6158\n",
      "Epoch 644/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 325.0077 - val_loss: 646.6008\n",
      "Epoch 645/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0078 - val_loss: 646.6100\n",
      "Epoch 646/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 325.0087 - val_loss: 646.6323\n",
      "Epoch 647/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 325.0077 - val_loss: 646.6169\n",
      "Epoch 648/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0081 - val_loss: 646.6752\n",
      "Epoch 649/1000\n",
      "320/320 [==============================] - 0s 810us/step - loss: 325.0078 - val_loss: 646.6692\n",
      "Epoch 650/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0065 - val_loss: 646.6400\n",
      "Epoch 651/1000\n",
      "320/320 [==============================] - 0s 796us/step - loss: 325.0076 - val_loss: 646.5795\n",
      "Epoch 652/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0069 - val_loss: 646.6193\n",
      "Epoch 653/1000\n",
      "320/320 [==============================] - 0s 788us/step - loss: 325.0071 - val_loss: 646.6358\n",
      "Epoch 654/1000\n",
      "320/320 [==============================] - 0s 896us/step - loss: 325.0070 - val_loss: 646.6038\n",
      "Epoch 655/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0065 - val_loss: 646.6083\n",
      "Epoch 656/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 325.0077 - val_loss: 646.6238\n",
      "Epoch 657/1000\n",
      "320/320 [==============================] - 0s 783us/step - loss: 325.0074 - val_loss: 646.6350\n",
      "Epoch 658/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 325.0079 - val_loss: 646.6264\n",
      "Epoch 659/1000\n",
      "320/320 [==============================] - 0s 802us/step - loss: 325.0085 - val_loss: 646.6120\n",
      "Epoch 660/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 325.0074 - val_loss: 646.5974\n",
      "Epoch 661/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 325.0074 - val_loss: 646.5821\n",
      "Epoch 662/1000\n",
      "320/320 [==============================] - 0s 849us/step - loss: 325.0074 - val_loss: 646.6595\n",
      "Epoch 663/1000\n",
      "320/320 [==============================] - 0s 815us/step - loss: 325.0070 - val_loss: 646.6456\n",
      "Epoch 664/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 325.0064 - val_loss: 646.6476\n",
      "Epoch 665/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0072 - val_loss: 646.6660\n",
      "Epoch 666/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0085 - val_loss: 646.7054\n",
      "Epoch 667/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 325.0067 - val_loss: 646.5937\n",
      "Epoch 668/1000\n",
      "320/320 [==============================] - 0s 911us/step - loss: 325.0075 - val_loss: 646.6064\n",
      "Epoch 669/1000\n",
      "320/320 [==============================] - 0s 849us/step - loss: 325.0073 - val_loss: 646.6067\n",
      "Epoch 670/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 325.0070 - val_loss: 646.6103\n",
      "Epoch 671/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0091 - val_loss: 646.6006\n",
      "Epoch 672/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0077 - val_loss: 646.6135\n",
      "Epoch 673/1000\n",
      "320/320 [==============================] - 0s 983us/step - loss: 325.0081 - val_loss: 646.6422\n",
      "Epoch 674/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0074 - val_loss: 646.5806\n",
      "Epoch 675/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0092 - val_loss: 646.6500\n",
      "Epoch 676/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 325.0074 - val_loss: 646.5966\n",
      "Epoch 677/1000\n",
      "320/320 [==============================] - 0s 835us/step - loss: 325.0077 - val_loss: 646.6032\n",
      "Epoch 678/1000\n",
      "320/320 [==============================] - 0s 920us/step - loss: 325.0079 - val_loss: 646.6358\n",
      "Epoch 679/1000\n",
      "320/320 [==============================] - 0s 973us/step - loss: 325.0095 - val_loss: 646.5728\n",
      "Epoch 680/1000\n",
      "320/320 [==============================] - 0s 864us/step - loss: 325.0076 - val_loss: 646.6078\n",
      "Epoch 681/1000\n",
      "320/320 [==============================] - 0s 922us/step - loss: 325.0072 - val_loss: 646.6054\n",
      "Epoch 682/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 325.0074 - val_loss: 646.6105\n",
      "Epoch 683/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 325.0085 - val_loss: 646.6270\n",
      "Epoch 684/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 325.0074 - val_loss: 646.5546\n",
      "Epoch 685/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0079 - val_loss: 646.5883\n",
      "Epoch 686/1000\n",
      "320/320 [==============================] - 0s 839us/step - loss: 325.0066 - val_loss: 646.5905\n",
      "Epoch 687/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 325.0085 - val_loss: 646.6141\n",
      "Epoch 688/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0077 - val_loss: 646.6053\n",
      "Epoch 689/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 325.0069 - val_loss: 646.5800\n",
      "Epoch 690/1000\n",
      "320/320 [==============================] - 0s 936us/step - loss: 325.0076 - val_loss: 646.6557\n",
      "Epoch 691/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0067 - val_loss: 646.6744\n",
      "Epoch 692/1000\n",
      "320/320 [==============================] - 0s 846us/step - loss: 325.0080 - val_loss: 646.5822\n",
      "Epoch 693/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 325.0071 - val_loss: 646.6266\n",
      "Epoch 694/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0080 - val_loss: 646.7017\n",
      "Epoch 695/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0072 - val_loss: 646.6161\n",
      "Epoch 696/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0074 - val_loss: 646.6506\n",
      "Epoch 697/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0073 - val_loss: 646.6970\n",
      "Epoch 698/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0068 - val_loss: 646.6311\n",
      "Epoch 699/1000\n",
      "320/320 [==============================] - 0s 955us/step - loss: 325.0063 - val_loss: 646.6196\n",
      "Epoch 700/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 325.0063 - val_loss: 646.6183\n",
      "Epoch 701/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0075 - val_loss: 646.6268\n",
      "Epoch 702/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 325.0073 - val_loss: 646.6107\n",
      "Epoch 703/1000\n",
      "320/320 [==============================] - 0s 916us/step - loss: 325.0073 - val_loss: 646.6551\n",
      "Epoch 704/1000\n",
      "320/320 [==============================] - 0s 896us/step - loss: 325.0075 - val_loss: 646.6215\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 807us/step - loss: 325.0074 - val_loss: 646.6060\n",
      "Epoch 706/1000\n",
      "320/320 [==============================] - 0s 874us/step - loss: 325.0078 - val_loss: 646.6684\n",
      "Epoch 707/1000\n",
      "320/320 [==============================] - 0s 839us/step - loss: 325.0078 - val_loss: 646.6555\n",
      "Epoch 708/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0075 - val_loss: 646.6505\n",
      "Epoch 709/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0080 - val_loss: 646.6644\n",
      "Epoch 710/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0065 - val_loss: 646.6009\n",
      "Epoch 711/1000\n",
      "320/320 [==============================] - 0s 855us/step - loss: 325.0074 - val_loss: 646.6899\n",
      "Epoch 712/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 325.0069 - val_loss: 646.6100\n",
      "Epoch 713/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0062 - val_loss: 646.6641\n",
      "Epoch 714/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 325.0070 - val_loss: 646.6339\n",
      "Epoch 715/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0078 - val_loss: 646.6259\n",
      "Epoch 716/1000\n",
      "320/320 [==============================] - 0s 902us/step - loss: 325.0065 - val_loss: 646.5668\n",
      "Epoch 717/1000\n",
      "320/320 [==============================] - 0s 910us/step - loss: 325.0066 - val_loss: 646.6212\n",
      "Epoch 718/1000\n",
      "320/320 [==============================] - 0s 961us/step - loss: 325.0080 - val_loss: 646.6433\n",
      "Epoch 719/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 325.0067 - val_loss: 646.6103\n",
      "Epoch 720/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 325.0076 - val_loss: 646.6191\n",
      "Epoch 721/1000\n",
      "320/320 [==============================] - 0s 943us/step - loss: 325.0071 - val_loss: 646.6286\n",
      "Epoch 722/1000\n",
      "320/320 [==============================] - 0s 908us/step - loss: 325.0073 - val_loss: 646.6134\n",
      "Epoch 723/1000\n",
      "320/320 [==============================] - 0s 912us/step - loss: 325.0087 - val_loss: 646.6479\n",
      "Epoch 724/1000\n",
      "320/320 [==============================] - 0s 911us/step - loss: 325.0078 - val_loss: 646.6650\n",
      "Epoch 725/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 325.0075 - val_loss: 646.5840\n",
      "Epoch 726/1000\n",
      "320/320 [==============================] - 0s 953us/step - loss: 325.0071 - val_loss: 646.6509\n",
      "Epoch 727/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0067 - val_loss: 646.6732\n",
      "Epoch 728/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0073 - val_loss: 646.6690\n",
      "Epoch 729/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0069 - val_loss: 646.6100\n",
      "Epoch 730/1000\n",
      "320/320 [==============================] - 0s 909us/step - loss: 325.0071 - val_loss: 646.6631\n",
      "Epoch 731/1000\n",
      "320/320 [==============================] - 0s 978us/step - loss: 325.0092 - val_loss: 646.6387\n",
      "Epoch 732/1000\n",
      "320/320 [==============================] - 0s 902us/step - loss: 325.0076 - val_loss: 646.6215\n",
      "Epoch 733/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0074 - val_loss: 646.6005\n",
      "Epoch 734/1000\n",
      "320/320 [==============================] - 0s 933us/step - loss: 325.0078 - val_loss: 646.6027\n",
      "Epoch 735/1000\n",
      "320/320 [==============================] - 0s 873us/step - loss: 325.0070 - val_loss: 646.6456\n",
      "Epoch 736/1000\n",
      "320/320 [==============================] - 0s 946us/step - loss: 325.0065 - val_loss: 646.6223\n",
      "Epoch 737/1000\n",
      "320/320 [==============================] - 0s 920us/step - loss: 325.0076 - val_loss: 646.5921\n",
      "Epoch 738/1000\n",
      "320/320 [==============================] - 0s 987us/step - loss: 325.0071 - val_loss: 646.6146\n",
      "Epoch 739/1000\n",
      "320/320 [==============================] - 0s 941us/step - loss: 325.0071 - val_loss: 646.6508\n",
      "Epoch 740/1000\n",
      "320/320 [==============================] - 0s 959us/step - loss: 325.0065 - val_loss: 646.6202\n",
      "Epoch 741/1000\n",
      "320/320 [==============================] - 0s 916us/step - loss: 325.0070 - val_loss: 646.6619\n",
      "Epoch 742/1000\n",
      "320/320 [==============================] - 0s 969us/step - loss: 325.0080 - val_loss: 646.6298\n",
      "Epoch 743/1000\n",
      "320/320 [==============================] - 0s 878us/step - loss: 325.0077 - val_loss: 646.6850\n",
      "Epoch 744/1000\n",
      "320/320 [==============================] - 0s 853us/step - loss: 325.0081 - val_loss: 646.6010\n",
      "Epoch 745/1000\n",
      "320/320 [==============================] - 0s 882us/step - loss: 325.0067 - val_loss: 646.6619\n",
      "Epoch 746/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0064 - val_loss: 646.6287\n",
      "Epoch 747/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0083 - val_loss: 646.5788\n",
      "Epoch 748/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0078 - val_loss: 646.6692\n",
      "Epoch 749/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0067 - val_loss: 646.6362\n",
      "Epoch 750/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0065 - val_loss: 646.6612\n",
      "Epoch 751/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0081 - val_loss: 646.6390\n",
      "Epoch 752/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0072 - val_loss: 646.5992\n",
      "Epoch 753/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0075 - val_loss: 646.6476\n",
      "Epoch 754/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 325.0071 - val_loss: 646.6743\n",
      "Epoch 755/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 325.0073 - val_loss: 646.6622\n",
      "Epoch 756/1000\n",
      "320/320 [==============================] - 0s 928us/step - loss: 325.0074 - val_loss: 646.5878\n",
      "Epoch 757/1000\n",
      "320/320 [==============================] - 0s 914us/step - loss: 325.0073 - val_loss: 646.6262\n",
      "Epoch 758/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 325.0069 - val_loss: 646.6194\n",
      "Epoch 759/1000\n",
      "320/320 [==============================] - 0s 944us/step - loss: 325.0069 - val_loss: 646.5692\n",
      "Epoch 760/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0070 - val_loss: 646.6190\n",
      "Epoch 761/1000\n",
      "320/320 [==============================] - 0s 858us/step - loss: 325.0082 - val_loss: 646.5570\n",
      "Epoch 762/1000\n",
      "320/320 [==============================] - 0s 886us/step - loss: 325.0076 - val_loss: 646.6458\n",
      "Epoch 763/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0069 - val_loss: 646.6628\n",
      "Epoch 764/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0077 - val_loss: 646.6245\n",
      "Epoch 765/1000\n",
      "320/320 [==============================] - 0s 906us/step - loss: 325.0075 - val_loss: 646.6136\n",
      "Epoch 766/1000\n",
      "320/320 [==============================] - 0s 946us/step - loss: 325.0081 - val_loss: 646.6050\n",
      "Epoch 767/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0074 - val_loss: 646.6250\n",
      "Epoch 768/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0072 - val_loss: 646.5905\n",
      "Epoch 769/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0076 - val_loss: 646.6066\n",
      "Epoch 770/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0065 - val_loss: 646.6008\n",
      "Epoch 771/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0077 - val_loss: 646.5836\n",
      "Epoch 772/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0073 - val_loss: 646.6244\n",
      "Epoch 773/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0065 - val_loss: 646.5821\n",
      "Epoch 774/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0067 - val_loss: 646.6288\n",
      "Epoch 775/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0071 - val_loss: 646.6503\n",
      "Epoch 776/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0066 - val_loss: 646.6326\n",
      "Epoch 777/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0074 - val_loss: 646.6219\n",
      "Epoch 778/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0076 - val_loss: 646.6656\n",
      "Epoch 779/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0070 - val_loss: 646.5965\n",
      "Epoch 780/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0070 - val_loss: 646.5981\n",
      "Epoch 781/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0080 - val_loss: 646.6550\n",
      "Epoch 782/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0069 - val_loss: 646.6152\n",
      "Epoch 783/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0074 - val_loss: 646.6340\n",
      "Epoch 784/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0071 - val_loss: 646.6091\n",
      "Epoch 785/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0068 - val_loss: 646.6198\n",
      "Epoch 786/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.6722\n",
      "Epoch 787/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0074 - val_loss: 646.5811\n",
      "Epoch 788/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0074 - val_loss: 646.6450\n",
      "Epoch 789/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0082 - val_loss: 646.6057\n",
      "Epoch 790/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0076 - val_loss: 646.6069\n",
      "Epoch 791/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0083 - val_loss: 646.6011\n",
      "Epoch 792/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0063 - val_loss: 646.6383\n",
      "Epoch 793/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.5891\n",
      "Epoch 794/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0084 - val_loss: 646.5965\n",
      "Epoch 795/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0074 - val_loss: 646.6084\n",
      "Epoch 796/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0094 - val_loss: 646.6042\n",
      "Epoch 797/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0076 - val_loss: 646.5846\n",
      "Epoch 798/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0078 - val_loss: 646.6171\n",
      "Epoch 799/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6136\n",
      "Epoch 800/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0080 - val_loss: 646.6181\n",
      "Epoch 801/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0080 - val_loss: 646.6469\n",
      "Epoch 802/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0067 - val_loss: 646.6613\n",
      "Epoch 803/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0084 - val_loss: 646.5991\n",
      "Epoch 804/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0073 - val_loss: 646.6198\n",
      "Epoch 805/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0073 - val_loss: 646.6755\n",
      "Epoch 806/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0081 - val_loss: 646.6390\n",
      "Epoch 807/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0081 - val_loss: 646.6417\n",
      "Epoch 808/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0068 - val_loss: 646.6488\n",
      "Epoch 809/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0076 - val_loss: 646.6013\n",
      "Epoch 810/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0061 - val_loss: 646.6504\n",
      "Epoch 811/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0072 - val_loss: 646.6536\n",
      "Epoch 812/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0073 - val_loss: 646.6163\n",
      "Epoch 813/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0092 - val_loss: 646.5946\n",
      "Epoch 814/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0098 - val_loss: 646.6585\n",
      "Epoch 815/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0070 - val_loss: 646.6635\n",
      "Epoch 816/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0085 - val_loss: 646.6772\n",
      "Epoch 817/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.5993\n",
      "Epoch 818/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0084 - val_loss: 646.5877\n",
      "Epoch 819/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6358\n",
      "Epoch 820/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0078 - val_loss: 646.6810\n",
      "Epoch 821/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0079 - val_loss: 646.6619\n",
      "Epoch 822/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0068 - val_loss: 646.6024\n",
      "Epoch 823/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.5757\n",
      "Epoch 824/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0096 - val_loss: 646.6128\n",
      "Epoch 825/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0077 - val_loss: 646.6261\n",
      "Epoch 826/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0065 - val_loss: 646.6464\n",
      "Epoch 827/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0078 - val_loss: 646.6262\n",
      "Epoch 828/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0082 - val_loss: 646.6152\n",
      "Epoch 829/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0076 - val_loss: 646.6318\n",
      "Epoch 830/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0080 - val_loss: 646.5930\n",
      "Epoch 831/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0069 - val_loss: 646.5963\n",
      "Epoch 832/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0078 - val_loss: 646.6166\n",
      "Epoch 833/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0063 - val_loss: 646.6218\n",
      "Epoch 834/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0069 - val_loss: 646.6415\n",
      "Epoch 835/1000\n",
      "320/320 [==============================] - 1s 3ms/step - loss: 325.0072 - val_loss: 646.6550\n",
      "Epoch 836/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0067 - val_loss: 646.6318\n",
      "Epoch 837/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 325.0081 - val_loss: 646.6122\n",
      "Epoch 838/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0074 - val_loss: 646.6380\n",
      "Epoch 839/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0089 - val_loss: 646.6405\n",
      "Epoch 840/1000\n",
      "320/320 [==============================] - 0s 928us/step - loss: 325.0080 - val_loss: 646.5797\n",
      "Epoch 841/1000\n",
      "320/320 [==============================] - 0s 823us/step - loss: 325.0079 - val_loss: 646.6284\n",
      "Epoch 842/1000\n",
      "320/320 [==============================] - 0s 838us/step - loss: 325.0086 - val_loss: 646.6288\n",
      "Epoch 843/1000\n",
      "320/320 [==============================] - 0s 774us/step - loss: 325.0069 - val_loss: 646.6387\n",
      "Epoch 844/1000\n",
      "320/320 [==============================] - 0s 797us/step - loss: 325.0080 - val_loss: 646.6061\n",
      "Epoch 845/1000\n",
      "320/320 [==============================] - 0s 778us/step - loss: 325.0071 - val_loss: 646.6086\n",
      "Epoch 846/1000\n",
      "320/320 [==============================] - 0s 862us/step - loss: 325.0077 - val_loss: 646.6369\n",
      "Epoch 847/1000\n",
      "320/320 [==============================] - 0s 815us/step - loss: 325.0077 - val_loss: 646.5718\n",
      "Epoch 848/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0074 - val_loss: 646.5971\n",
      "Epoch 849/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 325.0066 - val_loss: 646.6744\n",
      "Epoch 850/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 325.0071 - val_loss: 646.6483\n",
      "Epoch 851/1000\n",
      "320/320 [==============================] - 0s 784us/step - loss: 325.0076 - val_loss: 646.5754\n",
      "Epoch 852/1000\n",
      "320/320 [==============================] - 0s 811us/step - loss: 325.0077 - val_loss: 646.6198\n",
      "Epoch 853/1000\n",
      "320/320 [==============================] - 0s 871us/step - loss: 325.0061 - val_loss: 646.6270\n",
      "Epoch 854/1000\n",
      "320/320 [==============================] - 0s 955us/step - loss: 325.0095 - val_loss: 646.6027\n",
      "Epoch 855/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 899us/step - loss: 325.0074 - val_loss: 646.5934\n",
      "Epoch 856/1000\n",
      "320/320 [==============================] - 0s 924us/step - loss: 325.0067 - val_loss: 646.5937\n",
      "Epoch 857/1000\n",
      "320/320 [==============================] - 0s 895us/step - loss: 325.0063 - val_loss: 646.5942\n",
      "Epoch 858/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 325.0075 - val_loss: 646.6185\n",
      "Epoch 859/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0095 - val_loss: 646.5774\n",
      "Epoch 860/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0092 - val_loss: 646.6143\n",
      "Epoch 861/1000\n",
      "320/320 [==============================] - 0s 913us/step - loss: 325.0069 - val_loss: 646.5890\n",
      "Epoch 862/1000\n",
      "320/320 [==============================] - 0s 958us/step - loss: 325.0073 - val_loss: 646.6137\n",
      "Epoch 863/1000\n",
      "320/320 [==============================] - 0s 961us/step - loss: 325.0071 - val_loss: 646.5974\n",
      "Epoch 864/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0074 - val_loss: 646.6497\n",
      "Epoch 865/1000\n",
      "320/320 [==============================] - 0s 819us/step - loss: 325.0072 - val_loss: 646.5792\n",
      "Epoch 866/1000\n",
      "320/320 [==============================] - 0s 821us/step - loss: 325.0062 - val_loss: 646.6308\n",
      "Epoch 867/1000\n",
      "320/320 [==============================] - 0s 825us/step - loss: 325.0072 - val_loss: 646.6116\n",
      "Epoch 868/1000\n",
      "320/320 [==============================] - 0s 918us/step - loss: 325.0075 - val_loss: 646.6566\n",
      "Epoch 869/1000\n",
      "320/320 [==============================] - 0s 837us/step - loss: 325.0080 - val_loss: 646.5905\n",
      "Epoch 870/1000\n",
      "320/320 [==============================] - 0s 905us/step - loss: 325.0078 - val_loss: 646.6354\n",
      "Epoch 871/1000\n",
      "320/320 [==============================] - 0s 884us/step - loss: 325.0078 - val_loss: 646.6418\n",
      "Epoch 872/1000\n",
      "320/320 [==============================] - 0s 971us/step - loss: 325.0075 - val_loss: 646.6395\n",
      "Epoch 873/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0069 - val_loss: 646.6489\n",
      "Epoch 874/1000\n",
      "320/320 [==============================] - 0s 929us/step - loss: 325.0074 - val_loss: 646.6382\n",
      "Epoch 875/1000\n",
      "320/320 [==============================] - 0s 913us/step - loss: 325.0074 - val_loss: 646.6530\n",
      "Epoch 876/1000\n",
      "320/320 [==============================] - 0s 799us/step - loss: 325.0078 - val_loss: 646.6404\n",
      "Epoch 877/1000\n",
      "320/320 [==============================] - 0s 896us/step - loss: 325.0063 - val_loss: 646.6409\n",
      "Epoch 878/1000\n",
      "320/320 [==============================] - 0s 843us/step - loss: 325.0068 - val_loss: 646.6342\n",
      "Epoch 879/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0078 - val_loss: 646.5966\n",
      "Epoch 880/1000\n",
      "320/320 [==============================] - 0s 826us/step - loss: 325.0076 - val_loss: 646.6080\n",
      "Epoch 881/1000\n",
      "320/320 [==============================] - 0s 875us/step - loss: 325.0079 - val_loss: 646.5871\n",
      "Epoch 882/1000\n",
      "320/320 [==============================] - 0s 822us/step - loss: 325.0078 - val_loss: 646.6230\n",
      "Epoch 883/1000\n",
      "320/320 [==============================] - 0s 784us/step - loss: 325.0071 - val_loss: 646.6639\n",
      "Epoch 884/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0071 - val_loss: 646.6434\n",
      "Epoch 885/1000\n",
      "320/320 [==============================] - 0s 888us/step - loss: 325.0075 - val_loss: 646.6547\n",
      "Epoch 886/1000\n",
      "320/320 [==============================] - 0s 862us/step - loss: 325.0075 - val_loss: 646.5809\n",
      "Epoch 887/1000\n",
      "320/320 [==============================] - 0s 865us/step - loss: 325.0063 - val_loss: 646.6017\n",
      "Epoch 888/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0067 - val_loss: 646.6245\n",
      "Epoch 889/1000\n",
      "320/320 [==============================] - 0s 818us/step - loss: 325.0085 - val_loss: 646.6559\n",
      "Epoch 890/1000\n",
      "320/320 [==============================] - 0s 800us/step - loss: 325.0070 - val_loss: 646.6260\n",
      "Epoch 891/1000\n",
      "320/320 [==============================] - 0s 881us/step - loss: 325.0074 - val_loss: 646.5742\n",
      "Epoch 892/1000\n",
      "320/320 [==============================] - 0s 770us/step - loss: 325.0060 - val_loss: 646.6093\n",
      "Epoch 893/1000\n",
      "320/320 [==============================] - 0s 807us/step - loss: 325.0077 - val_loss: 646.6340\n",
      "Epoch 894/1000\n",
      "320/320 [==============================] - 0s 982us/step - loss: 325.0068 - val_loss: 646.5652\n",
      "Epoch 895/1000\n",
      "320/320 [==============================] - 0s 930us/step - loss: 325.0074 - val_loss: 646.5695\n",
      "Epoch 896/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0072 - val_loss: 646.6181\n",
      "Epoch 897/1000\n",
      "320/320 [==============================] - 0s 864us/step - loss: 325.0081 - val_loss: 646.6489\n",
      "Epoch 898/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0069 - val_loss: 646.6226\n",
      "Epoch 899/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 325.0079 - val_loss: 646.6314\n",
      "Epoch 900/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0063 - val_loss: 646.6080\n",
      "Epoch 901/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0074 - val_loss: 646.6299\n",
      "Epoch 902/1000\n",
      "320/320 [==============================] - 0s 784us/step - loss: 325.0060 - val_loss: 646.6193\n",
      "Epoch 903/1000\n",
      "320/320 [==============================] - 0s 821us/step - loss: 325.0067 - val_loss: 646.5935\n",
      "Epoch 904/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0076 - val_loss: 646.6545\n",
      "Epoch 905/1000\n",
      "320/320 [==============================] - 0s 815us/step - loss: 325.0068 - val_loss: 646.6344\n",
      "Epoch 906/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0069 - val_loss: 646.6359\n",
      "Epoch 907/1000\n",
      "320/320 [==============================] - 0s 879us/step - loss: 325.0081 - val_loss: 646.6146\n",
      "Epoch 908/1000\n",
      "320/320 [==============================] - 0s 759us/step - loss: 325.0078 - val_loss: 646.6378\n",
      "Epoch 909/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 325.0073 - val_loss: 646.5970\n",
      "Epoch 910/1000\n",
      "320/320 [==============================] - 0s 900us/step - loss: 325.0074 - val_loss: 646.5986\n",
      "Epoch 911/1000\n",
      "320/320 [==============================] - 0s 921us/step - loss: 325.0074 - val_loss: 646.6083\n",
      "Epoch 912/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0062 - val_loss: 646.6723\n",
      "Epoch 913/1000\n",
      "320/320 [==============================] - 0s 935us/step - loss: 325.0085 - val_loss: 646.5944\n",
      "Epoch 914/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0081 - val_loss: 646.6573\n",
      "Epoch 915/1000\n",
      "320/320 [==============================] - 0s 850us/step - loss: 325.0065 - val_loss: 646.6198\n",
      "Epoch 916/1000\n",
      "320/320 [==============================] - 0s 959us/step - loss: 325.0070 - val_loss: 646.6439\n",
      "Epoch 917/1000\n",
      "320/320 [==============================] - 0s 954us/step - loss: 325.0063 - val_loss: 646.6448\n",
      "Epoch 918/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0074 - val_loss: 646.6473\n",
      "Epoch 919/1000\n",
      "320/320 [==============================] - 0s 808us/step - loss: 325.0070 - val_loss: 646.6295\n",
      "Epoch 920/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0075 - val_loss: 646.6218\n",
      "Epoch 921/1000\n",
      "320/320 [==============================] - 0s 785us/step - loss: 325.0069 - val_loss: 646.6753\n",
      "Epoch 922/1000\n",
      "320/320 [==============================] - 0s 808us/step - loss: 325.0078 - val_loss: 646.6212\n",
      "Epoch 923/1000\n",
      "320/320 [==============================] - 0s 849us/step - loss: 325.0084 - val_loss: 646.6919\n",
      "Epoch 924/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 325.0067 - val_loss: 646.6242\n",
      "Epoch 925/1000\n",
      "320/320 [==============================] - 0s 840us/step - loss: 325.0072 - val_loss: 646.6075\n",
      "Epoch 926/1000\n",
      "320/320 [==============================] - 0s 868us/step - loss: 325.0071 - val_loss: 646.5861\n",
      "Epoch 927/1000\n",
      "320/320 [==============================] - 0s 770us/step - loss: 325.0074 - val_loss: 646.6046\n",
      "Epoch 928/1000\n",
      "320/320 [==============================] - 0s 841us/step - loss: 325.0074 - val_loss: 646.6166\n",
      "Epoch 929/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 864us/step - loss: 325.0073 - val_loss: 646.6024\n",
      "Epoch 930/1000\n",
      "320/320 [==============================] - 0s 778us/step - loss: 325.0065 - val_loss: 646.6393\n",
      "Epoch 931/1000\n",
      "320/320 [==============================] - 0s 848us/step - loss: 325.0070 - val_loss: 646.6526\n",
      "Epoch 932/1000\n",
      "320/320 [==============================] - 0s 898us/step - loss: 325.0078 - val_loss: 646.6290\n",
      "Epoch 933/1000\n",
      "320/320 [==============================] - 0s 826us/step - loss: 325.0079 - val_loss: 646.5964\n",
      "Epoch 934/1000\n",
      "320/320 [==============================] - 0s 808us/step - loss: 325.0065 - val_loss: 646.6116\n",
      "Epoch 935/1000\n",
      "320/320 [==============================] - 0s 854us/step - loss: 325.0068 - val_loss: 646.5693\n",
      "Epoch 936/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0073 - val_loss: 646.6495\n",
      "Epoch 937/1000\n",
      "320/320 [==============================] - 0s 834us/step - loss: 325.0080 - val_loss: 646.6423\n",
      "Epoch 938/1000\n",
      "320/320 [==============================] - 0s 857us/step - loss: 325.0085 - val_loss: 646.6133\n",
      "Epoch 939/1000\n",
      "320/320 [==============================] - 0s 806us/step - loss: 325.0071 - val_loss: 646.6946\n",
      "Epoch 940/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0068 - val_loss: 646.6257\n",
      "Epoch 941/1000\n",
      "320/320 [==============================] - 0s 832us/step - loss: 325.0066 - val_loss: 646.5911\n",
      "Epoch 942/1000\n",
      "320/320 [==============================] - 0s 842us/step - loss: 325.0071 - val_loss: 646.5993\n",
      "Epoch 943/1000\n",
      "320/320 [==============================] - 0s 790us/step - loss: 325.0075 - val_loss: 646.6551\n",
      "Epoch 944/1000\n",
      "320/320 [==============================] - 0s 866us/step - loss: 325.0080 - val_loss: 646.6014\n",
      "Epoch 945/1000\n",
      "320/320 [==============================] - 0s 821us/step - loss: 325.0076 - val_loss: 646.5643\n",
      "Epoch 946/1000\n",
      "320/320 [==============================] - 0s 876us/step - loss: 325.0074 - val_loss: 646.5978\n",
      "Epoch 947/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0069 - val_loss: 646.5836\n",
      "Epoch 948/1000\n",
      "320/320 [==============================] - 0s 815us/step - loss: 325.0066 - val_loss: 646.5864\n",
      "Epoch 949/1000\n",
      "320/320 [==============================] - 0s 861us/step - loss: 325.0074 - val_loss: 646.5844\n",
      "Epoch 950/1000\n",
      "320/320 [==============================] - 0s 907us/step - loss: 325.0085 - val_loss: 646.5871\n",
      "Epoch 951/1000\n",
      "320/320 [==============================] - 0s 883us/step - loss: 325.0068 - val_loss: 646.6506\n",
      "Epoch 952/1000\n",
      "320/320 [==============================] - 0s 814us/step - loss: 325.0073 - val_loss: 646.6442\n",
      "Epoch 953/1000\n",
      "320/320 [==============================] - 0s 859us/step - loss: 325.0077 - val_loss: 646.6180\n",
      "Epoch 954/1000\n",
      "320/320 [==============================] - 0s 867us/step - loss: 325.0075 - val_loss: 646.5953\n",
      "Epoch 955/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 325.0089 - val_loss: 646.5965\n",
      "Epoch 956/1000\n",
      "320/320 [==============================] - 0s 855us/step - loss: 325.0070 - val_loss: 646.6242\n",
      "Epoch 957/1000\n",
      "320/320 [==============================] - 0s 854us/step - loss: 325.0077 - val_loss: 646.6146\n",
      "Epoch 958/1000\n",
      "320/320 [==============================] - 0s 903us/step - loss: 325.0070 - val_loss: 646.6523\n",
      "Epoch 959/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0083 - val_loss: 646.5720\n",
      "Epoch 960/1000\n",
      "320/320 [==============================] - 0s 854us/step - loss: 325.0081 - val_loss: 646.5898\n",
      "Epoch 961/1000\n",
      "320/320 [==============================] - 0s 851us/step - loss: 325.0079 - val_loss: 646.6315\n",
      "Epoch 962/1000\n",
      "320/320 [==============================] - 0s 847us/step - loss: 325.0075 - val_loss: 646.6631\n",
      "Epoch 963/1000\n",
      "320/320 [==============================] - 0s 889us/step - loss: 325.0069 - val_loss: 646.6365\n",
      "Epoch 964/1000\n",
      "320/320 [==============================] - 0s 844us/step - loss: 325.0068 - val_loss: 646.5945\n",
      "Epoch 965/1000\n",
      "320/320 [==============================] - 0s 788us/step - loss: 325.0070 - val_loss: 646.6320\n",
      "Epoch 966/1000\n",
      "320/320 [==============================] - 0s 796us/step - loss: 325.0082 - val_loss: 646.6807\n",
      "Epoch 967/1000\n",
      "320/320 [==============================] - 0s 877us/step - loss: 325.0063 - val_loss: 646.6216\n",
      "Epoch 968/1000\n",
      "320/320 [==============================] - 0s 831us/step - loss: 325.0074 - val_loss: 646.6257\n",
      "Epoch 969/1000\n",
      "320/320 [==============================] - 0s 893us/step - loss: 325.0070 - val_loss: 646.5886\n",
      "Epoch 970/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0081 - val_loss: 646.5648\n",
      "Epoch 971/1000\n",
      "320/320 [==============================] - 0s 977us/step - loss: 325.0082 - val_loss: 646.6290\n",
      "Epoch 972/1000\n",
      "320/320 [==============================] - 0s 938us/step - loss: 325.0065 - val_loss: 646.6323\n",
      "Epoch 973/1000\n",
      "320/320 [==============================] - 0s 1ms/step - loss: 325.0082 - val_loss: 646.6477\n",
      "Epoch 974/1000\n",
      "320/320 [==============================] - 0s 971us/step - loss: 325.0078 - val_loss: 646.6600\n",
      "Epoch 975/1000\n",
      "320/320 [==============================] - 0s 885us/step - loss: 325.0067 - val_loss: 646.5932\n",
      "Epoch 976/1000\n",
      "320/320 [==============================] - 0s 828us/step - loss: 325.0066 - val_loss: 646.6341\n",
      "Epoch 977/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0074 - val_loss: 646.6097\n",
      "Epoch 978/1000\n",
      "320/320 [==============================] - 0s 845us/step - loss: 325.0091 - val_loss: 646.6508\n",
      "Epoch 979/1000\n",
      "320/320 [==============================] - 0s 841us/step - loss: 325.0076 - val_loss: 646.6282\n",
      "Epoch 980/1000\n",
      "320/320 [==============================] - 0s 852us/step - loss: 325.0070 - val_loss: 646.6280\n",
      "Epoch 981/1000\n",
      "320/320 [==============================] - 0s 906us/step - loss: 325.0068 - val_loss: 646.6069\n",
      "Epoch 982/1000\n",
      "320/320 [==============================] - 0s 919us/step - loss: 325.0073 - val_loss: 646.5587\n",
      "Epoch 983/1000\n",
      "320/320 [==============================] - 0s 971us/step - loss: 325.0078 - val_loss: 646.6450\n",
      "Epoch 984/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 325.0093 - val_loss: 646.6052\n",
      "Epoch 985/1000\n",
      "320/320 [==============================] - 0s 870us/step - loss: 325.0077 - val_loss: 646.5608\n",
      "Epoch 986/1000\n",
      "320/320 [==============================] - 0s 785us/step - loss: 325.0080 - val_loss: 646.6806\n",
      "Epoch 987/1000\n",
      "320/320 [==============================] - 0s 812us/step - loss: 325.0091 - val_loss: 646.6035\n",
      "Epoch 988/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0073 - val_loss: 646.6673\n",
      "Epoch 989/1000\n",
      "320/320 [==============================] - 0s 869us/step - loss: 325.0066 - val_loss: 646.6411\n",
      "Epoch 990/1000\n",
      "320/320 [==============================] - 0s 887us/step - loss: 325.0067 - val_loss: 646.6132\n",
      "Epoch 991/1000\n",
      "320/320 [==============================] - 0s 923us/step - loss: 325.0089 - val_loss: 646.6812\n",
      "Epoch 992/1000\n",
      "320/320 [==============================] - 0s 872us/step - loss: 325.0065 - val_loss: 646.6318\n",
      "Epoch 993/1000\n",
      "320/320 [==============================] - 0s 860us/step - loss: 325.0076 - val_loss: 646.6370\n",
      "Epoch 994/1000\n",
      "320/320 [==============================] - 0s 891us/step - loss: 325.0078 - val_loss: 646.6378\n",
      "Epoch 995/1000\n",
      "320/320 [==============================] - 0s 944us/step - loss: 325.0071 - val_loss: 646.6720\n",
      "Epoch 996/1000\n",
      "320/320 [==============================] - 0s 917us/step - loss: 325.0071 - val_loss: 646.6976\n",
      "Epoch 997/1000\n",
      "320/320 [==============================] - 0s 892us/step - loss: 325.0078 - val_loss: 646.6100\n",
      "Epoch 998/1000\n",
      "320/320 [==============================] - 0s 813us/step - loss: 325.0081 - val_loss: 646.6265\n",
      "Epoch 999/1000\n",
      "320/320 [==============================] - 0s 863us/step - loss: 325.0070 - val_loss: 646.6334\n",
      "Epoch 1000/1000\n",
      "320/320 [==============================] - 0s 856us/step - loss: 325.0084 - val_loss: 646.6619\n",
      "27/27 [==============================] - 0s 643us/step\n",
      "1014698 successful\n",
      "Epoch 1/1000\n",
      "306/306 [==============================] - 1s 1ms/step - loss: 16668715.0000 - val_loss: 725.5707\n",
      "Epoch 2/1000\n",
      "306/306 [==============================] - 0s 915us/step - loss: 413.8571 - val_loss: 691.2295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "306/306 [==============================] - 0s 960us/step - loss: 408.1015 - val_loss: 702.6375\n",
      "Epoch 4/1000\n",
      "306/306 [==============================] - 0s 934us/step - loss: 438.0848 - val_loss: 1316.0536\n",
      "Epoch 5/1000\n",
      "306/306 [==============================] - 0s 985us/step - loss: 448.6719 - val_loss: 607.1311\n",
      "Epoch 6/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 466.9186 - val_loss: 772.7614\n",
      "Epoch 7/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 515.5212 - val_loss: 1615.5800\n",
      "Epoch 8/1000\n",
      "306/306 [==============================] - 0s 961us/step - loss: 557.0758 - val_loss: 706.5131\n",
      "Epoch 9/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 630.1960 - val_loss: 677.6092\n",
      "Epoch 10/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1086.3212 - val_loss: 2120.9656\n",
      "Epoch 11/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 1828.8801 - val_loss: 847.9664\n",
      "Epoch 12/1000\n",
      "306/306 [==============================] - 0s 912us/step - loss: 4288.4043 - val_loss: 162024.4531\n",
      "Epoch 13/1000\n",
      "306/306 [==============================] - 0s 904us/step - loss: 118506.8516 - val_loss: 282737.6562\n",
      "Epoch 14/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 127414.7578 - val_loss: 2302.5471\n",
      "Epoch 15/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 135182.5625 - val_loss: 49323.2500\n",
      "Epoch 16/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 121896.5625 - val_loss: 283099.5000\n",
      "Epoch 17/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 132480.7969 - val_loss: 1072.4496\n",
      "Epoch 18/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 94078.5781 - val_loss: 311203.7812\n",
      "Epoch 19/1000\n",
      "306/306 [==============================] - 0s 993us/step - loss: 135262.5312 - val_loss: 38914.9805\n",
      "Epoch 20/1000\n",
      "306/306 [==============================] - 0s 950us/step - loss: 99642.6250 - val_loss: 28578.3652\n",
      "Epoch 21/1000\n",
      "306/306 [==============================] - 0s 963us/step - loss: 101245.0547 - val_loss: 1419.8972\n",
      "Epoch 22/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 129956.1797 - val_loss: 3153.1877\n",
      "Epoch 23/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 105828.4219 - val_loss: 1336.4606\n",
      "Epoch 24/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 95783.7812 - val_loss: 5891.1802\n",
      "Epoch 25/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 96904.2500 - val_loss: 24202.5254\n",
      "Epoch 26/1000\n",
      "306/306 [==============================] - 0s 988us/step - loss: 95931.8828 - val_loss: 125198.4609\n",
      "Epoch 27/1000\n",
      "306/306 [==============================] - 0s 997us/step - loss: 105839.0312 - val_loss: 1227661.0000\n",
      "Epoch 28/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 78325.0703 - val_loss: 94561.1641\n",
      "Epoch 29/1000\n",
      "306/306 [==============================] - 0s 873us/step - loss: 98217.5391 - val_loss: 1254.1084\n",
      "Epoch 30/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 92727.8906 - val_loss: 50428.1406\n",
      "Epoch 31/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 86330.5703 - val_loss: 301037.6250\n",
      "Epoch 32/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 83629.3438 - val_loss: 76323.1406\n",
      "Epoch 33/1000\n",
      "306/306 [==============================] - 0s 961us/step - loss: 105379.2969 - val_loss: 106116.8125\n",
      "Epoch 34/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 64321.6641 - val_loss: 652.5743\n",
      "Epoch 35/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 98715.2969 - val_loss: 9438.2500\n",
      "Epoch 36/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 70689.2031 - val_loss: 93886.3203\n",
      "Epoch 37/1000\n",
      "306/306 [==============================] - 0s 997us/step - loss: 82320.2500 - val_loss: 13538.8438\n",
      "Epoch 38/1000\n",
      "306/306 [==============================] - 0s 859us/step - loss: 80637.4531 - val_loss: 1028.7812\n",
      "Epoch 39/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 67642.8359 - val_loss: 45850.8516\n",
      "Epoch 40/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 81207.0859 - val_loss: 33398.4219\n",
      "Epoch 41/1000\n",
      "306/306 [==============================] - 0s 930us/step - loss: 71387.1328 - val_loss: 397208.9375\n",
      "Epoch 42/1000\n",
      "306/306 [==============================] - 0s 899us/step - loss: 74110.0078 - val_loss: 231590.4375\n",
      "Epoch 43/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 72412.1016 - val_loss: 73485.9922\n",
      "Epoch 44/1000\n",
      "306/306 [==============================] - 0s 889us/step - loss: 69486.2578 - val_loss: 2196.8879\n",
      "Epoch 45/1000\n",
      "306/306 [==============================] - 0s 960us/step - loss: 78622.0078 - val_loss: 46591.3359\n",
      "Epoch 46/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 67562.2812 - val_loss: 4123.7954\n",
      "Epoch 47/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 56476.6680 - val_loss: 40313.3906\n",
      "Epoch 48/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 70369.0078 - val_loss: 911.8373\n",
      "Epoch 49/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 57321.0508 - val_loss: 82574.0781\n",
      "Epoch 50/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 65629.1562 - val_loss: 654499.5625\n",
      "Epoch 51/1000\n",
      "306/306 [==============================] - 0s 974us/step - loss: 52174.0781 - val_loss: 17440.4883\n",
      "Epoch 52/1000\n",
      "306/306 [==============================] - 0s 954us/step - loss: 71196.2500 - val_loss: 7085.2437\n",
      "Epoch 53/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 46855.5234 - val_loss: 25415.0957\n",
      "Epoch 54/1000\n",
      "306/306 [==============================] - 0s 994us/step - loss: 58003.5117 - val_loss: 87016.4922\n",
      "Epoch 55/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 52312.7930 - val_loss: 111463.1641\n",
      "Epoch 56/1000\n",
      "306/306 [==============================] - 0s 981us/step - loss: 54852.0352 - val_loss: 32580.8301\n",
      "Epoch 57/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 48434.0664 - val_loss: 24931.8066\n",
      "Epoch 58/1000\n",
      "306/306 [==============================] - 0s 975us/step - loss: 43487.2188 - val_loss: 629.4955\n",
      "Epoch 59/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 47018.9492 - val_loss: 639.1681\n",
      "Epoch 60/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 40593.8438 - val_loss: 14802.3301\n",
      "Epoch 61/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 44663.1211 - val_loss: 66758.1250\n",
      "Epoch 62/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 46035.7852 - val_loss: 62026.7148\n",
      "Epoch 63/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 40068.0781 - val_loss: 75706.2500\n",
      "Epoch 64/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 46318.3242 - val_loss: 607.0827\n",
      "Epoch 65/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 44725.2266 - val_loss: 2249.1990\n",
      "Epoch 66/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 34554.9727 - val_loss: 99635.4375\n",
      "Epoch 67/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 47151.0977 - val_loss: 3847.5632\n",
      "Epoch 68/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 36491.5664 - val_loss: 31115.7852\n",
      "Epoch 69/1000\n",
      "306/306 [==============================] - 0s 936us/step - loss: 41641.0469 - val_loss: 18822.6680\n",
      "Epoch 70/1000\n",
      "306/306 [==============================] - 0s 908us/step - loss: 38139.6719 - val_loss: 383468.0625\n",
      "Epoch 71/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 34773.7578 - val_loss: 83701.4062\n",
      "Epoch 72/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 37367.6055 - val_loss: 28276.0645\n",
      "Epoch 73/1000\n",
      "306/306 [==============================] - 0s 872us/step - loss: 38640.1641 - val_loss: 18210.7207\n",
      "Epoch 74/1000\n",
      "306/306 [==============================] - 0s 930us/step - loss: 33756.2656 - val_loss: 21730.5039\n",
      "Epoch 75/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 33888.1719 - val_loss: 3547.2068\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 1ms/step - loss: 37608.0391 - val_loss: 2622.5811\n",
      "Epoch 77/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 37954.8438 - val_loss: 27902.5430\n",
      "Epoch 78/1000\n",
      "306/306 [==============================] - 0s 899us/step - loss: 28946.1758 - val_loss: 672.9514\n",
      "Epoch 79/1000\n",
      "306/306 [==============================] - 0s 833us/step - loss: 30965.0469 - val_loss: 17054.3438\n",
      "Epoch 80/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 32764.0430 - val_loss: 203628.2344\n",
      "Epoch 81/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 29601.0449 - val_loss: 17514.3047\n",
      "Epoch 82/1000\n",
      "306/306 [==============================] - 0s 846us/step - loss: 30744.3652 - val_loss: 27044.2070\n",
      "Epoch 83/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 29508.1074 - val_loss: 16936.2188\n",
      "Epoch 84/1000\n",
      "306/306 [==============================] - 0s 971us/step - loss: 28361.3496 - val_loss: 31307.1699\n",
      "Epoch 85/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 28358.2207 - val_loss: 28241.3984\n",
      "Epoch 86/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 30233.3828 - val_loss: 871.2748\n",
      "Epoch 87/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 30525.2812 - val_loss: 30456.1152\n",
      "Epoch 88/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 22634.4258 - val_loss: 89656.9219\n",
      "Epoch 89/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 13894.3809 - val_loss: 24245.2422\n",
      "Epoch 90/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 21441.7285 - val_loss: 9054.0078\n",
      "Epoch 91/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 19560.6016 - val_loss: 881.0236\n",
      "Epoch 92/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 24314.2383 - val_loss: 13830.3613\n",
      "Epoch 93/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 20153.1113 - val_loss: 23999.4375\n",
      "Epoch 94/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 23835.8535 - val_loss: 25800.3438\n",
      "Epoch 95/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 20264.2363 - val_loss: 729.9648\n",
      "Epoch 96/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 19175.8066 - val_loss: 32733.4102\n",
      "Epoch 97/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 21075.5273 - val_loss: 13431.0801\n",
      "Epoch 98/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 21289.0957 - val_loss: 22946.9375\n",
      "Epoch 99/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 18293.0625 - val_loss: 54287.5430\n",
      "Epoch 100/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 21788.8164 - val_loss: 4165.5425\n",
      "Epoch 101/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 16941.1641 - val_loss: 27512.4316\n",
      "Epoch 102/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 18783.4668 - val_loss: 7287.2974\n",
      "Epoch 103/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 24327.6191 - val_loss: 679.3000\n",
      "Epoch 104/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 17442.0645 - val_loss: 51399.2617\n",
      "Epoch 105/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14081.9082 - val_loss: 18963.2812\n",
      "Epoch 106/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 19020.1719 - val_loss: 12023.7188\n",
      "Epoch 107/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 18163.4707 - val_loss: 11902.7480\n",
      "Epoch 108/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 17347.5332 - val_loss: 20061.7266\n",
      "Epoch 109/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 15965.3516 - val_loss: 9430.3076\n",
      "Epoch 110/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 19754.4961 - val_loss: 40493.8828\n",
      "Epoch 111/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 17143.2891 - val_loss: 8809.3242\n",
      "Epoch 112/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14163.2646 - val_loss: 1078.0966\n",
      "Epoch 113/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 17193.6777 - val_loss: 6306.5391\n",
      "Epoch 114/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 16690.0371 - val_loss: 5205.9507\n",
      "Epoch 115/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 14877.0049 - val_loss: 1106.1935\n",
      "Epoch 116/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 15710.4502 - val_loss: 9980.1182\n",
      "Epoch 117/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14779.4111 - val_loss: 8417.7422\n",
      "Epoch 118/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 15433.2324 - val_loss: 9083.0078\n",
      "Epoch 119/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 14423.3428 - val_loss: 7134.1450\n",
      "Epoch 120/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 15368.9521 - val_loss: 748.6712\n",
      "Epoch 121/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13347.9648 - val_loss: 2144.5955\n",
      "Epoch 122/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13299.9180 - val_loss: 12114.6260\n",
      "Epoch 123/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 15696.1230 - val_loss: 2888.4512\n",
      "Epoch 124/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 12235.9492 - val_loss: 17634.6973\n",
      "Epoch 125/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14635.8584 - val_loss: 2056.6309\n",
      "Epoch 126/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 12937.9805 - val_loss: 77274.7891\n",
      "Epoch 127/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 12821.2256 - val_loss: 2164.5657\n",
      "Epoch 128/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13312.6592 - val_loss: 3954.8408\n",
      "Epoch 129/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 12096.6211 - val_loss: 9243.3564\n",
      "Epoch 130/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13538.2236 - val_loss: 3368.8582\n",
      "Epoch 131/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 11749.2344 - val_loss: 13105.0801\n",
      "Epoch 132/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 12145.3252 - val_loss: 7183.8643\n",
      "Epoch 133/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 13752.3252 - val_loss: 6482.1196\n",
      "Epoch 134/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 10894.8564 - val_loss: 856.9147\n",
      "Epoch 135/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 12208.8271 - val_loss: 3111.1375\n",
      "Epoch 136/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 10802.4678 - val_loss: 103237.4766\n",
      "Epoch 137/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 12729.8428 - val_loss: 735.6696\n",
      "Epoch 138/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 10927.4492 - val_loss: 1902.3760\n",
      "Epoch 139/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 9129.8193 - val_loss: 21334.4785\n",
      "Epoch 140/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 14192.9053 - val_loss: 1246.0626\n",
      "Epoch 141/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 10321.0566 - val_loss: 9656.2520\n",
      "Epoch 142/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9837.2803 - val_loss: 1065.4534\n",
      "Epoch 143/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 11960.6084 - val_loss: 7980.5942\n",
      "Epoch 144/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9454.9473 - val_loss: 8311.6875\n",
      "Epoch 145/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 11514.9531 - val_loss: 1998.5070\n",
      "Epoch 146/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 9459.6182 - val_loss: 738.6403\n",
      "Epoch 147/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 10116.4736 - val_loss: 11639.1934\n",
      "Epoch 148/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 11418.0723 - val_loss: 8330.7822\n",
      "Epoch 149/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9373.5273 - val_loss: 3324.7244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9657.4990 - val_loss: 656.5884\n",
      "Epoch 151/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9228.1875 - val_loss: 60851.7188\n",
      "Epoch 152/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 11495.0039 - val_loss: 2304.9561\n",
      "Epoch 153/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 9378.6113 - val_loss: 615.1285\n",
      "Epoch 154/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 8006.0200 - val_loss: 2159.8604\n",
      "Epoch 155/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 10494.0938 - val_loss: 10768.1982\n",
      "Epoch 156/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 8535.5264 - val_loss: 7725.3682\n",
      "Epoch 157/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 10510.2930 - val_loss: 23021.0117\n",
      "Epoch 158/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 8417.5391 - val_loss: 41033.2734\n",
      "Epoch 159/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 7942.3779 - val_loss: 614.2337\n",
      "Epoch 160/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 11561.5176 - val_loss: 13320.9678\n",
      "Epoch 161/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 6489.8604 - val_loss: 3605.6238\n",
      "Epoch 162/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 9259.8525 - val_loss: 3488.8760\n",
      "Epoch 163/1000\n",
      "306/306 [==============================] - 0s 930us/step - loss: 8541.4834 - val_loss: 24932.2344\n",
      "Epoch 164/1000\n",
      "306/306 [==============================] - 0s 870us/step - loss: 10551.9854 - val_loss: 1048.0784\n",
      "Epoch 165/1000\n",
      "306/306 [==============================] - 0s 939us/step - loss: 6472.8340 - val_loss: 662.3831\n",
      "Epoch 166/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 7333.7007 - val_loss: 7737.5874\n",
      "Epoch 167/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 8185.7729 - val_loss: 6043.3638\n",
      "Epoch 168/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 7512.5938 - val_loss: 705.0790\n",
      "Epoch 169/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 8840.4297 - val_loss: 5466.5801\n",
      "Epoch 170/1000\n",
      "306/306 [==============================] - 0s 984us/step - loss: 6302.0269 - val_loss: 1310.4414\n",
      "Epoch 171/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 9130.4424 - val_loss: 706.6184\n",
      "Epoch 172/1000\n",
      "306/306 [==============================] - 0s 854us/step - loss: 7617.3047 - val_loss: 4972.6855\n",
      "Epoch 173/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 7214.3701 - val_loss: 1118.6888\n",
      "Epoch 174/1000\n",
      "306/306 [==============================] - 0s 798us/step - loss: 8060.9658 - val_loss: 994.3734\n",
      "Epoch 175/1000\n",
      "306/306 [==============================] - 0s 867us/step - loss: 6662.9209 - val_loss: 1797.4165\n",
      "Epoch 176/1000\n",
      "306/306 [==============================] - 0s 885us/step - loss: 6583.7285 - val_loss: 10759.9121\n",
      "Epoch 177/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 7638.7085 - val_loss: 651.7644\n",
      "Epoch 178/1000\n",
      "306/306 [==============================] - 0s 981us/step - loss: 6842.1318 - val_loss: 608.9406\n",
      "Epoch 179/1000\n",
      "306/306 [==============================] - 0s 841us/step - loss: 7670.0928 - val_loss: 7939.8257\n",
      "Epoch 180/1000\n",
      "306/306 [==============================] - 0s 854us/step - loss: 5667.5654 - val_loss: 4167.4170\n",
      "Epoch 181/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 6465.7925 - val_loss: 831.5353\n",
      "Epoch 182/1000\n",
      "306/306 [==============================] - 0s 838us/step - loss: 6515.3267 - val_loss: 2777.1416\n",
      "Epoch 183/1000\n",
      "306/306 [==============================] - 0s 969us/step - loss: 6884.7192 - val_loss: 33839.4219\n",
      "Epoch 184/1000\n",
      "306/306 [==============================] - 0s 890us/step - loss: 6355.0527 - val_loss: 4490.9854\n",
      "Epoch 185/1000\n",
      "306/306 [==============================] - 0s 848us/step - loss: 5932.2090 - val_loss: 12019.7471\n",
      "Epoch 186/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 6947.3984 - val_loss: 4641.7490\n",
      "Epoch 187/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 6366.1895 - val_loss: 46595.0117\n",
      "Epoch 188/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 5443.2012 - val_loss: 1957.3756\n",
      "Epoch 189/1000\n",
      "306/306 [==============================] - 0s 861us/step - loss: 6837.9043 - val_loss: 5312.8442\n",
      "Epoch 190/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 5740.1230 - val_loss: 791.5732\n",
      "Epoch 191/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 5447.5269 - val_loss: 1010.3875\n",
      "Epoch 192/1000\n",
      "306/306 [==============================] - 0s 845us/step - loss: 6507.5396 - val_loss: 3895.9771\n",
      "Epoch 193/1000\n",
      "306/306 [==============================] - 0s 839us/step - loss: 5782.6118 - val_loss: 2072.1284\n",
      "Epoch 194/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 5839.4106 - val_loss: 3638.2385\n",
      "Epoch 195/1000\n",
      "306/306 [==============================] - 0s 825us/step - loss: 5593.9478 - val_loss: 11955.0029\n",
      "Epoch 196/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 5791.3379 - val_loss: 3361.1079\n",
      "Epoch 197/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 5186.5234 - val_loss: 1556.0217\n",
      "Epoch 198/1000\n",
      "306/306 [==============================] - 0s 956us/step - loss: 5148.5562 - val_loss: 35273.7305\n",
      "Epoch 199/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 6148.9194 - val_loss: 14623.7285\n",
      "Epoch 200/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 4826.6597 - val_loss: 4864.0190\n",
      "Epoch 201/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5518.8213 - val_loss: 9238.0195\n",
      "Epoch 202/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5992.4351 - val_loss: 3691.5591\n",
      "Epoch 203/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 4695.0503 - val_loss: 664.0105\n",
      "Epoch 204/1000\n",
      "306/306 [==============================] - 0s 994us/step - loss: 5410.5117 - val_loss: 13823.3594\n",
      "Epoch 205/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5706.2666 - val_loss: 7611.2148\n",
      "Epoch 206/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 4748.3867 - val_loss: 765.9823\n",
      "Epoch 207/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5288.2686 - val_loss: 7643.0151\n",
      "Epoch 208/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 4835.5083 - val_loss: 4513.4126\n",
      "Epoch 209/1000\n",
      "306/306 [==============================] - 0s 953us/step - loss: 4336.9980 - val_loss: 4679.1875\n",
      "Epoch 210/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 5200.4072 - val_loss: 3922.8486\n",
      "Epoch 211/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 4235.3115 - val_loss: 4022.1052\n",
      "Epoch 212/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 4589.4512 - val_loss: 23416.0957\n",
      "Epoch 213/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 5861.1099 - val_loss: 927.6387\n",
      "Epoch 214/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 3982.2107 - val_loss: 3065.5056\n",
      "Epoch 215/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 4899.7603 - val_loss: 1963.1022\n",
      "Epoch 216/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 4643.3286 - val_loss: 755.5576\n",
      "Epoch 217/1000\n",
      "306/306 [==============================] - 0s 824us/step - loss: 4814.1323 - val_loss: 2433.1482\n",
      "Epoch 218/1000\n",
      "306/306 [==============================] - 0s 826us/step - loss: 3836.7559 - val_loss: 1706.7617\n",
      "Epoch 219/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 4387.8643 - val_loss: 2986.6301\n",
      "Epoch 220/1000\n",
      "306/306 [==============================] - 0s 885us/step - loss: 5307.3340 - val_loss: 28191.3086\n",
      "Epoch 221/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 4185.7715 - val_loss: 764.5091\n",
      "Epoch 222/1000\n",
      "306/306 [==============================] - 0s 861us/step - loss: 4003.4087 - val_loss: 3612.3582\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 939us/step - loss: 4132.7041 - val_loss: 12866.1855\n",
      "Epoch 224/1000\n",
      "306/306 [==============================] - 0s 981us/step - loss: 4271.3545 - val_loss: 18319.9980\n",
      "Epoch 225/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 3186.4849 - val_loss: 11377.7139\n",
      "Epoch 226/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 4036.6372 - val_loss: 2033.9355\n",
      "Epoch 227/1000\n",
      "306/306 [==============================] - 0s 850us/step - loss: 6214.3184 - val_loss: 1964.3491\n",
      "Epoch 228/1000\n",
      "306/306 [==============================] - 0s 878us/step - loss: 2568.0283 - val_loss: 1187.9968\n",
      "Epoch 229/1000\n",
      "306/306 [==============================] - 0s 848us/step - loss: 3636.9329 - val_loss: 10016.7773\n",
      "Epoch 230/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 3917.0413 - val_loss: 2063.7109\n",
      "Epoch 231/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 3794.1968 - val_loss: 934.5334\n",
      "Epoch 232/1000\n",
      "306/306 [==============================] - 0s 877us/step - loss: 3675.6875 - val_loss: 3169.3203\n",
      "Epoch 233/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 3445.3079 - val_loss: 13396.7744\n",
      "Epoch 234/1000\n",
      "306/306 [==============================] - 0s 818us/step - loss: 4600.5747 - val_loss: 674.9542\n",
      "Epoch 235/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 2569.2480 - val_loss: 1470.7275\n",
      "Epoch 236/1000\n",
      "306/306 [==============================] - 0s 907us/step - loss: 3328.8503 - val_loss: 2753.6780\n",
      "Epoch 237/1000\n",
      "306/306 [==============================] - 0s 841us/step - loss: 4057.8992 - val_loss: 612.5664\n",
      "Epoch 238/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 3516.0164 - val_loss: 824.5460\n",
      "Epoch 239/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 3705.1370 - val_loss: 1944.2159\n",
      "Epoch 240/1000\n",
      "306/306 [==============================] - 0s 847us/step - loss: 3644.7830 - val_loss: 3652.5259\n",
      "Epoch 241/1000\n",
      "306/306 [==============================] - 0s 849us/step - loss: 2732.5637 - val_loss: 2341.1304\n",
      "Epoch 242/1000\n",
      "306/306 [==============================] - 0s 829us/step - loss: 4315.6157 - val_loss: 20669.0820\n",
      "Epoch 243/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 3111.5779 - val_loss: 1811.3115\n",
      "Epoch 244/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 2316.3298 - val_loss: 1052.1354\n",
      "Epoch 245/1000\n",
      "306/306 [==============================] - 0s 896us/step - loss: 3144.4995 - val_loss: 3452.8789\n",
      "Epoch 246/1000\n",
      "306/306 [==============================] - 0s 865us/step - loss: 3646.2996 - val_loss: 1147.9042\n",
      "Epoch 247/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 2667.7078 - val_loss: 17256.4805\n",
      "Epoch 248/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 3199.3494 - val_loss: 942518.5625\n",
      "Epoch 249/1000\n",
      "306/306 [==============================] - 0s 844us/step - loss: 133019.0781 - val_loss: 609.6250\n",
      "Epoch 250/1000\n",
      "306/306 [==============================] - 0s 973us/step - loss: 471.5370 - val_loss: 607.2972\n",
      "Epoch 251/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 477.1196 - val_loss: 614.3410\n",
      "Epoch 252/1000\n",
      "306/306 [==============================] - 0s 904us/step - loss: 506.5826 - val_loss: 5591.6353\n",
      "Epoch 253/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 666.9664 - val_loss: 618.5117\n",
      "Epoch 254/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 609.6807 - val_loss: 613.4217\n",
      "Epoch 255/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 784.5018 - val_loss: 1630.1910\n",
      "Epoch 256/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1021.1002 - val_loss: 1150.1526\n",
      "Epoch 257/1000\n",
      "306/306 [==============================] - 0s 890us/step - loss: 1219.4906 - val_loss: 1433.6161\n",
      "Epoch 258/1000\n",
      "306/306 [==============================] - 0s 858us/step - loss: 1784.3798 - val_loss: 5422.1328\n",
      "Epoch 259/1000\n",
      "306/306 [==============================] - 0s 960us/step - loss: 2385.8499 - val_loss: 607.0482\n",
      "Epoch 260/1000\n",
      "306/306 [==============================] - 0s 845us/step - loss: 2543.3237 - val_loss: 18242.8633\n",
      "Epoch 261/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 2790.7173 - val_loss: 3093.5850\n",
      "Epoch 262/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 2768.3362 - val_loss: 3730.9958\n",
      "Epoch 263/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 2343.3591 - val_loss: 2854.8044\n",
      "Epoch 264/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 3459.6704 - val_loss: 3793.2104\n",
      "Epoch 265/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2109.5771 - val_loss: 1172.7953\n",
      "Epoch 266/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 3061.2595 - val_loss: 753.4849\n",
      "Epoch 267/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2134.4771 - val_loss: 3861.0193\n",
      "Epoch 268/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2812.1946 - val_loss: 4186.0698\n",
      "Epoch 269/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2065.9634 - val_loss: 5081.1743\n",
      "Epoch 270/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2641.6191 - val_loss: 976.3381\n",
      "Epoch 271/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 2689.9373 - val_loss: 4071.4985\n",
      "Epoch 272/1000\n",
      "306/306 [==============================] - 0s 935us/step - loss: 3024.4688 - val_loss: 1142.8173\n",
      "Epoch 273/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 1990.8163 - val_loss: 3623.3569\n",
      "Epoch 274/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 2507.2183 - val_loss: 1849.3690\n",
      "Epoch 275/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 2159.7266 - val_loss: 3170.4875\n",
      "Epoch 276/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 2172.1643 - val_loss: 3501.7107\n",
      "Epoch 277/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 2512.5530 - val_loss: 6396.0137\n",
      "Epoch 278/1000\n",
      "306/306 [==============================] - 0s 864us/step - loss: 2275.5154 - val_loss: 1870.9736\n",
      "Epoch 279/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 1931.8209 - val_loss: 4788.6318\n",
      "Epoch 280/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 2752.7214 - val_loss: 1031.0298\n",
      "Epoch 281/1000\n",
      "306/306 [==============================] - 0s 862us/step - loss: 2458.2126 - val_loss: 9477.9824\n",
      "Epoch 282/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 1644.8848 - val_loss: 611.4601\n",
      "Epoch 283/1000\n",
      "306/306 [==============================] - 0s 953us/step - loss: 2238.3523 - val_loss: 662.7614\n",
      "Epoch 284/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 2003.4990 - val_loss: 3748.6001\n",
      "Epoch 285/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 1706.3503 - val_loss: 3806.3901\n",
      "Epoch 286/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 1753.9613 - val_loss: 1952.9915\n",
      "Epoch 287/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 2110.9531 - val_loss: 610.0207\n",
      "Epoch 288/1000\n",
      "306/306 [==============================] - 0s 859us/step - loss: 2616.0208 - val_loss: 870.1334\n",
      "Epoch 289/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 1636.6757 - val_loss: 1387.2517\n",
      "Epoch 290/1000\n",
      "306/306 [==============================] - 0s 938us/step - loss: 2197.0215 - val_loss: 627.5295\n",
      "Epoch 291/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 1648.6974 - val_loss: 1742.7574\n",
      "Epoch 292/1000\n",
      "306/306 [==============================] - 0s 858us/step - loss: 1896.4091 - val_loss: 1253.5547\n",
      "Epoch 293/1000\n",
      "306/306 [==============================] - 0s 859us/step - loss: 1859.9895 - val_loss: 4706.0220\n",
      "Epoch 294/1000\n",
      "306/306 [==============================] - 0s 890us/step - loss: 1963.4589 - val_loss: 1686.8086\n",
      "Epoch 295/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 1572.5634 - val_loss: 788.4106\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 870us/step - loss: 1746.0009 - val_loss: 2720.8533\n",
      "Epoch 297/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 1845.8716 - val_loss: 1926.6818\n",
      "Epoch 298/1000\n",
      "306/306 [==============================] - 0s 885us/step - loss: 1989.0122 - val_loss: 741.9368\n",
      "Epoch 299/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 1717.7363 - val_loss: 2485.6428\n",
      "Epoch 300/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 1527.6232 - val_loss: 2836.3833\n",
      "Epoch 301/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 1462.4349 - val_loss: 4007.3250\n",
      "Epoch 302/1000\n",
      "306/306 [==============================] - 0s 916us/step - loss: 2162.3279 - val_loss: 1832.8621\n",
      "Epoch 303/1000\n",
      "306/306 [==============================] - 0s 968us/step - loss: 1311.6842 - val_loss: 6384.6177\n",
      "Epoch 304/1000\n",
      "306/306 [==============================] - 0s 936us/step - loss: 1679.2806 - val_loss: 4121.0444\n",
      "Epoch 305/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 1660.2469 - val_loss: 701.0318\n",
      "Epoch 306/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 1171.4725 - val_loss: 776.8340\n",
      "Epoch 307/1000\n",
      "306/306 [==============================] - 0s 932us/step - loss: 1722.2627 - val_loss: 8645.9219\n",
      "Epoch 308/1000\n",
      "306/306 [==============================] - 0s 869us/step - loss: 1697.9387 - val_loss: 811.7822\n",
      "Epoch 309/1000\n",
      "306/306 [==============================] - 0s 929us/step - loss: 1847.7295 - val_loss: 607.1248\n",
      "Epoch 310/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 1337.6189 - val_loss: 607.7951\n",
      "Epoch 311/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 1469.0153 - val_loss: 614.5013\n",
      "Epoch 312/1000\n",
      "306/306 [==============================] - 0s 865us/step - loss: 1087.6727 - val_loss: 636.1938\n",
      "Epoch 313/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 1752.7419 - val_loss: 856.8623\n",
      "Epoch 314/1000\n",
      "306/306 [==============================] - 0s 925us/step - loss: 1265.4551 - val_loss: 4547.1270\n",
      "Epoch 315/1000\n",
      "306/306 [==============================] - 0s 853us/step - loss: 1497.4698 - val_loss: 3882.4585\n",
      "Epoch 316/1000\n",
      "306/306 [==============================] - 0s 874us/step - loss: 1264.4863 - val_loss: 1162.1062\n",
      "Epoch 317/1000\n",
      "306/306 [==============================] - 0s 952us/step - loss: 1738.9917 - val_loss: 607.3597\n",
      "Epoch 318/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 1336.5104 - val_loss: 2052.0740\n",
      "Epoch 319/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 1213.2737 - val_loss: 4195.4976\n",
      "Epoch 320/1000\n",
      "306/306 [==============================] - 0s 826us/step - loss: 1110.7797 - val_loss: 667.5617\n",
      "Epoch 321/1000\n",
      "306/306 [==============================] - 0s 933us/step - loss: 1196.4869 - val_loss: 671.3657\n",
      "Epoch 322/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 1688.4670 - val_loss: 902.9481\n",
      "Epoch 323/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 1280.5698 - val_loss: 694.7286\n",
      "Epoch 324/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 1125.2427 - val_loss: 1878.6727\n",
      "Epoch 325/1000\n",
      "306/306 [==============================] - 0s 950us/step - loss: 1194.5859 - val_loss: 4052.9795\n",
      "Epoch 326/1000\n",
      "306/306 [==============================] - 0s 951us/step - loss: 1253.1367 - val_loss: 1884.4480\n",
      "Epoch 327/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 1324.8976 - val_loss: 4100.9688\n",
      "Epoch 328/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 1168.1066 - val_loss: 792.7118\n",
      "Epoch 329/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 1138.4144 - val_loss: 616.2256\n",
      "Epoch 330/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 949.8411 - val_loss: 1983.4573\n",
      "Epoch 331/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 1149.7544 - val_loss: 608.0836\n",
      "Epoch 332/1000\n",
      "306/306 [==============================] - 0s 988us/step - loss: 989.0343 - val_loss: 715.9363\n",
      "Epoch 333/1000\n",
      "306/306 [==============================] - 0s 938us/step - loss: 1157.0326 - val_loss: 1095.8699\n",
      "Epoch 334/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1253.7091 - val_loss: 813.7879\n",
      "Epoch 335/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1001.3906 - val_loss: 697.7713\n",
      "Epoch 336/1000\n",
      "306/306 [==============================] - 0s 903us/step - loss: 1061.8680 - val_loss: 1356.9557\n",
      "Epoch 337/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 795.5116 - val_loss: 1546.7717\n",
      "Epoch 338/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1106.0447 - val_loss: 5172.9282\n",
      "Epoch 339/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 1066.5519 - val_loss: 855.3258\n",
      "Epoch 340/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 825.6463 - val_loss: 607.1808\n",
      "Epoch 341/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 1007.1257 - val_loss: 838.5157\n",
      "Epoch 342/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 805.7062 - val_loss: 607.3561\n",
      "Epoch 343/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 954.7957 - val_loss: 2139.8665\n",
      "Epoch 344/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 825.8892 - val_loss: 1154.5149\n",
      "Epoch 345/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 772.6891 - val_loss: 617.3530\n",
      "Epoch 346/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 996.8129 - val_loss: 611.5004\n",
      "Epoch 347/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 823.4908 - val_loss: 1931.1519\n",
      "Epoch 348/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 866.7702 - val_loss: 1266.8806\n",
      "Epoch 349/1000\n",
      "306/306 [==============================] - 0s 956us/step - loss: 905.9921 - val_loss: 1102.0100\n",
      "Epoch 350/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 1004.0048 - val_loss: 607.0558\n",
      "Epoch 351/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 614.0606 - val_loss: 2626.5222\n",
      "Epoch 352/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 788.4722 - val_loss: 1211.9307\n",
      "Epoch 353/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 969.0801 - val_loss: 1661.0920\n",
      "Epoch 354/1000\n",
      "306/306 [==============================] - 0s 974us/step - loss: 876.1374 - val_loss: 847.7607\n",
      "Epoch 355/1000\n",
      "306/306 [==============================] - 0s 963us/step - loss: 1663.0695 - val_loss: 1524.8577\n",
      "Epoch 356/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 611.6880 - val_loss: 1181.3263\n",
      "Epoch 357/1000\n",
      "306/306 [==============================] - 0s 1000us/step - loss: 706.9654 - val_loss: 1076.2057\n",
      "Epoch 358/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 642.0895 - val_loss: 2833.0745\n",
      "Epoch 359/1000\n",
      "306/306 [==============================] - 0s 861us/step - loss: 742.9164 - val_loss: 609.2424\n",
      "Epoch 360/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 619.4577 - val_loss: 1584.8599\n",
      "Epoch 361/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 642.5148 - val_loss: 670.9694\n",
      "Epoch 362/1000\n",
      "306/306 [==============================] - 0s 940us/step - loss: 703.5944 - val_loss: 850.2440\n",
      "Epoch 363/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 783.8759 - val_loss: 946.5957\n",
      "Epoch 364/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 970.8426 - val_loss: 880.6207\n",
      "Epoch 365/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 613.9274 - val_loss: 907.4131\n",
      "Epoch 366/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 531.9572 - val_loss: 629.4715\n",
      "Epoch 367/1000\n",
      "306/306 [==============================] - 0s 947us/step - loss: 672.4662 - val_loss: 1246.0176\n",
      "Epoch 368/1000\n",
      "306/306 [==============================] - 0s 949us/step - loss: 604.3544 - val_loss: 766.9835\n",
      "Epoch 369/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 557.4422 - val_loss: 623.8615\n",
      "Epoch 370/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 1ms/step - loss: 540.3521 - val_loss: 607.0482\n",
      "Epoch 371/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 552.0441 - val_loss: 1256.7767\n",
      "Epoch 372/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 671.5490 - val_loss: 615.8571\n",
      "Epoch 373/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 571.6304 - val_loss: 1324.7808\n",
      "Epoch 374/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 590.7209 - val_loss: 946.0027\n",
      "Epoch 375/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 576.6691 - val_loss: 612.3185\n",
      "Epoch 376/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 619.8616 - val_loss: 677.9874\n",
      "Epoch 377/1000\n",
      "306/306 [==============================] - 0s 930us/step - loss: 521.3624 - val_loss: 1037.1196\n",
      "Epoch 378/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 574.0704 - val_loss: 630.0606\n",
      "Epoch 379/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 564.5197 - val_loss: 607.3055\n",
      "Epoch 380/1000\n",
      "306/306 [==============================] - 0s 886us/step - loss: 519.1439 - val_loss: 615.4191\n",
      "Epoch 381/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 504.8880 - val_loss: 1133.3444\n",
      "Epoch 382/1000\n",
      "306/306 [==============================] - 0s 860us/step - loss: 489.0091 - val_loss: 733.5192\n",
      "Epoch 383/1000\n",
      "306/306 [==============================] - 0s 969us/step - loss: 565.7144 - val_loss: 635.9088\n",
      "Epoch 384/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 551.0905 - val_loss: 970.6899\n",
      "Epoch 385/1000\n",
      "306/306 [==============================] - 0s 940us/step - loss: 594.5825 - val_loss: 864.0445\n",
      "Epoch 386/1000\n",
      "306/306 [==============================] - 0s 973us/step - loss: 478.6677 - val_loss: 607.1007\n",
      "Epoch 387/1000\n",
      "306/306 [==============================] - 0s 933us/step - loss: 485.9286 - val_loss: 615.2052\n",
      "Epoch 388/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 467.6794 - val_loss: 636.0529\n",
      "Epoch 389/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 552.7817 - val_loss: 623.9023\n",
      "Epoch 390/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 508.3239 - val_loss: 763.7941\n",
      "Epoch 391/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 477.9136 - val_loss: 615.0048\n",
      "Epoch 392/1000\n",
      "306/306 [==============================] - 0s 970us/step - loss: 528.4403 - val_loss: 609.2332\n",
      "Epoch 393/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 2527.7532 - val_loss: 837.4306\n",
      "Epoch 394/1000\n",
      "306/306 [==============================] - 0s 962us/step - loss: 460.2236 - val_loss: 655.6032\n",
      "Epoch 395/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 491.7942 - val_loss: 867.2583\n",
      "Epoch 396/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 452.6700 - val_loss: 607.9589\n",
      "Epoch 397/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 450.6330 - val_loss: 699.8962\n",
      "Epoch 398/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 468.6014 - val_loss: 1046.4027\n",
      "Epoch 399/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 544.7422 - val_loss: 641.9581\n",
      "Epoch 400/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 452.3194 - val_loss: 911.8725\n",
      "Epoch 401/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 511.8178 - val_loss: 744.7930\n",
      "Epoch 402/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 462.7216 - val_loss: 666.6039\n",
      "Epoch 403/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 463.1289 - val_loss: 1017.4272\n",
      "Epoch 404/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 443.2993 - val_loss: 1024.9835\n",
      "Epoch 405/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 456.7134 - val_loss: 619.8807\n",
      "Epoch 406/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 462.5941 - val_loss: 881.8831\n",
      "Epoch 407/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 489.1949 - val_loss: 863.5627\n",
      "Epoch 408/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 427.4804 - val_loss: 694.0950\n",
      "Epoch 409/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 426.2229 - val_loss: 641.1624\n",
      "Epoch 410/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 434.6633 - val_loss: 613.1404\n",
      "Epoch 411/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 430.9522 - val_loss: 950.7548\n",
      "Epoch 412/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 432.6811 - val_loss: 607.8865\n",
      "Epoch 413/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 410.2742 - val_loss: 1043.1069\n",
      "Epoch 414/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 423.1266 - val_loss: 648.7973\n",
      "Epoch 415/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 416.2872 - val_loss: 608.3272\n",
      "Epoch 416/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 408.2766 - val_loss: 687.9895\n",
      "Epoch 417/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 403.4169 - val_loss: 618.8936\n",
      "Epoch 418/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 390.7841 - val_loss: 701.6559\n",
      "Epoch 419/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 395.3753 - val_loss: 648.0287\n",
      "Epoch 420/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 385.6523 - val_loss: 616.3853\n",
      "Epoch 421/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.8146 - val_loss: 654.8768\n",
      "Epoch 422/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.3561 - val_loss: 618.4406\n",
      "Epoch 423/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.6884 - val_loss: 685.2932\n",
      "Epoch 424/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 382.0437 - val_loss: 665.1138\n",
      "Epoch 425/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 379.7634 - val_loss: 654.9631\n",
      "Epoch 426/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.3862 - val_loss: 630.3732\n",
      "Epoch 427/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.0931 - val_loss: 656.8600\n",
      "Epoch 428/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.4029 - val_loss: 688.9035\n",
      "Epoch 429/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 379.2027 - val_loss: 621.1942\n",
      "Epoch 430/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 383.8317 - val_loss: 712.1896\n",
      "Epoch 431/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 381.3889 - val_loss: 715.2742\n",
      "Epoch 432/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 379.4250 - val_loss: 639.5250\n",
      "Epoch 433/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 387.3441 - val_loss: 670.1651\n",
      "Epoch 434/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 381.9585 - val_loss: 635.2475\n",
      "Epoch 435/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.1776 - val_loss: 683.2667\n",
      "Epoch 436/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 385.6148 - val_loss: 646.1642\n",
      "Epoch 437/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.5382 - val_loss: 710.8893\n",
      "Epoch 438/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 385.8145 - val_loss: 695.7615\n",
      "Epoch 439/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 382.9082 - val_loss: 612.2424\n",
      "Epoch 440/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.2710 - val_loss: 705.2453\n",
      "Epoch 441/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 381.9896 - val_loss: 679.5432\n",
      "Epoch 442/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.8966 - val_loss: 631.9717\n",
      "Epoch 443/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 379.7842 - val_loss: 695.7654\n",
      "Epoch 444/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.8922 - val_loss: 716.0536\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 1s 3ms/step - loss: 386.0393 - val_loss: 689.2476\n",
      "Epoch 446/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 385.1917 - val_loss: 651.5789\n",
      "Epoch 447/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.3344 - val_loss: 631.1815\n",
      "Epoch 448/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 387.3576 - val_loss: 616.1995\n",
      "Epoch 449/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 383.2095 - val_loss: 729.0262\n",
      "Epoch 450/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.2273 - val_loss: 641.3172\n",
      "Epoch 451/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 387.4947 - val_loss: 642.6745\n",
      "Epoch 452/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 381.8455 - val_loss: 629.7679\n",
      "Epoch 453/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 382.2401 - val_loss: 750.1331\n",
      "Epoch 454/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 386.0195 - val_loss: 643.2999\n",
      "Epoch 455/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 389.5758 - val_loss: 729.9733\n",
      "Epoch 456/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 384.8829 - val_loss: 616.4239\n",
      "Epoch 457/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 385.5749 - val_loss: 623.5909\n",
      "Epoch 458/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 380.4910 - val_loss: 687.5767\n",
      "Epoch 459/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 383.9742 - val_loss: 633.7936\n",
      "Epoch 460/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 1919.8401 - val_loss: 683.3868\n",
      "Epoch 461/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 425.3671 - val_loss: 627.9794\n",
      "Epoch 462/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 471.8341 - val_loss: 631.6039\n",
      "Epoch 463/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 447.8907 - val_loss: 1122.7294\n",
      "Epoch 464/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 442.8735 - val_loss: 607.5312\n",
      "Epoch 465/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 440.5974 - val_loss: 672.7077\n",
      "Epoch 466/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 442.5316 - val_loss: 649.8514\n",
      "Epoch 467/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 412.7520 - val_loss: 607.2936\n",
      "Epoch 468/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 404.3259 - val_loss: 653.2616\n",
      "Epoch 469/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 401.4364 - val_loss: 677.1576\n",
      "Epoch 470/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 412.0883 - val_loss: 702.3746\n",
      "Epoch 471/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 404.3593 - val_loss: 701.5547\n",
      "Epoch 472/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 396.6338 - val_loss: 626.4902\n",
      "Epoch 473/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 388.4953 - val_loss: 647.1082\n",
      "Epoch 474/1000\n",
      "306/306 [==============================] - 0s 2ms/step - loss: 384.2805 - val_loss: 621.9481\n",
      "Epoch 475/1000\n",
      "306/306 [==============================] - 0s 995us/step - loss: 381.6373 - val_loss: 614.9226\n",
      "Epoch 476/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 376.8417 - val_loss: 651.9719\n",
      "Epoch 477/1000\n",
      "306/306 [==============================] - 0s 886us/step - loss: 377.4615 - val_loss: 699.9698\n",
      "Epoch 478/1000\n",
      "306/306 [==============================] - 0s 971us/step - loss: 379.1318 - val_loss: 803.7655\n",
      "Epoch 479/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 380.3319 - val_loss: 664.6282\n",
      "Epoch 480/1000\n",
      "306/306 [==============================] - 0s 975us/step - loss: 381.4890 - val_loss: 757.1438\n",
      "Epoch 481/1000\n",
      "306/306 [==============================] - 0s 992us/step - loss: 379.6194 - val_loss: 644.2708\n",
      "Epoch 482/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 380.6621 - val_loss: 654.0461\n",
      "Epoch 483/1000\n",
      "306/306 [==============================] - 0s 883us/step - loss: 378.4532 - val_loss: 658.2359\n",
      "Epoch 484/1000\n",
      "306/306 [==============================] - 0s 840us/step - loss: 380.8285 - val_loss: 669.1510\n",
      "Epoch 485/1000\n",
      "306/306 [==============================] - 0s 814us/step - loss: 380.2426 - val_loss: 634.5624\n",
      "Epoch 486/1000\n",
      "306/306 [==============================] - 0s 906us/step - loss: 379.3519 - val_loss: 636.1279\n",
      "Epoch 487/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 381.9780 - val_loss: 628.1847\n",
      "Epoch 488/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 380.4121 - val_loss: 660.1187\n",
      "Epoch 489/1000\n",
      "306/306 [==============================] - 0s 907us/step - loss: 381.9637 - val_loss: 675.0434\n",
      "Epoch 490/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 383.0612 - val_loss: 662.4160\n",
      "Epoch 491/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 388.7469 - val_loss: 611.4634\n",
      "Epoch 492/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 379.3073 - val_loss: 690.7944\n",
      "Epoch 493/1000\n",
      "306/306 [==============================] - 0s 885us/step - loss: 380.9128 - val_loss: 619.0511\n",
      "Epoch 494/1000\n",
      "306/306 [==============================] - 0s 950us/step - loss: 381.8376 - val_loss: 685.3217\n",
      "Epoch 495/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 383.3893 - val_loss: 840.7905\n",
      "Epoch 496/1000\n",
      "306/306 [==============================] - 0s 820us/step - loss: 386.1125 - val_loss: 686.5382\n",
      "Epoch 497/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 380.4142 - val_loss: 638.9217\n",
      "Epoch 498/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 380.6472 - val_loss: 647.0397\n",
      "Epoch 499/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 381.8467 - val_loss: 677.3044\n",
      "Epoch 500/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 378.6154 - val_loss: 648.7399\n",
      "Epoch 501/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 386.0033 - val_loss: 710.4496\n",
      "Epoch 502/1000\n",
      "306/306 [==============================] - 0s 941us/step - loss: 384.0037 - val_loss: 668.4327\n",
      "Epoch 503/1000\n",
      "306/306 [==============================] - 0s 850us/step - loss: 380.8074 - val_loss: 688.4353\n",
      "Epoch 504/1000\n",
      "306/306 [==============================] - 0s 867us/step - loss: 380.0085 - val_loss: 607.1276\n",
      "Epoch 505/1000\n",
      "306/306 [==============================] - 0s 845us/step - loss: 386.8750 - val_loss: 625.1722\n",
      "Epoch 506/1000\n",
      "306/306 [==============================] - 0s 873us/step - loss: 383.5259 - val_loss: 661.0062\n",
      "Epoch 507/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 379.9553 - val_loss: 647.4133\n",
      "Epoch 508/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 379.2422 - val_loss: 650.8442\n",
      "Epoch 509/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 384.7340 - val_loss: 693.5223\n",
      "Epoch 510/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 380.4644 - val_loss: 632.8323\n",
      "Epoch 511/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 380.3701 - val_loss: 626.7885\n",
      "Epoch 512/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 382.7770 - val_loss: 609.9416\n",
      "Epoch 513/1000\n",
      "306/306 [==============================] - 0s 932us/step - loss: 376.7277 - val_loss: 645.8135\n",
      "Epoch 514/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 383.9512 - val_loss: 609.6615\n",
      "Epoch 515/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 382.7135 - val_loss: 655.5881\n",
      "Epoch 516/1000\n",
      "306/306 [==============================] - 0s 874us/step - loss: 379.5602 - val_loss: 609.9935\n",
      "Epoch 517/1000\n",
      "306/306 [==============================] - 0s 877us/step - loss: 380.9116 - val_loss: 656.0610\n",
      "Epoch 518/1000\n",
      "306/306 [==============================] - 0s 836us/step - loss: 380.4185 - val_loss: 704.3799\n",
      "Epoch 519/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 385.8263 - val_loss: 738.8667\n",
      "Epoch 520/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 878us/step - loss: 384.5012 - val_loss: 661.5733\n",
      "Epoch 521/1000\n",
      "306/306 [==============================] - 0s 868us/step - loss: 382.8943 - val_loss: 673.3890\n",
      "Epoch 522/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 380.0968 - val_loss: 654.4653\n",
      "Epoch 523/1000\n",
      "306/306 [==============================] - 0s 915us/step - loss: 378.7118 - val_loss: 643.9149\n",
      "Epoch 524/1000\n",
      "306/306 [==============================] - 0s 872us/step - loss: 510.4176 - val_loss: 613.3794\n",
      "Epoch 525/1000\n",
      "306/306 [==============================] - 0s 999us/step - loss: 382.5098 - val_loss: 609.1193\n",
      "Epoch 526/1000\n",
      "306/306 [==============================] - 0s 873us/step - loss: 380.0996 - val_loss: 630.9150\n",
      "Epoch 527/1000\n",
      "306/306 [==============================] - 0s 812us/step - loss: 378.7896 - val_loss: 626.0932\n",
      "Epoch 528/1000\n",
      "306/306 [==============================] - 0s 853us/step - loss: 378.9686 - val_loss: 641.2444\n",
      "Epoch 529/1000\n",
      "306/306 [==============================] - 0s 862us/step - loss: 378.8961 - val_loss: 661.9940\n",
      "Epoch 530/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 377.1290 - val_loss: 695.6086\n",
      "Epoch 531/1000\n",
      "306/306 [==============================] - 0s 936us/step - loss: 379.2143 - val_loss: 658.7288\n",
      "Epoch 532/1000\n",
      "306/306 [==============================] - 0s 833us/step - loss: 378.3226 - val_loss: 694.5400\n",
      "Epoch 533/1000\n",
      "306/306 [==============================] - 0s 874us/step - loss: 381.0753 - val_loss: 671.1061\n",
      "Epoch 534/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 378.2032 - val_loss: 621.0607\n",
      "Epoch 535/1000\n",
      "306/306 [==============================] - 0s 835us/step - loss: 376.9479 - val_loss: 714.2715\n",
      "Epoch 536/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 379.6342 - val_loss: 711.8933\n",
      "Epoch 537/1000\n",
      "306/306 [==============================] - 0s 890us/step - loss: 380.0999 - val_loss: 609.8049\n",
      "Epoch 538/1000\n",
      "306/306 [==============================] - 0s 999us/step - loss: 379.5694 - val_loss: 720.1092\n",
      "Epoch 539/1000\n",
      "306/306 [==============================] - 0s 916us/step - loss: 380.3593 - val_loss: 752.2755\n",
      "Epoch 540/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 380.8100 - val_loss: 660.8930\n",
      "Epoch 541/1000\n",
      "306/306 [==============================] - 0s 896us/step - loss: 378.4909 - val_loss: 684.2240\n",
      "Epoch 542/1000\n",
      "306/306 [==============================] - 0s 971us/step - loss: 377.1404 - val_loss: 633.9117\n",
      "Epoch 543/1000\n",
      "306/306 [==============================] - 0s 962us/step - loss: 378.8397 - val_loss: 670.5391\n",
      "Epoch 544/1000\n",
      "306/306 [==============================] - 0s 906us/step - loss: 378.2586 - val_loss: 669.1613\n",
      "Epoch 545/1000\n",
      "306/306 [==============================] - 0s 839us/step - loss: 377.2805 - val_loss: 623.6254\n",
      "Epoch 546/1000\n",
      "306/306 [==============================] - 0s 897us/step - loss: 378.7245 - val_loss: 720.1158\n",
      "Epoch 547/1000\n",
      "306/306 [==============================] - 0s 976us/step - loss: 377.1714 - val_loss: 615.4306\n",
      "Epoch 548/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 377.9181 - val_loss: 658.5963\n",
      "Epoch 549/1000\n",
      "306/306 [==============================] - 0s 925us/step - loss: 379.1973 - val_loss: 635.3198\n",
      "Epoch 550/1000\n",
      "306/306 [==============================] - 0s 889us/step - loss: 377.5854 - val_loss: 686.8234\n",
      "Epoch 551/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 378.2204 - val_loss: 693.5844\n",
      "Epoch 552/1000\n",
      "306/306 [==============================] - 0s 929us/step - loss: 377.6084 - val_loss: 649.8775\n",
      "Epoch 553/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 378.8821 - val_loss: 677.9280\n",
      "Epoch 554/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.3557 - val_loss: 678.8102\n",
      "Epoch 555/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 378.9579 - val_loss: 630.2932\n",
      "Epoch 556/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 381.1468 - val_loss: 737.6845\n",
      "Epoch 557/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 377.3904 - val_loss: 627.9634\n",
      "Epoch 558/1000\n",
      "306/306 [==============================] - 0s 915us/step - loss: 377.7580 - val_loss: 670.3625\n",
      "Epoch 559/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 377.4197 - val_loss: 692.4166\n",
      "Epoch 560/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 377.1057 - val_loss: 627.4651\n",
      "Epoch 561/1000\n",
      "306/306 [==============================] - 0s 881us/step - loss: 378.5836 - val_loss: 650.1039\n",
      "Epoch 562/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 377.4421 - val_loss: 693.7755\n",
      "Epoch 563/1000\n",
      "306/306 [==============================] - 0s 941us/step - loss: 377.0983 - val_loss: 655.1773\n",
      "Epoch 564/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 379.1245 - val_loss: 669.6045\n",
      "Epoch 565/1000\n",
      "306/306 [==============================] - 0s 844us/step - loss: 377.6536 - val_loss: 697.8429\n",
      "Epoch 566/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 377.8735 - val_loss: 621.1257\n",
      "Epoch 567/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 377.6666 - val_loss: 643.5308\n",
      "Epoch 568/1000\n",
      "306/306 [==============================] - 0s 935us/step - loss: 376.8991 - val_loss: 634.0764\n",
      "Epoch 569/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 377.6879 - val_loss: 630.2073\n",
      "Epoch 570/1000\n",
      "306/306 [==============================] - 0s 895us/step - loss: 376.5260 - val_loss: 653.6832\n",
      "Epoch 571/1000\n",
      "306/306 [==============================] - 0s 996us/step - loss: 376.4849 - val_loss: 707.2960\n",
      "Epoch 572/1000\n",
      "306/306 [==============================] - 0s 931us/step - loss: 377.7026 - val_loss: 629.5424\n",
      "Epoch 573/1000\n",
      "306/306 [==============================] - 0s 905us/step - loss: 377.9329 - val_loss: 687.8543\n",
      "Epoch 574/1000\n",
      "306/306 [==============================] - 0s 865us/step - loss: 378.3842 - val_loss: 661.4381\n",
      "Epoch 575/1000\n",
      "306/306 [==============================] - 0s 941us/step - loss: 489.2314 - val_loss: 633.0910\n",
      "Epoch 576/1000\n",
      "306/306 [==============================] - 0s 904us/step - loss: 378.0047 - val_loss: 710.2337\n",
      "Epoch 577/1000\n",
      "306/306 [==============================] - 0s 956us/step - loss: 378.3040 - val_loss: 655.4273\n",
      "Epoch 578/1000\n",
      "306/306 [==============================] - 0s 889us/step - loss: 376.2010 - val_loss: 668.7061\n",
      "Epoch 579/1000\n",
      "306/306 [==============================] - 0s 935us/step - loss: 375.8859 - val_loss: 643.5104\n",
      "Epoch 580/1000\n",
      "306/306 [==============================] - 0s 926us/step - loss: 377.6039 - val_loss: 681.0623\n",
      "Epoch 581/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 377.0047 - val_loss: 641.4384\n",
      "Epoch 582/1000\n",
      "306/306 [==============================] - 0s 982us/step - loss: 375.8761 - val_loss: 680.4501\n",
      "Epoch 583/1000\n",
      "306/306 [==============================] - 0s 872us/step - loss: 377.1521 - val_loss: 651.4413\n",
      "Epoch 584/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 378.4850 - val_loss: 687.6457\n",
      "Epoch 585/1000\n",
      "306/306 [==============================] - 0s 946us/step - loss: 376.1753 - val_loss: 683.9448\n",
      "Epoch 586/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 378.2903 - val_loss: 667.8625\n",
      "Epoch 587/1000\n",
      "306/306 [==============================] - 0s 968us/step - loss: 377.2577 - val_loss: 622.8897\n",
      "Epoch 588/1000\n",
      "306/306 [==============================] - 0s 989us/step - loss: 377.1519 - val_loss: 624.6587\n",
      "Epoch 589/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.0248 - val_loss: 656.2777\n",
      "Epoch 590/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 375.9427 - val_loss: 638.7142\n",
      "Epoch 591/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.5791 - val_loss: 631.6568\n",
      "Epoch 592/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 376.5082 - val_loss: 636.2502\n",
      "Epoch 593/1000\n",
      "306/306 [==============================] - 0s 886us/step - loss: 376.2857 - val_loss: 688.6438\n",
      "Epoch 594/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2348 - val_loss: 662.7648\n",
      "Epoch 595/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 376.4305 - val_loss: 645.2972\n",
      "Epoch 596/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.6353 - val_loss: 694.4736\n",
      "Epoch 597/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 377.0313 - val_loss: 667.3429\n",
      "Epoch 598/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 376.3071 - val_loss: 652.5056\n",
      "Epoch 599/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.9135 - val_loss: 696.5133\n",
      "Epoch 600/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.5792 - val_loss: 613.3531\n",
      "Epoch 601/1000\n",
      "306/306 [==============================] - 0s 869us/step - loss: 375.9987 - val_loss: 622.5969\n",
      "Epoch 602/1000\n",
      "306/306 [==============================] - 0s 899us/step - loss: 376.5986 - val_loss: 661.0005\n",
      "Epoch 603/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 376.7249 - val_loss: 671.9553\n",
      "Epoch 604/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 375.0324 - val_loss: 659.7099\n",
      "Epoch 605/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 376.2190 - val_loss: 643.4714\n",
      "Epoch 606/1000\n",
      "306/306 [==============================] - 0s 854us/step - loss: 377.0793 - val_loss: 644.0903\n",
      "Epoch 607/1000\n",
      "306/306 [==============================] - 0s 950us/step - loss: 376.6642 - val_loss: 689.8336\n",
      "Epoch 608/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 376.5060 - val_loss: 646.2273\n",
      "Epoch 609/1000\n",
      "306/306 [==============================] - 0s 974us/step - loss: 376.2976 - val_loss: 631.9302\n",
      "Epoch 610/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 376.2881 - val_loss: 667.8256\n",
      "Epoch 611/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 376.8148 - val_loss: 644.4129\n",
      "Epoch 612/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 378.1985 - val_loss: 636.4717\n",
      "Epoch 613/1000\n",
      "306/306 [==============================] - 0s 978us/step - loss: 377.8645 - val_loss: 720.3883\n",
      "Epoch 614/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 377.1385 - val_loss: 662.5665\n",
      "Epoch 615/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 377.3224 - val_loss: 614.3807\n",
      "Epoch 616/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 376.8461 - val_loss: 671.6952\n",
      "Epoch 617/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 376.5786 - val_loss: 632.5612\n",
      "Epoch 618/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 378.6157 - val_loss: 709.5941\n",
      "Epoch 619/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 376.5233 - val_loss: 649.0588\n",
      "Epoch 620/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 376.4880 - val_loss: 654.4189\n",
      "Epoch 621/1000\n",
      "306/306 [==============================] - 0s 873us/step - loss: 376.8681 - val_loss: 642.4490\n",
      "Epoch 622/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 376.7723 - val_loss: 663.1664\n",
      "Epoch 623/1000\n",
      "306/306 [==============================] - 0s 912us/step - loss: 376.1878 - val_loss: 668.2679\n",
      "Epoch 624/1000\n",
      "306/306 [==============================] - 0s 925us/step - loss: 377.3406 - val_loss: 641.8679\n",
      "Epoch 625/1000\n",
      "306/306 [==============================] - 0s 952us/step - loss: 377.7323 - val_loss: 619.0206\n",
      "Epoch 626/1000\n",
      "306/306 [==============================] - 0s 936us/step - loss: 376.8056 - val_loss: 689.1937\n",
      "Epoch 627/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 376.4234 - val_loss: 626.9756\n",
      "Epoch 628/1000\n",
      "306/306 [==============================] - 0s 876us/step - loss: 377.9835 - val_loss: 650.7441\n",
      "Epoch 629/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 377.0557 - val_loss: 638.8100\n",
      "Epoch 630/1000\n",
      "306/306 [==============================] - 0s 849us/step - loss: 375.8389 - val_loss: 647.8394\n",
      "Epoch 631/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 377.6708 - val_loss: 663.9260\n",
      "Epoch 632/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 376.5601 - val_loss: 647.9697\n",
      "Epoch 633/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 376.9947 - val_loss: 677.6040\n",
      "Epoch 634/1000\n",
      "306/306 [==============================] - 0s 864us/step - loss: 376.0370 - val_loss: 696.0208\n",
      "Epoch 635/1000\n",
      "306/306 [==============================] - 0s 860us/step - loss: 376.6003 - val_loss: 662.8782\n",
      "Epoch 636/1000\n",
      "306/306 [==============================] - 0s 825us/step - loss: 377.0258 - val_loss: 673.1530\n",
      "Epoch 637/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 378.2504 - val_loss: 640.7031\n",
      "Epoch 638/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 376.0988 - val_loss: 644.7477\n",
      "Epoch 639/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 376.8435 - val_loss: 636.2907\n",
      "Epoch 640/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 376.9403 - val_loss: 667.3924\n",
      "Epoch 641/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 376.7224 - val_loss: 650.5624\n",
      "Epoch 642/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 376.6206 - val_loss: 685.3616\n",
      "Epoch 643/1000\n",
      "306/306 [==============================] - 0s 846us/step - loss: 376.7452 - val_loss: 688.8026\n",
      "Epoch 644/1000\n",
      "306/306 [==============================] - 0s 843us/step - loss: 376.5594 - val_loss: 679.2167\n",
      "Epoch 645/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 376.2780 - val_loss: 647.0001\n",
      "Epoch 646/1000\n",
      "306/306 [==============================] - 0s 920us/step - loss: 377.0300 - val_loss: 626.2236\n",
      "Epoch 647/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 376.8429 - val_loss: 650.7755\n",
      "Epoch 648/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 376.2442 - val_loss: 661.9079\n",
      "Epoch 649/1000\n",
      "306/306 [==============================] - 0s 962us/step - loss: 377.8907 - val_loss: 617.0954\n",
      "Epoch 650/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 377.4855 - val_loss: 642.8545\n",
      "Epoch 651/1000\n",
      "306/306 [==============================] - 0s 978us/step - loss: 377.5182 - val_loss: 711.1230\n",
      "Epoch 652/1000\n",
      "306/306 [==============================] - 0s 892us/step - loss: 376.6950 - val_loss: 684.3265\n",
      "Epoch 653/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 376.7488 - val_loss: 683.6440\n",
      "Epoch 654/1000\n",
      "306/306 [==============================] - 0s 863us/step - loss: 376.9096 - val_loss: 635.3293\n",
      "Epoch 655/1000\n",
      "306/306 [==============================] - 0s 878us/step - loss: 377.2785 - val_loss: 644.2148\n",
      "Epoch 656/1000\n",
      "306/306 [==============================] - 0s 987us/step - loss: 375.3190 - val_loss: 657.7761\n",
      "Epoch 657/1000\n",
      "306/306 [==============================] - 0s 908us/step - loss: 377.3221 - val_loss: 652.5300\n",
      "Epoch 658/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 375.8461 - val_loss: 684.7001\n",
      "Epoch 659/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 377.4250 - val_loss: 641.1451\n",
      "Epoch 660/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.8349 - val_loss: 639.8049\n",
      "Epoch 661/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 377.2783 - val_loss: 671.8363\n",
      "Epoch 662/1000\n",
      "306/306 [==============================] - 0s 929us/step - loss: 375.9897 - val_loss: 681.6264\n",
      "Epoch 663/1000\n",
      "306/306 [==============================] - 0s 887us/step - loss: 378.0841 - val_loss: 687.7638\n",
      "Epoch 664/1000\n",
      "306/306 [==============================] - 0s 893us/step - loss: 376.3175 - val_loss: 642.7339\n",
      "Epoch 665/1000\n",
      "306/306 [==============================] - 0s 878us/step - loss: 377.3005 - val_loss: 671.2556\n",
      "Epoch 666/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 377.3542 - val_loss: 652.8085\n",
      "Epoch 667/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 377.0508 - val_loss: 656.2308\n",
      "Epoch 668/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 909us/step - loss: 376.9092 - val_loss: 675.7454\n",
      "Epoch 669/1000\n",
      "306/306 [==============================] - 0s 934us/step - loss: 376.7347 - val_loss: 635.0182\n",
      "Epoch 670/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.0347 - val_loss: 655.2822\n",
      "Epoch 671/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 375.7325 - val_loss: 712.2958\n",
      "Epoch 672/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 378.0164 - val_loss: 669.6467\n",
      "Epoch 673/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 377.5810 - val_loss: 635.6053\n",
      "Epoch 674/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 376.9995 - val_loss: 663.7004\n",
      "Epoch 675/1000\n",
      "306/306 [==============================] - 0s 993us/step - loss: 377.4976 - val_loss: 677.3223\n",
      "Epoch 676/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 376.7515 - val_loss: 677.9197\n",
      "Epoch 677/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 376.5007 - val_loss: 701.6075\n",
      "Epoch 678/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.6872 - val_loss: 661.5366\n",
      "Epoch 679/1000\n",
      "306/306 [==============================] - 0s 984us/step - loss: 378.8089 - val_loss: 715.4069\n",
      "Epoch 680/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.8506 - val_loss: 639.8581\n",
      "Epoch 681/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 377.6400 - val_loss: 663.4951\n",
      "Epoch 682/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.6572 - val_loss: 659.6277\n",
      "Epoch 683/1000\n",
      "306/306 [==============================] - 0s 934us/step - loss: 376.4321 - val_loss: 673.9665\n",
      "Epoch 684/1000\n",
      "306/306 [==============================] - 0s 907us/step - loss: 376.1377 - val_loss: 643.7318\n",
      "Epoch 685/1000\n",
      "306/306 [==============================] - 0s 867us/step - loss: 376.8488 - val_loss: 637.6694\n",
      "Epoch 686/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 377.8770 - val_loss: 688.5317\n",
      "Epoch 687/1000\n",
      "306/306 [==============================] - 0s 869us/step - loss: 376.6292 - val_loss: 664.2802\n",
      "Epoch 688/1000\n",
      "306/306 [==============================] - 0s 853us/step - loss: 377.2326 - val_loss: 636.1234\n",
      "Epoch 689/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 376.1572 - val_loss: 706.0605\n",
      "Epoch 690/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 377.0964 - val_loss: 667.7667\n",
      "Epoch 691/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.0556 - val_loss: 624.2533\n",
      "Epoch 692/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.5027 - val_loss: 642.9907\n",
      "Epoch 693/1000\n",
      "306/306 [==============================] - 0s 985us/step - loss: 376.7585 - val_loss: 652.6745\n",
      "Epoch 694/1000\n",
      "306/306 [==============================] - 0s 989us/step - loss: 376.0464 - val_loss: 634.7463\n",
      "Epoch 695/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 376.0313 - val_loss: 685.8876\n",
      "Epoch 696/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 376.9363 - val_loss: 682.7558\n",
      "Epoch 697/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 376.3641 - val_loss: 634.8413\n",
      "Epoch 698/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 378.6664 - val_loss: 643.9186\n",
      "Epoch 699/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 376.4449 - val_loss: 647.8596\n",
      "Epoch 700/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 377.0503 - val_loss: 642.3953\n",
      "Epoch 701/1000\n",
      "306/306 [==============================] - 0s 879us/step - loss: 376.0399 - val_loss: 662.7514\n",
      "Epoch 702/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 378.0288 - val_loss: 681.3101\n",
      "Epoch 703/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 376.1057 - val_loss: 672.5002\n",
      "Epoch 704/1000\n",
      "306/306 [==============================] - 0s 994us/step - loss: 376.8806 - val_loss: 653.8751\n",
      "Epoch 705/1000\n",
      "306/306 [==============================] - 0s 854us/step - loss: 378.5056 - val_loss: 652.7948\n",
      "Epoch 706/1000\n",
      "306/306 [==============================] - 0s 892us/step - loss: 376.1119 - val_loss: 676.7064\n",
      "Epoch 707/1000\n",
      "306/306 [==============================] - 0s 883us/step - loss: 376.6378 - val_loss: 663.9268\n",
      "Epoch 708/1000\n",
      "306/306 [==============================] - 0s 905us/step - loss: 376.5472 - val_loss: 636.8503\n",
      "Epoch 709/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 377.6707 - val_loss: 642.6044\n",
      "Epoch 710/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 376.6144 - val_loss: 644.0809\n",
      "Epoch 711/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 376.6292 - val_loss: 655.0801\n",
      "Epoch 712/1000\n",
      "306/306 [==============================] - 0s 839us/step - loss: 375.9389 - val_loss: 668.8815\n",
      "Epoch 713/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 377.3212 - val_loss: 674.6505\n",
      "Epoch 714/1000\n",
      "306/306 [==============================] - 0s 994us/step - loss: 377.2412 - val_loss: 623.2220\n",
      "Epoch 715/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 379.0218 - val_loss: 655.2317\n",
      "Epoch 716/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 377.6677 - val_loss: 679.0309\n",
      "Epoch 717/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 377.2104 - val_loss: 661.6793\n",
      "Epoch 718/1000\n",
      "306/306 [==============================] - 0s 910us/step - loss: 376.5610 - val_loss: 636.0692\n",
      "Epoch 719/1000\n",
      "306/306 [==============================] - 0s 931us/step - loss: 376.2521 - val_loss: 663.4333\n",
      "Epoch 720/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 376.1362 - val_loss: 648.0845\n",
      "Epoch 721/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 378.2043 - val_loss: 692.1182\n",
      "Epoch 722/1000\n",
      "306/306 [==============================] - 0s 915us/step - loss: 377.7040 - val_loss: 675.2767\n",
      "Epoch 723/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 377.5144 - val_loss: 691.1908\n",
      "Epoch 724/1000\n",
      "306/306 [==============================] - 0s 898us/step - loss: 377.9456 - val_loss: 632.2688\n",
      "Epoch 725/1000\n",
      "306/306 [==============================] - 0s 935us/step - loss: 377.1724 - val_loss: 665.1630\n",
      "Epoch 726/1000\n",
      "306/306 [==============================] - 0s 864us/step - loss: 376.9303 - val_loss: 672.1413\n",
      "Epoch 727/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.6799 - val_loss: 679.7904\n",
      "Epoch 728/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.9463 - val_loss: 629.8104\n",
      "Epoch 729/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.3446 - val_loss: 669.8149\n",
      "Epoch 730/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.0388 - val_loss: 692.2561\n",
      "Epoch 731/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.4867 - val_loss: 680.4970\n",
      "Epoch 732/1000\n",
      "306/306 [==============================] - 0s 2ms/step - loss: 377.1932 - val_loss: 645.1942\n",
      "Epoch 733/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.4868 - val_loss: 650.0972\n",
      "Epoch 734/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4909 - val_loss: 649.4406\n",
      "Epoch 735/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.5571 - val_loss: 645.6816\n",
      "Epoch 736/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.9972 - val_loss: 661.1218\n",
      "Epoch 737/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2416 - val_loss: 687.0497\n",
      "Epoch 738/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.6511 - val_loss: 649.2706\n",
      "Epoch 739/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 375.9078 - val_loss: 695.3884\n",
      "Epoch 740/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5446 - val_loss: 636.1955\n",
      "Epoch 741/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3445 - val_loss: 643.7911\n",
      "Epoch 742/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.8272 - val_loss: 656.0799\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 1s 3ms/step - loss: 375.9662 - val_loss: 621.6361\n",
      "Epoch 744/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.3323 - val_loss: 657.9429\n",
      "Epoch 745/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2889 - val_loss: 639.2589\n",
      "Epoch 746/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.7948 - val_loss: 670.2809\n",
      "Epoch 747/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5822 - val_loss: 620.3749\n",
      "Epoch 748/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.8896 - val_loss: 681.6067\n",
      "Epoch 749/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 378.0412 - val_loss: 644.1850\n",
      "Epoch 750/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3217 - val_loss: 644.6945\n",
      "Epoch 751/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2463 - val_loss: 615.2487\n",
      "Epoch 752/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.7047 - val_loss: 644.5419\n",
      "Epoch 753/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2003 - val_loss: 667.3175\n",
      "Epoch 754/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.8281 - val_loss: 630.8337\n",
      "Epoch 755/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.8235 - val_loss: 657.0488\n",
      "Epoch 756/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3208 - val_loss: 685.9169\n",
      "Epoch 757/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.6684 - val_loss: 682.1901\n",
      "Epoch 758/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 378.3432 - val_loss: 632.8505\n",
      "Epoch 759/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6205 - val_loss: 656.0213\n",
      "Epoch 760/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3777 - val_loss: 644.6340\n",
      "Epoch 761/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6462 - val_loss: 638.9598\n",
      "Epoch 762/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.9252 - val_loss: 656.4146\n",
      "Epoch 763/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2752 - val_loss: 650.4332\n",
      "Epoch 764/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.1118 - val_loss: 663.5994\n",
      "Epoch 765/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5525 - val_loss: 708.3444\n",
      "Epoch 766/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 375.9284 - val_loss: 678.5513\n",
      "Epoch 767/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.2604 - val_loss: 630.6543\n",
      "Epoch 768/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.9580 - val_loss: 674.9218\n",
      "Epoch 769/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 376.5146 - val_loss: 642.1942\n",
      "Epoch 770/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2187 - val_loss: 629.0030\n",
      "Epoch 771/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4886 - val_loss: 655.4245\n",
      "Epoch 772/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.1438 - val_loss: 648.9896\n",
      "Epoch 773/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.3046 - val_loss: 649.5635\n",
      "Epoch 774/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.9012 - val_loss: 678.2202\n",
      "Epoch 775/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 376.1821 - val_loss: 711.1792\n",
      "Epoch 776/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6074 - val_loss: 621.3558\n",
      "Epoch 777/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4532 - val_loss: 678.5924\n",
      "Epoch 778/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.9081 - val_loss: 646.8958\n",
      "Epoch 779/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5933 - val_loss: 660.2280\n",
      "Epoch 780/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.0161 - val_loss: 636.8649\n",
      "Epoch 781/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.7109 - val_loss: 645.0392\n",
      "Epoch 782/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.9636 - val_loss: 672.1355\n",
      "Epoch 783/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5128 - val_loss: 621.7065\n",
      "Epoch 784/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.3619 - val_loss: 664.7277\n",
      "Epoch 785/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.0557 - val_loss: 646.2784\n",
      "Epoch 786/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.5388 - val_loss: 634.1542\n",
      "Epoch 787/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.2095 - val_loss: 651.6707\n",
      "Epoch 788/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4297 - val_loss: 612.0688\n",
      "Epoch 789/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.2157 - val_loss: 648.7983\n",
      "Epoch 790/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.1952 - val_loss: 631.5474\n",
      "Epoch 791/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.7208 - val_loss: 645.2198\n",
      "Epoch 792/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.9052 - val_loss: 695.3229\n",
      "Epoch 793/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.4003 - val_loss: 677.3256\n",
      "Epoch 794/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6694 - val_loss: 631.4750\n",
      "Epoch 795/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.3290 - val_loss: 633.4065\n",
      "Epoch 796/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.2279 - val_loss: 616.5826\n",
      "Epoch 797/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.9923 - val_loss: 703.4385\n",
      "Epoch 798/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.1658 - val_loss: 679.3597\n",
      "Epoch 799/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.4260 - val_loss: 672.5338\n",
      "Epoch 800/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.0538 - val_loss: 661.0735\n",
      "Epoch 801/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.0413 - val_loss: 664.7501\n",
      "Epoch 802/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3775 - val_loss: 656.8723\n",
      "Epoch 803/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 376.0717 - val_loss: 646.7596\n",
      "Epoch 804/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.3947 - val_loss: 658.3408\n",
      "Epoch 805/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.1560 - val_loss: 697.8878\n",
      "Epoch 806/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.1587 - val_loss: 669.4421\n",
      "Epoch 807/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.7628 - val_loss: 647.5587\n",
      "Epoch 808/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 378.5418 - val_loss: 627.8096\n",
      "Epoch 809/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.7155 - val_loss: 676.4584\n",
      "Epoch 810/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.5623 - val_loss: 635.1232\n",
      "Epoch 811/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6140 - val_loss: 667.8131\n",
      "Epoch 812/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 376.3835 - val_loss: 615.4677\n",
      "Epoch 813/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.6826 - val_loss: 727.4700\n",
      "Epoch 814/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.6575 - val_loss: 652.7770\n",
      "Epoch 815/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.5668 - val_loss: 656.9316\n",
      "Epoch 816/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.7660 - val_loss: 673.9147\n",
      "Epoch 817/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 376.5699 - val_loss: 693.2495\n",
      "Epoch 818/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 375.9351 - val_loss: 632.4337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 819/1000\n",
      "306/306 [==============================] - 1s 3ms/step - loss: 377.9803 - val_loss: 673.4084\n",
      "Epoch 820/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 377.7097 - val_loss: 685.7318\n",
      "Epoch 821/1000\n",
      "306/306 [==============================] - 1s 2ms/step - loss: 375.6098 - val_loss: 641.6798\n",
      "Epoch 822/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2856 - val_loss: 673.7183\n",
      "Epoch 823/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2470 - val_loss: 644.0342\n",
      "Epoch 824/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 376.8452 - val_loss: 651.8534\n",
      "Epoch 825/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.8758 - val_loss: 630.7347\n",
      "Epoch 826/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.6207 - val_loss: 673.8694\n",
      "Epoch 827/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.5339 - val_loss: 677.7422\n",
      "Epoch 828/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.7716 - val_loss: 619.3248\n",
      "Epoch 829/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.4400 - val_loss: 652.4818\n",
      "Epoch 830/1000\n",
      "306/306 [==============================] - 0s 982us/step - loss: 376.8164 - val_loss: 672.5909\n",
      "Epoch 831/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2828 - val_loss: 692.4475\n",
      "Epoch 832/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 377.1952 - val_loss: 631.6225\n",
      "Epoch 833/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 376.3767 - val_loss: 669.2245\n",
      "Epoch 834/1000\n",
      "306/306 [==============================] - 0s 894us/step - loss: 378.4596 - val_loss: 614.5948\n",
      "Epoch 835/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 376.4516 - val_loss: 681.5825\n",
      "Epoch 836/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 376.6028 - val_loss: 692.5552\n",
      "Epoch 837/1000\n",
      "306/306 [==============================] - 0s 983us/step - loss: 376.3314 - val_loss: 659.8584\n",
      "Epoch 838/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.0592 - val_loss: 662.3749\n",
      "Epoch 839/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.0758 - val_loss: 656.0809\n",
      "Epoch 840/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.3615 - val_loss: 654.8185\n",
      "Epoch 841/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.9484 - val_loss: 642.8793\n",
      "Epoch 842/1000\n",
      "306/306 [==============================] - 0s 959us/step - loss: 376.5606 - val_loss: 659.3664\n",
      "Epoch 843/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.2611 - val_loss: 645.2925\n",
      "Epoch 844/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.8439 - val_loss: 675.9528\n",
      "Epoch 845/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 375.7941 - val_loss: 634.6713\n",
      "Epoch 846/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 377.5859 - val_loss: 644.6177\n",
      "Epoch 847/1000\n",
      "306/306 [==============================] - 0s 887us/step - loss: 376.5500 - val_loss: 635.6949\n",
      "Epoch 848/1000\n",
      "306/306 [==============================] - 0s 836us/step - loss: 376.8910 - val_loss: 664.6506\n",
      "Epoch 849/1000\n",
      "306/306 [==============================] - 0s 864us/step - loss: 376.0017 - val_loss: 676.4493\n",
      "Epoch 850/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 375.6820 - val_loss: 645.5939\n",
      "Epoch 851/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 377.0928 - val_loss: 668.7535\n",
      "Epoch 852/1000\n",
      "306/306 [==============================] - 0s 862us/step - loss: 375.6805 - val_loss: 637.8798\n",
      "Epoch 853/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 377.1203 - val_loss: 669.9186\n",
      "Epoch 854/1000\n",
      "306/306 [==============================] - 0s 919us/step - loss: 376.5682 - val_loss: 689.7025\n",
      "Epoch 855/1000\n",
      "306/306 [==============================] - 0s 970us/step - loss: 376.3637 - val_loss: 673.6945\n",
      "Epoch 856/1000\n",
      "306/306 [==============================] - 0s 937us/step - loss: 376.2603 - val_loss: 627.2698\n",
      "Epoch 857/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 376.3824 - val_loss: 656.5515\n",
      "Epoch 858/1000\n",
      "306/306 [==============================] - 0s 847us/step - loss: 377.5110 - val_loss: 700.0521\n",
      "Epoch 859/1000\n",
      "306/306 [==============================] - 0s 883us/step - loss: 377.3620 - val_loss: 692.1343\n",
      "Epoch 860/1000\n",
      "306/306 [==============================] - 0s 837us/step - loss: 375.9878 - val_loss: 631.9848\n",
      "Epoch 861/1000\n",
      "306/306 [==============================] - 0s 986us/step - loss: 376.5908 - val_loss: 656.6349\n",
      "Epoch 862/1000\n",
      "306/306 [==============================] - 0s 888us/step - loss: 378.1565 - val_loss: 653.8523\n",
      "Epoch 863/1000\n",
      "306/306 [==============================] - 0s 889us/step - loss: 375.9209 - val_loss: 669.0185\n",
      "Epoch 864/1000\n",
      "306/306 [==============================] - 0s 848us/step - loss: 375.8548 - val_loss: 725.5286\n",
      "Epoch 865/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 377.2180 - val_loss: 654.4992\n",
      "Epoch 866/1000\n",
      "306/306 [==============================] - 0s 960us/step - loss: 377.7008 - val_loss: 678.8164\n",
      "Epoch 867/1000\n",
      "306/306 [==============================] - 0s 983us/step - loss: 375.8256 - val_loss: 644.8284\n",
      "Epoch 868/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 376.8470 - val_loss: 646.9789\n",
      "Epoch 869/1000\n",
      "306/306 [==============================] - 0s 971us/step - loss: 377.0365 - val_loss: 685.9563\n",
      "Epoch 870/1000\n",
      "306/306 [==============================] - 0s 951us/step - loss: 377.0413 - val_loss: 668.7973\n",
      "Epoch 871/1000\n",
      "306/306 [==============================] - 0s 969us/step - loss: 377.7573 - val_loss: 656.3199\n",
      "Epoch 872/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 376.7097 - val_loss: 629.5068\n",
      "Epoch 873/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 377.6718 - val_loss: 681.9343\n",
      "Epoch 874/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 377.4704 - val_loss: 638.9189\n",
      "Epoch 875/1000\n",
      "306/306 [==============================] - 0s 914us/step - loss: 376.9142 - val_loss: 684.1799\n",
      "Epoch 876/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 376.8150 - val_loss: 670.0425\n",
      "Epoch 877/1000\n",
      "306/306 [==============================] - 0s 932us/step - loss: 375.6219 - val_loss: 651.0414\n",
      "Epoch 878/1000\n",
      "306/306 [==============================] - 0s 861us/step - loss: 376.3769 - val_loss: 649.7325\n",
      "Epoch 879/1000\n",
      "306/306 [==============================] - 0s 912us/step - loss: 376.6575 - val_loss: 682.6642\n",
      "Epoch 880/1000\n",
      "306/306 [==============================] - 0s 882us/step - loss: 378.5685 - val_loss: 709.9277\n",
      "Epoch 881/1000\n",
      "306/306 [==============================] - 0s 943us/step - loss: 376.6885 - val_loss: 633.4992\n",
      "Epoch 882/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 376.9831 - val_loss: 633.4531\n",
      "Epoch 883/1000\n",
      "306/306 [==============================] - 0s 840us/step - loss: 376.8391 - val_loss: 653.1478\n",
      "Epoch 884/1000\n",
      "306/306 [==============================] - 0s 860us/step - loss: 377.2471 - val_loss: 693.1755\n",
      "Epoch 885/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.7449 - val_loss: 654.1600\n",
      "Epoch 886/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 377.0142 - val_loss: 691.8387\n",
      "Epoch 887/1000\n",
      "306/306 [==============================] - 0s 984us/step - loss: 376.2705 - val_loss: 648.6395\n",
      "Epoch 888/1000\n",
      "306/306 [==============================] - 0s 932us/step - loss: 376.6567 - val_loss: 649.6604\n",
      "Epoch 889/1000\n",
      "306/306 [==============================] - 0s 951us/step - loss: 376.9191 - val_loss: 713.3937\n",
      "Epoch 890/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 376.1132 - val_loss: 667.3622\n",
      "Epoch 891/1000\n",
      "306/306 [==============================] - 0s 941us/step - loss: 376.7582 - val_loss: 674.8460\n",
      "Epoch 892/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 378.9479 - val_loss: 673.5698\n",
      "Epoch 893/1000\n",
      "306/306 [==============================] - 0s 887us/step - loss: 376.5374 - val_loss: 681.9822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 376.2024 - val_loss: 718.7902\n",
      "Epoch 895/1000\n",
      "306/306 [==============================] - 0s 938us/step - loss: 376.1560 - val_loss: 665.6384\n",
      "Epoch 896/1000\n",
      "306/306 [==============================] - 0s 963us/step - loss: 375.7243 - val_loss: 650.5802\n",
      "Epoch 897/1000\n",
      "306/306 [==============================] - 0s 944us/step - loss: 376.5804 - val_loss: 665.7024\n",
      "Epoch 898/1000\n",
      "306/306 [==============================] - 0s 979us/step - loss: 377.8563 - val_loss: 690.4075\n",
      "Epoch 899/1000\n",
      "306/306 [==============================] - 0s 924us/step - loss: 376.6646 - val_loss: 653.5164\n",
      "Epoch 900/1000\n",
      "306/306 [==============================] - 0s 983us/step - loss: 378.3756 - val_loss: 664.0841\n",
      "Epoch 901/1000\n",
      "306/306 [==============================] - 0s 839us/step - loss: 377.1407 - val_loss: 642.1483\n",
      "Epoch 902/1000\n",
      "306/306 [==============================] - 0s 899us/step - loss: 376.4655 - val_loss: 629.6737\n",
      "Epoch 903/1000\n",
      "306/306 [==============================] - 0s 887us/step - loss: 377.0901 - val_loss: 634.9009\n",
      "Epoch 904/1000\n",
      "306/306 [==============================] - 0s 862us/step - loss: 376.4613 - val_loss: 672.1472\n",
      "Epoch 905/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 376.7114 - val_loss: 715.8499\n",
      "Epoch 906/1000\n",
      "306/306 [==============================] - 0s 842us/step - loss: 375.9740 - val_loss: 624.2642\n",
      "Epoch 907/1000\n",
      "306/306 [==============================] - 0s 851us/step - loss: 376.1053 - val_loss: 670.9909\n",
      "Epoch 908/1000\n",
      "306/306 [==============================] - 0s 896us/step - loss: 376.8742 - val_loss: 683.8243\n",
      "Epoch 909/1000\n",
      "306/306 [==============================] - 0s 868us/step - loss: 376.3737 - val_loss: 664.5647\n",
      "Epoch 910/1000\n",
      "306/306 [==============================] - 0s 840us/step - loss: 377.0817 - val_loss: 641.6296\n",
      "Epoch 911/1000\n",
      "306/306 [==============================] - 0s 823us/step - loss: 375.8200 - val_loss: 653.0757\n",
      "Epoch 912/1000\n",
      "306/306 [==============================] - 0s 903us/step - loss: 377.9650 - val_loss: 664.1348\n",
      "Epoch 913/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 375.7127 - val_loss: 655.4456\n",
      "Epoch 914/1000\n",
      "306/306 [==============================] - 0s 927us/step - loss: 376.3341 - val_loss: 699.3244\n",
      "Epoch 915/1000\n",
      "306/306 [==============================] - 0s 925us/step - loss: 376.7147 - val_loss: 642.5801\n",
      "Epoch 916/1000\n",
      "306/306 [==============================] - 0s 921us/step - loss: 376.6499 - val_loss: 671.4103\n",
      "Epoch 917/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 375.7707 - val_loss: 658.3116\n",
      "Epoch 918/1000\n",
      "306/306 [==============================] - 0s 880us/step - loss: 376.8659 - val_loss: 676.3306\n",
      "Epoch 919/1000\n",
      "306/306 [==============================] - 0s 922us/step - loss: 376.2986 - val_loss: 634.6673\n",
      "Epoch 920/1000\n",
      "306/306 [==============================] - 0s 945us/step - loss: 376.7167 - val_loss: 627.2319\n",
      "Epoch 921/1000\n",
      "306/306 [==============================] - 0s 897us/step - loss: 377.7003 - val_loss: 644.1177\n",
      "Epoch 922/1000\n",
      "306/306 [==============================] - 0s 903us/step - loss: 376.6106 - val_loss: 638.2476\n",
      "Epoch 923/1000\n",
      "306/306 [==============================] - 0s 934us/step - loss: 376.2052 - val_loss: 631.7530\n",
      "Epoch 924/1000\n",
      "306/306 [==============================] - 0s 988us/step - loss: 376.6042 - val_loss: 676.8166\n",
      "Epoch 925/1000\n",
      "306/306 [==============================] - 0s 875us/step - loss: 377.6440 - val_loss: 683.5294\n",
      "Epoch 926/1000\n",
      "306/306 [==============================] - 0s 908us/step - loss: 377.0313 - val_loss: 682.1138\n",
      "Epoch 927/1000\n",
      "306/306 [==============================] - 0s 948us/step - loss: 376.2799 - val_loss: 677.3655\n",
      "Epoch 928/1000\n",
      "306/306 [==============================] - 0s 942us/step - loss: 377.5099 - val_loss: 666.1989\n",
      "Epoch 929/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 378.2057 - val_loss: 651.0715\n",
      "Epoch 930/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.2247 - val_loss: 665.0895\n",
      "Epoch 931/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 375.4558 - val_loss: 630.4020\n",
      "Epoch 932/1000\n",
      "306/306 [==============================] - 0s 916us/step - loss: 377.0088 - val_loss: 675.0096\n",
      "Epoch 933/1000\n",
      "306/306 [==============================] - 0s 939us/step - loss: 375.8731 - val_loss: 630.1809\n",
      "Epoch 934/1000\n",
      "306/306 [==============================] - 0s 878us/step - loss: 376.5651 - val_loss: 655.4441\n",
      "Epoch 935/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.3121 - val_loss: 621.8265\n",
      "Epoch 936/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 376.5160 - val_loss: 701.8004\n",
      "Epoch 937/1000\n",
      "306/306 [==============================] - 0s 867us/step - loss: 375.9202 - val_loss: 630.7947\n",
      "Epoch 938/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 377.8928 - val_loss: 636.2429\n",
      "Epoch 939/1000\n",
      "306/306 [==============================] - 0s 917us/step - loss: 376.6832 - val_loss: 640.5786\n",
      "Epoch 940/1000\n",
      "306/306 [==============================] - 0s 857us/step - loss: 377.5161 - val_loss: 634.1090\n",
      "Epoch 941/1000\n",
      "306/306 [==============================] - 0s 957us/step - loss: 377.0765 - val_loss: 690.1431\n",
      "Epoch 942/1000\n",
      "306/306 [==============================] - 0s 952us/step - loss: 375.9776 - val_loss: 628.7468\n",
      "Epoch 943/1000\n",
      "306/306 [==============================] - 0s 958us/step - loss: 376.9547 - val_loss: 619.8049\n",
      "Epoch 944/1000\n",
      "306/306 [==============================] - 0s 845us/step - loss: 377.5578 - val_loss: 642.0438\n",
      "Epoch 945/1000\n",
      "306/306 [==============================] - 0s 868us/step - loss: 377.2819 - val_loss: 626.0226\n",
      "Epoch 946/1000\n",
      "306/306 [==============================] - 0s 913us/step - loss: 376.8075 - val_loss: 669.8616\n",
      "Epoch 947/1000\n",
      "306/306 [==============================] - 0s 875us/step - loss: 376.6404 - val_loss: 635.4019\n",
      "Epoch 948/1000\n",
      "306/306 [==============================] - 0s 980us/step - loss: 377.7452 - val_loss: 649.6267\n",
      "Epoch 949/1000\n",
      "306/306 [==============================] - 0s 977us/step - loss: 377.1042 - val_loss: 658.4584\n",
      "Epoch 950/1000\n",
      "306/306 [==============================] - 0s 886us/step - loss: 375.9863 - val_loss: 662.2129\n",
      "Epoch 951/1000\n",
      "306/306 [==============================] - 0s 954us/step - loss: 376.3385 - val_loss: 721.1440\n",
      "Epoch 952/1000\n",
      "306/306 [==============================] - 0s 905us/step - loss: 376.6025 - val_loss: 724.8478\n",
      "Epoch 953/1000\n",
      "306/306 [==============================] - 0s 896us/step - loss: 377.3182 - val_loss: 659.1741\n",
      "Epoch 954/1000\n",
      "306/306 [==============================] - 0s 926us/step - loss: 375.7856 - val_loss: 662.9410\n",
      "Epoch 955/1000\n",
      "306/306 [==============================] - 0s 953us/step - loss: 376.4834 - val_loss: 663.8303\n",
      "Epoch 956/1000\n",
      "306/306 [==============================] - 0s 891us/step - loss: 376.6987 - val_loss: 645.9927\n",
      "Epoch 957/1000\n",
      "306/306 [==============================] - 0s 928us/step - loss: 375.7481 - val_loss: 641.6994\n",
      "Epoch 958/1000\n",
      "306/306 [==============================] - 0s 940us/step - loss: 376.2783 - val_loss: 679.0236\n",
      "Epoch 959/1000\n",
      "306/306 [==============================] - 0s 871us/step - loss: 376.7026 - val_loss: 665.1874\n",
      "Epoch 960/1000\n",
      "306/306 [==============================] - 0s 815us/step - loss: 376.0112 - val_loss: 686.6555\n",
      "Epoch 961/1000\n",
      "306/306 [==============================] - 0s 874us/step - loss: 376.3078 - val_loss: 681.7307\n",
      "Epoch 962/1000\n",
      "306/306 [==============================] - 0s 900us/step - loss: 377.8055 - val_loss: 672.3560\n",
      "Epoch 963/1000\n",
      "306/306 [==============================] - 0s 855us/step - loss: 376.6385 - val_loss: 684.8071\n",
      "Epoch 964/1000\n",
      "306/306 [==============================] - 0s 902us/step - loss: 376.1516 - val_loss: 698.9270\n",
      "Epoch 965/1000\n",
      "306/306 [==============================] - 0s 916us/step - loss: 376.5632 - val_loss: 686.8330\n",
      "Epoch 966/1000\n",
      "306/306 [==============================] - 0s 926us/step - loss: 377.6211 - val_loss: 663.4271\n",
      "Epoch 967/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 376.9543 - val_loss: 686.0061\n",
      "Epoch 968/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 0s 977us/step - loss: 376.7314 - val_loss: 641.7000\n",
      "Epoch 969/1000\n",
      "306/306 [==============================] - 0s 843us/step - loss: 376.3375 - val_loss: 649.9773\n",
      "Epoch 970/1000\n",
      "306/306 [==============================] - 0s 918us/step - loss: 376.2517 - val_loss: 623.9791\n",
      "Epoch 971/1000\n",
      "306/306 [==============================] - 0s 852us/step - loss: 377.1015 - val_loss: 702.1207\n",
      "Epoch 972/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.1210 - val_loss: 648.8347\n",
      "Epoch 973/1000\n",
      "306/306 [==============================] - 0s 883us/step - loss: 376.2775 - val_loss: 642.9918\n",
      "Epoch 974/1000\n",
      "306/306 [==============================] - 0s 901us/step - loss: 377.2425 - val_loss: 629.2966\n",
      "Epoch 975/1000\n",
      "306/306 [==============================] - 0s 865us/step - loss: 377.0097 - val_loss: 645.3540\n",
      "Epoch 976/1000\n",
      "306/306 [==============================] - 0s 908us/step - loss: 376.9926 - val_loss: 638.6667\n",
      "Epoch 977/1000\n",
      "306/306 [==============================] - 0s 998us/step - loss: 376.2220 - val_loss: 664.1487\n",
      "Epoch 978/1000\n",
      "306/306 [==============================] - 0s 877us/step - loss: 377.2578 - val_loss: 620.8152\n",
      "Epoch 979/1000\n",
      "306/306 [==============================] - 0s 872us/step - loss: 376.5573 - val_loss: 683.1656\n",
      "Epoch 980/1000\n",
      "306/306 [==============================] - 0s 909us/step - loss: 376.5830 - val_loss: 619.4189\n",
      "Epoch 981/1000\n",
      "306/306 [==============================] - 0s 929us/step - loss: 376.4390 - val_loss: 669.0353\n",
      "Epoch 982/1000\n",
      "306/306 [==============================] - 0s 881us/step - loss: 376.1884 - val_loss: 679.0941\n",
      "Epoch 983/1000\n",
      "306/306 [==============================] - 0s 952us/step - loss: 377.0507 - val_loss: 634.9178\n",
      "Epoch 984/1000\n",
      "306/306 [==============================] - 0s 964us/step - loss: 376.8678 - val_loss: 700.8135\n",
      "Epoch 985/1000\n",
      "306/306 [==============================] - 0s 955us/step - loss: 377.6125 - val_loss: 632.4811\n",
      "Epoch 986/1000\n",
      "306/306 [==============================] - 0s 911us/step - loss: 376.8264 - val_loss: 654.7578\n",
      "Epoch 987/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 376.2354 - val_loss: 646.8673\n",
      "Epoch 988/1000\n",
      "306/306 [==============================] - 0s 965us/step - loss: 375.7956 - val_loss: 677.5084\n",
      "Epoch 989/1000\n",
      "306/306 [==============================] - 0s 962us/step - loss: 376.9041 - val_loss: 682.9476\n",
      "Epoch 990/1000\n",
      "306/306 [==============================] - 0s 894us/step - loss: 377.2148 - val_loss: 679.9526\n",
      "Epoch 991/1000\n",
      "306/306 [==============================] - 0s 949us/step - loss: 376.2468 - val_loss: 685.3542\n",
      "Epoch 992/1000\n",
      "306/306 [==============================] - 0s 966us/step - loss: 375.8989 - val_loss: 643.4043\n",
      "Epoch 993/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.7576 - val_loss: 668.7538\n",
      "Epoch 994/1000\n",
      "306/306 [==============================] - 0s 978us/step - loss: 376.1052 - val_loss: 667.8942\n",
      "Epoch 995/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 375.8075 - val_loss: 635.0323\n",
      "Epoch 996/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.4827 - val_loss: 609.2195\n",
      "Epoch 997/1000\n",
      "306/306 [==============================] - 0s 988us/step - loss: 377.7238 - val_loss: 665.8333\n",
      "Epoch 998/1000\n",
      "306/306 [==============================] - 0s 923us/step - loss: 375.8245 - val_loss: 684.0662\n",
      "Epoch 999/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 379.2137 - val_loss: 658.9714\n",
      "Epoch 1000/1000\n",
      "306/306 [==============================] - 0s 1ms/step - loss: 376.5586 - val_loss: 675.5674\n",
      "46/46 [==============================] - 0s 635us/step\n",
      "1014692 successful\n",
      "Epoch 1/1000\n",
      "302/302 [==============================] - 1s 1ms/step - loss: 51100936.0000 - val_loss: 673.1472\n",
      "Epoch 2/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.8465 - val_loss: 720.3132\n",
      "Epoch 3/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.6205 - val_loss: 729.0806\n",
      "Epoch 4/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.3606 - val_loss: 707.7944\n",
      "Epoch 5/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 361.8488 - val_loss: 798.5742\n",
      "Epoch 6/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 366.0503 - val_loss: 658.6378\n",
      "Epoch 7/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 362.0444 - val_loss: 644.7413\n",
      "Epoch 8/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 381.9134 - val_loss: 609.8887\n",
      "Epoch 9/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 392.2898 - val_loss: 611.8759\n",
      "Epoch 10/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 435.5177 - val_loss: 617.8886\n",
      "Epoch 11/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 430.1154 - val_loss: 609.7782\n",
      "Epoch 12/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 430.8732 - val_loss: 1013.3246\n",
      "Epoch 13/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 458.0296 - val_loss: 1048.5065\n",
      "Epoch 14/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 434.3365 - val_loss: 927.6290\n",
      "Epoch 15/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 502.2624 - val_loss: 707.9219\n",
      "Epoch 16/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 709.7697 - val_loss: 900.5232\n",
      "Epoch 17/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 615.2348 - val_loss: 737.6921\n",
      "Epoch 18/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 1152.2327 - val_loss: 2520.8625\n",
      "Epoch 19/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 4668.7188 - val_loss: 34606.5195\n",
      "Epoch 20/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 42406.7031 - val_loss: 96760.1797\n",
      "Epoch 21/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 54532.0742 - val_loss: 27977.8633\n",
      "Epoch 22/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 44625.6992 - val_loss: 1611.0031\n",
      "Epoch 23/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 47569.0117 - val_loss: 33476.5000\n",
      "Epoch 24/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 44878.7695 - val_loss: 19182.6562\n",
      "Epoch 25/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 58722.3984 - val_loss: 14218.8945\n",
      "Epoch 26/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 29898.2285 - val_loss: 18475.7363\n",
      "Epoch 27/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 44492.2500 - val_loss: 27830.1230\n",
      "Epoch 28/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 42945.1680 - val_loss: 818.5386\n",
      "Epoch 29/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 42059.4727 - val_loss: 19437.5762\n",
      "Epoch 30/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 41219.6406 - val_loss: 22117.4199\n",
      "Epoch 31/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 41177.5391 - val_loss: 5582.6865\n",
      "Epoch 32/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 39211.9844 - val_loss: 20150.3027\n",
      "Epoch 33/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 40519.7852 - val_loss: 756.5637\n",
      "Epoch 34/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 34183.8047 - val_loss: 5610.3862\n",
      "Epoch 35/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 33431.2188 - val_loss: 67335.0938\n",
      "Epoch 36/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 40728.7305 - val_loss: 668.6897\n",
      "Epoch 37/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 30716.1133 - val_loss: 16739.0684\n",
      "Epoch 38/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 35661.4531 - val_loss: 5452.7739\n",
      "Epoch 39/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 29288.1289 - val_loss: 8989.8398\n",
      "Epoch 40/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 31161.1582 - val_loss: 1262.3414\n",
      "Epoch 41/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 30180.2520 - val_loss: 11841.0479\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 1s 2ms/step - loss: 31388.7070 - val_loss: 37431.4180\n",
      "Epoch 43/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 25982.2500 - val_loss: 3984.8936\n",
      "Epoch 44/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 31891.8789 - val_loss: 16742.9316\n",
      "Epoch 45/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 23323.8086 - val_loss: 6219.7886\n",
      "Epoch 46/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 24710.6035 - val_loss: 795.3392\n",
      "Epoch 47/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 25137.9395 - val_loss: 2634.1118\n",
      "Epoch 48/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 23429.5488 - val_loss: 10250.7256\n",
      "Epoch 49/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 27215.0430 - val_loss: 722.1696\n",
      "Epoch 50/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 22008.7637 - val_loss: 13117.0029\n",
      "Epoch 51/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 22954.5371 - val_loss: 47609.4414\n",
      "Epoch 52/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 20195.3242 - val_loss: 51580.0430\n",
      "Epoch 53/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 23837.2910 - val_loss: 657.4044\n",
      "Epoch 54/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 20271.4727 - val_loss: 6557.0264\n",
      "Epoch 55/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 19145.8203 - val_loss: 31851.1953\n",
      "Epoch 56/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 11414.2783 - val_loss: 8368.8154\n",
      "Epoch 57/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 14494.1875 - val_loss: 27959.4727\n",
      "Epoch 58/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 15559.8584 - val_loss: 12038.5391\n",
      "Epoch 59/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 15002.2646 - val_loss: 107479.4766\n",
      "Epoch 60/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 13593.0078 - val_loss: 13433.4980\n",
      "Epoch 61/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 17942.0234 - val_loss: 1031.0311\n",
      "Epoch 62/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 16612.6953 - val_loss: 7332.0830\n",
      "Epoch 63/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 11426.8857 - val_loss: 701.5336\n",
      "Epoch 64/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 14194.7324 - val_loss: 5091.0034\n",
      "Epoch 65/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 14247.2578 - val_loss: 17706.1621\n",
      "Epoch 66/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 15678.3564 - val_loss: 615.5285\n",
      "Epoch 67/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 12647.2969 - val_loss: 5954.7729\n",
      "Epoch 68/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 13219.2705 - val_loss: 8251.3154\n",
      "Epoch 69/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 14337.0547 - val_loss: 1438.3291\n",
      "Epoch 70/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 11843.6211 - val_loss: 1270.4960\n",
      "Epoch 71/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 14105.3262 - val_loss: 6030.5366\n",
      "Epoch 72/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 12954.6699 - val_loss: 1455.1619\n",
      "Epoch 73/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 12422.9004 - val_loss: 743.0343\n",
      "Epoch 74/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 846277.3125 - val_loss: 154313.5625\n",
      "Epoch 75/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 12011.2549 - val_loss: 626.1301\n",
      "Epoch 76/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 406.8169 - val_loss: 770.7404\n",
      "Epoch 77/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 409.2556 - val_loss: 616.4680\n",
      "Epoch 78/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 434.9095 - val_loss: 646.9902\n",
      "Epoch 79/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 484.0474 - val_loss: 1045.1597\n",
      "Epoch 80/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 466.1638 - val_loss: 960.0068\n",
      "Epoch 81/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 509.6581 - val_loss: 663.8715\n",
      "Epoch 82/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 602.1584 - val_loss: 647.7128\n",
      "Epoch 83/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 669.2695 - val_loss: 2111.5229\n",
      "Epoch 84/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 839.9875 - val_loss: 641.6990\n",
      "Epoch 85/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 1823.3417 - val_loss: 734.8061\n",
      "Epoch 86/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6564.5562 - val_loss: 879.4422\n",
      "Epoch 87/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 8755.5000 - val_loss: 20097.2559\n",
      "Epoch 88/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 8054.2197 - val_loss: 1390.2949\n",
      "Epoch 89/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 9679.5059 - val_loss: 8734.1973\n",
      "Epoch 90/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 8162.1797 - val_loss: 19244.7812\n",
      "Epoch 91/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 9429.4248 - val_loss: 699.3543\n",
      "Epoch 92/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 7856.5723 - val_loss: 714.9976\n",
      "Epoch 93/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 9127.5205 - val_loss: 6706.3389\n",
      "Epoch 94/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 8082.2451 - val_loss: 6652.8730\n",
      "Epoch 95/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6792.5107 - val_loss: 711.5358\n",
      "Epoch 96/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 9184.7725 - val_loss: 2722.7554\n",
      "Epoch 97/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 7421.5688 - val_loss: 1366.5222\n",
      "Epoch 98/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6608.7222 - val_loss: 745.5944\n",
      "Epoch 99/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 9196.3955 - val_loss: 3616.0349\n",
      "Epoch 100/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 5528.4844 - val_loss: 681.0605\n",
      "Epoch 101/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 8085.2891 - val_loss: 26400.9219\n",
      "Epoch 102/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6307.9360 - val_loss: 43986.1406\n",
      "Epoch 103/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 7537.5796 - val_loss: 11390.5059\n",
      "Epoch 104/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 6440.9844 - val_loss: 1029.0469\n",
      "Epoch 105/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 5895.3774 - val_loss: 6494.3306\n",
      "Epoch 106/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6735.2319 - val_loss: 25207.0859\n",
      "Epoch 107/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6440.1162 - val_loss: 22080.0137\n",
      "Epoch 108/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6288.3564 - val_loss: 14829.7354\n",
      "Epoch 109/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 6541.1890 - val_loss: 908.1147\n",
      "Epoch 110/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 6115.0063 - val_loss: 22369.8516\n",
      "Epoch 111/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 5381.0859 - val_loss: 2235.7231\n",
      "Epoch 112/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 6445.8335 - val_loss: 6642.5947\n",
      "Epoch 113/1000\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 5002.8105 - val_loss: 6909.0068\n",
      "Epoch 114/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5056.2261 - val_loss: 4194.1440\n",
      "Epoch 115/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 6329.3369 - val_loss: 4413.1602\n",
      "Epoch 116/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 4810.2607 - val_loss: 10359.0547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "302/302 [==============================] - 0s 956us/step - loss: 5809.5508 - val_loss: 940.1435\n",
      "Epoch 118/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 4014.3728 - val_loss: 9460.1006\n",
      "Epoch 119/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5678.3682 - val_loss: 7452.3979\n",
      "Epoch 120/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 4555.5508 - val_loss: 4758.4683\n",
      "Epoch 121/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 4477.3955 - val_loss: 14358.9775\n",
      "Epoch 122/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5272.7236 - val_loss: 834.0128\n",
      "Epoch 123/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5134.2275 - val_loss: 14185.4619\n",
      "Epoch 124/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3774.7083 - val_loss: 6985.9570\n",
      "Epoch 125/1000\n",
      "302/302 [==============================] - 0s 984us/step - loss: 4295.9385 - val_loss: 12231.3672\n",
      "Epoch 126/1000\n",
      "302/302 [==============================] - 0s 891us/step - loss: 4344.8853 - val_loss: 1764.5050\n",
      "Epoch 127/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 5686.2271 - val_loss: 1061.1163\n",
      "Epoch 128/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3165.4167 - val_loss: 2607.9658\n",
      "Epoch 129/1000\n",
      "302/302 [==============================] - 0s 887us/step - loss: 4185.6011 - val_loss: 5092.5083\n",
      "Epoch 130/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 4334.9575 - val_loss: 1823.4004\n",
      "Epoch 131/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 3684.6931 - val_loss: 1113.3259\n",
      "Epoch 132/1000\n",
      "302/302 [==============================] - 0s 831us/step - loss: 3980.0369 - val_loss: 2313.4404\n",
      "Epoch 133/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 3614.7183 - val_loss: 4457.9746\n",
      "Epoch 134/1000\n",
      "302/302 [==============================] - 0s 911us/step - loss: 5013.5688 - val_loss: 1326.4246\n",
      "Epoch 135/1000\n",
      "302/302 [==============================] - 0s 990us/step - loss: 2676.0037 - val_loss: 9711.4277\n",
      "Epoch 136/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 4082.6531 - val_loss: 1672.3356\n",
      "Epoch 137/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3243.2639 - val_loss: 12948.4561\n",
      "Epoch 138/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3689.2637 - val_loss: 5640.5767\n",
      "Epoch 139/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 4224.1279 - val_loss: 1176.4232\n",
      "Epoch 140/1000\n",
      "302/302 [==============================] - 0s 974us/step - loss: 2454.8669 - val_loss: 1390.0646\n",
      "Epoch 141/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3826.9458 - val_loss: 2648.9058\n",
      "Epoch 142/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 2914.8501 - val_loss: 649.8594\n",
      "Epoch 143/1000\n",
      "302/302 [==============================] - 0s 941us/step - loss: 2839.3442 - val_loss: 679.8779\n",
      "Epoch 144/1000\n",
      "302/302 [==============================] - 0s 936us/step - loss: 3316.2126 - val_loss: 894.6457\n",
      "Epoch 145/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2559.8909 - val_loss: 1252.2040\n",
      "Epoch 146/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3606.1406 - val_loss: 818.6420\n",
      "Epoch 147/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2607.1274 - val_loss: 2045.1904\n",
      "Epoch 148/1000\n",
      "302/302 [==============================] - 0s 992us/step - loss: 2887.5930 - val_loss: 1226.8954\n",
      "Epoch 149/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 2891.5437 - val_loss: 3766.4504\n",
      "Epoch 150/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 3281.6638 - val_loss: 4221.6294\n",
      "Epoch 151/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 2405.9431 - val_loss: 5120.3013\n",
      "Epoch 152/1000\n",
      "302/302 [==============================] - 0s 870us/step - loss: 2087.5203 - val_loss: 8037.3218\n",
      "Epoch 153/1000\n",
      "302/302 [==============================] - 0s 948us/step - loss: 3825.1758 - val_loss: 950.1523\n",
      "Epoch 154/1000\n",
      "302/302 [==============================] - 0s 897us/step - loss: 2108.5986 - val_loss: 695.5175\n",
      "Epoch 155/1000\n",
      "302/302 [==============================] - 0s 955us/step - loss: 2193.5396 - val_loss: 2178.0076\n",
      "Epoch 156/1000\n",
      "302/302 [==============================] - 0s 888us/step - loss: 2676.5776 - val_loss: 6904.3823\n",
      "Epoch 157/1000\n",
      "302/302 [==============================] - 0s 964us/step - loss: 1746.3994 - val_loss: 2067.0613\n",
      "Epoch 158/1000\n",
      "302/302 [==============================] - 0s 925us/step - loss: 2931.7961 - val_loss: 673.6808\n",
      "Epoch 159/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 2381.4089 - val_loss: 2902.1270\n",
      "Epoch 160/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2235.1968 - val_loss: 3868.0952\n",
      "Epoch 161/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2197.2046 - val_loss: 837.2858\n",
      "Epoch 162/1000\n",
      "302/302 [==============================] - 0s 937us/step - loss: 2274.9973 - val_loss: 1817.6227\n",
      "Epoch 163/1000\n",
      "302/302 [==============================] - 0s 893us/step - loss: 1898.4424 - val_loss: 1095.2871\n",
      "Epoch 164/1000\n",
      "302/302 [==============================] - 0s 993us/step - loss: 2333.9434 - val_loss: 6378.8359\n",
      "Epoch 165/1000\n",
      "302/302 [==============================] - 0s 870us/step - loss: 1782.3445 - val_loss: 4347.4263\n",
      "Epoch 166/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 1975.0486 - val_loss: 5203.7124\n",
      "Epoch 167/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 1682.1848 - val_loss: 2134.4106\n",
      "Epoch 168/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2251.5574 - val_loss: 864.9283\n",
      "Epoch 169/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 2233.4382 - val_loss: 2104.1545\n",
      "Epoch 170/1000\n",
      "302/302 [==============================] - 0s 952us/step - loss: 1507.1143 - val_loss: 2742.6707\n",
      "Epoch 171/1000\n",
      "302/302 [==============================] - 0s 910us/step - loss: 1614.0203 - val_loss: 5525.0200\n",
      "Epoch 172/1000\n",
      "302/302 [==============================] - 0s 910us/step - loss: 2331.5847 - val_loss: 1558.9962\n",
      "Epoch 173/1000\n",
      "302/302 [==============================] - 0s 932us/step - loss: 1898.8784 - val_loss: 776.3033\n",
      "Epoch 174/1000\n",
      "302/302 [==============================] - 0s 869us/step - loss: 1476.7355 - val_loss: 771.6942\n",
      "Epoch 175/1000\n",
      "302/302 [==============================] - 0s 909us/step - loss: 1472.2594 - val_loss: 919.8709\n",
      "Epoch 176/1000\n",
      "302/302 [==============================] - 0s 894us/step - loss: 1813.8412 - val_loss: 4625.2344\n",
      "Epoch 177/1000\n",
      "302/302 [==============================] - 0s 960us/step - loss: 2182.5867 - val_loss: 695.5447\n",
      "Epoch 178/1000\n",
      "302/302 [==============================] - 0s 879us/step - loss: 1564.9768 - val_loss: 609.7604\n",
      "Epoch 179/1000\n",
      "302/302 [==============================] - 0s 937us/step - loss: 101663.9922 - val_loss: 829.0640\n",
      "Epoch 180/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 379.3944 - val_loss: 668.2944\n",
      "Epoch 181/1000\n",
      "302/302 [==============================] - 0s 938us/step - loss: 401.4668 - val_loss: 620.4416\n",
      "Epoch 182/1000\n",
      "302/302 [==============================] - 0s 992us/step - loss: 391.6537 - val_loss: 1261.3030\n",
      "Epoch 183/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 412.1355 - val_loss: 617.4804\n",
      "Epoch 184/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 419.7297 - val_loss: 741.3752\n",
      "Epoch 185/1000\n",
      "302/302 [==============================] - 0s 864us/step - loss: 482.3771 - val_loss: 694.2970\n",
      "Epoch 186/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 531.6913 - val_loss: 957.4276\n",
      "Epoch 187/1000\n",
      "302/302 [==============================] - 0s 920us/step - loss: 603.2005 - val_loss: 1845.0232\n",
      "Epoch 188/1000\n",
      "302/302 [==============================] - 0s 876us/step - loss: 668.0328 - val_loss: 1356.9709\n",
      "Epoch 189/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 748.7587 - val_loss: 1251.7003\n",
      "Epoch 190/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 921.7736 - val_loss: 770.0947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/1000\n",
      "302/302 [==============================] - 0s 990us/step - loss: 874.9353 - val_loss: 1212.7526\n",
      "Epoch 192/1000\n",
      "302/302 [==============================] - 0s 907us/step - loss: 1506.7682 - val_loss: 3236.5964\n",
      "Epoch 193/1000\n",
      "302/302 [==============================] - 0s 973us/step - loss: 1162.5272 - val_loss: 706.2133\n",
      "Epoch 194/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 1044.1482 - val_loss: 1562.7406\n",
      "Epoch 195/1000\n",
      "302/302 [==============================] - 0s 890us/step - loss: 1317.0007 - val_loss: 1277.5203\n",
      "Epoch 196/1000\n",
      "302/302 [==============================] - 0s 951us/step - loss: 1503.5309 - val_loss: 1313.4393\n",
      "Epoch 197/1000\n",
      "302/302 [==============================] - 0s 892us/step - loss: 1358.6023 - val_loss: 609.7560\n",
      "Epoch 198/1000\n",
      "302/302 [==============================] - 0s 860us/step - loss: 1356.5906 - val_loss: 725.4046\n",
      "Epoch 199/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 1122.5199 - val_loss: 1427.8354\n",
      "Epoch 200/1000\n",
      "302/302 [==============================] - 0s 964us/step - loss: 988.9862 - val_loss: 611.9610\n",
      "Epoch 201/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 1158.2626 - val_loss: 2685.9785\n",
      "Epoch 202/1000\n",
      "302/302 [==============================] - 0s 986us/step - loss: 1279.0563 - val_loss: 643.2633\n",
      "Epoch 203/1000\n",
      "302/302 [==============================] - 0s 944us/step - loss: 953.9678 - val_loss: 1891.9882\n",
      "Epoch 204/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 1124.7340 - val_loss: 854.8594\n",
      "Epoch 205/1000\n",
      "302/302 [==============================] - 0s 936us/step - loss: 1569.2407 - val_loss: 641.9446\n",
      "Epoch 206/1000\n",
      "302/302 [==============================] - 0s 919us/step - loss: 1017.1795 - val_loss: 825.0574\n",
      "Epoch 207/1000\n",
      "302/302 [==============================] - 0s 897us/step - loss: 1039.3146 - val_loss: 1038.2239\n",
      "Epoch 208/1000\n",
      "302/302 [==============================] - 0s 892us/step - loss: 1071.9409 - val_loss: 675.6155\n",
      "Epoch 209/1000\n",
      "302/302 [==============================] - 0s 921us/step - loss: 1218.3046 - val_loss: 4585.6963\n",
      "Epoch 210/1000\n",
      "302/302 [==============================] - 0s 901us/step - loss: 964.7979 - val_loss: 968.5969\n",
      "Epoch 211/1000\n",
      "302/302 [==============================] - 0s 895us/step - loss: 999.6813 - val_loss: 999.7687\n",
      "Epoch 212/1000\n",
      "302/302 [==============================] - 0s 875us/step - loss: 924.7620 - val_loss: 1986.6173\n",
      "Epoch 213/1000\n",
      "302/302 [==============================] - 0s 905us/step - loss: 815.2987 - val_loss: 764.8188\n",
      "Epoch 214/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 1016.5617 - val_loss: 4947.9204\n",
      "Epoch 215/1000\n",
      "302/302 [==============================] - 0s 863us/step - loss: 903.5056 - val_loss: 1634.7152\n",
      "Epoch 216/1000\n",
      "302/302 [==============================] - 0s 908us/step - loss: 1034.3701 - val_loss: 3341.3086\n",
      "Epoch 217/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 987.5701 - val_loss: 2028.3135\n",
      "Epoch 218/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 880.0004 - val_loss: 667.0215\n",
      "Epoch 219/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 1039.9846 - val_loss: 737.6312\n",
      "Epoch 220/1000\n",
      "302/302 [==============================] - 0s 918us/step - loss: 734.4320 - val_loss: 1173.4221\n",
      "Epoch 221/1000\n",
      "302/302 [==============================] - 0s 945us/step - loss: 959.3403 - val_loss: 785.3828\n",
      "Epoch 222/1000\n",
      "302/302 [==============================] - 0s 932us/step - loss: 956.0882 - val_loss: 1144.2034\n",
      "Epoch 223/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 871.5835 - val_loss: 1163.3510\n",
      "Epoch 224/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 877.2789 - val_loss: 718.2863\n",
      "Epoch 225/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 734.7435 - val_loss: 786.7766\n",
      "Epoch 226/1000\n",
      "302/302 [==============================] - 0s 929us/step - loss: 753.1737 - val_loss: 619.7064\n",
      "Epoch 227/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 1070.6354 - val_loss: 1245.5660\n",
      "Epoch 228/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 639.1213 - val_loss: 990.0416\n",
      "Epoch 229/1000\n",
      "302/302 [==============================] - 0s 912us/step - loss: 791.4896 - val_loss: 721.7175\n",
      "Epoch 230/1000\n",
      "302/302 [==============================] - 0s 901us/step - loss: 861.3198 - val_loss: 637.7672\n",
      "Epoch 231/1000\n",
      "302/302 [==============================] - 0s 908us/step - loss: 699.4260 - val_loss: 1074.4032\n",
      "Epoch 232/1000\n",
      "302/302 [==============================] - 0s 872us/step - loss: 849.0340 - val_loss: 2538.1484\n",
      "Epoch 233/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 24617.3672 - val_loss: 651.7870\n",
      "Epoch 234/1000\n",
      "302/302 [==============================] - 0s 877us/step - loss: 377.2501 - val_loss: 609.6814\n",
      "Epoch 235/1000\n",
      "302/302 [==============================] - 0s 882us/step - loss: 396.5244 - val_loss: 636.6959\n",
      "Epoch 236/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 432.5896 - val_loss: 610.2779\n",
      "Epoch 237/1000\n",
      "302/302 [==============================] - 0s 918us/step - loss: 417.7501 - val_loss: 910.4334\n",
      "Epoch 238/1000\n",
      "302/302 [==============================] - 0s 890us/step - loss: 465.6313 - val_loss: 669.1487\n",
      "Epoch 239/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 440.7091 - val_loss: 736.1321\n",
      "Epoch 240/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 448.3947 - val_loss: 943.4422\n",
      "Epoch 241/1000\n",
      "302/302 [==============================] - 0s 835us/step - loss: 528.9354 - val_loss: 1839.5469\n",
      "Epoch 242/1000\n",
      "302/302 [==============================] - 0s 938us/step - loss: 604.2061 - val_loss: 858.4398\n",
      "Epoch 243/1000\n",
      "302/302 [==============================] - 0s 911us/step - loss: 640.9922 - val_loss: 757.8486\n",
      "Epoch 244/1000\n",
      "302/302 [==============================] - 0s 874us/step - loss: 744.7093 - val_loss: 611.9178\n",
      "Epoch 245/1000\n",
      "302/302 [==============================] - 0s 824us/step - loss: 626.6125 - val_loss: 610.4592\n",
      "Epoch 246/1000\n",
      "302/302 [==============================] - 0s 903us/step - loss: 611.3005 - val_loss: 716.7757\n",
      "Epoch 247/1000\n",
      "302/302 [==============================] - 0s 862us/step - loss: 676.0948 - val_loss: 753.0624\n",
      "Epoch 248/1000\n",
      "302/302 [==============================] - 0s 829us/step - loss: 599.9234 - val_loss: 609.6769\n",
      "Epoch 249/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 777.2505 - val_loss: 645.3378\n",
      "Epoch 250/1000\n",
      "302/302 [==============================] - 0s 955us/step - loss: 728.2454 - val_loss: 688.0297\n",
      "Epoch 251/1000\n",
      "302/302 [==============================] - 0s 954us/step - loss: 653.4798 - val_loss: 648.8750\n",
      "Epoch 252/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 652.1392 - val_loss: 889.6928\n",
      "Epoch 253/1000\n",
      "302/302 [==============================] - 0s 962us/step - loss: 663.9341 - val_loss: 1131.0887\n",
      "Epoch 254/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 564.6245 - val_loss: 932.2742\n",
      "Epoch 255/1000\n",
      "302/302 [==============================] - 0s 974us/step - loss: 530.1215 - val_loss: 717.3122\n",
      "Epoch 256/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 508.9024 - val_loss: 1030.4729\n",
      "Epoch 257/1000\n",
      "302/302 [==============================] - 0s 968us/step - loss: 536.1398 - val_loss: 1727.6775\n",
      "Epoch 258/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 634.6039 - val_loss: 647.8228\n",
      "Epoch 259/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 614.9590 - val_loss: 1129.4620\n",
      "Epoch 260/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 502.0406 - val_loss: 619.8789\n",
      "Epoch 261/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 618.9888 - val_loss: 611.0923\n",
      "Epoch 262/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 518.9586 - val_loss: 783.2532\n",
      "Epoch 263/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 501.4996 - val_loss: 631.2279\n",
      "Epoch 264/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 509.8154 - val_loss: 648.7000\n",
      "Epoch 265/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 1ms/step - loss: 525.9444 - val_loss: 1345.4209\n",
      "Epoch 266/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 617.8246 - val_loss: 842.0434\n",
      "Epoch 267/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 513.8832 - val_loss: 926.8423\n",
      "Epoch 268/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 522.1829 - val_loss: 743.3925\n",
      "Epoch 269/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 507.5060 - val_loss: 624.2262\n",
      "Epoch 270/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 502.6042 - val_loss: 972.0355\n",
      "Epoch 271/1000\n",
      "302/302 [==============================] - 0s 937us/step - loss: 432.2763 - val_loss: 842.6530\n",
      "Epoch 272/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 416.5214 - val_loss: 670.0946\n",
      "Epoch 273/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 465.2347 - val_loss: 640.1290\n",
      "Epoch 274/1000\n",
      "302/302 [==============================] - 0s 1000us/step - loss: 457.8143 - val_loss: 640.2045\n",
      "Epoch 275/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 413.5594 - val_loss: 628.3948\n",
      "Epoch 276/1000\n",
      "302/302 [==============================] - 0s 982us/step - loss: 388.7867 - val_loss: 647.0944\n",
      "Epoch 277/1000\n",
      "302/302 [==============================] - 0s 984us/step - loss: 420.1449 - val_loss: 609.9892\n",
      "Epoch 278/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 385.9324 - val_loss: 643.5517\n",
      "Epoch 279/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 389.2169 - val_loss: 930.7077\n",
      "Epoch 280/1000\n",
      "302/302 [==============================] - 0s 933us/step - loss: 388.2551 - val_loss: 617.1459\n",
      "Epoch 281/1000\n",
      "302/302 [==============================] - 0s 957us/step - loss: 372.2403 - val_loss: 947.4092\n",
      "Epoch 282/1000\n",
      "302/302 [==============================] - 0s 899us/step - loss: 384.0511 - val_loss: 692.2394\n",
      "Epoch 283/1000\n",
      "302/302 [==============================] - 0s 952us/step - loss: 385.8345 - val_loss: 692.9703\n",
      "Epoch 284/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 368.2198 - val_loss: 1046.4442\n",
      "Epoch 285/1000\n",
      "302/302 [==============================] - 0s 970us/step - loss: 369.3187 - val_loss: 803.2834\n",
      "Epoch 286/1000\n",
      "302/302 [==============================] - 0s 965us/step - loss: 351.2103 - val_loss: 686.0201\n",
      "Epoch 287/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 351.3290 - val_loss: 735.6545\n",
      "Epoch 288/1000\n",
      "302/302 [==============================] - 0s 910us/step - loss: 349.7541 - val_loss: 734.5208\n",
      "Epoch 289/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 345.5001 - val_loss: 614.0955\n",
      "Epoch 290/1000\n",
      "302/302 [==============================] - 0s 865us/step - loss: 347.2324 - val_loss: 765.3307\n",
      "Epoch 291/1000\n",
      "302/302 [==============================] - 0s 903us/step - loss: 348.3275 - val_loss: 707.9213\n",
      "Epoch 292/1000\n",
      "302/302 [==============================] - 0s 893us/step - loss: 348.3391 - val_loss: 679.8081\n",
      "Epoch 293/1000\n",
      "302/302 [==============================] - 0s 874us/step - loss: 348.3135 - val_loss: 662.8438\n",
      "Epoch 294/1000\n",
      "302/302 [==============================] - 0s 927us/step - loss: 348.5982 - val_loss: 615.5341\n",
      "Epoch 295/1000\n",
      "302/302 [==============================] - 0s 968us/step - loss: 346.5860 - val_loss: 644.2631\n",
      "Epoch 296/1000\n",
      "302/302 [==============================] - 0s 955us/step - loss: 351.7690 - val_loss: 681.9666\n",
      "Epoch 297/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.0848 - val_loss: 681.6412\n",
      "Epoch 298/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 351.5768 - val_loss: 712.0864\n",
      "Epoch 299/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.2031 - val_loss: 726.5769\n",
      "Epoch 300/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 349.8889 - val_loss: 609.7900\n",
      "Epoch 301/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.5776 - val_loss: 754.5223\n",
      "Epoch 302/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 350.3106 - val_loss: 747.4485\n",
      "Epoch 303/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 349.4001 - val_loss: 752.0378\n",
      "Epoch 304/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 350.9003 - val_loss: 767.7598\n",
      "Epoch 305/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 348.4660 - val_loss: 703.9389\n",
      "Epoch 306/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.6023 - val_loss: 717.4054\n",
      "Epoch 307/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 354.7997 - val_loss: 739.3098\n",
      "Epoch 308/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 354.4614 - val_loss: 656.2707\n",
      "Epoch 309/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.4546 - val_loss: 844.2224\n",
      "Epoch 310/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 350.3930 - val_loss: 636.6224\n",
      "Epoch 311/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 351.8253 - val_loss: 792.2809\n",
      "Epoch 312/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 356.6343 - val_loss: 641.0130\n",
      "Epoch 313/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 355.4177 - val_loss: 628.2543\n",
      "Epoch 314/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 349.8180 - val_loss: 779.8055\n",
      "Epoch 315/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 2630.2305 - val_loss: 655.4810\n",
      "Epoch 316/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 346.0093 - val_loss: 629.9315\n",
      "Epoch 317/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 346.7593 - val_loss: 683.7201\n",
      "Epoch 318/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 346.9532 - val_loss: 682.9268\n",
      "Epoch 319/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 345.4867 - val_loss: 726.3668\n",
      "Epoch 320/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 347.8472 - val_loss: 728.1381\n",
      "Epoch 321/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 346.0378 - val_loss: 666.3027\n",
      "Epoch 322/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.6159 - val_loss: 644.7845\n",
      "Epoch 323/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.5840 - val_loss: 645.0831\n",
      "Epoch 324/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 345.1511 - val_loss: 649.6809\n",
      "Epoch 325/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.7399 - val_loss: 655.7217\n",
      "Epoch 326/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.4119 - val_loss: 647.2905\n",
      "Epoch 327/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.1841 - val_loss: 736.5056\n",
      "Epoch 328/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.9195 - val_loss: 639.5077\n",
      "Epoch 329/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.2335 - val_loss: 654.2010\n",
      "Epoch 330/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 345.8241 - val_loss: 659.3793\n",
      "Epoch 331/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 350.7527 - val_loss: 696.6140\n",
      "Epoch 332/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.0445 - val_loss: 769.5503\n",
      "Epoch 333/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 347.0214 - val_loss: 637.1560\n",
      "Epoch 334/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.9997 - val_loss: 665.9566\n",
      "Epoch 335/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.8112 - val_loss: 736.8879\n",
      "Epoch 336/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 351.8170 - val_loss: 670.9724\n",
      "Epoch 337/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.6492 - val_loss: 719.0919\n",
      "Epoch 338/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 347.7042 - val_loss: 687.9066\n",
      "Epoch 339/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 353.2447 - val_loss: 675.1471\n",
      "Epoch 340/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 1s 3ms/step - loss: 349.6817 - val_loss: 762.9915\n",
      "Epoch 341/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.3745 - val_loss: 643.0799\n",
      "Epoch 342/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 347.6250 - val_loss: 640.4437\n",
      "Epoch 343/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.9340 - val_loss: 689.3500\n",
      "Epoch 344/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.3217 - val_loss: 619.2307\n",
      "Epoch 345/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 354.1462 - val_loss: 738.0648\n",
      "Epoch 346/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 351.7758 - val_loss: 624.9252\n",
      "Epoch 347/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.9849 - val_loss: 709.7390\n",
      "Epoch 348/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 350.4437 - val_loss: 640.0834\n",
      "Epoch 349/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.8842 - val_loss: 735.3585\n",
      "Epoch 350/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.4173 - val_loss: 664.5638\n",
      "Epoch 351/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.2263 - val_loss: 635.3000\n",
      "Epoch 352/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 353.5087 - val_loss: 644.8169\n",
      "Epoch 353/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.4173 - val_loss: 667.6273\n",
      "Epoch 354/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 348.5054 - val_loss: 657.2829\n",
      "Epoch 355/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.5418 - val_loss: 690.4017\n",
      "Epoch 356/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 354.3057 - val_loss: 645.2009\n",
      "Epoch 357/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 348.3809 - val_loss: 697.0779\n",
      "Epoch 358/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 351.3253 - val_loss: 728.9750\n",
      "Epoch 359/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.1530 - val_loss: 639.9359\n",
      "Epoch 360/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 354.7825 - val_loss: 817.7932\n",
      "Epoch 361/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.0349 - val_loss: 668.4048\n",
      "Epoch 362/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 355.0090 - val_loss: 758.9641\n",
      "Epoch 363/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 349.3001 - val_loss: 717.8715\n",
      "Epoch 364/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 352.3476 - val_loss: 884.9746\n",
      "Epoch 365/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 352.1985 - val_loss: 776.5832\n",
      "Epoch 366/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 351.3293 - val_loss: 646.6601\n",
      "Epoch 367/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 350.8627 - val_loss: 708.2081\n",
      "Epoch 368/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 348.2843 - val_loss: 675.0658\n",
      "Epoch 369/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 348.0278 - val_loss: 659.2234\n",
      "Epoch 370/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 351.7507 - val_loss: 624.6656\n",
      "Epoch 371/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 2325.0305 - val_loss: 1460.1570\n",
      "Epoch 372/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 780.1894 - val_loss: 1443.4285\n",
      "Epoch 373/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 768.2201 - val_loss: 1426.9095\n",
      "Epoch 374/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 756.4504 - val_loss: 1410.6088\n",
      "Epoch 375/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 744.8751 - val_loss: 1394.4873\n",
      "Epoch 376/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 733.4856 - val_loss: 1378.6056\n",
      "Epoch 377/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 722.2826 - val_loss: 1362.8577\n",
      "Epoch 378/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 711.2487 - val_loss: 1347.3066\n",
      "Epoch 379/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 700.3924 - val_loss: 1331.9840\n",
      "Epoch 380/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 689.7255 - val_loss: 1316.7900\n",
      "Epoch 381/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 679.2367 - val_loss: 1301.8596\n",
      "Epoch 382/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 668.9084 - val_loss: 1287.0059\n",
      "Epoch 383/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 658.7535 - val_loss: 1272.3905\n",
      "Epoch 384/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 648.7833 - val_loss: 1257.9592\n",
      "Epoch 385/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 638.9751 - val_loss: 1243.6624\n",
      "Epoch 386/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 629.3546 - val_loss: 1229.5785\n",
      "Epoch 387/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 619.8901 - val_loss: 1215.6412\n",
      "Epoch 388/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 610.5861 - val_loss: 1201.8882\n",
      "Epoch 389/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 601.4744 - val_loss: 1188.3293\n",
      "Epoch 390/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 592.5305 - val_loss: 1174.9568\n",
      "Epoch 391/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 583.7543 - val_loss: 1161.7720\n",
      "Epoch 392/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 575.1516 - val_loss: 1148.7325\n",
      "Epoch 393/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 566.7202 - val_loss: 1135.9027\n",
      "Epoch 394/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 558.4473 - val_loss: 1123.2515\n",
      "Epoch 395/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 550.3516 - val_loss: 1110.7134\n",
      "Epoch 396/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 542.4333 - val_loss: 1098.4723\n",
      "Epoch 397/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 534.6812 - val_loss: 1086.2930\n",
      "Epoch 398/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 527.0963 - val_loss: 1074.3850\n",
      "Epoch 399/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 519.6718 - val_loss: 1062.5565\n",
      "Epoch 400/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 512.4223 - val_loss: 1050.9808\n",
      "Epoch 401/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 505.3366 - val_loss: 1039.5356\n",
      "Epoch 402/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 498.4077 - val_loss: 1028.2860\n",
      "Epoch 403/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 491.6492 - val_loss: 1017.2108\n",
      "Epoch 404/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 485.0556 - val_loss: 1006.3190\n",
      "Epoch 405/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 478.6254 - val_loss: 995.5704\n",
      "Epoch 406/1000\n",
      "302/302 [==============================] - 0s 976us/step - loss: 472.3601 - val_loss: 985.0042\n",
      "Epoch 407/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 466.2733 - val_loss: 974.6292\n",
      "Epoch 408/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 460.3527 - val_loss: 964.4902\n",
      "Epoch 409/1000\n",
      "302/302 [==============================] - 0s 951us/step - loss: 454.5985 - val_loss: 954.5276\n",
      "Epoch 410/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 449.0106 - val_loss: 944.7162\n",
      "Epoch 411/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 443.5730 - val_loss: 935.0372\n",
      "Epoch 412/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 438.2799 - val_loss: 925.5591\n",
      "Epoch 413/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 433.1485 - val_loss: 916.2158\n",
      "Epoch 414/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 428.1848 - val_loss: 907.1055\n",
      "Epoch 415/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 1ms/step - loss: 423.3734 - val_loss: 898.1221\n",
      "Epoch 416/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 418.7350 - val_loss: 889.3859\n",
      "Epoch 417/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 414.2630 - val_loss: 880.8248\n",
      "Epoch 418/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 409.9344 - val_loss: 872.4033\n",
      "Epoch 419/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 405.7744 - val_loss: 864.2061\n",
      "Epoch 420/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 401.7682 - val_loss: 856.1878\n",
      "Epoch 421/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 397.9065 - val_loss: 848.3327\n",
      "Epoch 422/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 394.2117 - val_loss: 840.6868\n",
      "Epoch 423/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 390.6655 - val_loss: 833.1888\n",
      "Epoch 424/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 387.2640 - val_loss: 825.8864\n",
      "Epoch 425/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 384.0231 - val_loss: 818.7795\n",
      "Epoch 426/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 380.9380 - val_loss: 811.8768\n",
      "Epoch 427/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 378.0061 - val_loss: 805.2476\n",
      "Epoch 428/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 375.2079 - val_loss: 798.6529\n",
      "Epoch 429/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 372.5471 - val_loss: 792.2896\n",
      "Epoch 430/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 370.0250 - val_loss: 786.0961\n",
      "Epoch 431/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 367.6322 - val_loss: 780.1194\n",
      "Epoch 432/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 365.3810 - val_loss: 774.3080\n",
      "Epoch 433/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 363.2761 - val_loss: 768.6984\n",
      "Epoch 434/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 361.2988 - val_loss: 763.3162\n",
      "Epoch 435/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 359.4549 - val_loss: 758.0958\n",
      "Epoch 436/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 357.7346 - val_loss: 753.1218\n",
      "Epoch 437/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 356.1301 - val_loss: 748.2884\n",
      "Epoch 438/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 354.6475 - val_loss: 743.6157\n",
      "Epoch 439/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 353.2736 - val_loss: 739.1625\n",
      "Epoch 440/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 351.9944 - val_loss: 734.8529\n",
      "Epoch 441/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 350.8286 - val_loss: 730.6937\n",
      "Epoch 442/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 349.7741 - val_loss: 726.8345\n",
      "Epoch 443/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 348.8121 - val_loss: 723.1783\n",
      "Epoch 444/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 347.9445 - val_loss: 719.7038\n",
      "Epoch 445/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 347.1609 - val_loss: 716.3998\n",
      "Epoch 446/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 346.4521 - val_loss: 713.1984\n",
      "Epoch 447/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 345.8238 - val_loss: 710.1998\n",
      "Epoch 448/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 345.2710 - val_loss: 707.4879\n",
      "Epoch 449/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 344.7849 - val_loss: 704.9641\n",
      "Epoch 450/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 344.3588 - val_loss: 702.5352\n",
      "Epoch 451/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 343.9813 - val_loss: 700.2565\n",
      "Epoch 452/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 343.6520 - val_loss: 698.1990\n",
      "Epoch 453/1000\n",
      "302/302 [==============================] - 0s 989us/step - loss: 343.3697 - val_loss: 696.2742\n",
      "Epoch 454/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 343.1250 - val_loss: 694.5433\n",
      "Epoch 455/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.9111 - val_loss: 692.8211\n",
      "Epoch 456/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.7276 - val_loss: 691.3180\n",
      "Epoch 457/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.5720 - val_loss: 689.8238\n",
      "Epoch 458/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.4380 - val_loss: 688.5822\n",
      "Epoch 459/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.3235 - val_loss: 687.3306\n",
      "Epoch 460/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.2281 - val_loss: 686.1674\n",
      "Epoch 461/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.1487 - val_loss: 685.2104\n",
      "Epoch 462/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.0823 - val_loss: 684.3781\n",
      "Epoch 463/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 342.0244 - val_loss: 683.4799\n",
      "Epoch 464/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.9768 - val_loss: 682.6868\n",
      "Epoch 465/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.9375 - val_loss: 682.0228\n",
      "Epoch 466/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.9044 - val_loss: 681.4084\n",
      "Epoch 467/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.8766 - val_loss: 680.7969\n",
      "Epoch 468/1000\n",
      "302/302 [==============================] - 0s 965us/step - loss: 341.8550 - val_loss: 680.2838\n",
      "Epoch 469/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.8350 - val_loss: 679.8891\n",
      "Epoch 470/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.8171 - val_loss: 679.3339\n",
      "Epoch 471/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.8047 - val_loss: 679.0081\n",
      "Epoch 472/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7933 - val_loss: 678.5876\n",
      "Epoch 473/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7847 - val_loss: 678.2567\n",
      "Epoch 474/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7763 - val_loss: 677.9067\n",
      "Epoch 475/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7715 - val_loss: 677.6851\n",
      "Epoch 476/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7654 - val_loss: 677.4090\n",
      "Epoch 477/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7613 - val_loss: 677.2410\n",
      "Epoch 478/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7575 - val_loss: 677.0652\n",
      "Epoch 479/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7547 - val_loss: 676.8591\n",
      "Epoch 480/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7520 - val_loss: 676.6575\n",
      "Epoch 481/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7504 - val_loss: 676.5791\n",
      "Epoch 482/1000\n",
      "302/302 [==============================] - 0s 985us/step - loss: 341.7490 - val_loss: 676.3758\n",
      "Epoch 483/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7460 - val_loss: 676.2646\n",
      "Epoch 484/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7458 - val_loss: 676.1741\n",
      "Epoch 485/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7452 - val_loss: 676.1033\n",
      "Epoch 486/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7454 - val_loss: 676.0098\n",
      "Epoch 487/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7433 - val_loss: 675.9061\n",
      "Epoch 488/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7432 - val_loss: 675.7937\n",
      "Epoch 489/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7430 - val_loss: 675.7683\n",
      "Epoch 490/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7421 - val_loss: 675.7020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7423 - val_loss: 675.6353\n",
      "Epoch 492/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7417 - val_loss: 675.5685\n",
      "Epoch 493/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 675.5396\n",
      "Epoch 494/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 675.4380\n",
      "Epoch 495/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7419 - val_loss: 675.4582\n",
      "Epoch 496/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 675.3810\n",
      "Epoch 497/1000\n",
      "302/302 [==============================] - 0s 984us/step - loss: 341.7425 - val_loss: 675.3776\n",
      "Epoch 498/1000\n",
      "302/302 [==============================] - 0s 985us/step - loss: 341.7403 - val_loss: 675.3469\n",
      "Epoch 499/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7398 - val_loss: 675.2989\n",
      "Epoch 500/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.3118\n",
      "Epoch 501/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7403 - val_loss: 675.2687\n",
      "Epoch 502/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7407 - val_loss: 675.2828\n",
      "Epoch 503/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.2715\n",
      "Epoch 504/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7417 - val_loss: 675.2404\n",
      "Epoch 505/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7398 - val_loss: 675.1777\n",
      "Epoch 506/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 675.2003\n",
      "Epoch 507/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.1298\n",
      "Epoch 508/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 675.1594\n",
      "Epoch 509/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 675.0751\n",
      "Epoch 510/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 341.7410 - val_loss: 675.0731\n",
      "Epoch 511/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7409 - val_loss: 675.0935\n",
      "Epoch 512/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 675.1522\n",
      "Epoch 513/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7405 - val_loss: 675.0909\n",
      "Epoch 514/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7403 - val_loss: 675.0531\n",
      "Epoch 515/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7409 - val_loss: 675.0240\n",
      "Epoch 516/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 675.0568\n",
      "Epoch 517/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7416 - val_loss: 675.0080\n",
      "Epoch 518/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.0458\n",
      "Epoch 519/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 675.0446\n",
      "Epoch 520/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 674.9882\n",
      "Epoch 521/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 674.9847\n",
      "Epoch 522/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.0170\n",
      "Epoch 523/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9675\n",
      "Epoch 524/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7414 - val_loss: 675.0219\n",
      "Epoch 525/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 674.9783\n",
      "Epoch 526/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7405 - val_loss: 675.0148\n",
      "Epoch 527/1000\n",
      "302/302 [==============================] - 0s 956us/step - loss: 341.7414 - val_loss: 675.0121\n",
      "Epoch 528/1000\n",
      "302/302 [==============================] - 0s 973us/step - loss: 341.7409 - val_loss: 675.0120\n",
      "Epoch 529/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 341.7399 - val_loss: 674.9978\n",
      "Epoch 530/1000\n",
      "302/302 [==============================] - 0s 914us/step - loss: 341.7404 - val_loss: 674.9257\n",
      "Epoch 531/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 341.7413 - val_loss: 674.9820\n",
      "Epoch 532/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7395 - val_loss: 674.9894\n",
      "Epoch 533/1000\n",
      "302/302 [==============================] - 0s 931us/step - loss: 341.7401 - val_loss: 674.9915\n",
      "Epoch 534/1000\n",
      "302/302 [==============================] - 0s 914us/step - loss: 341.7406 - val_loss: 675.0144\n",
      "Epoch 535/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 341.7398 - val_loss: 675.0161\n",
      "Epoch 536/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7403 - val_loss: 675.0035\n",
      "Epoch 537/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 341.7395 - val_loss: 674.9976\n",
      "Epoch 538/1000\n",
      "302/302 [==============================] - 0s 909us/step - loss: 341.7399 - val_loss: 674.9977\n",
      "Epoch 539/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 674.9882\n",
      "Epoch 540/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7400 - val_loss: 674.9728\n",
      "Epoch 541/1000\n",
      "302/302 [==============================] - 0s 962us/step - loss: 341.7402 - val_loss: 674.9675\n",
      "Epoch 542/1000\n",
      "302/302 [==============================] - 0s 924us/step - loss: 341.7404 - val_loss: 674.9739\n",
      "Epoch 543/1000\n",
      "302/302 [==============================] - 0s 958us/step - loss: 341.7403 - val_loss: 675.0156\n",
      "Epoch 544/1000\n",
      "302/302 [==============================] - 0s 988us/step - loss: 341.7401 - val_loss: 675.0248\n",
      "Epoch 545/1000\n",
      "302/302 [==============================] - 0s 885us/step - loss: 341.7411 - val_loss: 674.9882\n",
      "Epoch 546/1000\n",
      "302/302 [==============================] - 0s 967us/step - loss: 341.7413 - val_loss: 674.9913\n",
      "Epoch 547/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7407 - val_loss: 674.9702\n",
      "Epoch 548/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 341.7419 - val_loss: 674.9924\n",
      "Epoch 549/1000\n",
      "302/302 [==============================] - 0s 923us/step - loss: 341.7407 - val_loss: 674.9675\n",
      "Epoch 550/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7405 - val_loss: 674.9741\n",
      "Epoch 551/1000\n",
      "302/302 [==============================] - 0s 943us/step - loss: 341.7402 - val_loss: 674.9831\n",
      "Epoch 552/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7393 - val_loss: 674.9820\n",
      "Epoch 553/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 341.7393 - val_loss: 675.0207\n",
      "Epoch 554/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 341.7401 - val_loss: 674.9588\n",
      "Epoch 555/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 341.7409 - val_loss: 675.0332\n",
      "Epoch 556/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 341.7401 - val_loss: 675.0476\n",
      "Epoch 557/1000\n",
      "302/302 [==============================] - 0s 978us/step - loss: 341.7396 - val_loss: 675.0125\n",
      "Epoch 558/1000\n",
      "302/302 [==============================] - 0s 949us/step - loss: 341.7413 - val_loss: 675.0975\n",
      "Epoch 559/1000\n",
      "302/302 [==============================] - 0s 975us/step - loss: 341.7414 - val_loss: 675.0311\n",
      "Epoch 560/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 674.9744\n",
      "Epoch 561/1000\n",
      "302/302 [==============================] - 0s 962us/step - loss: 341.7401 - val_loss: 675.0183\n",
      "Epoch 562/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7411 - val_loss: 674.9238\n",
      "Epoch 563/1000\n",
      "302/302 [==============================] - 0s 927us/step - loss: 341.7402 - val_loss: 674.9460\n",
      "Epoch 564/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7420 - val_loss: 674.9154\n",
      "Epoch 565/1000\n",
      "302/302 [==============================] - 0s 978us/step - loss: 341.7419 - val_loss: 674.9517\n",
      "Epoch 566/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 893us/step - loss: 341.7405 - val_loss: 674.9276\n",
      "Epoch 567/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7412 - val_loss: 674.9828\n",
      "Epoch 568/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7394 - val_loss: 674.9997\n",
      "Epoch 569/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7407 - val_loss: 674.9844\n",
      "Epoch 570/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.0071\n",
      "Epoch 571/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9999\n",
      "Epoch 572/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7403 - val_loss: 674.9762\n",
      "Epoch 573/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7409 - val_loss: 674.9706\n",
      "Epoch 574/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9590\n",
      "Epoch 575/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9520\n",
      "Epoch 576/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7392 - val_loss: 674.9995\n",
      "Epoch 577/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7392 - val_loss: 675.0115\n",
      "Epoch 578/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 675.0305\n",
      "Epoch 579/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 674.9160\n",
      "Epoch 580/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.9460\n",
      "Epoch 581/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7415 - val_loss: 674.9974\n",
      "Epoch 582/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7403 - val_loss: 674.9605\n",
      "Epoch 583/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7393 - val_loss: 674.9540\n",
      "Epoch 584/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 674.9790\n",
      "Epoch 585/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0314\n",
      "Epoch 586/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 675.0470\n",
      "Epoch 587/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9559\n",
      "Epoch 588/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7400 - val_loss: 674.9598\n",
      "Epoch 589/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7409 - val_loss: 674.9913\n",
      "Epoch 590/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0401\n",
      "Epoch 591/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 675.0648\n",
      "Epoch 592/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 675.0029\n",
      "Epoch 593/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0243\n",
      "Epoch 594/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 675.0159\n",
      "Epoch 595/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7397 - val_loss: 675.0495\n",
      "Epoch 596/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 675.0346\n",
      "Epoch 597/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0092\n",
      "Epoch 598/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9763\n",
      "Epoch 599/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0014\n",
      "Epoch 600/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 675.0190\n",
      "Epoch 601/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9628\n",
      "Epoch 602/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7408 - val_loss: 675.0028\n",
      "Epoch 603/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 675.0565\n",
      "Epoch 604/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7400 - val_loss: 675.0396\n",
      "Epoch 605/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7390 - val_loss: 675.0165\n",
      "Epoch 606/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 675.0026\n",
      "Epoch 607/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 675.0049\n",
      "Epoch 608/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0423\n",
      "Epoch 609/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 675.0269\n",
      "Epoch 610/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7404 - val_loss: 675.0242\n",
      "Epoch 611/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7412 - val_loss: 674.9225\n",
      "Epoch 612/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7394 - val_loss: 675.0145\n",
      "Epoch 613/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7410 - val_loss: 675.0753\n",
      "Epoch 614/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7411 - val_loss: 675.0576\n",
      "Epoch 615/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7409 - val_loss: 674.9858\n",
      "Epoch 616/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 675.0116\n",
      "Epoch 617/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7425 - val_loss: 675.0577\n",
      "Epoch 618/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 675.0330\n",
      "Epoch 619/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7407 - val_loss: 675.0449\n",
      "Epoch 620/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7403 - val_loss: 675.0156\n",
      "Epoch 621/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9835\n",
      "Epoch 622/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7406 - val_loss: 675.0211\n",
      "Epoch 623/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7400 - val_loss: 675.0510\n",
      "Epoch 624/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7413 - val_loss: 675.0865\n",
      "Epoch 625/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 675.0781\n",
      "Epoch 626/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0454\n",
      "Epoch 627/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7411 - val_loss: 675.0782\n",
      "Epoch 628/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7412 - val_loss: 675.0285\n",
      "Epoch 629/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 675.0121\n",
      "Epoch 630/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7402 - val_loss: 675.0337\n",
      "Epoch 631/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 674.9836\n",
      "Epoch 632/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7411 - val_loss: 674.9639\n",
      "Epoch 633/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 674.9320\n",
      "Epoch 634/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0344\n",
      "Epoch 635/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 674.9743\n",
      "Epoch 636/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 675.0083\n",
      "Epoch 637/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7415 - val_loss: 675.0519\n",
      "Epoch 638/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 674.9920\n",
      "Epoch 639/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 675.0057\n",
      "Epoch 640/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7408 - val_loss: 674.9830\n",
      "Epoch 641/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7412 - val_loss: 675.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 642/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7415 - val_loss: 675.0024\n",
      "Epoch 643/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 675.0165\n",
      "Epoch 644/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7413 - val_loss: 675.0162\n",
      "Epoch 645/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7396 - val_loss: 675.0151\n",
      "Epoch 646/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9584\n",
      "Epoch 647/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9810\n",
      "Epoch 648/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7413 - val_loss: 675.0303\n",
      "Epoch 649/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 674.9604\n",
      "Epoch 650/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7397 - val_loss: 675.0191\n",
      "Epoch 651/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7423 - val_loss: 674.9148\n",
      "Epoch 652/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 674.9709\n",
      "Epoch 653/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7407 - val_loss: 674.9288\n",
      "Epoch 654/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.8723\n",
      "Epoch 655/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.9539\n",
      "Epoch 656/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 674.9488\n",
      "Epoch 657/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9379\n",
      "Epoch 658/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9257\n",
      "Epoch 659/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 674.9526\n",
      "Epoch 660/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 674.9216\n",
      "Epoch 661/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7418 - val_loss: 674.8325\n",
      "Epoch 662/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.9313\n",
      "Epoch 663/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.8851\n",
      "Epoch 664/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7392 - val_loss: 674.9555\n",
      "Epoch 665/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7410 - val_loss: 674.9711\n",
      "Epoch 666/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7396 - val_loss: 674.9426\n",
      "Epoch 667/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 674.9708\n",
      "Epoch 668/1000\n",
      "302/302 [==============================] - 0s 920us/step - loss: 341.7406 - val_loss: 674.9005\n",
      "Epoch 669/1000\n",
      "302/302 [==============================] - 0s 880us/step - loss: 341.7405 - val_loss: 674.9516\n",
      "Epoch 670/1000\n",
      "302/302 [==============================] - 0s 918us/step - loss: 341.7403 - val_loss: 674.9593\n",
      "Epoch 671/1000\n",
      "302/302 [==============================] - 0s 921us/step - loss: 341.7400 - val_loss: 674.9913\n",
      "Epoch 672/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 341.7403 - val_loss: 674.9481\n",
      "Epoch 673/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7404 - val_loss: 675.0396\n",
      "Epoch 674/1000\n",
      "302/302 [==============================] - 0s 990us/step - loss: 341.7396 - val_loss: 674.9807\n",
      "Epoch 675/1000\n",
      "302/302 [==============================] - 0s 981us/step - loss: 341.7411 - val_loss: 675.0091\n",
      "Epoch 676/1000\n",
      "302/302 [==============================] - 0s 963us/step - loss: 341.7397 - val_loss: 674.9757\n",
      "Epoch 677/1000\n",
      "302/302 [==============================] - 0s 865us/step - loss: 341.7407 - val_loss: 674.9638\n",
      "Epoch 678/1000\n",
      "302/302 [==============================] - 0s 911us/step - loss: 341.7407 - val_loss: 675.0180\n",
      "Epoch 679/1000\n",
      "302/302 [==============================] - 0s 840us/step - loss: 341.7425 - val_loss: 675.0464\n",
      "Epoch 680/1000\n",
      "302/302 [==============================] - 0s 920us/step - loss: 341.7414 - val_loss: 674.9885\n",
      "Epoch 681/1000\n",
      "302/302 [==============================] - 0s 851us/step - loss: 341.7408 - val_loss: 674.9944\n",
      "Epoch 682/1000\n",
      "302/302 [==============================] - 0s 874us/step - loss: 341.7413 - val_loss: 674.9940\n",
      "Epoch 683/1000\n",
      "302/302 [==============================] - 0s 981us/step - loss: 341.7393 - val_loss: 675.0362\n",
      "Epoch 684/1000\n",
      "302/302 [==============================] - 0s 911us/step - loss: 341.7396 - val_loss: 674.9788\n",
      "Epoch 685/1000\n",
      "302/302 [==============================] - 0s 871us/step - loss: 341.7393 - val_loss: 674.9922\n",
      "Epoch 686/1000\n",
      "302/302 [==============================] - 0s 867us/step - loss: 341.7400 - val_loss: 674.9825\n",
      "Epoch 687/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 341.7407 - val_loss: 675.0031\n",
      "Epoch 688/1000\n",
      "302/302 [==============================] - 0s 958us/step - loss: 341.7399 - val_loss: 674.9363\n",
      "Epoch 689/1000\n",
      "302/302 [==============================] - 0s 968us/step - loss: 341.7401 - val_loss: 674.9625\n",
      "Epoch 690/1000\n",
      "302/302 [==============================] - 0s 903us/step - loss: 341.7399 - val_loss: 674.9286\n",
      "Epoch 691/1000\n",
      "302/302 [==============================] - 0s 905us/step - loss: 341.7404 - val_loss: 674.9830\n",
      "Epoch 692/1000\n",
      "302/302 [==============================] - 0s 975us/step - loss: 341.7412 - val_loss: 674.9022\n",
      "Epoch 693/1000\n",
      "302/302 [==============================] - 0s 945us/step - loss: 341.7408 - val_loss: 674.9229\n",
      "Epoch 694/1000\n",
      "302/302 [==============================] - 0s 914us/step - loss: 341.7402 - val_loss: 674.9505\n",
      "Epoch 695/1000\n",
      "302/302 [==============================] - 0s 846us/step - loss: 341.7404 - val_loss: 675.0120\n",
      "Epoch 696/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7406 - val_loss: 674.9470\n",
      "Epoch 697/1000\n",
      "302/302 [==============================] - 0s 932us/step - loss: 341.7408 - val_loss: 675.0023\n",
      "Epoch 698/1000\n",
      "302/302 [==============================] - 0s 949us/step - loss: 341.7408 - val_loss: 674.9637\n",
      "Epoch 699/1000\n",
      "302/302 [==============================] - 0s 840us/step - loss: 341.7395 - val_loss: 674.9578\n",
      "Epoch 700/1000\n",
      "302/302 [==============================] - 0s 961us/step - loss: 341.7398 - val_loss: 675.0219\n",
      "Epoch 701/1000\n",
      "302/302 [==============================] - 0s 903us/step - loss: 341.7397 - val_loss: 675.0070\n",
      "Epoch 702/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 341.7413 - val_loss: 674.9543\n",
      "Epoch 703/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 341.7405 - val_loss: 674.9322\n",
      "Epoch 704/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7396 - val_loss: 675.0012\n",
      "Epoch 705/1000\n",
      "302/302 [==============================] - 0s 945us/step - loss: 341.7413 - val_loss: 675.0062\n",
      "Epoch 706/1000\n",
      "302/302 [==============================] - 0s 919us/step - loss: 341.7400 - val_loss: 674.9677\n",
      "Epoch 707/1000\n",
      "302/302 [==============================] - 0s 838us/step - loss: 341.7407 - val_loss: 675.0190\n",
      "Epoch 708/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.0346\n",
      "Epoch 709/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7402 - val_loss: 675.0203\n",
      "Epoch 710/1000\n",
      "302/302 [==============================] - 0s 964us/step - loss: 341.7413 - val_loss: 675.0105\n",
      "Epoch 711/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7396 - val_loss: 674.9846\n",
      "Epoch 712/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7390 - val_loss: 674.9503\n",
      "Epoch 713/1000\n",
      "302/302 [==============================] - 0s 980us/step - loss: 341.7405 - val_loss: 675.0040\n",
      "Epoch 714/1000\n",
      "302/302 [==============================] - 0s 977us/step - loss: 341.7404 - val_loss: 674.9345\n",
      "Epoch 715/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9066\n",
      "Epoch 716/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9788\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 967us/step - loss: 341.7402 - val_loss: 675.0137\n",
      "Epoch 718/1000\n",
      "302/302 [==============================] - 0s 969us/step - loss: 341.7408 - val_loss: 675.0068\n",
      "Epoch 719/1000\n",
      "302/302 [==============================] - 0s 956us/step - loss: 341.7411 - val_loss: 674.9584\n",
      "Epoch 720/1000\n",
      "302/302 [==============================] - 0s 849us/step - loss: 341.7408 - val_loss: 675.0109\n",
      "Epoch 721/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 341.7413 - val_loss: 674.9570\n",
      "Epoch 722/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.0139\n",
      "Epoch 723/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7420 - val_loss: 675.0879\n",
      "Epoch 724/1000\n",
      "302/302 [==============================] - 0s 892us/step - loss: 341.7410 - val_loss: 674.9921\n",
      "Epoch 725/1000\n",
      "302/302 [==============================] - 0s 971us/step - loss: 341.7397 - val_loss: 675.0198\n",
      "Epoch 726/1000\n",
      "302/302 [==============================] - 0s 854us/step - loss: 341.7398 - val_loss: 675.0088\n",
      "Epoch 727/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7402 - val_loss: 675.0338\n",
      "Epoch 728/1000\n",
      "302/302 [==============================] - 0s 841us/step - loss: 341.7416 - val_loss: 674.9944\n",
      "Epoch 729/1000\n",
      "302/302 [==============================] - 0s 933us/step - loss: 341.7395 - val_loss: 675.0150\n",
      "Epoch 730/1000\n",
      "302/302 [==============================] - 0s 901us/step - loss: 341.7413 - val_loss: 674.9555\n",
      "Epoch 731/1000\n",
      "302/302 [==============================] - 0s 857us/step - loss: 341.7392 - val_loss: 675.0181\n",
      "Epoch 732/1000\n",
      "302/302 [==============================] - 0s 930us/step - loss: 341.7401 - val_loss: 674.9661\n",
      "Epoch 733/1000\n",
      "302/302 [==============================] - 0s 919us/step - loss: 341.7396 - val_loss: 675.0151\n",
      "Epoch 734/1000\n",
      "302/302 [==============================] - 0s 854us/step - loss: 341.7396 - val_loss: 674.9994\n",
      "Epoch 735/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 341.7403 - val_loss: 675.0394\n",
      "Epoch 736/1000\n",
      "302/302 [==============================] - 0s 948us/step - loss: 341.7404 - val_loss: 675.0272\n",
      "Epoch 737/1000\n",
      "302/302 [==============================] - 0s 846us/step - loss: 341.7401 - val_loss: 675.0015\n",
      "Epoch 738/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 341.7415 - val_loss: 675.0109\n",
      "Epoch 739/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7398 - val_loss: 674.9995\n",
      "Epoch 740/1000\n",
      "302/302 [==============================] - 0s 858us/step - loss: 341.7397 - val_loss: 675.0098\n",
      "Epoch 741/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 341.7416 - val_loss: 675.0374\n",
      "Epoch 742/1000\n",
      "302/302 [==============================] - 0s 889us/step - loss: 341.7407 - val_loss: 674.9831\n",
      "Epoch 743/1000\n",
      "302/302 [==============================] - 0s 925us/step - loss: 341.7407 - val_loss: 675.0157\n",
      "Epoch 744/1000\n",
      "302/302 [==============================] - 0s 898us/step - loss: 341.7393 - val_loss: 674.9879\n",
      "Epoch 745/1000\n",
      "302/302 [==============================] - 0s 866us/step - loss: 341.7401 - val_loss: 675.0082\n",
      "Epoch 746/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 341.7408 - val_loss: 675.0032\n",
      "Epoch 747/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7409 - val_loss: 675.0134\n",
      "Epoch 748/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 341.7398 - val_loss: 674.9741\n",
      "Epoch 749/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7421 - val_loss: 675.0623\n",
      "Epoch 750/1000\n",
      "302/302 [==============================] - 0s 932us/step - loss: 341.7403 - val_loss: 674.9808\n",
      "Epoch 751/1000\n",
      "302/302 [==============================] - 0s 957us/step - loss: 341.7415 - val_loss: 675.0301\n",
      "Epoch 752/1000\n",
      "302/302 [==============================] - 0s 909us/step - loss: 341.7401 - val_loss: 675.0316\n",
      "Epoch 753/1000\n",
      "302/302 [==============================] - 0s 855us/step - loss: 341.7401 - val_loss: 674.9984\n",
      "Epoch 754/1000\n",
      "302/302 [==============================] - 0s 973us/step - loss: 341.7391 - val_loss: 674.9963\n",
      "Epoch 755/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7410 - val_loss: 674.9749\n",
      "Epoch 756/1000\n",
      "302/302 [==============================] - 0s 934us/step - loss: 341.7405 - val_loss: 674.9529\n",
      "Epoch 757/1000\n",
      "302/302 [==============================] - 0s 988us/step - loss: 341.7403 - val_loss: 674.9738\n",
      "Epoch 758/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 341.7397 - val_loss: 675.0093\n",
      "Epoch 759/1000\n",
      "302/302 [==============================] - 0s 941us/step - loss: 341.7403 - val_loss: 674.9897\n",
      "Epoch 760/1000\n",
      "302/302 [==============================] - 0s 944us/step - loss: 341.7400 - val_loss: 674.9637\n",
      "Epoch 761/1000\n",
      "302/302 [==============================] - 0s 926us/step - loss: 341.7391 - val_loss: 674.9885\n",
      "Epoch 762/1000\n",
      "302/302 [==============================] - 0s 909us/step - loss: 341.7396 - val_loss: 674.9241\n",
      "Epoch 763/1000\n",
      "302/302 [==============================] - 0s 873us/step - loss: 341.7412 - val_loss: 674.9430\n",
      "Epoch 764/1000\n",
      "302/302 [==============================] - 0s 944us/step - loss: 341.7416 - val_loss: 674.9555\n",
      "Epoch 765/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 674.9368\n",
      "Epoch 766/1000\n",
      "302/302 [==============================] - 0s 990us/step - loss: 341.7412 - val_loss: 674.9866\n",
      "Epoch 767/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 341.7394 - val_loss: 674.9775\n",
      "Epoch 768/1000\n",
      "302/302 [==============================] - 0s 886us/step - loss: 341.7395 - val_loss: 674.9828\n",
      "Epoch 769/1000\n",
      "302/302 [==============================] - 0s 927us/step - loss: 341.7399 - val_loss: 674.9970\n",
      "Epoch 770/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7400 - val_loss: 674.9930\n",
      "Epoch 771/1000\n",
      "302/302 [==============================] - 0s 948us/step - loss: 341.7394 - val_loss: 675.0082\n",
      "Epoch 772/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 341.7401 - val_loss: 674.9543\n",
      "Epoch 773/1000\n",
      "302/302 [==============================] - 0s 959us/step - loss: 341.7393 - val_loss: 675.0225\n",
      "Epoch 774/1000\n",
      "302/302 [==============================] - 0s 999us/step - loss: 341.7400 - val_loss: 675.0187\n",
      "Epoch 775/1000\n",
      "302/302 [==============================] - 0s 947us/step - loss: 341.7410 - val_loss: 674.9838\n",
      "Epoch 776/1000\n",
      "302/302 [==============================] - 0s 971us/step - loss: 341.7405 - val_loss: 675.0543\n",
      "Epoch 777/1000\n",
      "302/302 [==============================] - 0s 965us/step - loss: 341.7401 - val_loss: 675.0347\n",
      "Epoch 778/1000\n",
      "302/302 [==============================] - 0s 971us/step - loss: 341.7396 - val_loss: 674.9731\n",
      "Epoch 779/1000\n",
      "302/302 [==============================] - 0s 991us/step - loss: 341.7402 - val_loss: 674.9677\n",
      "Epoch 780/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 341.7407 - val_loss: 675.0416\n",
      "Epoch 781/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 341.7401 - val_loss: 675.0181\n",
      "Epoch 782/1000\n",
      "302/302 [==============================] - 0s 872us/step - loss: 341.7405 - val_loss: 675.0108\n",
      "Epoch 783/1000\n",
      "302/302 [==============================] - 0s 839us/step - loss: 341.7422 - val_loss: 674.9955\n",
      "Epoch 784/1000\n",
      "302/302 [==============================] - 0s 901us/step - loss: 341.7413 - val_loss: 675.0055\n",
      "Epoch 785/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7405 - val_loss: 674.9810\n",
      "Epoch 786/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9779\n",
      "Epoch 787/1000\n",
      "302/302 [==============================] - 0s 922us/step - loss: 341.7403 - val_loss: 675.0220\n",
      "Epoch 788/1000\n",
      "302/302 [==============================] - 0s 889us/step - loss: 341.7403 - val_loss: 674.9662\n",
      "Epoch 789/1000\n",
      "302/302 [==============================] - 0s 907us/step - loss: 341.7408 - val_loss: 674.9536\n",
      "Epoch 790/1000\n",
      "302/302 [==============================] - 0s 936us/step - loss: 341.7405 - val_loss: 675.0697\n",
      "Epoch 791/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7406 - val_loss: 675.0168\n",
      "Epoch 792/1000\n",
      "302/302 [==============================] - 0s 987us/step - loss: 341.7401 - val_loss: 675.0279\n",
      "Epoch 793/1000\n",
      "302/302 [==============================] - 0s 881us/step - loss: 341.7402 - val_loss: 674.9807\n",
      "Epoch 794/1000\n",
      "302/302 [==============================] - 0s 879us/step - loss: 341.7409 - val_loss: 674.9930\n",
      "Epoch 795/1000\n",
      "302/302 [==============================] - 0s 846us/step - loss: 341.7393 - val_loss: 674.9988\n",
      "Epoch 796/1000\n",
      "302/302 [==============================] - 0s 925us/step - loss: 341.7417 - val_loss: 674.9944\n",
      "Epoch 797/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 341.7415 - val_loss: 674.9996\n",
      "Epoch 798/1000\n",
      "302/302 [==============================] - 0s 866us/step - loss: 341.7402 - val_loss: 674.9913\n",
      "Epoch 799/1000\n",
      "302/302 [==============================] - 0s 859us/step - loss: 341.7413 - val_loss: 675.0081\n",
      "Epoch 800/1000\n",
      "302/302 [==============================] - 0s 924us/step - loss: 341.7400 - val_loss: 674.9748\n",
      "Epoch 801/1000\n",
      "302/302 [==============================] - 0s 871us/step - loss: 341.7402 - val_loss: 674.9985\n",
      "Epoch 802/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7405 - val_loss: 675.0118\n",
      "Epoch 803/1000\n",
      "302/302 [==============================] - 0s 953us/step - loss: 341.7397 - val_loss: 674.9651\n",
      "Epoch 804/1000\n",
      "302/302 [==============================] - 0s 867us/step - loss: 341.7399 - val_loss: 674.9783\n",
      "Epoch 805/1000\n",
      "302/302 [==============================] - 0s 881us/step - loss: 341.7407 - val_loss: 675.0121\n",
      "Epoch 806/1000\n",
      "302/302 [==============================] - 0s 921us/step - loss: 341.7397 - val_loss: 675.0120\n",
      "Epoch 807/1000\n",
      "302/302 [==============================] - 0s 842us/step - loss: 341.7401 - val_loss: 674.9775\n",
      "Epoch 808/1000\n",
      "302/302 [==============================] - 0s 906us/step - loss: 341.7399 - val_loss: 674.9816\n",
      "Epoch 809/1000\n",
      "302/302 [==============================] - 0s 874us/step - loss: 341.7412 - val_loss: 675.0712\n",
      "Epoch 810/1000\n",
      "302/302 [==============================] - 0s 902us/step - loss: 341.7405 - val_loss: 675.0119\n",
      "Epoch 811/1000\n",
      "302/302 [==============================] - 0s 863us/step - loss: 341.7400 - val_loss: 675.0383\n",
      "Epoch 812/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7403 - val_loss: 675.0529\n",
      "Epoch 813/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 341.7403 - val_loss: 675.0029\n",
      "Epoch 814/1000\n",
      "302/302 [==============================] - 0s 857us/step - loss: 341.7414 - val_loss: 675.0567\n",
      "Epoch 815/1000\n",
      "302/302 [==============================] - 0s 940us/step - loss: 341.7410 - val_loss: 675.0085\n",
      "Epoch 816/1000\n",
      "302/302 [==============================] - 0s 935us/step - loss: 341.7411 - val_loss: 675.0955\n",
      "Epoch 817/1000\n",
      "302/302 [==============================] - 0s 896us/step - loss: 341.7421 - val_loss: 674.9933\n",
      "Epoch 818/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7409 - val_loss: 675.0366\n",
      "Epoch 819/1000\n",
      "302/302 [==============================] - 0s 928us/step - loss: 341.7421 - val_loss: 674.9882\n",
      "Epoch 820/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 341.7400 - val_loss: 675.0782\n",
      "Epoch 821/1000\n",
      "302/302 [==============================] - 0s 844us/step - loss: 341.7400 - val_loss: 675.0394\n",
      "Epoch 822/1000\n",
      "302/302 [==============================] - 0s 975us/step - loss: 341.7401 - val_loss: 675.0477\n",
      "Epoch 823/1000\n",
      "302/302 [==============================] - 0s 939us/step - loss: 341.7394 - val_loss: 675.0042\n",
      "Epoch 824/1000\n",
      "302/302 [==============================] - 0s 896us/step - loss: 341.7397 - val_loss: 675.0096\n",
      "Epoch 825/1000\n",
      "302/302 [==============================] - 0s 907us/step - loss: 341.7412 - val_loss: 674.9869\n",
      "Epoch 826/1000\n",
      "302/302 [==============================] - 0s 886us/step - loss: 341.7404 - val_loss: 675.0170\n",
      "Epoch 827/1000\n",
      "302/302 [==============================] - 0s 900us/step - loss: 341.7417 - val_loss: 674.9956\n",
      "Epoch 828/1000\n",
      "302/302 [==============================] - 0s 930us/step - loss: 341.7392 - val_loss: 674.9758\n",
      "Epoch 829/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 341.7398 - val_loss: 675.0332\n",
      "Epoch 830/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7400 - val_loss: 674.9998\n",
      "Epoch 831/1000\n",
      "302/302 [==============================] - 0s 847us/step - loss: 341.7391 - val_loss: 675.0346\n",
      "Epoch 832/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7394 - val_loss: 674.9717\n",
      "Epoch 833/1000\n",
      "302/302 [==============================] - 0s 893us/step - loss: 341.7403 - val_loss: 674.9597\n",
      "Epoch 834/1000\n",
      "302/302 [==============================] - 0s 944us/step - loss: 341.7411 - val_loss: 675.0297\n",
      "Epoch 835/1000\n",
      "302/302 [==============================] - 0s 969us/step - loss: 341.7413 - val_loss: 674.9680\n",
      "Epoch 836/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 341.7411 - val_loss: 674.9775\n",
      "Epoch 837/1000\n",
      "302/302 [==============================] - 0s 887us/step - loss: 341.7409 - val_loss: 675.0190\n",
      "Epoch 838/1000\n",
      "302/302 [==============================] - 0s 979us/step - loss: 341.7396 - val_loss: 674.9819\n",
      "Epoch 839/1000\n",
      "302/302 [==============================] - 0s 931us/step - loss: 341.7395 - val_loss: 674.9969\n",
      "Epoch 840/1000\n",
      "302/302 [==============================] - 0s 977us/step - loss: 341.7403 - val_loss: 674.9617\n",
      "Epoch 841/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7403 - val_loss: 674.9716\n",
      "Epoch 842/1000\n",
      "302/302 [==============================] - 0s 913us/step - loss: 341.7411 - val_loss: 674.9739\n",
      "Epoch 843/1000\n",
      "302/302 [==============================] - 0s 889us/step - loss: 341.7393 - val_loss: 674.9529\n",
      "Epoch 844/1000\n",
      "302/302 [==============================] - 0s 927us/step - loss: 341.7401 - val_loss: 675.0092\n",
      "Epoch 845/1000\n",
      "302/302 [==============================] - 0s 917us/step - loss: 341.7398 - val_loss: 674.9945\n",
      "Epoch 846/1000\n",
      "302/302 [==============================] - 0s 894us/step - loss: 341.7419 - val_loss: 674.9839\n",
      "Epoch 847/1000\n",
      "302/302 [==============================] - 0s 867us/step - loss: 341.7411 - val_loss: 674.9933\n",
      "Epoch 848/1000\n",
      "302/302 [==============================] - 0s 937us/step - loss: 341.7398 - val_loss: 674.9985\n",
      "Epoch 849/1000\n",
      "302/302 [==============================] - 0s 957us/step - loss: 341.7396 - val_loss: 674.9847\n",
      "Epoch 850/1000\n",
      "302/302 [==============================] - 0s 926us/step - loss: 341.7403 - val_loss: 675.0612\n",
      "Epoch 851/1000\n",
      "302/302 [==============================] - 0s 986us/step - loss: 341.7418 - val_loss: 675.0414\n",
      "Epoch 852/1000\n",
      "302/302 [==============================] - 0s 972us/step - loss: 341.7405 - val_loss: 675.0049\n",
      "Epoch 853/1000\n",
      "302/302 [==============================] - 0s 904us/step - loss: 341.7393 - val_loss: 675.0283\n",
      "Epoch 854/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7420 - val_loss: 675.0057\n",
      "Epoch 855/1000\n",
      "302/302 [==============================] - 0s 1000us/step - loss: 341.7393 - val_loss: 674.9673\n",
      "Epoch 856/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7404 - val_loss: 675.0554\n",
      "Epoch 857/1000\n",
      "302/302 [==============================] - 0s 862us/step - loss: 341.7408 - val_loss: 674.9281\n",
      "Epoch 858/1000\n",
      "302/302 [==============================] - 0s 912us/step - loss: 341.7407 - val_loss: 674.9261\n",
      "Epoch 859/1000\n",
      "302/302 [==============================] - 0s 915us/step - loss: 341.7411 - val_loss: 674.9449\n",
      "Epoch 860/1000\n",
      "302/302 [==============================] - 0s 878us/step - loss: 341.7395 - val_loss: 675.0483\n",
      "Epoch 861/1000\n",
      "302/302 [==============================] - 0s 889us/step - loss: 341.7401 - val_loss: 675.0092\n",
      "Epoch 862/1000\n",
      "302/302 [==============================] - 0s 894us/step - loss: 341.7405 - val_loss: 674.9584\n",
      "Epoch 863/1000\n",
      "302/302 [==============================] - 0s 883us/step - loss: 341.7429 - val_loss: 675.0166\n",
      "Epoch 864/1000\n",
      "302/302 [==============================] - 0s 908us/step - loss: 341.7407 - val_loss: 675.0057\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s 896us/step - loss: 341.7407 - val_loss: 675.0195\n",
      "Epoch 866/1000\n",
      "302/302 [==============================] - 0s 988us/step - loss: 341.7408 - val_loss: 674.9819\n",
      "Epoch 867/1000\n",
      "302/302 [==============================] - 0s 931us/step - loss: 341.7398 - val_loss: 675.0898\n",
      "Epoch 868/1000\n",
      "302/302 [==============================] - 0s 951us/step - loss: 341.7400 - val_loss: 674.9997\n",
      "Epoch 869/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 674.9960\n",
      "Epoch 870/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 675.0129\n",
      "Epoch 871/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7397 - val_loss: 674.9835\n",
      "Epoch 872/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7399 - val_loss: 675.0146\n",
      "Epoch 873/1000\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 341.7403 - val_loss: 674.9784\n",
      "Epoch 874/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 675.0378\n",
      "Epoch 875/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7414 - val_loss: 675.0673\n",
      "Epoch 876/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7388 - val_loss: 675.0146\n",
      "Epoch 877/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7411 - val_loss: 674.9998\n",
      "Epoch 878/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7398 - val_loss: 675.0402\n",
      "Epoch 879/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7397 - val_loss: 675.0325\n",
      "Epoch 880/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7407 - val_loss: 675.0542\n",
      "Epoch 881/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7410 - val_loss: 675.0070\n",
      "Epoch 882/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7409 - val_loss: 674.9628\n",
      "Epoch 883/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7422 - val_loss: 675.0001\n",
      "Epoch 884/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7393 - val_loss: 674.9996\n",
      "Epoch 885/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7401 - val_loss: 675.0172\n",
      "Epoch 886/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 675.0231\n",
      "Epoch 887/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7407 - val_loss: 674.9899\n",
      "Epoch 888/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 674.8962\n",
      "Epoch 889/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 674.9836\n",
      "Epoch 890/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7413 - val_loss: 675.0291\n",
      "Epoch 891/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7393 - val_loss: 675.0035\n",
      "Epoch 892/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7396 - val_loss: 674.9235\n",
      "Epoch 893/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7393 - val_loss: 674.9356\n",
      "Epoch 894/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7399 - val_loss: 674.8872\n",
      "Epoch 895/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7401 - val_loss: 674.9471\n",
      "Epoch 896/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9543\n",
      "Epoch 897/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 675.0159\n",
      "Epoch 898/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7400 - val_loss: 674.9820\n",
      "Epoch 899/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7408 - val_loss: 674.9258\n",
      "Epoch 900/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 674.9342\n",
      "Epoch 901/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7413 - val_loss: 674.9340\n",
      "Epoch 902/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9570\n",
      "Epoch 903/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9453\n",
      "Epoch 904/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 674.9894\n",
      "Epoch 905/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7395 - val_loss: 674.9927\n",
      "Epoch 906/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7417 - val_loss: 674.9739\n",
      "Epoch 907/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7395 - val_loss: 675.0481\n",
      "Epoch 908/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7403 - val_loss: 675.0156\n",
      "Epoch 909/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 675.0281\n",
      "Epoch 910/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7412 - val_loss: 674.9960\n",
      "Epoch 911/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7417 - val_loss: 674.9827\n",
      "Epoch 912/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7438 - val_loss: 674.9822\n",
      "Epoch 913/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7399 - val_loss: 675.0515\n",
      "Epoch 914/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9786\n",
      "Epoch 915/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7403 - val_loss: 674.9700\n",
      "Epoch 916/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7402 - val_loss: 674.9825\n",
      "Epoch 917/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7420 - val_loss: 674.9714\n",
      "Epoch 918/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7410 - val_loss: 674.9889\n",
      "Epoch 919/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9542\n",
      "Epoch 920/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7402 - val_loss: 674.9156\n",
      "Epoch 921/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7407 - val_loss: 674.9925\n",
      "Epoch 922/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9228\n",
      "Epoch 923/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9506\n",
      "Epoch 924/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 674.9105\n",
      "Epoch 925/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9124\n",
      "Epoch 926/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7397 - val_loss: 674.8957\n",
      "Epoch 927/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7409 - val_loss: 674.9440\n",
      "Epoch 928/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7397 - val_loss: 674.9466\n",
      "Epoch 929/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7415 - val_loss: 674.9252\n",
      "Epoch 930/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7412 - val_loss: 674.9801\n",
      "Epoch 931/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7418 - val_loss: 674.9500\n",
      "Epoch 932/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9591\n",
      "Epoch 933/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7402 - val_loss: 674.9960\n",
      "Epoch 934/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7396 - val_loss: 674.9520\n",
      "Epoch 935/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7398 - val_loss: 674.9395\n",
      "Epoch 936/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7400 - val_loss: 674.9114\n",
      "Epoch 937/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.8978\n",
      "Epoch 938/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7402 - val_loss: 674.9814\n",
      "Epoch 939/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7394 - val_loss: 674.9944\n",
      "Epoch 940/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7409 - val_loss: 674.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 941/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9807\n",
      "Epoch 942/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7403 - val_loss: 674.9454\n",
      "Epoch 943/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7403 - val_loss: 674.9802\n",
      "Epoch 944/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7408 - val_loss: 674.9549\n",
      "Epoch 945/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9987\n",
      "Epoch 946/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7410 - val_loss: 674.9877\n",
      "Epoch 947/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9902\n",
      "Epoch 948/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7411 - val_loss: 674.9695\n",
      "Epoch 949/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7392 - val_loss: 674.9700\n",
      "Epoch 950/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7394 - val_loss: 674.9724\n",
      "Epoch 951/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9749\n",
      "Epoch 952/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7408 - val_loss: 674.9399\n",
      "Epoch 953/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9799\n",
      "Epoch 954/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9993\n",
      "Epoch 955/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7411 - val_loss: 674.9677\n",
      "Epoch 956/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7397 - val_loss: 675.0259\n",
      "Epoch 957/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7396 - val_loss: 674.9661\n",
      "Epoch 958/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9714\n",
      "Epoch 959/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7396 - val_loss: 674.9741\n",
      "Epoch 960/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7406 - val_loss: 674.9553\n",
      "Epoch 961/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7406 - val_loss: 675.0341\n",
      "Epoch 962/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9053\n",
      "Epoch 963/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7401 - val_loss: 674.9539\n",
      "Epoch 964/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7393 - val_loss: 674.9464\n",
      "Epoch 965/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7404 - val_loss: 674.9438\n",
      "Epoch 966/1000\n",
      "302/302 [==============================] - 1s 2ms/step - loss: 341.7401 - val_loss: 675.0334\n",
      "Epoch 967/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7403 - val_loss: 675.0402\n",
      "Epoch 968/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7405 - val_loss: 674.9705\n",
      "Epoch 969/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7404 - val_loss: 674.9554\n",
      "Epoch 970/1000\n",
      "302/302 [==============================] - 1s 3ms/step - loss: 341.7411 - val_loss: 674.9492\n",
      "Epoch 971/1000\n",
      "302/302 [==============================] - 0s 2ms/step - loss: 341.7414 - val_loss: 674.9882\n",
      "Epoch 972/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7429 - val_loss: 674.9234\n",
      "Epoch 973/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7413 - val_loss: 675.0229\n",
      "Epoch 974/1000\n",
      "302/302 [==============================] - 0s 966us/step - loss: 341.7407 - val_loss: 674.9858\n",
      "Epoch 975/1000\n",
      "302/302 [==============================] - 0s 974us/step - loss: 341.7404 - val_loss: 674.9985\n",
      "Epoch 976/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7391 - val_loss: 675.0289\n",
      "Epoch 977/1000\n",
      "302/302 [==============================] - 0s 961us/step - loss: 341.7397 - val_loss: 675.0516\n",
      "Epoch 978/1000\n",
      "302/302 [==============================] - 0s 973us/step - loss: 341.7409 - val_loss: 674.9810\n",
      "Epoch 979/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7405 - val_loss: 675.0224\n",
      "Epoch 980/1000\n",
      "302/302 [==============================] - 0s 822us/step - loss: 341.7403 - val_loss: 675.0116\n",
      "Epoch 981/1000\n",
      "302/302 [==============================] - 0s 955us/step - loss: 341.7403 - val_loss: 675.0138\n",
      "Epoch 982/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7408 - val_loss: 674.9989\n",
      "Epoch 983/1000\n",
      "302/302 [==============================] - 0s 916us/step - loss: 341.7390 - val_loss: 675.0238\n",
      "Epoch 984/1000\n",
      "302/302 [==============================] - 0s 921us/step - loss: 341.7402 - val_loss: 674.9596\n",
      "Epoch 985/1000\n",
      "302/302 [==============================] - 0s 946us/step - loss: 341.7433 - val_loss: 674.9947\n",
      "Epoch 986/1000\n",
      "302/302 [==============================] - 0s 977us/step - loss: 341.7395 - val_loss: 674.9846\n",
      "Epoch 987/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7396 - val_loss: 674.9877\n",
      "Epoch 988/1000\n",
      "302/302 [==============================] - 0s 983us/step - loss: 341.7401 - val_loss: 674.9702\n",
      "Epoch 989/1000\n",
      "302/302 [==============================] - 0s 958us/step - loss: 341.7404 - val_loss: 674.9983\n",
      "Epoch 990/1000\n",
      "302/302 [==============================] - 0s 982us/step - loss: 341.7398 - val_loss: 674.9889\n",
      "Epoch 991/1000\n",
      "302/302 [==============================] - 0s 945us/step - loss: 341.7401 - val_loss: 674.9938\n",
      "Epoch 992/1000\n",
      "302/302 [==============================] - 0s 996us/step - loss: 341.7401 - val_loss: 674.9636\n",
      "Epoch 993/1000\n",
      "302/302 [==============================] - 0s 1000us/step - loss: 341.7402 - val_loss: 674.9910\n",
      "Epoch 994/1000\n",
      "302/302 [==============================] - 0s 1ms/step - loss: 341.7401 - val_loss: 675.0606\n",
      "Epoch 995/1000\n",
      "302/302 [==============================] - 0s 994us/step - loss: 341.7415 - val_loss: 674.9966\n",
      "Epoch 996/1000\n",
      "302/302 [==============================] - 0s 834us/step - loss: 341.7400 - val_loss: 675.0055\n",
      "Epoch 997/1000\n",
      "302/302 [==============================] - 0s 949us/step - loss: 341.7410 - val_loss: 675.0687\n",
      "Epoch 998/1000\n",
      "302/302 [==============================] - 0s 967us/step - loss: 341.7402 - val_loss: 675.0338\n",
      "Epoch 999/1000\n",
      "302/302 [==============================] - 0s 918us/step - loss: 341.7398 - val_loss: 675.0262\n",
      "Epoch 1000/1000\n",
      "302/302 [==============================] - 0s 907us/step - loss: 341.7397 - val_loss: 675.0486\n",
      "50/50 [==============================] - 0s 475us/step\n",
      "1014697 successful\n",
      "Epoch 1/1000\n",
      "308/308 [==============================] - 1s 1ms/step - loss: 649978.5625 - val_loss: 1036.9358\n",
      "Epoch 2/1000\n",
      "308/308 [==============================] - 0s 955us/step - loss: 655.8464 - val_loss: 645.7344\n",
      "Epoch 3/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 778.3404 - val_loss: 1210.3651\n",
      "Epoch 4/1000\n",
      "308/308 [==============================] - 0s 976us/step - loss: 1055.6810 - val_loss: 2217.4739\n",
      "Epoch 5/1000\n",
      "308/308 [==============================] - 0s 892us/step - loss: 21623.5801 - val_loss: 15299.8184\n",
      "Epoch 6/1000\n",
      "308/308 [==============================] - 0s 873us/step - loss: 54832.8828 - val_loss: 7596.8555\n",
      "Epoch 7/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 51881.9922 - val_loss: 3688.7329\n",
      "Epoch 8/1000\n",
      "308/308 [==============================] - 0s 940us/step - loss: 53463.8203 - val_loss: 100153.8672\n",
      "Epoch 9/1000\n",
      "308/308 [==============================] - 0s 953us/step - loss: 55763.3164 - val_loss: 157674.4531\n",
      "Epoch 10/1000\n",
      "308/308 [==============================] - 0s 903us/step - loss: 44113.5195 - val_loss: 12923.2402\n",
      "Epoch 11/1000\n",
      "308/308 [==============================] - 0s 840us/step - loss: 44449.7227 - val_loss: 5529.9292\n",
      "Epoch 12/1000\n",
      "308/308 [==============================] - 0s 946us/step - loss: 46997.0273 - val_loss: 90895.4766\n",
      "Epoch 13/1000\n",
      "308/308 [==============================] - 0s 897us/step - loss: 44027.7930 - val_loss: 3965.7446\n",
      "Epoch 14/1000\n",
      "308/308 [==============================] - 0s 931us/step - loss: 42125.4219 - val_loss: 32461.9473\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 946us/step - loss: 56404.7422 - val_loss: 28837.7266\n",
      "Epoch 16/1000\n",
      "308/308 [==============================] - 0s 981us/step - loss: 30937.6934 - val_loss: 40691.5430\n",
      "Epoch 17/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 39550.6328 - val_loss: 8810.3535\n",
      "Epoch 18/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 35487.3555 - val_loss: 3213.9392\n",
      "Epoch 19/1000\n",
      "308/308 [==============================] - 0s 841us/step - loss: 33154.7148 - val_loss: 1153.0387\n",
      "Epoch 20/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 41174.3125 - val_loss: 33134.3516\n",
      "Epoch 21/1000\n",
      "308/308 [==============================] - 0s 968us/step - loss: 32486.6953 - val_loss: 608.4377\n",
      "Epoch 22/1000\n",
      "308/308 [==============================] - 0s 843us/step - loss: 38792.8164 - val_loss: 17435.9004\n",
      "Epoch 23/1000\n",
      "308/308 [==============================] - 0s 843us/step - loss: 2352865.0000 - val_loss: 686.6620\n",
      "Epoch 24/1000\n",
      "308/308 [==============================] - 0s 982us/step - loss: 439.0532 - val_loss: 628.5326\n",
      "Epoch 25/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 449.9188 - val_loss: 785.1375\n",
      "Epoch 26/1000\n",
      "308/308 [==============================] - 0s 949us/step - loss: 458.9730 - val_loss: 996.8371\n",
      "Epoch 27/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 443.1615 - val_loss: 1308.1935\n",
      "Epoch 28/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 472.7801 - val_loss: 635.9392\n",
      "Epoch 29/1000\n",
      "308/308 [==============================] - 0s 839us/step - loss: 534.2890 - val_loss: 743.1175\n",
      "Epoch 30/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 517.5455 - val_loss: 628.2613\n",
      "Epoch 31/1000\n",
      "308/308 [==============================] - 0s 977us/step - loss: 665.9529 - val_loss: 723.3432\n",
      "Epoch 32/1000\n",
      "308/308 [==============================] - 0s 849us/step - loss: 628.8541 - val_loss: 2025.4395\n",
      "Epoch 33/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 935.2996 - val_loss: 1111.5063\n",
      "Epoch 34/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 943.2170 - val_loss: 1867.9471\n",
      "Epoch 35/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 3683.5830 - val_loss: 2347.8506\n",
      "Epoch 36/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 11685.7949 - val_loss: 1023.8840\n",
      "Epoch 37/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 18488.8848 - val_loss: 2821.2483\n",
      "Epoch 38/1000\n",
      "308/308 [==============================] - 0s 941us/step - loss: 15828.1465 - val_loss: 8304.9346\n",
      "Epoch 39/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 16149.6553 - val_loss: 77207.8359\n",
      "Epoch 40/1000\n",
      "308/308 [==============================] - 0s 856us/step - loss: 16186.5264 - val_loss: 13046.6016\n",
      "Epoch 41/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 16921.8965 - val_loss: 7607.0400\n",
      "Epoch 42/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 15628.1045 - val_loss: 62916.8984\n",
      "Epoch 43/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 14516.8750 - val_loss: 15302.1982\n",
      "Epoch 44/1000\n",
      "308/308 [==============================] - 0s 861us/step - loss: 14607.9434 - val_loss: 20995.5078\n",
      "Epoch 45/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 12096.3262 - val_loss: 7134.9121\n",
      "Epoch 46/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 14229.2939 - val_loss: 698.7062\n",
      "Epoch 47/1000\n",
      "308/308 [==============================] - 0s 835us/step - loss: 14760.7773 - val_loss: 47095.6602\n",
      "Epoch 48/1000\n",
      "308/308 [==============================] - 0s 818us/step - loss: 11781.1855 - val_loss: 1214.1558\n",
      "Epoch 49/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 13433.3994 - val_loss: 659.8860\n",
      "Epoch 50/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 13686.5693 - val_loss: 1431.1013\n",
      "Epoch 51/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 12828.8066 - val_loss: 2604.8447\n",
      "Epoch 52/1000\n",
      "308/308 [==============================] - 0s 907us/step - loss: 11418.0488 - val_loss: 15357.2646\n",
      "Epoch 53/1000\n",
      "308/308 [==============================] - 0s 817us/step - loss: 10126.8242 - val_loss: 16632.5508\n",
      "Epoch 54/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 12912.3281 - val_loss: 712.9030\n",
      "Epoch 55/1000\n",
      "308/308 [==============================] - 0s 864us/step - loss: 11170.8809 - val_loss: 1042.3783\n",
      "Epoch 56/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 13075.6143 - val_loss: 755.8066\n",
      "Epoch 57/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 9952.0996 - val_loss: 9262.8057\n",
      "Epoch 58/1000\n",
      "308/308 [==============================] - 0s 837us/step - loss: 11281.8467 - val_loss: 18185.7266\n",
      "Epoch 59/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 10740.7676 - val_loss: 1056.7914\n",
      "Epoch 60/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 10880.8281 - val_loss: 10122.8047\n",
      "Epoch 61/1000\n",
      "308/308 [==============================] - 0s 944us/step - loss: 9031.4473 - val_loss: 23657.6094\n",
      "Epoch 62/1000\n",
      "308/308 [==============================] - 0s 945us/step - loss: 9987.0186 - val_loss: 1182.4968\n",
      "Epoch 63/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 895128.1250 - val_loss: 679.0684\n",
      "Epoch 64/1000\n",
      "308/308 [==============================] - 0s 897us/step - loss: 412.6048 - val_loss: 628.4509\n",
      "Epoch 65/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 474.2574 - val_loss: 720.0009\n",
      "Epoch 66/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 451.4618 - val_loss: 611.1515\n",
      "Epoch 67/1000\n",
      "308/308 [==============================] - 0s 890us/step - loss: 462.7640 - val_loss: 911.6779\n",
      "Epoch 68/1000\n",
      "308/308 [==============================] - 0s 846us/step - loss: 532.6002 - val_loss: 613.3378\n",
      "Epoch 69/1000\n",
      "308/308 [==============================] - 0s 847us/step - loss: 545.7051 - val_loss: 928.5342\n",
      "Epoch 70/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 510.3193 - val_loss: 928.2132\n",
      "Epoch 71/1000\n",
      "308/308 [==============================] - 0s 865us/step - loss: 674.9479 - val_loss: 605.7847\n",
      "Epoch 72/1000\n",
      "308/308 [==============================] - 0s 970us/step - loss: 656.6193 - val_loss: 730.4720\n",
      "Epoch 73/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 813.1751 - val_loss: 904.4444\n",
      "Epoch 74/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 1351.1168 - val_loss: 621.7832\n",
      "Epoch 75/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 1348.5659 - val_loss: 1013.2495\n",
      "Epoch 76/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 6029.1084 - val_loss: 604.4085\n",
      "Epoch 77/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 5702.2119 - val_loss: 10845.4111\n",
      "Epoch 78/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 7495.9893 - val_loss: 6936.5859\n",
      "Epoch 79/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 5237.6812 - val_loss: 2536.4683\n",
      "Epoch 80/1000\n",
      "308/308 [==============================] - 0s 955us/step - loss: 6687.4722 - val_loss: 969.3508\n",
      "Epoch 81/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 6386.2559 - val_loss: 10467.8135\n",
      "Epoch 82/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 6447.2446 - val_loss: 28398.5078\n",
      "Epoch 83/1000\n",
      "308/308 [==============================] - 0s 942us/step - loss: 5794.1665 - val_loss: 1202.7656\n",
      "Epoch 84/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 5388.5850 - val_loss: 604.3884\n",
      "Epoch 85/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 4868.1182 - val_loss: 7952.4009\n",
      "Epoch 86/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 5929.2607 - val_loss: 789.9273\n",
      "Epoch 87/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 5093.4985 - val_loss: 1434.4700\n",
      "Epoch 88/1000\n",
      "308/308 [==============================] - 0s 871us/step - loss: 5115.0889 - val_loss: 15023.1514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/1000\n",
      "308/308 [==============================] - 0s 892us/step - loss: 5625.9429 - val_loss: 2905.2300\n",
      "Epoch 90/1000\n",
      "308/308 [==============================] - 0s 902us/step - loss: 6017.1958 - val_loss: 604.6592\n",
      "Epoch 91/1000\n",
      "308/308 [==============================] - 0s 954us/step - loss: 3652.3489 - val_loss: 4612.9004\n",
      "Epoch 92/1000\n",
      "308/308 [==============================] - 0s 967us/step - loss: 4157.8218 - val_loss: 8455.3604\n",
      "Epoch 93/1000\n",
      "308/308 [==============================] - 0s 883us/step - loss: 5177.1606 - val_loss: 984.9551\n",
      "Epoch 94/1000\n",
      "308/308 [==============================] - 0s 867us/step - loss: 4836.0874 - val_loss: 965.3740\n",
      "Epoch 95/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 4584.2310 - val_loss: 947.5366\n",
      "Epoch 96/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 3950.4182 - val_loss: 1535.4160\n",
      "Epoch 97/1000\n",
      "308/308 [==============================] - 0s 942us/step - loss: 5114.0171 - val_loss: 4361.3335\n",
      "Epoch 98/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 4339.3262 - val_loss: 718.2676\n",
      "Epoch 99/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 3802.1975 - val_loss: 6650.7607\n",
      "Epoch 100/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 4899.2837 - val_loss: 778.4590\n",
      "Epoch 101/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 2964.0422 - val_loss: 19651.7559\n",
      "Epoch 102/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 3798.5781 - val_loss: 3523.2053\n",
      "Epoch 103/1000\n",
      "308/308 [==============================] - 0s 939us/step - loss: 4355.5879 - val_loss: 853.1735\n",
      "Epoch 104/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 4247.8496 - val_loss: 1119.4189\n",
      "Epoch 105/1000\n",
      "308/308 [==============================] - 0s 979us/step - loss: 3062.8296 - val_loss: 772.3049\n",
      "Epoch 106/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 3404.9634 - val_loss: 1113.2054\n",
      "Epoch 107/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 4112.8262 - val_loss: 616.7375\n",
      "Epoch 108/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 3469.2651 - val_loss: 1402.3508\n",
      "Epoch 109/1000\n",
      "308/308 [==============================] - 0s 919us/step - loss: 3097.7625 - val_loss: 810.4759\n",
      "Epoch 110/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 3130.7690 - val_loss: 3635.5183\n",
      "Epoch 111/1000\n",
      "308/308 [==============================] - 0s 978us/step - loss: 3773.0508 - val_loss: 5632.7271\n",
      "Epoch 112/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 3527.1021 - val_loss: 640.5759\n",
      "Epoch 113/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 3003.6409 - val_loss: 6326.6719\n",
      "Epoch 114/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 3589.9788 - val_loss: 2182.5090\n",
      "Epoch 115/1000\n",
      "308/308 [==============================] - 0s 966us/step - loss: 3077.8511 - val_loss: 677.1130\n",
      "Epoch 116/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 3262.7913 - val_loss: 636.6133\n",
      "Epoch 117/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 2479.7944 - val_loss: 1008.5809\n",
      "Epoch 118/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 3547.2288 - val_loss: 849.9292\n",
      "Epoch 119/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 2601.5371 - val_loss: 620.4323\n",
      "Epoch 120/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 3050.4158 - val_loss: 5294.0327\n",
      "Epoch 121/1000\n",
      "308/308 [==============================] - 0s 985us/step - loss: 2687.8904 - val_loss: 918.6356\n",
      "Epoch 122/1000\n",
      "308/308 [==============================] - 0s 946us/step - loss: 3025.4924 - val_loss: 2644.9856\n",
      "Epoch 123/1000\n",
      "308/308 [==============================] - 0s 921us/step - loss: 2735.1528 - val_loss: 2558.7021\n",
      "Epoch 124/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 1819.8049 - val_loss: 2064.6768\n",
      "Epoch 125/1000\n",
      "308/308 [==============================] - 0s 961us/step - loss: 2793.3403 - val_loss: 608.7010\n",
      "Epoch 126/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 2768.9951 - val_loss: 17608.3340\n",
      "Epoch 127/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 2122.6729 - val_loss: 1150.1027\n",
      "Epoch 128/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 223384.1094 - val_loss: 869.9398\n",
      "Epoch 129/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 417.5418 - val_loss: 607.0294\n",
      "Epoch 130/1000\n",
      "308/308 [==============================] - 0s 898us/step - loss: 434.4387 - val_loss: 708.5915\n",
      "Epoch 131/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 440.4980 - val_loss: 605.0048\n",
      "Epoch 132/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 442.6288 - val_loss: 631.3013\n",
      "Epoch 133/1000\n",
      "308/308 [==============================] - 0s 948us/step - loss: 492.7846 - val_loss: 605.3469\n",
      "Epoch 134/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 496.7766 - val_loss: 734.3815\n",
      "Epoch 135/1000\n",
      "308/308 [==============================] - 0s 976us/step - loss: 538.6027 - val_loss: 1624.9843\n",
      "Epoch 136/1000\n",
      "308/308 [==============================] - 0s 861us/step - loss: 734.0311 - val_loss: 709.4450\n",
      "Epoch 137/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 574.0132 - val_loss: 729.7942\n",
      "Epoch 138/1000\n",
      "308/308 [==============================] - 0s 914us/step - loss: 737.5569 - val_loss: 625.1440\n",
      "Epoch 139/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 793.4789 - val_loss: 7515.8545\n",
      "Epoch 140/1000\n",
      "308/308 [==============================] - 0s 871us/step - loss: 1105.1135 - val_loss: 703.3163\n",
      "Epoch 141/1000\n",
      "308/308 [==============================] - 0s 902us/step - loss: 952.2550 - val_loss: 708.5806\n",
      "Epoch 142/1000\n",
      "308/308 [==============================] - 0s 906us/step - loss: 1753.0482 - val_loss: 1676.9330\n",
      "Epoch 143/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 1677.2645 - val_loss: 1420.3931\n",
      "Epoch 144/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 1558.5714 - val_loss: 3341.8364\n",
      "Epoch 145/1000\n",
      "308/308 [==============================] - 0s 914us/step - loss: 1660.4261 - val_loss: 17430.9570\n",
      "Epoch 146/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1940.3414 - val_loss: 661.8782\n",
      "Epoch 147/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1112.4100 - val_loss: 4214.1660\n",
      "Epoch 148/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1628.5649 - val_loss: 651.5772\n",
      "Epoch 149/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1406.0111 - val_loss: 974.6302\n",
      "Epoch 150/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1636.2339 - val_loss: 4177.4521\n",
      "Epoch 151/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1452.6289 - val_loss: 7121.7886\n",
      "Epoch 152/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1214.2493 - val_loss: 1269.6671\n",
      "Epoch 153/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 1645.0140 - val_loss: 975.7736\n",
      "Epoch 154/1000\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 1237.7426 - val_loss: 983.4656\n",
      "Epoch 155/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1074.2042 - val_loss: 617.3303\n",
      "Epoch 156/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1140.2551 - val_loss: 606.6882\n",
      "Epoch 157/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1042.0658 - val_loss: 1449.6901\n",
      "Epoch 158/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 1205.4698 - val_loss: 604.6376\n",
      "Epoch 159/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 932.1937 - val_loss: 1108.1763\n",
      "Epoch 160/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 1036.0759 - val_loss: 620.9600\n",
      "Epoch 161/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 1055.1033 - val_loss: 3608.1172\n",
      "Epoch 162/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 941.2295 - val_loss: 604.4510\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 1s 3ms/step - loss: 1014.3054 - val_loss: 642.2847\n",
      "Epoch 164/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 773.8700 - val_loss: 4029.1025\n",
      "Epoch 165/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 818.0311 - val_loss: 1383.5043\n",
      "Epoch 166/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 755.9995 - val_loss: 608.2174\n",
      "Epoch 167/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 827.8535 - val_loss: 2244.0610\n",
      "Epoch 168/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 703.6675 - val_loss: 818.6582\n",
      "Epoch 169/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 626.4495 - val_loss: 635.1669\n",
      "Epoch 170/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 780.1111 - val_loss: 1667.7629\n",
      "Epoch 171/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 535.5732 - val_loss: 1355.8979\n",
      "Epoch 172/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 687.5743 - val_loss: 890.1470\n",
      "Epoch 173/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 609.8471 - val_loss: 790.5563\n",
      "Epoch 174/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 481.8032 - val_loss: 616.3074\n",
      "Epoch 175/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 458.6715 - val_loss: 672.8271\n",
      "Epoch 176/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 480.9867 - val_loss: 943.2640\n",
      "Epoch 177/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 462.7061 - val_loss: 685.5237\n",
      "Epoch 178/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 433.1450 - val_loss: 688.4183\n",
      "Epoch 179/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 408.7296 - val_loss: 679.0992\n",
      "Epoch 180/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.5914 - val_loss: 669.4427\n",
      "Epoch 181/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 393.0366 - val_loss: 628.4251\n",
      "Epoch 182/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.3434 - val_loss: 643.3666\n",
      "Epoch 183/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 396.6788 - val_loss: 707.2410\n",
      "Epoch 184/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 391.9267 - val_loss: 639.0633\n",
      "Epoch 185/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.2396 - val_loss: 627.9684\n",
      "Epoch 186/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.1860 - val_loss: 652.1780\n",
      "Epoch 187/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 396.4176 - val_loss: 604.5690\n",
      "Epoch 188/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.9176 - val_loss: 673.8997\n",
      "Epoch 189/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.2676 - val_loss: 809.5928\n",
      "Epoch 190/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 395.3818 - val_loss: 627.0992\n",
      "Epoch 191/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 395.7607 - val_loss: 646.7567\n",
      "Epoch 192/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 396.7039 - val_loss: 736.7892\n",
      "Epoch 193/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.5956 - val_loss: 664.3818\n",
      "Epoch 194/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 400.4670 - val_loss: 617.0279\n",
      "Epoch 195/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 394.6631 - val_loss: 748.8724\n",
      "Epoch 196/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 398.4645 - val_loss: 614.9403\n",
      "Epoch 197/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 401.5168 - val_loss: 666.3303\n",
      "Epoch 198/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 398.1216 - val_loss: 657.6788\n",
      "Epoch 199/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 410.1325 - val_loss: 608.0609\n",
      "Epoch 200/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 408.1585 - val_loss: 693.7601\n",
      "Epoch 201/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 401.3816 - val_loss: 748.7923\n",
      "Epoch 202/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 403.2649 - val_loss: 628.6121\n",
      "Epoch 203/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 408.6700 - val_loss: 643.1306\n",
      "Epoch 204/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 404.7090 - val_loss: 714.8572\n",
      "Epoch 205/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 577.4419 - val_loss: 663.4313\n",
      "Epoch 206/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 403.4269 - val_loss: 676.2881\n",
      "Epoch 207/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 397.2176 - val_loss: 627.7756\n",
      "Epoch 208/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.9590 - val_loss: 729.8436\n",
      "Epoch 209/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.2847 - val_loss: 654.4701\n",
      "Epoch 210/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.5530 - val_loss: 641.1614\n",
      "Epoch 211/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 404.9722 - val_loss: 618.8962\n",
      "Epoch 212/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 403.2505 - val_loss: 645.3804\n",
      "Epoch 213/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 401.6036 - val_loss: 708.1967\n",
      "Epoch 214/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 405.5475 - val_loss: 609.1147\n",
      "Epoch 215/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 402.2238 - val_loss: 704.4553\n",
      "Epoch 216/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 409.3515 - val_loss: 629.9377\n",
      "Epoch 217/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 404.1661 - val_loss: 607.3821\n",
      "Epoch 218/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.9767 - val_loss: 612.7410\n",
      "Epoch 219/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 396.3903 - val_loss: 679.9630\n",
      "Epoch 220/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 404.3572 - val_loss: 736.5999\n",
      "Epoch 221/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 403.8308 - val_loss: 725.3124\n",
      "Epoch 222/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.4297 - val_loss: 613.3812\n",
      "Epoch 223/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 405.7064 - val_loss: 604.4836\n",
      "Epoch 224/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 402.3832 - val_loss: 732.9480\n",
      "Epoch 225/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 400.5804 - val_loss: 611.5752\n",
      "Epoch 226/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 406.9961 - val_loss: 678.7026\n",
      "Epoch 227/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 407.9660 - val_loss: 610.7953\n",
      "Epoch 228/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 408.8287 - val_loss: 679.7277\n",
      "Epoch 229/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 400.9136 - val_loss: 604.8259\n",
      "Epoch 230/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 414.9931 - val_loss: 622.0115\n",
      "Epoch 231/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 409.9508 - val_loss: 714.0629\n",
      "Epoch 232/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 398.6944 - val_loss: 606.0228\n",
      "Epoch 233/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 400.1774 - val_loss: 738.9425\n",
      "Epoch 234/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 412.7834 - val_loss: 771.1822\n",
      "Epoch 235/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 401.8212 - val_loss: 715.7161\n",
      "Epoch 236/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 399.4796 - val_loss: 646.5739\n",
      "Epoch 237/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 420.3926 - val_loss: 627.2095\n",
      "Epoch 238/1000\n",
      "308/308 [==============================] - 0s 2ms/step - loss: 398.0651 - val_loss: 711.2902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 401.1481 - val_loss: 621.7477\n",
      "Epoch 240/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 24859.2852 - val_loss: 1457.0447\n",
      "Epoch 241/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 895.8212 - val_loss: 1451.6077\n",
      "Epoch 242/1000\n",
      "308/308 [==============================] - 0s 936us/step - loss: 891.3326 - val_loss: 1445.4298\n",
      "Epoch 243/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 886.2418 - val_loss: 1438.4210\n",
      "Epoch 244/1000\n",
      "308/308 [==============================] - 0s 978us/step - loss: 880.5101 - val_loss: 1430.5682\n",
      "Epoch 245/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 874.1097 - val_loss: 1421.8141\n",
      "Epoch 246/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 867.0261 - val_loss: 1412.1667\n",
      "Epoch 247/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 859.2723 - val_loss: 1401.6283\n",
      "Epoch 248/1000\n",
      "308/308 [==============================] - 0s 907us/step - loss: 850.8786 - val_loss: 1390.2706\n",
      "Epoch 249/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 841.9003 - val_loss: 1378.1599\n",
      "Epoch 250/1000\n",
      "308/308 [==============================] - 0s 914us/step - loss: 832.4008 - val_loss: 1365.3885\n",
      "Epoch 251/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 822.4786 - val_loss: 1352.0946\n",
      "Epoch 252/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 812.2153 - val_loss: 1338.4023\n",
      "Epoch 253/1000\n",
      "308/308 [==============================] - 0s 850us/step - loss: 801.6942 - val_loss: 1324.3705\n",
      "Epoch 254/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 791.0193 - val_loss: 1310.1125\n",
      "Epoch 255/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 780.2664 - val_loss: 1295.7734\n",
      "Epoch 256/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 769.4674 - val_loss: 1281.3319\n",
      "Epoch 257/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 758.6909 - val_loss: 1266.8911\n",
      "Epoch 258/1000\n",
      "308/308 [==============================] - 0s 956us/step - loss: 747.9637 - val_loss: 1252.5128\n",
      "Epoch 259/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 737.3132 - val_loss: 1238.1780\n",
      "Epoch 260/1000\n",
      "308/308 [==============================] - 0s 974us/step - loss: 726.7717 - val_loss: 1223.9874\n",
      "Epoch 261/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 716.3562 - val_loss: 1209.8567\n",
      "Epoch 262/1000\n",
      "308/308 [==============================] - 0s 967us/step - loss: 706.0848 - val_loss: 1195.9384\n",
      "Epoch 263/1000\n",
      "308/308 [==============================] - 0s 955us/step - loss: 695.9741 - val_loss: 1182.1548\n",
      "Epoch 264/1000\n",
      "308/308 [==============================] - 0s 833us/step - loss: 686.0300 - val_loss: 1168.5118\n",
      "Epoch 265/1000\n",
      "308/308 [==============================] - 0s 893us/step - loss: 676.2380 - val_loss: 1155.0472\n",
      "Epoch 266/1000\n",
      "308/308 [==============================] - 0s 933us/step - loss: 666.6064 - val_loss: 1141.7567\n",
      "Epoch 267/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 657.1438 - val_loss: 1128.6561\n",
      "Epoch 268/1000\n",
      "308/308 [==============================] - 0s 907us/step - loss: 647.8381 - val_loss: 1115.6526\n",
      "Epoch 269/1000\n",
      "308/308 [==============================] - 0s 859us/step - loss: 638.7029 - val_loss: 1102.8729\n",
      "Epoch 270/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 629.7560 - val_loss: 1090.2655\n",
      "Epoch 271/1000\n",
      "308/308 [==============================] - 0s 835us/step - loss: 620.9805 - val_loss: 1077.8346\n",
      "Epoch 272/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 612.3897 - val_loss: 1065.6399\n",
      "Epoch 273/1000\n",
      "308/308 [==============================] - 0s 819us/step - loss: 603.9571 - val_loss: 1053.5636\n",
      "Epoch 274/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 595.7019 - val_loss: 1041.6593\n",
      "Epoch 275/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 587.6263 - val_loss: 1029.9818\n",
      "Epoch 276/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 579.7280 - val_loss: 1018.4692\n",
      "Epoch 277/1000\n",
      "308/308 [==============================] - 0s 909us/step - loss: 571.9990 - val_loss: 1007.1442\n",
      "Epoch 278/1000\n",
      "308/308 [==============================] - 0s 922us/step - loss: 564.4428 - val_loss: 995.9795\n",
      "Epoch 279/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 557.0575 - val_loss: 984.9968\n",
      "Epoch 280/1000\n",
      "308/308 [==============================] - 0s 947us/step - loss: 549.8466 - val_loss: 974.1979\n",
      "Epoch 281/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 542.8072 - val_loss: 963.6089\n",
      "Epoch 282/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 535.9370 - val_loss: 953.1561\n",
      "Epoch 283/1000\n",
      "308/308 [==============================] - 0s 965us/step - loss: 529.2408 - val_loss: 942.8811\n",
      "Epoch 284/1000\n",
      "308/308 [==============================] - 0s 986us/step - loss: 522.7307 - val_loss: 932.8412\n",
      "Epoch 285/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 516.3904 - val_loss: 922.9973\n",
      "Epoch 286/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 510.2222 - val_loss: 913.3186\n",
      "Epoch 287/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 504.2223 - val_loss: 903.8123\n",
      "Epoch 288/1000\n",
      "308/308 [==============================] - 0s 951us/step - loss: 498.3844 - val_loss: 894.4745\n",
      "Epoch 289/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 492.7235 - val_loss: 885.3232\n",
      "Epoch 290/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 487.2301 - val_loss: 876.3926\n",
      "Epoch 291/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 481.9039 - val_loss: 867.6027\n",
      "Epoch 292/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 476.7469 - val_loss: 858.9982\n",
      "Epoch 293/1000\n",
      "308/308 [==============================] - 0s 948us/step - loss: 471.7471 - val_loss: 850.6102\n",
      "Epoch 294/1000\n",
      "308/308 [==============================] - 0s 817us/step - loss: 466.9121 - val_loss: 842.3671\n",
      "Epoch 295/1000\n",
      "308/308 [==============================] - 0s 978us/step - loss: 462.2527 - val_loss: 834.3599\n",
      "Epoch 296/1000\n",
      "308/308 [==============================] - 0s 876us/step - loss: 457.7704 - val_loss: 826.5166\n",
      "Epoch 297/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 453.4492 - val_loss: 818.8575\n",
      "Epoch 298/1000\n",
      "308/308 [==============================] - 0s 936us/step - loss: 449.2785 - val_loss: 811.4106\n",
      "Epoch 299/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 445.2690 - val_loss: 804.1120\n",
      "Epoch 300/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 441.4194 - val_loss: 797.0051\n",
      "Epoch 301/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 437.7322 - val_loss: 790.0803\n",
      "Epoch 302/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 434.2099 - val_loss: 783.3150\n",
      "Epoch 303/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 430.8349 - val_loss: 776.7902\n",
      "Epoch 304/1000\n",
      "308/308 [==============================] - 0s 861us/step - loss: 427.6086 - val_loss: 770.4188\n",
      "Epoch 305/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 424.5405 - val_loss: 764.2527\n",
      "Epoch 306/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 421.6222 - val_loss: 758.2319\n",
      "Epoch 307/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 418.8456 - val_loss: 752.4064\n",
      "Epoch 308/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 416.2120 - val_loss: 746.7496\n",
      "Epoch 309/1000\n",
      "308/308 [==============================] - 0s 894us/step - loss: 413.7158 - val_loss: 741.2922\n",
      "Epoch 310/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 411.3627 - val_loss: 735.9929\n",
      "Epoch 311/1000\n",
      "308/308 [==============================] - 0s 985us/step - loss: 409.1463 - val_loss: 730.8781\n",
      "Epoch 312/1000\n",
      "308/308 [==============================] - 0s 999us/step - loss: 407.0707 - val_loss: 725.9719\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 955us/step - loss: 405.1264 - val_loss: 721.2705\n",
      "Epoch 314/1000\n",
      "308/308 [==============================] - 0s 987us/step - loss: 403.3050 - val_loss: 716.7036\n",
      "Epoch 315/1000\n",
      "308/308 [==============================] - 0s 935us/step - loss: 401.6209 - val_loss: 712.3529\n",
      "Epoch 316/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 400.0564 - val_loss: 708.1414\n",
      "Epoch 317/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 398.6054 - val_loss: 704.1463\n",
      "Epoch 318/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 397.2650 - val_loss: 700.3107\n",
      "Epoch 319/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 396.0431 - val_loss: 696.6428\n",
      "Epoch 320/1000\n",
      "308/308 [==============================] - 0s 890us/step - loss: 394.9310 - val_loss: 693.2081\n",
      "Epoch 321/1000\n",
      "308/308 [==============================] - 0s 992us/step - loss: 393.9159 - val_loss: 689.9711\n",
      "Epoch 322/1000\n",
      "308/308 [==============================] - 0s 854us/step - loss: 392.9940 - val_loss: 686.8039\n",
      "Epoch 323/1000\n",
      "308/308 [==============================] - 0s 880us/step - loss: 392.1577 - val_loss: 683.8987\n",
      "Epoch 324/1000\n",
      "308/308 [==============================] - 0s 865us/step - loss: 391.4247 - val_loss: 681.1637\n",
      "Epoch 325/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 390.7733 - val_loss: 678.5992\n",
      "Epoch 326/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 390.1875 - val_loss: 676.2068\n",
      "Epoch 327/1000\n",
      "308/308 [==============================] - 0s 845us/step - loss: 389.6662 - val_loss: 673.9935\n",
      "Epoch 328/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 389.2113 - val_loss: 671.9369\n",
      "Epoch 329/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 388.8131 - val_loss: 669.9343\n",
      "Epoch 330/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 388.4654 - val_loss: 668.1761\n",
      "Epoch 331/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 388.1573 - val_loss: 666.4798\n",
      "Epoch 332/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 387.8907 - val_loss: 664.9451\n",
      "Epoch 333/1000\n",
      "308/308 [==============================] - 0s 873us/step - loss: 387.6613 - val_loss: 663.5080\n",
      "Epoch 334/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 387.4617 - val_loss: 662.1606\n",
      "Epoch 335/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 387.2894 - val_loss: 660.9445\n",
      "Epoch 336/1000\n",
      "308/308 [==============================] - 0s 871us/step - loss: 387.1422 - val_loss: 659.8630\n",
      "Epoch 337/1000\n",
      "308/308 [==============================] - 0s 849us/step - loss: 387.0166 - val_loss: 658.7813\n",
      "Epoch 338/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 386.9109 - val_loss: 657.8430\n",
      "Epoch 339/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 386.8214 - val_loss: 656.9910\n",
      "Epoch 340/1000\n",
      "308/308 [==============================] - 0s 849us/step - loss: 386.7435 - val_loss: 656.1689\n",
      "Epoch 341/1000\n",
      "308/308 [==============================] - 0s 962us/step - loss: 386.6776 - val_loss: 655.4274\n",
      "Epoch 342/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.6226 - val_loss: 654.7474\n",
      "Epoch 343/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 386.5765 - val_loss: 654.1378\n",
      "Epoch 344/1000\n",
      "308/308 [==============================] - 0s 903us/step - loss: 386.5388 - val_loss: 653.6242\n",
      "Epoch 345/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 386.5050 - val_loss: 653.0532\n",
      "Epoch 346/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.4792 - val_loss: 652.6379\n",
      "Epoch 347/1000\n",
      "308/308 [==============================] - 0s 828us/step - loss: 386.4562 - val_loss: 652.2339\n",
      "Epoch 348/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 386.4384 - val_loss: 651.8073\n",
      "Epoch 349/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 386.4217 - val_loss: 651.4486\n",
      "Epoch 350/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 386.4093 - val_loss: 651.1729\n",
      "Epoch 351/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 386.3952 - val_loss: 650.8109\n",
      "Epoch 352/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 386.3855 - val_loss: 650.5881\n",
      "Epoch 353/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 386.3793 - val_loss: 650.3046\n",
      "Epoch 354/1000\n",
      "308/308 [==============================] - 0s 954us/step - loss: 386.3730 - val_loss: 650.0585\n",
      "Epoch 355/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 386.3666 - val_loss: 649.8812\n",
      "Epoch 356/1000\n",
      "308/308 [==============================] - 0s 922us/step - loss: 386.3623 - val_loss: 649.6969\n",
      "Epoch 357/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 386.3568 - val_loss: 649.5389\n",
      "Epoch 358/1000\n",
      "308/308 [==============================] - 0s 882us/step - loss: 386.3555 - val_loss: 649.3946\n",
      "Epoch 359/1000\n",
      "308/308 [==============================] - 0s 864us/step - loss: 386.3531 - val_loss: 649.2773\n",
      "Epoch 360/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3487 - val_loss: 649.1235\n",
      "Epoch 361/1000\n",
      "308/308 [==============================] - 0s 882us/step - loss: 386.3482 - val_loss: 649.0038\n",
      "Epoch 362/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 386.3456 - val_loss: 648.9407\n",
      "Epoch 363/1000\n",
      "308/308 [==============================] - 0s 940us/step - loss: 386.3453 - val_loss: 648.7958\n",
      "Epoch 364/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 386.3437 - val_loss: 648.6570\n",
      "Epoch 365/1000\n",
      "308/308 [==============================] - 0s 883us/step - loss: 386.3441 - val_loss: 648.6761\n",
      "Epoch 366/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 386.3420 - val_loss: 648.5907\n",
      "Epoch 367/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 386.3411 - val_loss: 648.5211\n",
      "Epoch 368/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 386.3404 - val_loss: 648.4589\n",
      "Epoch 369/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 386.3405 - val_loss: 648.3760\n",
      "Epoch 370/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 386.3409 - val_loss: 648.3136\n",
      "Epoch 371/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 386.3392 - val_loss: 648.2891\n",
      "Epoch 372/1000\n",
      "308/308 [==============================] - 0s 942us/step - loss: 386.3390 - val_loss: 648.2073\n",
      "Epoch 373/1000\n",
      "308/308 [==============================] - 0s 894us/step - loss: 386.3396 - val_loss: 648.2463\n",
      "Epoch 374/1000\n",
      "308/308 [==============================] - 0s 846us/step - loss: 386.3393 - val_loss: 648.1888\n",
      "Epoch 375/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 386.3382 - val_loss: 648.1371\n",
      "Epoch 376/1000\n",
      "308/308 [==============================] - 0s 874us/step - loss: 386.3398 - val_loss: 648.1446\n",
      "Epoch 377/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 386.3388 - val_loss: 648.1108\n",
      "Epoch 378/1000\n",
      "308/308 [==============================] - 0s 868us/step - loss: 386.3378 - val_loss: 648.0638\n",
      "Epoch 379/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 386.3378 - val_loss: 648.0684\n",
      "Epoch 380/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.3379 - val_loss: 647.9950\n",
      "Epoch 381/1000\n",
      "308/308 [==============================] - 0s 868us/step - loss: 386.3389 - val_loss: 647.9856\n",
      "Epoch 382/1000\n",
      "308/308 [==============================] - 0s 919us/step - loss: 386.3386 - val_loss: 647.9369\n",
      "Epoch 383/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 386.3379 - val_loss: 647.9312\n",
      "Epoch 384/1000\n",
      "308/308 [==============================] - 0s 830us/step - loss: 386.3380 - val_loss: 647.9932\n",
      "Epoch 385/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 386.3383 - val_loss: 647.8427\n",
      "Epoch 386/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 386.3392 - val_loss: 647.8962\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 902us/step - loss: 386.3377 - val_loss: 647.8806\n",
      "Epoch 388/1000\n",
      "308/308 [==============================] - 0s 927us/step - loss: 386.3386 - val_loss: 647.8703\n",
      "Epoch 389/1000\n",
      "308/308 [==============================] - 0s 906us/step - loss: 386.3371 - val_loss: 647.8506\n",
      "Epoch 390/1000\n",
      "308/308 [==============================] - 0s 851us/step - loss: 386.3382 - val_loss: 647.8423\n",
      "Epoch 391/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 386.3382 - val_loss: 647.8008\n",
      "Epoch 392/1000\n",
      "308/308 [==============================] - 0s 887us/step - loss: 386.3367 - val_loss: 647.8260\n",
      "Epoch 393/1000\n",
      "308/308 [==============================] - 0s 938us/step - loss: 386.3377 - val_loss: 647.8298\n",
      "Epoch 394/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3388 - val_loss: 647.8204\n",
      "Epoch 395/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 386.3382 - val_loss: 647.7878\n",
      "Epoch 396/1000\n",
      "308/308 [==============================] - 0s 959us/step - loss: 386.3387 - val_loss: 647.7972\n",
      "Epoch 397/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3383 - val_loss: 647.7845\n",
      "Epoch 398/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3379 - val_loss: 647.7925\n",
      "Epoch 399/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3372 - val_loss: 647.7682\n",
      "Epoch 400/1000\n",
      "308/308 [==============================] - 0s 974us/step - loss: 386.3370 - val_loss: 647.7634\n",
      "Epoch 401/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 386.3382 - val_loss: 647.8132\n",
      "Epoch 402/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 386.3378 - val_loss: 647.8293\n",
      "Epoch 403/1000\n",
      "308/308 [==============================] - 0s 938us/step - loss: 386.3371 - val_loss: 647.7977\n",
      "Epoch 404/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 386.3377 - val_loss: 647.8029\n",
      "Epoch 405/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3379 - val_loss: 647.7794\n",
      "Epoch 406/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 386.3383 - val_loss: 647.7772\n",
      "Epoch 407/1000\n",
      "308/308 [==============================] - 0s 976us/step - loss: 386.3366 - val_loss: 647.8118\n",
      "Epoch 408/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 386.3379 - val_loss: 647.7740\n",
      "Epoch 409/1000\n",
      "308/308 [==============================] - 0s 965us/step - loss: 386.3374 - val_loss: 647.7772\n",
      "Epoch 410/1000\n",
      "308/308 [==============================] - 0s 834us/step - loss: 386.3388 - val_loss: 647.7952\n",
      "Epoch 411/1000\n",
      "308/308 [==============================] - 0s 961us/step - loss: 386.3379 - val_loss: 647.7598\n",
      "Epoch 412/1000\n",
      "308/308 [==============================] - 0s 860us/step - loss: 386.3376 - val_loss: 647.8206\n",
      "Epoch 413/1000\n",
      "308/308 [==============================] - 0s 977us/step - loss: 386.3390 - val_loss: 647.8209\n",
      "Epoch 414/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 386.3375 - val_loss: 647.7884\n",
      "Epoch 415/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3373 - val_loss: 647.7527\n",
      "Epoch 416/1000\n",
      "308/308 [==============================] - 0s 883us/step - loss: 386.3365 - val_loss: 647.7923\n",
      "Epoch 417/1000\n",
      "308/308 [==============================] - 0s 902us/step - loss: 386.3376 - val_loss: 647.7429\n",
      "Epoch 418/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 386.3387 - val_loss: 647.7398\n",
      "Epoch 419/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 386.3377 - val_loss: 647.7749\n",
      "Epoch 420/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 386.3373 - val_loss: 647.7972\n",
      "Epoch 421/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3377 - val_loss: 647.8057\n",
      "Epoch 422/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3373 - val_loss: 647.7945\n",
      "Epoch 423/1000\n",
      "308/308 [==============================] - 0s 954us/step - loss: 386.3376 - val_loss: 647.7966\n",
      "Epoch 424/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 386.3376 - val_loss: 647.8453\n",
      "Epoch 425/1000\n",
      "308/308 [==============================] - 0s 984us/step - loss: 386.3382 - val_loss: 647.7238\n",
      "Epoch 426/1000\n",
      "308/308 [==============================] - 0s 946us/step - loss: 386.3369 - val_loss: 647.7725\n",
      "Epoch 427/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3396 - val_loss: 647.7581\n",
      "Epoch 428/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3381 - val_loss: 647.7521\n",
      "Epoch 429/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3376 - val_loss: 647.7391\n",
      "Epoch 430/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3372 - val_loss: 647.7711\n",
      "Epoch 431/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3373 - val_loss: 647.7435\n",
      "Epoch 432/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3391 - val_loss: 647.7842\n",
      "Epoch 433/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3376 - val_loss: 647.7589\n",
      "Epoch 434/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3381 - val_loss: 647.7213\n",
      "Epoch 435/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3376 - val_loss: 647.7460\n",
      "Epoch 436/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3384 - val_loss: 647.7506\n",
      "Epoch 437/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3365 - val_loss: 647.7419\n",
      "Epoch 438/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3387 - val_loss: 647.7107\n",
      "Epoch 439/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3388 - val_loss: 647.7503\n",
      "Epoch 440/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3372 - val_loss: 647.7304\n",
      "Epoch 441/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3369 - val_loss: 647.7767\n",
      "Epoch 442/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3381 - val_loss: 647.7251\n",
      "Epoch 443/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3392 - val_loss: 647.7269\n",
      "Epoch 444/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3367 - val_loss: 647.7736\n",
      "Epoch 445/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7107\n",
      "Epoch 446/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7006\n",
      "Epoch 447/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7557\n",
      "Epoch 448/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3377 - val_loss: 647.7190\n",
      "Epoch 449/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3375 - val_loss: 647.7234\n",
      "Epoch 450/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7151\n",
      "Epoch 451/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3385 - val_loss: 647.7246\n",
      "Epoch 452/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3382 - val_loss: 647.7280\n",
      "Epoch 453/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3370 - val_loss: 647.7729\n",
      "Epoch 454/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3372 - val_loss: 647.7407\n",
      "Epoch 455/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7657\n",
      "Epoch 456/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3372 - val_loss: 647.7468\n",
      "Epoch 457/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7740\n",
      "Epoch 458/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3374 - val_loss: 647.8083\n",
      "Epoch 459/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.8124\n",
      "Epoch 460/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3370 - val_loss: 647.7422\n",
      "Epoch 461/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3375 - val_loss: 647.7263\n",
      "Epoch 462/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3386 - val_loss: 647.7328\n",
      "Epoch 463/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3387 - val_loss: 647.7565\n",
      "Epoch 464/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7122\n",
      "Epoch 465/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7210\n",
      "Epoch 466/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7333\n",
      "Epoch 467/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3383 - val_loss: 647.7828\n",
      "Epoch 468/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3382 - val_loss: 647.7970\n",
      "Epoch 469/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3382 - val_loss: 647.7615\n",
      "Epoch 470/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3386 - val_loss: 647.7338\n",
      "Epoch 471/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3398 - val_loss: 647.7841\n",
      "Epoch 472/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3371 - val_loss: 647.8151\n",
      "Epoch 473/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.7561\n",
      "Epoch 474/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7626\n",
      "Epoch 475/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3368 - val_loss: 647.7363\n",
      "Epoch 476/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3390 - val_loss: 647.7762\n",
      "Epoch 477/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3372 - val_loss: 647.7411\n",
      "Epoch 478/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7814\n",
      "Epoch 479/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3367 - val_loss: 647.7196\n",
      "Epoch 480/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3362 - val_loss: 647.7452\n",
      "Epoch 481/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7010\n",
      "Epoch 482/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3382 - val_loss: 647.7130\n",
      "Epoch 483/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3374 - val_loss: 647.7419\n",
      "Epoch 484/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3372 - val_loss: 647.7818\n",
      "Epoch 485/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3379 - val_loss: 647.7059\n",
      "Epoch 486/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7280\n",
      "Epoch 487/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3379 - val_loss: 647.7659\n",
      "Epoch 488/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3385 - val_loss: 647.6981\n",
      "Epoch 489/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3387 - val_loss: 647.7300\n",
      "Epoch 490/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3383 - val_loss: 647.7286\n",
      "Epoch 491/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3376 - val_loss: 647.7300\n",
      "Epoch 492/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3366 - val_loss: 647.7366\n",
      "Epoch 493/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7245\n",
      "Epoch 494/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7123\n",
      "Epoch 495/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3385 - val_loss: 647.7429\n",
      "Epoch 496/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7473\n",
      "Epoch 497/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.6900\n",
      "Epoch 498/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.7418\n",
      "Epoch 499/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7290\n",
      "Epoch 500/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3381 - val_loss: 647.7179\n",
      "Epoch 501/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3382 - val_loss: 647.7347\n",
      "Epoch 502/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3387 - val_loss: 647.7609\n",
      "Epoch 503/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3374 - val_loss: 647.7851\n",
      "Epoch 504/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3371 - val_loss: 647.7145\n",
      "Epoch 505/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3377 - val_loss: 647.7482\n",
      "Epoch 506/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7601\n",
      "Epoch 507/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7269\n",
      "Epoch 508/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3390 - val_loss: 647.6780\n",
      "Epoch 509/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3390 - val_loss: 647.7394\n",
      "Epoch 510/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3389 - val_loss: 647.6894\n",
      "Epoch 511/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3387 - val_loss: 647.6666\n",
      "Epoch 512/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3391 - val_loss: 647.6935\n",
      "Epoch 513/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3369 - val_loss: 647.7253\n",
      "Epoch 514/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7152\n",
      "Epoch 515/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3380 - val_loss: 647.7297\n",
      "Epoch 516/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3373 - val_loss: 647.7040\n",
      "Epoch 517/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3366 - val_loss: 647.7388\n",
      "Epoch 518/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3372 - val_loss: 647.6996\n",
      "Epoch 519/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3394 - val_loss: 647.6966\n",
      "Epoch 520/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3383 - val_loss: 647.7311\n",
      "Epoch 521/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7697\n",
      "Epoch 522/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3370 - val_loss: 647.7059\n",
      "Epoch 523/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3389 - val_loss: 647.7367\n",
      "Epoch 524/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7322\n",
      "Epoch 525/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3373 - val_loss: 647.7375\n",
      "Epoch 526/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3383 - val_loss: 647.6891\n",
      "Epoch 527/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.6863\n",
      "Epoch 528/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3376 - val_loss: 647.7160\n",
      "Epoch 529/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3381 - val_loss: 647.7053\n",
      "Epoch 530/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3384 - val_loss: 647.7396\n",
      "Epoch 531/1000\n",
      "308/308 [==============================] - 0s 951us/step - loss: 386.3383 - val_loss: 647.7800\n",
      "Epoch 532/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 386.3373 - val_loss: 647.7375\n",
      "Epoch 533/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3366 - val_loss: 647.7655\n",
      "Epoch 534/1000\n",
      "308/308 [==============================] - 0s 890us/step - loss: 386.3373 - val_loss: 647.7160\n",
      "Epoch 535/1000\n",
      "308/308 [==============================] - 0s 856us/step - loss: 386.3376 - val_loss: 647.6801\n",
      "Epoch 536/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3380 - val_loss: 647.7293\n",
      "Epoch 537/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3388 - val_loss: 647.7223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 538/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 386.3375 - val_loss: 647.6793\n",
      "Epoch 539/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.3388 - val_loss: 647.7281\n",
      "Epoch 540/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 386.3381 - val_loss: 647.7426\n",
      "Epoch 541/1000\n",
      "308/308 [==============================] - 0s 874us/step - loss: 386.3378 - val_loss: 647.7473\n",
      "Epoch 542/1000\n",
      "308/308 [==============================] - 0s 905us/step - loss: 386.3376 - val_loss: 647.7162\n",
      "Epoch 543/1000\n",
      "308/308 [==============================] - 0s 869us/step - loss: 386.3385 - val_loss: 647.7086\n",
      "Epoch 544/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 386.3387 - val_loss: 647.7117\n",
      "Epoch 545/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3375 - val_loss: 647.7095\n",
      "Epoch 546/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 386.3379 - val_loss: 647.7032\n",
      "Epoch 547/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3372 - val_loss: 647.6707\n",
      "Epoch 548/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3380 - val_loss: 647.7391\n",
      "Epoch 549/1000\n",
      "308/308 [==============================] - 0s 823us/step - loss: 386.3370 - val_loss: 647.7430\n",
      "Epoch 550/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 386.3374 - val_loss: 647.7561\n",
      "Epoch 551/1000\n",
      "308/308 [==============================] - 0s 968us/step - loss: 386.3380 - val_loss: 647.7225\n",
      "Epoch 552/1000\n",
      "308/308 [==============================] - 0s 868us/step - loss: 386.3366 - val_loss: 647.7448\n",
      "Epoch 553/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 386.3378 - val_loss: 647.7533\n",
      "Epoch 554/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 386.3376 - val_loss: 647.7721\n",
      "Epoch 555/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.3367 - val_loss: 647.7520\n",
      "Epoch 556/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 386.3373 - val_loss: 647.7694\n",
      "Epoch 557/1000\n",
      "308/308 [==============================] - 0s 848us/step - loss: 386.3372 - val_loss: 647.7988\n",
      "Epoch 558/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3370 - val_loss: 647.7404\n",
      "Epoch 559/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 386.3385 - val_loss: 647.7656\n",
      "Epoch 560/1000\n",
      "308/308 [==============================] - 0s 949us/step - loss: 386.3394 - val_loss: 647.7531\n",
      "Epoch 561/1000\n",
      "308/308 [==============================] - 0s 842us/step - loss: 386.3382 - val_loss: 647.7519\n",
      "Epoch 562/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3381 - val_loss: 647.7465\n",
      "Epoch 563/1000\n",
      "308/308 [==============================] - 0s 851us/step - loss: 386.3391 - val_loss: 647.7584\n",
      "Epoch 564/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3391 - val_loss: 647.7344\n",
      "Epoch 565/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 386.3368 - val_loss: 647.7817\n",
      "Epoch 566/1000\n",
      "308/308 [==============================] - 0s 949us/step - loss: 386.3384 - val_loss: 647.7473\n",
      "Epoch 567/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3365 - val_loss: 647.7482\n",
      "Epoch 568/1000\n",
      "308/308 [==============================] - 0s 984us/step - loss: 386.3390 - val_loss: 647.6807\n",
      "Epoch 569/1000\n",
      "308/308 [==============================] - 0s 859us/step - loss: 386.3388 - val_loss: 647.7252\n",
      "Epoch 570/1000\n",
      "308/308 [==============================] - 0s 882us/step - loss: 386.3373 - val_loss: 647.7499\n",
      "Epoch 571/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 386.3388 - val_loss: 647.7584\n",
      "Epoch 572/1000\n",
      "308/308 [==============================] - 0s 891us/step - loss: 386.3394 - val_loss: 647.7450\n",
      "Epoch 573/1000\n",
      "308/308 [==============================] - 0s 843us/step - loss: 386.3387 - val_loss: 647.7248\n",
      "Epoch 574/1000\n",
      "308/308 [==============================] - 0s 982us/step - loss: 386.3382 - val_loss: 647.7507\n",
      "Epoch 575/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 386.3377 - val_loss: 647.6898\n",
      "Epoch 576/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3390 - val_loss: 647.6993\n",
      "Epoch 577/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3376 - val_loss: 647.7106\n",
      "Epoch 578/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 386.3369 - val_loss: 647.6810\n",
      "Epoch 579/1000\n",
      "308/308 [==============================] - 0s 908us/step - loss: 386.3383 - val_loss: 647.7886\n",
      "Epoch 580/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 386.3385 - val_loss: 647.7111\n",
      "Epoch 581/1000\n",
      "308/308 [==============================] - 0s 898us/step - loss: 386.3386 - val_loss: 647.7284\n",
      "Epoch 582/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 386.3375 - val_loss: 647.7596\n",
      "Epoch 583/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 386.3378 - val_loss: 647.7511\n",
      "Epoch 584/1000\n",
      "308/308 [==============================] - 0s 854us/step - loss: 386.3378 - val_loss: 647.7501\n",
      "Epoch 585/1000\n",
      "308/308 [==============================] - 0s 894us/step - loss: 386.3379 - val_loss: 647.7759\n",
      "Epoch 586/1000\n",
      "308/308 [==============================] - 0s 921us/step - loss: 386.3390 - val_loss: 647.7719\n",
      "Epoch 587/1000\n",
      "308/308 [==============================] - 0s 893us/step - loss: 386.3371 - val_loss: 647.7984\n",
      "Epoch 588/1000\n",
      "308/308 [==============================] - 0s 865us/step - loss: 386.3381 - val_loss: 647.7805\n",
      "Epoch 589/1000\n",
      "308/308 [==============================] - 0s 880us/step - loss: 386.3374 - val_loss: 647.8269\n",
      "Epoch 590/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 386.3369 - val_loss: 647.7720\n",
      "Epoch 591/1000\n",
      "308/308 [==============================] - 0s 880us/step - loss: 386.3385 - val_loss: 647.8021\n",
      "Epoch 592/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 386.3387 - val_loss: 647.7862\n",
      "Epoch 593/1000\n",
      "308/308 [==============================] - 0s 891us/step - loss: 386.3382 - val_loss: 647.8127\n",
      "Epoch 594/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3390 - val_loss: 647.7770\n",
      "Epoch 595/1000\n",
      "308/308 [==============================] - 0s 836us/step - loss: 386.3371 - val_loss: 647.7892\n",
      "Epoch 596/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 386.3370 - val_loss: 647.7724\n",
      "Epoch 597/1000\n",
      "308/308 [==============================] - 0s 941us/step - loss: 386.3379 - val_loss: 647.8275\n",
      "Epoch 598/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 386.3384 - val_loss: 647.7749\n",
      "Epoch 599/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 386.3372 - val_loss: 647.8160\n",
      "Epoch 600/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3377 - val_loss: 647.7916\n",
      "Epoch 601/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 386.3393 - val_loss: 647.7742\n",
      "Epoch 602/1000\n",
      "308/308 [==============================] - 0s 965us/step - loss: 386.3370 - val_loss: 647.7857\n",
      "Epoch 603/1000\n",
      "308/308 [==============================] - 0s 839us/step - loss: 386.3372 - val_loss: 647.7477\n",
      "Epoch 604/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 386.3372 - val_loss: 647.7992\n",
      "Epoch 605/1000\n",
      "308/308 [==============================] - 0s 902us/step - loss: 386.3388 - val_loss: 647.8129\n",
      "Epoch 606/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3363 - val_loss: 647.7610\n",
      "Epoch 607/1000\n",
      "308/308 [==============================] - 0s 897us/step - loss: 386.3372 - val_loss: 647.7507\n",
      "Epoch 608/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 386.3406 - val_loss: 647.7615\n",
      "Epoch 609/1000\n",
      "308/308 [==============================] - 0s 940us/step - loss: 386.3391 - val_loss: 647.8474\n",
      "Epoch 610/1000\n",
      "308/308 [==============================] - 0s 953us/step - loss: 386.3381 - val_loss: 647.7944\n",
      "Epoch 611/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3363 - val_loss: 647.7861\n",
      "Epoch 612/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 976us/step - loss: 386.3376 - val_loss: 647.8213\n",
      "Epoch 613/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3402 - val_loss: 647.8017\n",
      "Epoch 614/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3405 - val_loss: 647.7612\n",
      "Epoch 615/1000\n",
      "308/308 [==============================] - 0s 978us/step - loss: 386.3365 - val_loss: 647.7704\n",
      "Epoch 616/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3383 - val_loss: 647.7190\n",
      "Epoch 617/1000\n",
      "308/308 [==============================] - 0s 946us/step - loss: 386.3373 - val_loss: 647.7531\n",
      "Epoch 618/1000\n",
      "308/308 [==============================] - 0s 939us/step - loss: 386.3383 - val_loss: 647.7748\n",
      "Epoch 619/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3373 - val_loss: 647.7919\n",
      "Epoch 620/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 386.3372 - val_loss: 647.7574\n",
      "Epoch 621/1000\n",
      "308/308 [==============================] - 0s 948us/step - loss: 386.3374 - val_loss: 647.8343\n",
      "Epoch 622/1000\n",
      "308/308 [==============================] - 0s 919us/step - loss: 386.3379 - val_loss: 647.7881\n",
      "Epoch 623/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 386.3369 - val_loss: 647.7632\n",
      "Epoch 624/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 386.3376 - val_loss: 647.7521\n",
      "Epoch 625/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3392 - val_loss: 647.7398\n",
      "Epoch 626/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 386.3379 - val_loss: 647.7981\n",
      "Epoch 627/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 386.3379 - val_loss: 647.7760\n",
      "Epoch 628/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3372 - val_loss: 647.7702\n",
      "Epoch 629/1000\n",
      "308/308 [==============================] - 0s 969us/step - loss: 386.3386 - val_loss: 647.8160\n",
      "Epoch 630/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 386.3368 - val_loss: 647.7992\n",
      "Epoch 631/1000\n",
      "308/308 [==============================] - 0s 961us/step - loss: 386.3376 - val_loss: 647.8066\n",
      "Epoch 632/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 386.3369 - val_loss: 647.8334\n",
      "Epoch 633/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 386.3374 - val_loss: 647.8260\n",
      "Epoch 634/1000\n",
      "308/308 [==============================] - 0s 976us/step - loss: 386.3374 - val_loss: 647.8258\n",
      "Epoch 635/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 386.3378 - val_loss: 647.7969\n",
      "Epoch 636/1000\n",
      "308/308 [==============================] - 0s 958us/step - loss: 386.3375 - val_loss: 647.8366\n",
      "Epoch 637/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3396 - val_loss: 647.8134\n",
      "Epoch 638/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3379 - val_loss: 647.8467\n",
      "Epoch 639/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 386.3396 - val_loss: 647.8400\n",
      "Epoch 640/1000\n",
      "308/308 [==============================] - 0s 925us/step - loss: 386.3384 - val_loss: 647.8278\n",
      "Epoch 641/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 386.3371 - val_loss: 647.7852\n",
      "Epoch 642/1000\n",
      "308/308 [==============================] - 0s 983us/step - loss: 386.3391 - val_loss: 647.8315\n",
      "Epoch 643/1000\n",
      "308/308 [==============================] - 0s 822us/step - loss: 386.3381 - val_loss: 647.7346\n",
      "Epoch 644/1000\n",
      "308/308 [==============================] - 0s 964us/step - loss: 386.3397 - val_loss: 647.7441\n",
      "Epoch 645/1000\n",
      "308/308 [==============================] - 0s 948us/step - loss: 386.3386 - val_loss: 647.8142\n",
      "Epoch 646/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 386.3367 - val_loss: 647.7659\n",
      "Epoch 647/1000\n",
      "308/308 [==============================] - 0s 981us/step - loss: 386.3387 - val_loss: 647.7755\n",
      "Epoch 648/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 386.3379 - val_loss: 647.7953\n",
      "Epoch 649/1000\n",
      "308/308 [==============================] - 0s 956us/step - loss: 386.3386 - val_loss: 647.7869\n",
      "Epoch 650/1000\n",
      "308/308 [==============================] - 0s 953us/step - loss: 386.3369 - val_loss: 647.6836\n",
      "Epoch 651/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3373 - val_loss: 647.6976\n",
      "Epoch 652/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3386 - val_loss: 647.7343\n",
      "Epoch 653/1000\n",
      "308/308 [==============================] - 0s 882us/step - loss: 386.3391 - val_loss: 647.6681\n",
      "Epoch 654/1000\n",
      "308/308 [==============================] - 0s 867us/step - loss: 386.3375 - val_loss: 647.7336\n",
      "Epoch 655/1000\n",
      "308/308 [==============================] - 0s 957us/step - loss: 386.3369 - val_loss: 647.7444\n",
      "Epoch 656/1000\n",
      "308/308 [==============================] - 0s 993us/step - loss: 386.3369 - val_loss: 647.7535\n",
      "Epoch 657/1000\n",
      "308/308 [==============================] - 0s 930us/step - loss: 386.3376 - val_loss: 647.7225\n",
      "Epoch 658/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3376 - val_loss: 647.6925\n",
      "Epoch 659/1000\n",
      "308/308 [==============================] - 0s 910us/step - loss: 386.3381 - val_loss: 647.7593\n",
      "Epoch 660/1000\n",
      "308/308 [==============================] - 0s 833us/step - loss: 386.3382 - val_loss: 647.7542\n",
      "Epoch 661/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3376 - val_loss: 647.7181\n",
      "Epoch 662/1000\n",
      "308/308 [==============================] - 0s 860us/step - loss: 386.3370 - val_loss: 647.7548\n",
      "Epoch 663/1000\n",
      "308/308 [==============================] - 0s 941us/step - loss: 386.3379 - val_loss: 647.7849\n",
      "Epoch 664/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 386.3389 - val_loss: 647.7276\n",
      "Epoch 665/1000\n",
      "308/308 [==============================] - 0s 935us/step - loss: 386.3373 - val_loss: 647.7452\n",
      "Epoch 666/1000\n",
      "308/308 [==============================] - 0s 903us/step - loss: 386.3367 - val_loss: 647.7416\n",
      "Epoch 667/1000\n",
      "308/308 [==============================] - 0s 906us/step - loss: 386.3380 - val_loss: 647.7371\n",
      "Epoch 668/1000\n",
      "308/308 [==============================] - 0s 962us/step - loss: 386.3391 - val_loss: 647.7729\n",
      "Epoch 669/1000\n",
      "308/308 [==============================] - 0s 948us/step - loss: 386.3369 - val_loss: 647.7256\n",
      "Epoch 670/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 386.3372 - val_loss: 647.6964\n",
      "Epoch 671/1000\n",
      "308/308 [==============================] - 0s 971us/step - loss: 386.3406 - val_loss: 647.6994\n",
      "Epoch 672/1000\n",
      "308/308 [==============================] - 0s 903us/step - loss: 386.3378 - val_loss: 647.7152\n",
      "Epoch 673/1000\n",
      "308/308 [==============================] - 0s 908us/step - loss: 386.3389 - val_loss: 647.7849\n",
      "Epoch 674/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 386.3394 - val_loss: 647.7168\n",
      "Epoch 675/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3373 - val_loss: 647.7494\n",
      "Epoch 676/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3375 - val_loss: 647.7704\n",
      "Epoch 677/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3373 - val_loss: 647.7603\n",
      "Epoch 678/1000\n",
      "308/308 [==============================] - 0s 944us/step - loss: 386.3373 - val_loss: 647.8323\n",
      "Epoch 679/1000\n",
      "308/308 [==============================] - 0s 908us/step - loss: 386.3385 - val_loss: 647.7084\n",
      "Epoch 680/1000\n",
      "308/308 [==============================] - 0s 853us/step - loss: 386.3381 - val_loss: 647.7804\n",
      "Epoch 681/1000\n",
      "308/308 [==============================] - 0s 928us/step - loss: 386.3378 - val_loss: 647.7333\n",
      "Epoch 682/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3381 - val_loss: 647.7506\n",
      "Epoch 683/1000\n",
      "308/308 [==============================] - 0s 939us/step - loss: 386.3374 - val_loss: 647.7615\n",
      "Epoch 684/1000\n",
      "308/308 [==============================] - 0s 880us/step - loss: 386.3387 - val_loss: 647.8221\n",
      "Epoch 685/1000\n",
      "308/308 [==============================] - 0s 913us/step - loss: 386.3374 - val_loss: 647.8069\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 906us/step - loss: 386.3376 - val_loss: 647.7631\n",
      "Epoch 687/1000\n",
      "308/308 [==============================] - 0s 957us/step - loss: 386.3384 - val_loss: 647.7447\n",
      "Epoch 688/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 386.3374 - val_loss: 647.7429\n",
      "Epoch 689/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3381 - val_loss: 647.7447\n",
      "Epoch 690/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3375 - val_loss: 647.7292\n",
      "Epoch 691/1000\n",
      "308/308 [==============================] - 0s 961us/step - loss: 386.3419 - val_loss: 647.7751\n",
      "Epoch 692/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3369 - val_loss: 647.7819\n",
      "Epoch 693/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 386.3382 - val_loss: 647.7800\n",
      "Epoch 694/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 386.3378 - val_loss: 647.7794\n",
      "Epoch 695/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 386.3367 - val_loss: 647.7797\n",
      "Epoch 696/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 386.3369 - val_loss: 647.7693\n",
      "Epoch 697/1000\n",
      "308/308 [==============================] - 0s 854us/step - loss: 386.3369 - val_loss: 647.7840\n",
      "Epoch 698/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 386.3379 - val_loss: 647.7604\n",
      "Epoch 699/1000\n",
      "308/308 [==============================] - 0s 950us/step - loss: 386.3385 - val_loss: 647.7397\n",
      "Epoch 700/1000\n",
      "308/308 [==============================] - 0s 965us/step - loss: 386.3376 - val_loss: 647.8248\n",
      "Epoch 701/1000\n",
      "308/308 [==============================] - 0s 983us/step - loss: 386.3377 - val_loss: 647.7503\n",
      "Epoch 702/1000\n",
      "308/308 [==============================] - 0s 906us/step - loss: 386.3370 - val_loss: 647.8049\n",
      "Epoch 703/1000\n",
      "308/308 [==============================] - 0s 837us/step - loss: 386.3387 - val_loss: 647.7394\n",
      "Epoch 704/1000\n",
      "308/308 [==============================] - 0s 880us/step - loss: 386.3385 - val_loss: 647.7460\n",
      "Epoch 705/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 386.3365 - val_loss: 647.7954\n",
      "Epoch 706/1000\n",
      "308/308 [==============================] - 0s 868us/step - loss: 386.3373 - val_loss: 647.8007\n",
      "Epoch 707/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 386.3365 - val_loss: 647.7981\n",
      "Epoch 708/1000\n",
      "308/308 [==============================] - 0s 922us/step - loss: 386.3376 - val_loss: 647.7641\n",
      "Epoch 709/1000\n",
      "308/308 [==============================] - 0s 871us/step - loss: 386.3362 - val_loss: 647.7925\n",
      "Epoch 710/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 386.3378 - val_loss: 647.7729\n",
      "Epoch 711/1000\n",
      "308/308 [==============================] - 0s 922us/step - loss: 386.3378 - val_loss: 647.8229\n",
      "Epoch 712/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 386.3381 - val_loss: 647.7836\n",
      "Epoch 713/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 386.3365 - val_loss: 647.7615\n",
      "Epoch 714/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 386.3381 - val_loss: 647.8066\n",
      "Epoch 715/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 386.3371 - val_loss: 647.7744\n",
      "Epoch 716/1000\n",
      "308/308 [==============================] - 0s 936us/step - loss: 386.3381 - val_loss: 647.7949\n",
      "Epoch 717/1000\n",
      "308/308 [==============================] - 0s 955us/step - loss: 386.3387 - val_loss: 647.7729\n",
      "Epoch 718/1000\n",
      "308/308 [==============================] - 0s 921us/step - loss: 386.3370 - val_loss: 647.7839\n",
      "Epoch 719/1000\n",
      "308/308 [==============================] - 0s 898us/step - loss: 386.3383 - val_loss: 647.8262\n",
      "Epoch 720/1000\n",
      "308/308 [==============================] - 0s 982us/step - loss: 386.3382 - val_loss: 647.7806\n",
      "Epoch 721/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3378 - val_loss: 647.7860\n",
      "Epoch 722/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3388 - val_loss: 647.8022\n",
      "Epoch 723/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3381 - val_loss: 647.7487\n",
      "Epoch 724/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3370 - val_loss: 647.7784\n",
      "Epoch 725/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3389 - val_loss: 647.7742\n",
      "Epoch 726/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3375 - val_loss: 647.7696\n",
      "Epoch 727/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3368 - val_loss: 647.8015\n",
      "Epoch 728/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3382 - val_loss: 647.7789\n",
      "Epoch 729/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7678\n",
      "Epoch 730/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3370 - val_loss: 647.7379\n",
      "Epoch 731/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3386 - val_loss: 647.7401\n",
      "Epoch 732/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3381 - val_loss: 647.7941\n",
      "Epoch 733/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.7552\n",
      "Epoch 734/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3381 - val_loss: 647.7774\n",
      "Epoch 735/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3381 - val_loss: 647.7499\n",
      "Epoch 736/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3393 - val_loss: 647.7619\n",
      "Epoch 737/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3376 - val_loss: 647.7714\n",
      "Epoch 738/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3393 - val_loss: 647.7547\n",
      "Epoch 739/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3370 - val_loss: 647.7256\n",
      "Epoch 740/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7391\n",
      "Epoch 741/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3399 - val_loss: 647.7328\n",
      "Epoch 742/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3394 - val_loss: 647.7217\n",
      "Epoch 743/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3372 - val_loss: 647.7641\n",
      "Epoch 744/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3381 - val_loss: 647.8038\n",
      "Epoch 745/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3391 - val_loss: 647.7883\n",
      "Epoch 746/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7468\n",
      "Epoch 747/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3375 - val_loss: 647.7682\n",
      "Epoch 748/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3376 - val_loss: 647.7335\n",
      "Epoch 749/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3378 - val_loss: 647.7219\n",
      "Epoch 750/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7266\n",
      "Epoch 751/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3374 - val_loss: 647.7282\n",
      "Epoch 752/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3386 - val_loss: 647.7388\n",
      "Epoch 753/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3366 - val_loss: 647.7452\n",
      "Epoch 754/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3374 - val_loss: 647.7555\n",
      "Epoch 755/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3375 - val_loss: 647.7362\n",
      "Epoch 756/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3387 - val_loss: 647.7022\n",
      "Epoch 757/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3411 - val_loss: 647.7787\n",
      "Epoch 758/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3384 - val_loss: 647.7153\n",
      "Epoch 759/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3376 - val_loss: 647.7252\n",
      "Epoch 760/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3375 - val_loss: 647.7693\n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3375 - val_loss: 647.7263\n",
      "Epoch 762/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3370 - val_loss: 647.7626\n",
      "Epoch 763/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3370 - val_loss: 647.6945\n",
      "Epoch 764/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3381 - val_loss: 647.7006\n",
      "Epoch 765/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3402 - val_loss: 647.6913\n",
      "Epoch 766/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3361 - val_loss: 647.7113\n",
      "Epoch 767/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3388 - val_loss: 647.7169\n",
      "Epoch 768/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3370 - val_loss: 647.7560\n",
      "Epoch 769/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7291\n",
      "Epoch 770/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3392 - val_loss: 647.7823\n",
      "Epoch 771/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3378 - val_loss: 647.7859\n",
      "Epoch 772/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3392 - val_loss: 647.7301\n",
      "Epoch 773/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3373 - val_loss: 647.7619\n",
      "Epoch 774/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3391 - val_loss: 647.7908\n",
      "Epoch 775/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3389 - val_loss: 647.7796\n",
      "Epoch 776/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3381 - val_loss: 647.8078\n",
      "Epoch 777/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3371 - val_loss: 647.7612\n",
      "Epoch 778/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3386 - val_loss: 647.7303\n",
      "Epoch 779/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3387 - val_loss: 647.8269\n",
      "Epoch 780/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3370 - val_loss: 647.8295\n",
      "Epoch 781/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3371 - val_loss: 647.7555\n",
      "Epoch 782/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3377 - val_loss: 647.7802\n",
      "Epoch 783/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7502\n",
      "Epoch 784/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3372 - val_loss: 647.7742\n",
      "Epoch 785/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3373 - val_loss: 647.7504\n",
      "Epoch 786/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.7770\n",
      "Epoch 787/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7744\n",
      "Epoch 788/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3380 - val_loss: 647.7691\n",
      "Epoch 789/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3372 - val_loss: 647.7760\n",
      "Epoch 790/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3374 - val_loss: 647.7736\n",
      "Epoch 791/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3367 - val_loss: 647.7704\n",
      "Epoch 792/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7598\n",
      "Epoch 793/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3375 - val_loss: 647.7577\n",
      "Epoch 794/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3376 - val_loss: 647.7353\n",
      "Epoch 795/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3398 - val_loss: 647.8278\n",
      "Epoch 796/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3376 - val_loss: 647.7333\n",
      "Epoch 797/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3375 - val_loss: 647.7518\n",
      "Epoch 798/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3388 - val_loss: 647.7993\n",
      "Epoch 799/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3377 - val_loss: 647.7855\n",
      "Epoch 800/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3384 - val_loss: 647.7778\n",
      "Epoch 801/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3380 - val_loss: 647.7886\n",
      "Epoch 802/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3371 - val_loss: 647.7841\n",
      "Epoch 803/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3383 - val_loss: 647.7988\n",
      "Epoch 804/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3406 - val_loss: 647.8804\n",
      "Epoch 805/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3386 - val_loss: 647.7778\n",
      "Epoch 806/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3385 - val_loss: 647.7468\n",
      "Epoch 807/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3374 - val_loss: 647.7776\n",
      "Epoch 808/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3371 - val_loss: 647.7806\n",
      "Epoch 809/1000\n",
      "308/308 [==============================] - 1s 2ms/step - loss: 386.3373 - val_loss: 647.7657\n",
      "Epoch 810/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7830\n",
      "Epoch 811/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3379 - val_loss: 647.7710\n",
      "Epoch 812/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3394 - val_loss: 647.8018\n",
      "Epoch 813/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3368 - val_loss: 647.7712\n",
      "Epoch 814/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3369 - val_loss: 647.7567\n",
      "Epoch 815/1000\n",
      "308/308 [==============================] - 1s 3ms/step - loss: 386.3395 - val_loss: 647.7466\n",
      "Epoch 816/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3380 - val_loss: 647.7533\n",
      "Epoch 817/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3370 - val_loss: 647.7336\n",
      "Epoch 818/1000\n",
      "308/308 [==============================] - 0s 953us/step - loss: 386.3384 - val_loss: 647.7343\n",
      "Epoch 819/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 386.3387 - val_loss: 647.7379\n",
      "Epoch 820/1000\n",
      "308/308 [==============================] - 0s 946us/step - loss: 386.3372 - val_loss: 647.7802\n",
      "Epoch 821/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3372 - val_loss: 647.7836\n",
      "Epoch 822/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 386.3376 - val_loss: 647.7733\n",
      "Epoch 823/1000\n",
      "308/308 [==============================] - 0s 854us/step - loss: 386.3370 - val_loss: 647.7998\n",
      "Epoch 824/1000\n",
      "308/308 [==============================] - 0s 891us/step - loss: 386.3369 - val_loss: 647.7957\n",
      "Epoch 825/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3387 - val_loss: 647.8093\n",
      "Epoch 826/1000\n",
      "308/308 [==============================] - 0s 906us/step - loss: 386.3377 - val_loss: 647.7670\n",
      "Epoch 827/1000\n",
      "308/308 [==============================] - 0s 852us/step - loss: 386.3377 - val_loss: 647.7750\n",
      "Epoch 828/1000\n",
      "308/308 [==============================] - 0s 887us/step - loss: 386.3393 - val_loss: 647.7879\n",
      "Epoch 829/1000\n",
      "308/308 [==============================] - 0s 963us/step - loss: 386.3379 - val_loss: 647.8099\n",
      "Epoch 830/1000\n",
      "308/308 [==============================] - 0s 855us/step - loss: 386.3387 - val_loss: 647.7515\n",
      "Epoch 831/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 386.3386 - val_loss: 647.7362\n",
      "Epoch 832/1000\n",
      "308/308 [==============================] - 0s 989us/step - loss: 386.3373 - val_loss: 647.7676\n",
      "Epoch 833/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 386.3368 - val_loss: 647.7796\n",
      "Epoch 834/1000\n",
      "308/308 [==============================] - 0s 940us/step - loss: 386.3370 - val_loss: 647.8266\n",
      "Epoch 835/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3378 - val_loss: 647.7795\n",
      "Epoch 836/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 917us/step - loss: 386.3399 - val_loss: 647.7612\n",
      "Epoch 837/1000\n",
      "308/308 [==============================] - 0s 927us/step - loss: 386.3373 - val_loss: 647.7537\n",
      "Epoch 838/1000\n",
      "308/308 [==============================] - 0s 979us/step - loss: 386.3387 - val_loss: 647.7854\n",
      "Epoch 839/1000\n",
      "308/308 [==============================] - 0s 942us/step - loss: 386.3382 - val_loss: 647.7729\n",
      "Epoch 840/1000\n",
      "308/308 [==============================] - 0s 945us/step - loss: 386.3372 - val_loss: 647.7951\n",
      "Epoch 841/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 386.3374 - val_loss: 647.8192\n",
      "Epoch 842/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3380 - val_loss: 647.7495\n",
      "Epoch 843/1000\n",
      "308/308 [==============================] - 0s 908us/step - loss: 386.3384 - val_loss: 647.7734\n",
      "Epoch 844/1000\n",
      "308/308 [==============================] - 0s 952us/step - loss: 386.3386 - val_loss: 647.7075\n",
      "Epoch 845/1000\n",
      "308/308 [==============================] - 0s 899us/step - loss: 386.3370 - val_loss: 647.7424\n",
      "Epoch 846/1000\n",
      "308/308 [==============================] - 0s 861us/step - loss: 386.3393 - val_loss: 647.7444\n",
      "Epoch 847/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 386.3387 - val_loss: 647.6895\n",
      "Epoch 848/1000\n",
      "308/308 [==============================] - 0s 814us/step - loss: 386.3379 - val_loss: 647.7399\n",
      "Epoch 849/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 386.3365 - val_loss: 647.7795\n",
      "Epoch 850/1000\n",
      "308/308 [==============================] - 0s 896us/step - loss: 386.3381 - val_loss: 647.7549\n",
      "Epoch 851/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 386.3378 - val_loss: 647.7504\n",
      "Epoch 852/1000\n",
      "308/308 [==============================] - 0s 888us/step - loss: 386.3370 - val_loss: 647.7772\n",
      "Epoch 853/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 386.3383 - val_loss: 647.7828\n",
      "Epoch 854/1000\n",
      "308/308 [==============================] - 0s 843us/step - loss: 386.3365 - val_loss: 647.7808\n",
      "Epoch 855/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3388 - val_loss: 647.7623\n",
      "Epoch 856/1000\n",
      "308/308 [==============================] - 0s 845us/step - loss: 386.3400 - val_loss: 647.7741\n",
      "Epoch 857/1000\n",
      "308/308 [==============================] - 0s 835us/step - loss: 386.3373 - val_loss: 647.7683\n",
      "Epoch 858/1000\n",
      "308/308 [==============================] - 0s 864us/step - loss: 386.3372 - val_loss: 647.7490\n",
      "Epoch 859/1000\n",
      "308/308 [==============================] - 0s 848us/step - loss: 386.3390 - val_loss: 647.7823\n",
      "Epoch 860/1000\n",
      "308/308 [==============================] - 0s 957us/step - loss: 386.3381 - val_loss: 647.7632\n",
      "Epoch 861/1000\n",
      "308/308 [==============================] - 0s 911us/step - loss: 386.3376 - val_loss: 647.7532\n",
      "Epoch 862/1000\n",
      "308/308 [==============================] - 0s 908us/step - loss: 386.3380 - val_loss: 647.7603\n",
      "Epoch 863/1000\n",
      "308/308 [==============================] - 0s 883us/step - loss: 386.3388 - val_loss: 647.7577\n",
      "Epoch 864/1000\n",
      "308/308 [==============================] - 0s 837us/step - loss: 386.3376 - val_loss: 647.7578\n",
      "Epoch 865/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 386.3369 - val_loss: 647.7396\n",
      "Epoch 866/1000\n",
      "308/308 [==============================] - 0s 890us/step - loss: 386.3396 - val_loss: 647.7852\n",
      "Epoch 867/1000\n",
      "308/308 [==============================] - 0s 874us/step - loss: 386.3364 - val_loss: 647.7878\n",
      "Epoch 868/1000\n",
      "308/308 [==============================] - 0s 797us/step - loss: 386.3372 - val_loss: 647.7746\n",
      "Epoch 869/1000\n",
      "308/308 [==============================] - 0s 823us/step - loss: 386.3371 - val_loss: 647.7520\n",
      "Epoch 870/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3376 - val_loss: 647.7589\n",
      "Epoch 871/1000\n",
      "308/308 [==============================] - 0s 825us/step - loss: 386.3376 - val_loss: 647.7778\n",
      "Epoch 872/1000\n",
      "308/308 [==============================] - 0s 909us/step - loss: 386.3381 - val_loss: 647.7946\n",
      "Epoch 873/1000\n",
      "308/308 [==============================] - 0s 820us/step - loss: 386.3380 - val_loss: 647.8195\n",
      "Epoch 874/1000\n",
      "308/308 [==============================] - 0s 860us/step - loss: 386.3385 - val_loss: 647.8635\n",
      "Epoch 875/1000\n",
      "308/308 [==============================] - 0s 920us/step - loss: 386.3388 - val_loss: 647.7979\n",
      "Epoch 876/1000\n",
      "308/308 [==============================] - 0s 843us/step - loss: 386.3375 - val_loss: 647.7596\n",
      "Epoch 877/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3385 - val_loss: 647.7819\n",
      "Epoch 878/1000\n",
      "308/308 [==============================] - 0s 908us/step - loss: 386.3374 - val_loss: 647.7723\n",
      "Epoch 879/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 386.3389 - val_loss: 647.7097\n",
      "Epoch 880/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 386.3380 - val_loss: 647.7451\n",
      "Epoch 881/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3374 - val_loss: 647.7485\n",
      "Epoch 882/1000\n",
      "308/308 [==============================] - 0s 940us/step - loss: 386.3383 - val_loss: 647.7216\n",
      "Epoch 883/1000\n",
      "308/308 [==============================] - 0s 912us/step - loss: 386.3381 - val_loss: 647.7934\n",
      "Epoch 884/1000\n",
      "308/308 [==============================] - 0s 822us/step - loss: 386.3373 - val_loss: 647.7784\n",
      "Epoch 885/1000\n",
      "308/308 [==============================] - 0s 877us/step - loss: 386.3380 - val_loss: 647.7874\n",
      "Epoch 886/1000\n",
      "308/308 [==============================] - 0s 957us/step - loss: 386.3369 - val_loss: 647.7419\n",
      "Epoch 887/1000\n",
      "308/308 [==============================] - 0s 817us/step - loss: 386.3386 - val_loss: 647.7397\n",
      "Epoch 888/1000\n",
      "308/308 [==============================] - 0s 943us/step - loss: 386.3373 - val_loss: 647.7902\n",
      "Epoch 889/1000\n",
      "308/308 [==============================] - 0s 862us/step - loss: 386.3375 - val_loss: 647.7365\n",
      "Epoch 890/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 386.3371 - val_loss: 647.7650\n",
      "Epoch 891/1000\n",
      "308/308 [==============================] - 0s 834us/step - loss: 386.3376 - val_loss: 647.7304\n",
      "Epoch 892/1000\n",
      "308/308 [==============================] - 0s 973us/step - loss: 386.3372 - val_loss: 647.7300\n",
      "Epoch 893/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 386.3384 - val_loss: 647.7382\n",
      "Epoch 894/1000\n",
      "308/308 [==============================] - 0s 916us/step - loss: 386.3388 - val_loss: 647.7382\n",
      "Epoch 895/1000\n",
      "308/308 [==============================] - 0s 859us/step - loss: 386.3393 - val_loss: 647.7397\n",
      "Epoch 896/1000\n",
      "308/308 [==============================] - 0s 832us/step - loss: 386.3367 - val_loss: 647.7198\n",
      "Epoch 897/1000\n",
      "308/308 [==============================] - 0s 942us/step - loss: 386.3372 - val_loss: 647.7210\n",
      "Epoch 898/1000\n",
      "308/308 [==============================] - 0s 894us/step - loss: 386.3366 - val_loss: 647.7137\n",
      "Epoch 899/1000\n",
      "308/308 [==============================] - 0s 891us/step - loss: 386.3371 - val_loss: 647.6929\n",
      "Epoch 900/1000\n",
      "308/308 [==============================] - 0s 872us/step - loss: 386.3381 - val_loss: 647.7420\n",
      "Epoch 901/1000\n",
      "308/308 [==============================] - 0s 873us/step - loss: 386.3386 - val_loss: 647.7559\n",
      "Epoch 902/1000\n",
      "308/308 [==============================] - 0s 814us/step - loss: 386.3376 - val_loss: 647.6965\n",
      "Epoch 903/1000\n",
      "308/308 [==============================] - 0s 921us/step - loss: 386.3383 - val_loss: 647.6815\n",
      "Epoch 904/1000\n",
      "308/308 [==============================] - 0s 866us/step - loss: 386.3376 - val_loss: 647.7235\n",
      "Epoch 905/1000\n",
      "308/308 [==============================] - 0s 852us/step - loss: 386.3378 - val_loss: 647.7284\n",
      "Epoch 906/1000\n",
      "308/308 [==============================] - 0s 897us/step - loss: 386.3383 - val_loss: 647.6882\n",
      "Epoch 907/1000\n",
      "308/308 [==============================] - 0s 835us/step - loss: 386.3369 - val_loss: 647.7126\n",
      "Epoch 908/1000\n",
      "308/308 [==============================] - 0s 863us/step - loss: 386.3388 - val_loss: 647.7166\n",
      "Epoch 909/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 386.3385 - val_loss: 647.7268\n",
      "Epoch 910/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 858us/step - loss: 386.3373 - val_loss: 647.7583\n",
      "Epoch 911/1000\n",
      "308/308 [==============================] - 0s 893us/step - loss: 386.3373 - val_loss: 647.7332\n",
      "Epoch 912/1000\n",
      "308/308 [==============================] - 0s 909us/step - loss: 386.3391 - val_loss: 647.7628\n",
      "Epoch 913/1000\n",
      "308/308 [==============================] - 0s 838us/step - loss: 386.3369 - val_loss: 647.7197\n",
      "Epoch 914/1000\n",
      "308/308 [==============================] - 0s 840us/step - loss: 386.3376 - val_loss: 647.7615\n",
      "Epoch 915/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 386.3375 - val_loss: 647.7632\n",
      "Epoch 916/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3372 - val_loss: 647.7559\n",
      "Epoch 917/1000\n",
      "308/308 [==============================] - 0s 852us/step - loss: 386.3383 - val_loss: 647.7350\n",
      "Epoch 918/1000\n",
      "308/308 [==============================] - 0s 865us/step - loss: 386.3388 - val_loss: 647.7615\n",
      "Epoch 919/1000\n",
      "308/308 [==============================] - 0s 935us/step - loss: 386.3368 - val_loss: 647.7473\n",
      "Epoch 920/1000\n",
      "308/308 [==============================] - 0s 868us/step - loss: 386.3388 - val_loss: 647.7744\n",
      "Epoch 921/1000\n",
      "308/308 [==============================] - 0s 865us/step - loss: 386.3376 - val_loss: 647.7314\n",
      "Epoch 922/1000\n",
      "308/308 [==============================] - 0s 917us/step - loss: 386.3390 - val_loss: 647.8058\n",
      "Epoch 923/1000\n",
      "308/308 [==============================] - 0s 875us/step - loss: 386.3370 - val_loss: 647.7528\n",
      "Epoch 924/1000\n",
      "308/308 [==============================] - 0s 847us/step - loss: 386.3388 - val_loss: 647.7460\n",
      "Epoch 925/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 386.3371 - val_loss: 647.7888\n",
      "Epoch 926/1000\n",
      "308/308 [==============================] - 0s 829us/step - loss: 386.3393 - val_loss: 647.7474\n",
      "Epoch 927/1000\n",
      "308/308 [==============================] - 0s 892us/step - loss: 386.3365 - val_loss: 647.8013\n",
      "Epoch 928/1000\n",
      "308/308 [==============================] - 0s 886us/step - loss: 386.3379 - val_loss: 647.7707\n",
      "Epoch 929/1000\n",
      "308/308 [==============================] - 0s 940us/step - loss: 386.3374 - val_loss: 647.7527\n",
      "Epoch 930/1000\n",
      "308/308 [==============================] - 0s 984us/step - loss: 386.3382 - val_loss: 647.7790\n",
      "Epoch 931/1000\n",
      "308/308 [==============================] - 0s 901us/step - loss: 386.3365 - val_loss: 647.7411\n",
      "Epoch 932/1000\n",
      "308/308 [==============================] - 0s 909us/step - loss: 386.3387 - val_loss: 647.7542\n",
      "Epoch 933/1000\n",
      "308/308 [==============================] - 0s 969us/step - loss: 386.3385 - val_loss: 647.7578\n",
      "Epoch 934/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 386.3376 - val_loss: 647.8058\n",
      "Epoch 935/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 386.3378 - val_loss: 647.7578\n",
      "Epoch 936/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3378 - val_loss: 647.7512\n",
      "Epoch 937/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 386.3384 - val_loss: 647.7480\n",
      "Epoch 938/1000\n",
      "308/308 [==============================] - 0s 865us/step - loss: 386.3371 - val_loss: 647.7603\n",
      "Epoch 939/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 386.3393 - val_loss: 647.7209\n",
      "Epoch 940/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 386.3362 - val_loss: 647.7453\n",
      "Epoch 941/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3388 - val_loss: 647.7859\n",
      "Epoch 942/1000\n",
      "308/308 [==============================] - 0s 848us/step - loss: 386.3371 - val_loss: 647.7911\n",
      "Epoch 943/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 386.3372 - val_loss: 647.6905\n",
      "Epoch 944/1000\n",
      "308/308 [==============================] - 0s 840us/step - loss: 386.3379 - val_loss: 647.7004\n",
      "Epoch 945/1000\n",
      "308/308 [==============================] - 0s 918us/step - loss: 386.3382 - val_loss: 647.7647\n",
      "Epoch 946/1000\n",
      "308/308 [==============================] - 0s 870us/step - loss: 386.3378 - val_loss: 647.7249\n",
      "Epoch 947/1000\n",
      "308/308 [==============================] - 0s 934us/step - loss: 386.3387 - val_loss: 647.7559\n",
      "Epoch 948/1000\n",
      "308/308 [==============================] - 0s 897us/step - loss: 386.3381 - val_loss: 647.7547\n",
      "Epoch 949/1000\n",
      "308/308 [==============================] - 0s 874us/step - loss: 386.3379 - val_loss: 647.7630\n",
      "Epoch 950/1000\n",
      "308/308 [==============================] - 0s 1ms/step - loss: 386.3391 - val_loss: 647.8159\n",
      "Epoch 951/1000\n",
      "308/308 [==============================] - 0s 931us/step - loss: 386.3370 - val_loss: 647.7549\n",
      "Epoch 952/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3378 - val_loss: 647.7656\n",
      "Epoch 953/1000\n",
      "308/308 [==============================] - 0s 887us/step - loss: 386.3385 - val_loss: 647.8098\n",
      "Epoch 954/1000\n",
      "308/308 [==============================] - 0s 882us/step - loss: 386.3381 - val_loss: 647.7388\n",
      "Epoch 955/1000\n",
      "308/308 [==============================] - 0s 889us/step - loss: 386.3380 - val_loss: 647.7744\n",
      "Epoch 956/1000\n",
      "308/308 [==============================] - 0s 939us/step - loss: 386.3372 - val_loss: 647.7506\n",
      "Epoch 957/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 386.3378 - val_loss: 647.7555\n",
      "Epoch 958/1000\n",
      "308/308 [==============================] - 0s 950us/step - loss: 386.3384 - val_loss: 647.7635\n",
      "Epoch 959/1000\n",
      "308/308 [==============================] - 0s 864us/step - loss: 386.3370 - val_loss: 647.7673\n",
      "Epoch 960/1000\n",
      "308/308 [==============================] - 0s 850us/step - loss: 386.3377 - val_loss: 647.7593\n",
      "Epoch 961/1000\n",
      "308/308 [==============================] - 0s 839us/step - loss: 386.3369 - val_loss: 647.7330\n",
      "Epoch 962/1000\n",
      "308/308 [==============================] - 0s 959us/step - loss: 386.3384 - val_loss: 647.7625\n",
      "Epoch 963/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3380 - val_loss: 647.7318\n",
      "Epoch 964/1000\n",
      "308/308 [==============================] - 0s 895us/step - loss: 386.3376 - val_loss: 647.7667\n",
      "Epoch 965/1000\n",
      "308/308 [==============================] - 0s 929us/step - loss: 386.3391 - val_loss: 647.7587\n",
      "Epoch 966/1000\n",
      "308/308 [==============================] - 0s 828us/step - loss: 386.3379 - val_loss: 647.7162\n",
      "Epoch 967/1000\n",
      "308/308 [==============================] - 0s 898us/step - loss: 386.3379 - val_loss: 647.7209\n",
      "Epoch 968/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 386.3372 - val_loss: 647.7344\n",
      "Epoch 969/1000\n",
      "308/308 [==============================] - 0s 898us/step - loss: 386.3373 - val_loss: 647.7835\n",
      "Epoch 970/1000\n",
      "308/308 [==============================] - 0s 884us/step - loss: 386.3376 - val_loss: 647.7738\n",
      "Epoch 971/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 386.3371 - val_loss: 647.7522\n",
      "Epoch 972/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3402 - val_loss: 647.7845\n",
      "Epoch 973/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 386.3388 - val_loss: 647.7335\n",
      "Epoch 974/1000\n",
      "308/308 [==============================] - 0s 915us/step - loss: 386.3391 - val_loss: 647.7471\n",
      "Epoch 975/1000\n",
      "308/308 [==============================] - 0s 933us/step - loss: 386.3370 - val_loss: 647.7778\n",
      "Epoch 976/1000\n",
      "308/308 [==============================] - 0s 921us/step - loss: 386.3376 - val_loss: 647.7874\n",
      "Epoch 977/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3384 - val_loss: 647.7388\n",
      "Epoch 978/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 386.3380 - val_loss: 647.8248\n",
      "Epoch 979/1000\n",
      "308/308 [==============================] - 0s 966us/step - loss: 386.3375 - val_loss: 647.8112\n",
      "Epoch 980/1000\n",
      "308/308 [==============================] - 0s 926us/step - loss: 386.3399 - val_loss: 647.6976\n",
      "Epoch 981/1000\n",
      "308/308 [==============================] - 0s 950us/step - loss: 386.3382 - val_loss: 647.7756\n",
      "Epoch 982/1000\n",
      "308/308 [==============================] - 0s 932us/step - loss: 386.3370 - val_loss: 647.7665\n",
      "Epoch 983/1000\n",
      "308/308 [==============================] - 0s 924us/step - loss: 386.3372 - val_loss: 647.7474\n",
      "Epoch 984/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308/308 [==============================] - 0s 837us/step - loss: 386.3376 - val_loss: 647.7737\n",
      "Epoch 985/1000\n",
      "308/308 [==============================] - 0s 881us/step - loss: 386.3388 - val_loss: 647.7062\n",
      "Epoch 986/1000\n",
      "308/308 [==============================] - 0s 904us/step - loss: 386.3382 - val_loss: 647.8026\n",
      "Epoch 987/1000\n",
      "308/308 [==============================] - 0s 923us/step - loss: 386.3372 - val_loss: 647.7896\n",
      "Epoch 988/1000\n",
      "308/308 [==============================] - 0s 885us/step - loss: 386.3377 - val_loss: 647.7436\n",
      "Epoch 989/1000\n",
      "308/308 [==============================] - 0s 900us/step - loss: 386.3384 - val_loss: 647.7717\n",
      "Epoch 990/1000\n",
      "308/308 [==============================] - 0s 871us/step - loss: 386.3379 - val_loss: 647.7748\n",
      "Epoch 991/1000\n",
      "308/308 [==============================] - 0s 879us/step - loss: 386.3381 - val_loss: 647.7742\n",
      "Epoch 992/1000\n",
      "308/308 [==============================] - 0s 826us/step - loss: 386.3395 - val_loss: 647.8182\n",
      "Epoch 993/1000\n",
      "308/308 [==============================] - 0s 897us/step - loss: 386.3389 - val_loss: 647.7795\n",
      "Epoch 994/1000\n",
      "308/308 [==============================] - 0s 893us/step - loss: 386.3379 - val_loss: 647.7772\n",
      "Epoch 995/1000\n",
      "308/308 [==============================] - 0s 892us/step - loss: 386.3387 - val_loss: 647.7733\n",
      "Epoch 996/1000\n",
      "308/308 [==============================] - 0s 854us/step - loss: 386.3380 - val_loss: 647.8379\n",
      "Epoch 997/1000\n",
      "308/308 [==============================] - 0s 908us/step - loss: 386.3372 - val_loss: 647.7681\n",
      "Epoch 998/1000\n",
      "308/308 [==============================] - 0s 919us/step - loss: 386.3389 - val_loss: 647.7902\n",
      "Epoch 999/1000\n",
      "308/308 [==============================] - 0s 878us/step - loss: 386.3375 - val_loss: 647.7468\n",
      "Epoch 1000/1000\n",
      "308/308 [==============================] - 0s 857us/step - loss: 386.3386 - val_loss: 647.6965\n",
      "43/43 [==============================] - 0s 539us/step\n",
      "1290038 successful\n",
      "Epoch 1/1000\n",
      "290/290 [==============================] - 1s 1ms/step - loss: 20756472.0000 - val_loss: 654.7694\n",
      "Epoch 2/1000\n",
      "290/290 [==============================] - 0s 922us/step - loss: 304.8403 - val_loss: 770.2894\n",
      "Epoch 3/1000\n",
      "290/290 [==============================] - 0s 893us/step - loss: 310.3583 - val_loss: 660.3877\n",
      "Epoch 4/1000\n",
      "290/290 [==============================] - 0s 928us/step - loss: 320.2625 - val_loss: 759.0458\n",
      "Epoch 5/1000\n",
      "290/290 [==============================] - 0s 837us/step - loss: 354.1628 - val_loss: 1235.3998\n",
      "Epoch 6/1000\n",
      "290/290 [==============================] - 0s 902us/step - loss: 356.6682 - val_loss: 636.0472\n",
      "Epoch 7/1000\n",
      "290/290 [==============================] - 0s 942us/step - loss: 353.0153 - val_loss: 785.9225\n",
      "Epoch 8/1000\n",
      "290/290 [==============================] - 0s 850us/step - loss: 338.1691 - val_loss: 696.5483\n",
      "Epoch 9/1000\n",
      "290/290 [==============================] - 0s 826us/step - loss: 435.8800 - val_loss: 686.6355\n",
      "Epoch 10/1000\n",
      "290/290 [==============================] - 0s 879us/step - loss: 382.7626 - val_loss: 745.0225\n",
      "Epoch 11/1000\n",
      "290/290 [==============================] - 0s 846us/step - loss: 647.5295 - val_loss: 966.2797\n",
      "Epoch 12/1000\n",
      "290/290 [==============================] - 0s 892us/step - loss: 540.1024 - val_loss: 654.3099\n",
      "Epoch 13/1000\n",
      "290/290 [==============================] - 0s 883us/step - loss: 788.6780 - val_loss: 1605.9360\n",
      "Epoch 14/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 2216.7368 - val_loss: 631.0293\n",
      "Epoch 15/1000\n",
      "290/290 [==============================] - 0s 860us/step - loss: 70650.0938 - val_loss: 5882.1421\n",
      "Epoch 16/1000\n",
      "290/290 [==============================] - 0s 937us/step - loss: 112130.7266 - val_loss: 35205.6641\n",
      "Epoch 17/1000\n",
      "290/290 [==============================] - 0s 902us/step - loss: 62945.6523 - val_loss: 835.8620\n",
      "Epoch 18/1000\n",
      "290/290 [==============================] - 0s 866us/step - loss: 117334.0625 - val_loss: 40537.5195\n",
      "Epoch 19/1000\n",
      "290/290 [==============================] - 0s 847us/step - loss: 76958.0781 - val_loss: 17953.7754\n",
      "Epoch 20/1000\n",
      "290/290 [==============================] - 0s 907us/step - loss: 84571.9141 - val_loss: 726.4526\n",
      "Epoch 21/1000\n",
      "290/290 [==============================] - 0s 873us/step - loss: 73704.5000 - val_loss: 303178.9688\n",
      "Epoch 22/1000\n",
      "290/290 [==============================] - 0s 867us/step - loss: 82419.6562 - val_loss: 17926.9453\n",
      "Epoch 23/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 76738.1250 - val_loss: 103987.5781\n",
      "Epoch 24/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 87870.5938 - val_loss: 25190.1836\n",
      "Epoch 25/1000\n",
      "290/290 [==============================] - 0s 915us/step - loss: 82419.3672 - val_loss: 44035.3047\n",
      "Epoch 26/1000\n",
      "290/290 [==============================] - 0s 861us/step - loss: 92941.1406 - val_loss: 47319.7891\n",
      "Epoch 27/1000\n",
      "290/290 [==============================] - 0s 926us/step - loss: 49455.3477 - val_loss: 733.2623\n",
      "Epoch 28/1000\n",
      "290/290 [==============================] - 0s 863us/step - loss: 69967.1875 - val_loss: 2447.8423\n",
      "Epoch 29/1000\n",
      "290/290 [==============================] - 0s 917us/step - loss: 62921.8008 - val_loss: 91630.9062\n",
      "Epoch 30/1000\n",
      "290/290 [==============================] - 0s 915us/step - loss: 682208.8750 - val_loss: 1156.8224\n",
      "Epoch 31/1000\n",
      "290/290 [==============================] - 0s 837us/step - loss: 612.7990 - val_loss: 781.3448\n",
      "Epoch 32/1000\n",
      "290/290 [==============================] - 0s 899us/step - loss: 697.8611 - val_loss: 1234.8878\n",
      "Epoch 33/1000\n",
      "290/290 [==============================] - 0s 948us/step - loss: 1483.5898 - val_loss: 4882.4741\n",
      "Epoch 34/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 71808.9844 - val_loss: 788.5835\n",
      "Epoch 35/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 72780.2188 - val_loss: 627.2106\n",
      "Epoch 36/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 48774.4023 - val_loss: 144887.8438\n",
      "Epoch 37/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 64136.9453 - val_loss: 15352.8730\n",
      "Epoch 38/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 57664.2852 - val_loss: 10387.9775\n",
      "Epoch 39/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 64986.6055 - val_loss: 109206.7656\n",
      "Epoch 40/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 65066.5625 - val_loss: 21734.9844\n",
      "Epoch 41/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 60734.8750 - val_loss: 683.3213\n",
      "Epoch 42/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 54040.7383 - val_loss: 59898.3359\n",
      "Epoch 43/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 55056.2969 - val_loss: 650.0755\n",
      "Epoch 44/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 65358.2539 - val_loss: 56774.2617\n",
      "Epoch 45/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 50053.8906 - val_loss: 5419.8428\n",
      "Epoch 46/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 55168.7539 - val_loss: 19464.1816\n",
      "Epoch 47/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 47183.1055 - val_loss: 16662.0312\n",
      "Epoch 48/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 53680.0625 - val_loss: 42195.9531\n",
      "Epoch 49/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 51122.0391 - val_loss: 670.0105\n",
      "Epoch 50/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 47227.9648 - val_loss: 59368.1914\n",
      "Epoch 51/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 49512.0234 - val_loss: 74596.2891\n",
      "Epoch 52/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 50484.3906 - val_loss: 8923.1104\n",
      "Epoch 53/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 42742.4922 - val_loss: 677.5428\n",
      "Epoch 54/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 44040.3203 - val_loss: 80482.0469\n",
      "Epoch 55/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 38452.7188 - val_loss: 29554.6934\n",
      "Epoch 56/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 43098.5430 - val_loss: 29668.0117\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 1s 2ms/step - loss: 47851.1484 - val_loss: 1886.3965\n",
      "Epoch 58/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 39976.7422 - val_loss: 913.2894\n",
      "Epoch 59/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 38553.4336 - val_loss: 31982.5605\n",
      "Epoch 60/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 43640.7031 - val_loss: 59895.8984\n",
      "Epoch 61/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 28686.5293 - val_loss: 1737.9132\n",
      "Epoch 62/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 39196.9062 - val_loss: 3069.0601\n",
      "Epoch 63/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 30770.6211 - val_loss: 18334.5898\n",
      "Epoch 64/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 35521.7500 - val_loss: 4878.2285\n",
      "Epoch 65/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 34582.8359 - val_loss: 3634.8052\n",
      "Epoch 66/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 28273.7578 - val_loss: 3385.3416\n",
      "Epoch 67/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 35378.2188 - val_loss: 26151.6973\n",
      "Epoch 68/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 36451.0273 - val_loss: 3211.1448\n",
      "Epoch 69/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 24839.2754 - val_loss: 5712.0835\n",
      "Epoch 70/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 29087.4824 - val_loss: 8827.8682\n",
      "Epoch 71/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 30223.3125 - val_loss: 1834.1840\n",
      "Epoch 72/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 31520.4062 - val_loss: 10766.1631\n",
      "Epoch 73/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 1162617.6250 - val_loss: 1085.3463\n",
      "Epoch 74/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 339.5430 - val_loss: 654.8385\n",
      "Epoch 75/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 363.4704 - val_loss: 766.7722\n",
      "Epoch 76/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 368.1504 - val_loss: 649.0942\n",
      "Epoch 77/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 414.5542 - val_loss: 748.8164\n",
      "Epoch 78/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 409.9646 - val_loss: 643.5982\n",
      "Epoch 79/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 643.2546 - val_loss: 689.2570\n",
      "Epoch 80/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 611.8575 - val_loss: 979.3631\n",
      "Epoch 81/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 764.2802 - val_loss: 679.9625\n",
      "Epoch 82/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 1252.2218 - val_loss: 3786.0479\n",
      "Epoch 83/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 7749.3335 - val_loss: 1019.3868\n",
      "Epoch 84/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 20941.6680 - val_loss: 9160.4512\n",
      "Epoch 85/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 19622.5723 - val_loss: 674.8544\n",
      "Epoch 86/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 20478.0918 - val_loss: 20466.7266\n",
      "Epoch 87/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 15839.4844 - val_loss: 21205.7383\n",
      "Epoch 88/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 19244.3887 - val_loss: 3329.5425\n",
      "Epoch 89/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 18671.1523 - val_loss: 1974.1962\n",
      "Epoch 90/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 15063.1309 - val_loss: 28449.3828\n",
      "Epoch 91/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 17537.2637 - val_loss: 30205.1777\n",
      "Epoch 92/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 11004.2510 - val_loss: 2112.8091\n",
      "Epoch 93/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 12722.8965 - val_loss: 62612.6289\n",
      "Epoch 94/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 13518.7705 - val_loss: 25615.4805\n",
      "Epoch 95/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 12794.1543 - val_loss: 40601.4023\n",
      "Epoch 96/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 15252.2598 - val_loss: 63902.0273\n",
      "Epoch 97/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 12239.8037 - val_loss: 2688.4810\n",
      "Epoch 98/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 13885.8896 - val_loss: 7547.4790\n",
      "Epoch 99/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 12636.0469 - val_loss: 625.9153\n",
      "Epoch 100/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 13614.6846 - val_loss: 8531.9170\n",
      "Epoch 101/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 11941.7979 - val_loss: 1942.5884\n",
      "Epoch 102/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 12119.6455 - val_loss: 8799.9004\n",
      "Epoch 103/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 12183.8691 - val_loss: 49952.4805\n",
      "Epoch 104/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 13467.3916 - val_loss: 869.9785\n",
      "Epoch 105/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 10609.1582 - val_loss: 4940.2295\n",
      "Epoch 106/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 11095.9980 - val_loss: 2552.5176\n",
      "Epoch 107/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 11083.8447 - val_loss: 1044.5420\n",
      "Epoch 108/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 11713.3623 - val_loss: 17009.0996\n",
      "Epoch 109/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 10598.3193 - val_loss: 4365.6177\n",
      "Epoch 110/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 9782.2500 - val_loss: 59238.4375\n",
      "Epoch 111/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 11601.1670 - val_loss: 10485.4941\n",
      "Epoch 112/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 10015.1025 - val_loss: 33161.5820\n",
      "Epoch 113/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 9632.8877 - val_loss: 5741.9121\n",
      "Epoch 114/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 9139.1641 - val_loss: 1202.4060\n",
      "Epoch 115/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 11142.9863 - val_loss: 3540.4968\n",
      "Epoch 116/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 9053.6758 - val_loss: 17081.1621\n",
      "Epoch 117/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 9271.2666 - val_loss: 1053.6956\n",
      "Epoch 118/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 8672.1406 - val_loss: 2752.4636\n",
      "Epoch 119/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 7304.1597 - val_loss: 2429.1799\n",
      "Epoch 120/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 9201.2500 - val_loss: 5472.8828\n",
      "Epoch 121/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 8062.3384 - val_loss: 9028.0967\n",
      "Epoch 122/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 8324.2793 - val_loss: 21770.8379\n",
      "Epoch 123/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 7853.3403 - val_loss: 10613.4707\n",
      "Epoch 124/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 7661.9849 - val_loss: 17491.8027\n",
      "Epoch 125/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 115899.6484 - val_loss: 5136.1724\n",
      "Epoch 126/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 550.2466 - val_loss: 1157.0624\n",
      "Epoch 127/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 420.3387 - val_loss: 948.2248\n",
      "Epoch 128/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 495.3980 - val_loss: 1950.3362\n",
      "Epoch 129/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 654.6583 - val_loss: 650.2048\n",
      "Epoch 130/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 1203.4379 - val_loss: 826.2803\n",
      "Epoch 131/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 1s 2ms/step - loss: 1193.6125 - val_loss: 1354.3174\n",
      "Epoch 132/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 4320.5273 - val_loss: 738.3676\n",
      "Epoch 133/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 5154.6289 - val_loss: 20917.9395\n",
      "Epoch 134/1000\n",
      "290/290 [==============================] - 0s 931us/step - loss: 6574.4492 - val_loss: 10850.5312\n",
      "Epoch 135/1000\n",
      "290/290 [==============================] - 0s 867us/step - loss: 5423.1338 - val_loss: 623.6799\n",
      "Epoch 136/1000\n",
      "290/290 [==============================] - 0s 913us/step - loss: 5993.5742 - val_loss: 2523.9185\n",
      "Epoch 137/1000\n",
      "290/290 [==============================] - 0s 881us/step - loss: 5511.2817 - val_loss: 1574.9293\n",
      "Epoch 138/1000\n",
      "290/290 [==============================] - 0s 891us/step - loss: 4957.2544 - val_loss: 6072.2021\n",
      "Epoch 139/1000\n",
      "290/290 [==============================] - 0s 813us/step - loss: 6221.7998 - val_loss: 8900.0508\n",
      "Epoch 140/1000\n",
      "290/290 [==============================] - 0s 807us/step - loss: 3477.7388 - val_loss: 2046.2242\n",
      "Epoch 141/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 2960.4299 - val_loss: 2968.2485\n",
      "Epoch 142/1000\n",
      "290/290 [==============================] - 0s 864us/step - loss: 5355.3823 - val_loss: 1037.8115\n",
      "Epoch 143/1000\n",
      "290/290 [==============================] - 0s 913us/step - loss: 3054.1851 - val_loss: 10097.5068\n",
      "Epoch 144/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 4232.3276 - val_loss: 1788.6051\n",
      "Epoch 145/1000\n",
      "290/290 [==============================] - 0s 911us/step - loss: 3204.7441 - val_loss: 1210.3519\n",
      "Epoch 146/1000\n",
      "290/290 [==============================] - 0s 841us/step - loss: 4148.6577 - val_loss: 3844.7598\n",
      "Epoch 147/1000\n",
      "290/290 [==============================] - 0s 945us/step - loss: 4420.3228 - val_loss: 8507.6348\n",
      "Epoch 148/1000\n",
      "290/290 [==============================] - 0s 974us/step - loss: 3218.7651 - val_loss: 2700.6799\n",
      "Epoch 149/1000\n",
      "290/290 [==============================] - 0s 933us/step - loss: 3635.9590 - val_loss: 778.5471\n",
      "Epoch 150/1000\n",
      "290/290 [==============================] - 0s 871us/step - loss: 3294.8445 - val_loss: 3796.3333\n",
      "Epoch 151/1000\n",
      "290/290 [==============================] - 0s 848us/step - loss: 3095.0398 - val_loss: 4157.0317\n",
      "Epoch 152/1000\n",
      "290/290 [==============================] - 0s 833us/step - loss: 4011.3184 - val_loss: 13259.5908\n",
      "Epoch 153/1000\n",
      "290/290 [==============================] - 0s 866us/step - loss: 2691.1348 - val_loss: 626.8486\n",
      "Epoch 154/1000\n",
      "290/290 [==============================] - 0s 856us/step - loss: 3271.0776 - val_loss: 7844.6211\n",
      "Epoch 155/1000\n",
      "290/290 [==============================] - 0s 886us/step - loss: 2866.1768 - val_loss: 1028.1846\n",
      "Epoch 156/1000\n",
      "290/290 [==============================] - 0s 801us/step - loss: 3097.2646 - val_loss: 623.7366\n",
      "Epoch 157/1000\n",
      "290/290 [==============================] - 0s 918us/step - loss: 4164.1782 - val_loss: 7896.7031\n",
      "Epoch 158/1000\n",
      "290/290 [==============================] - 0s 837us/step - loss: 2507.3608 - val_loss: 6141.7554\n",
      "Epoch 159/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 3521.7388 - val_loss: 2151.6829\n",
      "Epoch 160/1000\n",
      "290/290 [==============================] - 0s 839us/step - loss: 1910.7109 - val_loss: 761.2803\n",
      "Epoch 161/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 2994.3562 - val_loss: 5280.7041\n",
      "Epoch 162/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 3109.4292 - val_loss: 5150.5845\n",
      "Epoch 163/1000\n",
      "290/290 [==============================] - 0s 901us/step - loss: 2743.9597 - val_loss: 624.4354\n",
      "Epoch 164/1000\n",
      "290/290 [==============================] - 0s 955us/step - loss: 2708.7856 - val_loss: 13245.2041\n",
      "Epoch 165/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 2113.1655 - val_loss: 6965.6714\n",
      "Epoch 166/1000\n",
      "290/290 [==============================] - 0s 916us/step - loss: 2589.1072 - val_loss: 2268.3088\n",
      "Epoch 167/1000\n",
      "290/290 [==============================] - 0s 866us/step - loss: 1650.9607 - val_loss: 865.9016\n",
      "Epoch 168/1000\n",
      "290/290 [==============================] - 0s 837us/step - loss: 2912.0090 - val_loss: 783.4058\n",
      "Epoch 169/1000\n",
      "290/290 [==============================] - 0s 923us/step - loss: 1732.9906 - val_loss: 1470.7389\n",
      "Epoch 170/1000\n",
      "290/290 [==============================] - 0s 820us/step - loss: 2255.6792 - val_loss: 1226.2069\n",
      "Epoch 171/1000\n",
      "290/290 [==============================] - 0s 820us/step - loss: 2118.3450 - val_loss: 1348.3199\n",
      "Epoch 172/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 2206.0625 - val_loss: 1179.6569\n",
      "Epoch 173/1000\n",
      "290/290 [==============================] - 0s 910us/step - loss: 1857.0001 - val_loss: 890.8895\n",
      "Epoch 174/1000\n",
      "290/290 [==============================] - 0s 813us/step - loss: 2756.1841 - val_loss: 661.5794\n",
      "Epoch 175/1000\n",
      "290/290 [==============================] - 0s 867us/step - loss: 2141.3923 - val_loss: 2570.7312\n",
      "Epoch 176/1000\n",
      "290/290 [==============================] - 0s 823us/step - loss: 1778.8453 - val_loss: 999.0909\n",
      "Epoch 177/1000\n",
      "290/290 [==============================] - 0s 906us/step - loss: 2327.6609 - val_loss: 2274.9622\n",
      "Epoch 178/1000\n",
      "290/290 [==============================] - 0s 856us/step - loss: 2157.8662 - val_loss: 2647.4451\n",
      "Epoch 179/1000\n",
      "290/290 [==============================] - 0s 919us/step - loss: 1856.5248 - val_loss: 806.9546\n",
      "Epoch 180/1000\n",
      "290/290 [==============================] - 0s 916us/step - loss: 2017.0559 - val_loss: 3040.0071\n",
      "Epoch 181/1000\n",
      "290/290 [==============================] - 0s 913us/step - loss: 1872.8759 - val_loss: 4383.9868\n",
      "Epoch 182/1000\n",
      "290/290 [==============================] - 0s 869us/step - loss: 1900.4169 - val_loss: 853.0884\n",
      "Epoch 183/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 1600.1138 - val_loss: 1320.5887\n",
      "Epoch 184/1000\n",
      "290/290 [==============================] - 0s 907us/step - loss: 2087.8804 - val_loss: 1395.2733\n",
      "Epoch 185/1000\n",
      "290/290 [==============================] - 0s 887us/step - loss: 1642.8911 - val_loss: 2841.2754\n",
      "Epoch 186/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 2248.3845 - val_loss: 640.4171\n",
      "Epoch 187/1000\n",
      "290/290 [==============================] - 0s 872us/step - loss: 1702.2145 - val_loss: 3266.7771\n",
      "Epoch 188/1000\n",
      "290/290 [==============================] - 0s 864us/step - loss: 1708.1033 - val_loss: 1286.5586\n",
      "Epoch 189/1000\n",
      "290/290 [==============================] - 0s 875us/step - loss: 1958.4042 - val_loss: 1306.7102\n",
      "Epoch 190/1000\n",
      "290/290 [==============================] - 0s 875us/step - loss: 1888.5583 - val_loss: 2193.1282\n",
      "Epoch 191/1000\n",
      "290/290 [==============================] - 0s 834us/step - loss: 1439.8638 - val_loss: 624.4301\n",
      "Epoch 192/1000\n",
      "290/290 [==============================] - 0s 816us/step - loss: 1837.3571 - val_loss: 5972.5664\n",
      "Epoch 193/1000\n",
      "290/290 [==============================] - 0s 893us/step - loss: 2104.5686 - val_loss: 985.1586\n",
      "Epoch 194/1000\n",
      "290/290 [==============================] - 0s 891us/step - loss: 1234.2987 - val_loss: 632.1843\n",
      "Epoch 195/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 2008.3046 - val_loss: 853.5295\n",
      "Epoch 196/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 1544.0217 - val_loss: 814.0776\n",
      "Epoch 197/1000\n",
      "290/290 [==============================] - 0s 960us/step - loss: 1651.0345 - val_loss: 724.5973\n",
      "Epoch 198/1000\n",
      "290/290 [==============================] - 0s 874us/step - loss: 1526.3824 - val_loss: 711.2482\n",
      "Epoch 199/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 1512.2195 - val_loss: 1258.8320\n",
      "Epoch 200/1000\n",
      "290/290 [==============================] - 0s 871us/step - loss: 1434.2864 - val_loss: 1268.1995\n",
      "Epoch 201/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 1924.2382 - val_loss: 3124.2107\n",
      "Epoch 202/1000\n",
      "290/290 [==============================] - 0s 910us/step - loss: 1658.4644 - val_loss: 7800.8530\n",
      "Epoch 203/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 1337.8982 - val_loss: 947.2703\n",
      "Epoch 204/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 0s 918us/step - loss: 1467.7247 - val_loss: 1279.2992\n",
      "Epoch 205/1000\n",
      "290/290 [==============================] - 0s 839us/step - loss: 1385.3419 - val_loss: 1767.2139\n",
      "Epoch 206/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 1756.1503 - val_loss: 1660.3666\n",
      "Epoch 207/1000\n",
      "290/290 [==============================] - 0s 824us/step - loss: 1787.0844 - val_loss: 1306.6982\n",
      "Epoch 208/1000\n",
      "290/290 [==============================] - 0s 872us/step - loss: 1071.1780 - val_loss: 654.7180\n",
      "Epoch 209/1000\n",
      "290/290 [==============================] - 0s 850us/step - loss: 1489.7928 - val_loss: 1448.0427\n",
      "Epoch 210/1000\n",
      "290/290 [==============================] - 0s 836us/step - loss: 1124.9742 - val_loss: 633.7577\n",
      "Epoch 211/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 1484.4669 - val_loss: 631.0477\n",
      "Epoch 212/1000\n",
      "290/290 [==============================] - 0s 841us/step - loss: 1256.4736 - val_loss: 624.6357\n",
      "Epoch 213/1000\n",
      "290/290 [==============================] - 0s 839us/step - loss: 1118.0392 - val_loss: 926.4265\n",
      "Epoch 214/1000\n",
      "290/290 [==============================] - 0s 821us/step - loss: 1438.7523 - val_loss: 895.5367\n",
      "Epoch 215/1000\n",
      "290/290 [==============================] - 0s 833us/step - loss: 1143.3850 - val_loss: 635.7585\n",
      "Epoch 216/1000\n",
      "290/290 [==============================] - 0s 850us/step - loss: 1470.8414 - val_loss: 1516.8407\n",
      "Epoch 217/1000\n",
      "290/290 [==============================] - 0s 910us/step - loss: 1135.8096 - val_loss: 1372.2451\n",
      "Epoch 218/1000\n",
      "290/290 [==============================] - 0s 837us/step - loss: 1157.3424 - val_loss: 688.3471\n",
      "Epoch 219/1000\n",
      "290/290 [==============================] - 0s 911us/step - loss: 1182.7645 - val_loss: 915.7448\n",
      "Epoch 220/1000\n",
      "290/290 [==============================] - 0s 885us/step - loss: 1656.0463 - val_loss: 1081.3086\n",
      "Epoch 221/1000\n",
      "290/290 [==============================] - 0s 933us/step - loss: 1010.9325 - val_loss: 956.9067\n",
      "Epoch 222/1000\n",
      "290/290 [==============================] - 0s 901us/step - loss: 1170.8970 - val_loss: 1896.9944\n",
      "Epoch 223/1000\n",
      "290/290 [==============================] - 0s 862us/step - loss: 1197.0118 - val_loss: 624.4841\n",
      "Epoch 224/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 1254.6730 - val_loss: 624.3119\n",
      "Epoch 225/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 811.3059 - val_loss: 642.7615\n",
      "Epoch 226/1000\n",
      "290/290 [==============================] - 0s 923us/step - loss: 1034.6909 - val_loss: 2475.5037\n",
      "Epoch 227/1000\n",
      "290/290 [==============================] - 0s 898us/step - loss: 1324.9548 - val_loss: 1412.9211\n",
      "Epoch 228/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 1087.2444 - val_loss: 677.5577\n",
      "Epoch 229/1000\n",
      "290/290 [==============================] - 0s 872us/step - loss: 910.1831 - val_loss: 629.4928\n",
      "Epoch 230/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 1082.7391 - val_loss: 1284.7847\n",
      "Epoch 231/1000\n",
      "290/290 [==============================] - 0s 915us/step - loss: 1150.7983 - val_loss: 1124.0695\n",
      "Epoch 232/1000\n",
      "290/290 [==============================] - 0s 901us/step - loss: 1118.5374 - val_loss: 623.6708\n",
      "Epoch 233/1000\n",
      "290/290 [==============================] - 0s 918us/step - loss: 833.1600 - val_loss: 676.7574\n",
      "Epoch 234/1000\n",
      "290/290 [==============================] - 0s 947us/step - loss: 743.9213 - val_loss: 668.2687\n",
      "Epoch 235/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 1124.8777 - val_loss: 1729.1997\n",
      "Epoch 236/1000\n",
      "290/290 [==============================] - 0s 912us/step - loss: 837.9400 - val_loss: 705.5436\n",
      "Epoch 237/1000\n",
      "290/290 [==============================] - 0s 918us/step - loss: 730.6309 - val_loss: 665.4348\n",
      "Epoch 238/1000\n",
      "290/290 [==============================] - 0s 827us/step - loss: 1418.9000 - val_loss: 9261.6484\n",
      "Epoch 239/1000\n",
      "290/290 [==============================] - 0s 827us/step - loss: 823.6832 - val_loss: 1193.4990\n",
      "Epoch 240/1000\n",
      "290/290 [==============================] - 0s 902us/step - loss: 709.4402 - val_loss: 1102.6558\n",
      "Epoch 241/1000\n",
      "290/290 [==============================] - 0s 833us/step - loss: 793.4795 - val_loss: 1217.1044\n",
      "Epoch 242/1000\n",
      "290/290 [==============================] - 0s 846us/step - loss: 749.8903 - val_loss: 626.2793\n",
      "Epoch 243/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 877.5180 - val_loss: 626.8012\n",
      "Epoch 244/1000\n",
      "290/290 [==============================] - 0s 901us/step - loss: 904.4385 - val_loss: 1184.2235\n",
      "Epoch 245/1000\n",
      "290/290 [==============================] - 0s 904us/step - loss: 833.6829 - val_loss: 1174.1093\n",
      "Epoch 246/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 721.2673 - val_loss: 642.3846\n",
      "Epoch 247/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 7493.1323 - val_loss: 902.3833\n",
      "Epoch 248/1000\n",
      "290/290 [==============================] - 0s 871us/step - loss: 351.8767 - val_loss: 643.1489\n",
      "Epoch 249/1000\n",
      "290/290 [==============================] - 0s 897us/step - loss: 373.5701 - val_loss: 835.1189\n",
      "Epoch 250/1000\n",
      "290/290 [==============================] - 0s 859us/step - loss: 406.3817 - val_loss: 1298.9247\n",
      "Epoch 251/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 470.4177 - val_loss: 710.1062\n",
      "Epoch 252/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 430.0741 - val_loss: 729.4873\n",
      "Epoch 253/1000\n",
      "290/290 [==============================] - 0s 922us/step - loss: 478.1255 - val_loss: 662.5344\n",
      "Epoch 254/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 614.9351 - val_loss: 1700.1398\n",
      "Epoch 255/1000\n",
      "290/290 [==============================] - 0s 848us/step - loss: 484.6402 - val_loss: 1168.9429\n",
      "Epoch 256/1000\n",
      "290/290 [==============================] - 0s 908us/step - loss: 672.4201 - val_loss: 710.4211\n",
      "Epoch 257/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 605.2338 - val_loss: 901.6714\n",
      "Epoch 258/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 588.7137 - val_loss: 2240.3882\n",
      "Epoch 259/1000\n",
      "290/290 [==============================] - 0s 899us/step - loss: 576.3610 - val_loss: 1313.2637\n",
      "Epoch 260/1000\n",
      "290/290 [==============================] - 0s 857us/step - loss: 623.9095 - val_loss: 651.4938\n",
      "Epoch 261/1000\n",
      "290/290 [==============================] - 0s 933us/step - loss: 662.2784 - val_loss: 1810.8148\n",
      "Epoch 262/1000\n",
      "290/290 [==============================] - 0s 929us/step - loss: 486.0750 - val_loss: 845.5924\n",
      "Epoch 263/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 609.7141 - val_loss: 1986.0468\n",
      "Epoch 264/1000\n",
      "290/290 [==============================] - 0s 972us/step - loss: 704.2387 - val_loss: 633.3044\n",
      "Epoch 265/1000\n",
      "290/290 [==============================] - 0s 883us/step - loss: 632.6029 - val_loss: 695.5885\n",
      "Epoch 266/1000\n",
      "290/290 [==============================] - 0s 939us/step - loss: 508.8239 - val_loss: 697.5693\n",
      "Epoch 267/1000\n",
      "290/290 [==============================] - 0s 913us/step - loss: 487.5151 - val_loss: 1387.0183\n",
      "Epoch 268/1000\n",
      "290/290 [==============================] - 0s 818us/step - loss: 572.3716 - val_loss: 668.4962\n",
      "Epoch 269/1000\n",
      "290/290 [==============================] - 0s 886us/step - loss: 617.6371 - val_loss: 902.0786\n",
      "Epoch 270/1000\n",
      "290/290 [==============================] - 0s 886us/step - loss: 591.6500 - val_loss: 643.0703\n",
      "Epoch 271/1000\n",
      "290/290 [==============================] - 0s 974us/step - loss: 527.0547 - val_loss: 679.1132\n",
      "Epoch 272/1000\n",
      "290/290 [==============================] - 0s 927us/step - loss: 618.8569 - val_loss: 1034.6707\n",
      "Epoch 273/1000\n",
      "290/290 [==============================] - 0s 932us/step - loss: 395.4149 - val_loss: 1667.2765\n",
      "Epoch 274/1000\n",
      "290/290 [==============================] - 0s 866us/step - loss: 849.4791 - val_loss: 1225.4784\n",
      "Epoch 275/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 481.7677 - val_loss: 1500.4888\n",
      "Epoch 276/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 529.9876 - val_loss: 629.1429\n",
      "Epoch 277/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 493.4782 - val_loss: 652.5970\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 0s 908us/step - loss: 491.2465 - val_loss: 639.0211\n",
      "Epoch 279/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 441.1962 - val_loss: 678.3743\n",
      "Epoch 280/1000\n",
      "290/290 [==============================] - 0s 815us/step - loss: 483.0131 - val_loss: 636.4896\n",
      "Epoch 281/1000\n",
      "290/290 [==============================] - 0s 887us/step - loss: 450.6605 - val_loss: 742.6821\n",
      "Epoch 282/1000\n",
      "290/290 [==============================] - 0s 946us/step - loss: 463.5972 - val_loss: 636.9414\n",
      "Epoch 283/1000\n",
      "290/290 [==============================] - 0s 864us/step - loss: 494.5105 - val_loss: 1961.3196\n",
      "Epoch 284/1000\n",
      "290/290 [==============================] - 0s 868us/step - loss: 453.8249 - val_loss: 825.3318\n",
      "Epoch 285/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 512.6323 - val_loss: 1727.5791\n",
      "Epoch 286/1000\n",
      "290/290 [==============================] - 0s 924us/step - loss: 410.6507 - val_loss: 631.6960\n",
      "Epoch 287/1000\n",
      "290/290 [==============================] - 0s 895us/step - loss: 407.1143 - val_loss: 666.1984\n",
      "Epoch 288/1000\n",
      "290/290 [==============================] - 0s 829us/step - loss: 477.3928 - val_loss: 969.2911\n",
      "Epoch 289/1000\n",
      "290/290 [==============================] - 0s 920us/step - loss: 375.7928 - val_loss: 893.3254\n",
      "Epoch 290/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 368.0649 - val_loss: 637.3673\n",
      "Epoch 291/1000\n",
      "290/290 [==============================] - 0s 889us/step - loss: 371.9484 - val_loss: 756.7225\n",
      "Epoch 292/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 404.9922 - val_loss: 684.5728\n",
      "Epoch 293/1000\n",
      "290/290 [==============================] - 0s 896us/step - loss: 344.4222 - val_loss: 822.2709\n",
      "Epoch 294/1000\n",
      "290/290 [==============================] - 0s 927us/step - loss: 317.8316 - val_loss: 626.1235\n",
      "Epoch 295/1000\n",
      "290/290 [==============================] - 0s 896us/step - loss: 356.2514 - val_loss: 759.4944\n",
      "Epoch 296/1000\n",
      "290/290 [==============================] - 0s 859us/step - loss: 345.2214 - val_loss: 652.1120\n",
      "Epoch 297/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 317.6481 - val_loss: 656.7673\n",
      "Epoch 298/1000\n",
      "290/290 [==============================] - 0s 899us/step - loss: 309.4947 - val_loss: 785.0123\n",
      "Epoch 299/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 304.9010 - val_loss: 661.6271\n",
      "Epoch 300/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 302.0406 - val_loss: 692.7295\n",
      "Epoch 301/1000\n",
      "290/290 [==============================] - 0s 906us/step - loss: 299.3889 - val_loss: 823.6509\n",
      "Epoch 302/1000\n",
      "290/290 [==============================] - 0s 857us/step - loss: 294.3102 - val_loss: 788.0900\n",
      "Epoch 303/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 294.1812 - val_loss: 697.6143\n",
      "Epoch 304/1000\n",
      "290/290 [==============================] - 0s 857us/step - loss: 294.6671 - val_loss: 688.2438\n",
      "Epoch 305/1000\n",
      "290/290 [==============================] - 0s 893us/step - loss: 293.5788 - val_loss: 646.5952\n",
      "Epoch 306/1000\n",
      "290/290 [==============================] - 0s 828us/step - loss: 296.1973 - val_loss: 671.7126\n",
      "Epoch 307/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 295.6357 - val_loss: 699.5915\n",
      "Epoch 308/1000\n",
      "290/290 [==============================] - 0s 939us/step - loss: 294.8535 - val_loss: 654.2393\n",
      "Epoch 309/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 297.0233 - val_loss: 669.5345\n",
      "Epoch 310/1000\n",
      "290/290 [==============================] - 0s 941us/step - loss: 299.3945 - val_loss: 685.3909\n",
      "Epoch 311/1000\n",
      "290/290 [==============================] - 0s 925us/step - loss: 295.5385 - val_loss: 823.5632\n",
      "Epoch 312/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 299.8440 - val_loss: 731.0720\n",
      "Epoch 313/1000\n",
      "290/290 [==============================] - 0s 925us/step - loss: 299.4442 - val_loss: 694.6541\n",
      "Epoch 314/1000\n",
      "290/290 [==============================] - 0s 945us/step - loss: 299.3457 - val_loss: 728.6134\n",
      "Epoch 315/1000\n",
      "290/290 [==============================] - 0s 937us/step - loss: 297.6373 - val_loss: 678.1859\n",
      "Epoch 316/1000\n",
      "290/290 [==============================] - 0s 878us/step - loss: 297.9509 - val_loss: 689.2718\n",
      "Epoch 317/1000\n",
      "290/290 [==============================] - 0s 851us/step - loss: 297.7376 - val_loss: 661.3543\n",
      "Epoch 318/1000\n",
      "290/290 [==============================] - 0s 941us/step - loss: 294.9533 - val_loss: 639.5925\n",
      "Epoch 319/1000\n",
      "290/290 [==============================] - 0s 876us/step - loss: 304.2062 - val_loss: 647.4508\n",
      "Epoch 320/1000\n",
      "290/290 [==============================] - 0s 989us/step - loss: 301.3460 - val_loss: 699.1214\n",
      "Epoch 321/1000\n",
      "290/290 [==============================] - 0s 913us/step - loss: 298.6122 - val_loss: 683.6913\n",
      "Epoch 322/1000\n",
      "290/290 [==============================] - 0s 835us/step - loss: 300.1057 - val_loss: 725.0662\n",
      "Epoch 323/1000\n",
      "290/290 [==============================] - 0s 869us/step - loss: 298.7242 - val_loss: 691.6085\n",
      "Epoch 324/1000\n",
      "290/290 [==============================] - 0s 830us/step - loss: 298.8783 - val_loss: 667.9116\n",
      "Epoch 325/1000\n",
      "290/290 [==============================] - 0s 962us/step - loss: 301.3150 - val_loss: 760.9619\n",
      "Epoch 326/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 300.3674 - val_loss: 749.8013\n",
      "Epoch 327/1000\n",
      "290/290 [==============================] - 0s 916us/step - loss: 300.8857 - val_loss: 706.8384\n",
      "Epoch 328/1000\n",
      "290/290 [==============================] - 0s 896us/step - loss: 302.5852 - val_loss: 742.3054\n",
      "Epoch 329/1000\n",
      "290/290 [==============================] - 0s 944us/step - loss: 298.3970 - val_loss: 714.4045\n",
      "Epoch 330/1000\n",
      "290/290 [==============================] - 0s 891us/step - loss: 372.5796 - val_loss: 787.7867\n",
      "Epoch 331/1000\n",
      "290/290 [==============================] - 0s 942us/step - loss: 302.1736 - val_loss: 678.0460\n",
      "Epoch 332/1000\n",
      "290/290 [==============================] - 0s 921us/step - loss: 303.1521 - val_loss: 661.5800\n",
      "Epoch 333/1000\n",
      "290/290 [==============================] - 0s 938us/step - loss: 303.2373 - val_loss: 787.7853\n",
      "Epoch 334/1000\n",
      "290/290 [==============================] - 0s 910us/step - loss: 300.2442 - val_loss: 828.9135\n",
      "Epoch 335/1000\n",
      "290/290 [==============================] - 0s 863us/step - loss: 302.8824 - val_loss: 740.2018\n",
      "Epoch 336/1000\n",
      "290/290 [==============================] - 0s 879us/step - loss: 298.5338 - val_loss: 744.5661\n",
      "Epoch 337/1000\n",
      "290/290 [==============================] - 0s 876us/step - loss: 299.7907 - val_loss: 693.2135\n",
      "Epoch 338/1000\n",
      "290/290 [==============================] - 0s 923us/step - loss: 301.2009 - val_loss: 664.6078\n",
      "Epoch 339/1000\n",
      "290/290 [==============================] - 0s 893us/step - loss: 300.3485 - val_loss: 760.7664\n",
      "Epoch 340/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 301.1589 - val_loss: 679.7986\n",
      "Epoch 341/1000\n",
      "290/290 [==============================] - 0s 818us/step - loss: 298.9013 - val_loss: 677.8301\n",
      "Epoch 342/1000\n",
      "290/290 [==============================] - 0s 955us/step - loss: 297.6771 - val_loss: 656.3120\n",
      "Epoch 343/1000\n",
      "290/290 [==============================] - 0s 949us/step - loss: 298.8051 - val_loss: 722.4102\n",
      "Epoch 344/1000\n",
      "290/290 [==============================] - 0s 841us/step - loss: 300.5508 - val_loss: 685.9130\n",
      "Epoch 345/1000\n",
      "290/290 [==============================] - 0s 885us/step - loss: 301.3061 - val_loss: 630.0893\n",
      "Epoch 346/1000\n",
      "290/290 [==============================] - 0s 819us/step - loss: 297.1456 - val_loss: 769.1672\n",
      "Epoch 347/1000\n",
      "290/290 [==============================] - 0s 836us/step - loss: 300.4462 - val_loss: 866.8295\n",
      "Epoch 348/1000\n",
      "290/290 [==============================] - 0s 955us/step - loss: 299.1316 - val_loss: 633.8437\n",
      "Epoch 349/1000\n",
      "290/290 [==============================] - 0s 874us/step - loss: 299.1277 - val_loss: 784.5032\n",
      "Epoch 350/1000\n",
      "290/290 [==============================] - 0s 917us/step - loss: 301.0972 - val_loss: 735.7058\n",
      "Epoch 351/1000\n",
      "290/290 [==============================] - 0s 925us/step - loss: 296.6693 - val_loss: 788.0008\n",
      "Epoch 352/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 0s 888us/step - loss: 301.3012 - val_loss: 797.5660\n",
      "Epoch 353/1000\n",
      "290/290 [==============================] - 0s 940us/step - loss: 305.1871 - val_loss: 740.3568\n",
      "Epoch 354/1000\n",
      "290/290 [==============================] - 0s 945us/step - loss: 306.7294 - val_loss: 731.7228\n",
      "Epoch 355/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 297.6158 - val_loss: 671.2594\n",
      "Epoch 356/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 299.6463 - val_loss: 768.0320\n",
      "Epoch 357/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 303.1310 - val_loss: 753.9283\n",
      "Epoch 358/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 297.6010 - val_loss: 739.8117\n",
      "Epoch 359/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 299.6335 - val_loss: 771.9744\n",
      "Epoch 360/1000\n",
      "290/290 [==============================] - 0s 2ms/step - loss: 301.1084 - val_loss: 701.7424\n",
      "Epoch 361/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 299.2368 - val_loss: 715.8018\n",
      "Epoch 362/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 300.7094 - val_loss: 695.6024\n",
      "Epoch 363/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 300.4386 - val_loss: 672.7791\n",
      "Epoch 364/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 301.2444 - val_loss: 792.7685\n",
      "Epoch 365/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 308.6911 - val_loss: 773.7403\n",
      "Epoch 366/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.9657 - val_loss: 731.1273\n",
      "Epoch 367/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.6611 - val_loss: 702.7183\n",
      "Epoch 368/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.4922 - val_loss: 710.8466\n",
      "Epoch 369/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.3651 - val_loss: 687.9313\n",
      "Epoch 370/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 299.8045 - val_loss: 666.2936\n",
      "Epoch 371/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.9123 - val_loss: 655.9965\n",
      "Epoch 372/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 299.7182 - val_loss: 741.0335\n",
      "Epoch 373/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.5248 - val_loss: 784.1840\n",
      "Epoch 374/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 294.4329 - val_loss: 722.4899\n",
      "Epoch 375/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.9944 - val_loss: 754.6735\n",
      "Epoch 376/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 297.8557 - val_loss: 674.0075\n",
      "Epoch 377/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.3752 - val_loss: 634.7590\n",
      "Epoch 378/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 300.5305 - val_loss: 681.6404\n",
      "Epoch 379/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 297.2643 - val_loss: 662.4702\n",
      "Epoch 380/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.2454 - val_loss: 746.5635\n",
      "Epoch 381/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.4324 - val_loss: 721.5894\n",
      "Epoch 382/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.3456 - val_loss: 661.0127\n",
      "Epoch 383/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 297.8626 - val_loss: 718.0598\n",
      "Epoch 384/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 299.7896 - val_loss: 673.8646\n",
      "Epoch 385/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.1231 - val_loss: 666.9872\n",
      "Epoch 386/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.1687 - val_loss: 700.8955\n",
      "Epoch 387/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.4559 - val_loss: 698.6713\n",
      "Epoch 388/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.5376 - val_loss: 803.6160\n",
      "Epoch 389/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 299.3665 - val_loss: 665.1514\n",
      "Epoch 390/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.7215 - val_loss: 683.7287\n",
      "Epoch 391/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.2762 - val_loss: 751.4703\n",
      "Epoch 392/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.0300 - val_loss: 706.3757\n",
      "Epoch 393/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.9938 - val_loss: 777.7830\n",
      "Epoch 394/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 300.7794 - val_loss: 653.9695\n",
      "Epoch 395/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.9827 - val_loss: 700.9780\n",
      "Epoch 396/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.2265 - val_loss: 700.3197\n",
      "Epoch 397/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 298.6831 - val_loss: 703.5543\n",
      "Epoch 398/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.7584 - val_loss: 705.9105\n",
      "Epoch 399/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.2161 - val_loss: 735.1038\n",
      "Epoch 400/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.3811 - val_loss: 749.2570\n",
      "Epoch 401/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 296.8854 - val_loss: 750.0804\n",
      "Epoch 402/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 301.2121 - val_loss: 699.9056\n",
      "Epoch 403/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.7918 - val_loss: 684.7350\n",
      "Epoch 404/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.4474 - val_loss: 687.1290\n",
      "Epoch 405/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.7971 - val_loss: 723.8559\n",
      "Epoch 406/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.9348 - val_loss: 712.1815\n",
      "Epoch 407/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.9894 - val_loss: 715.4996\n",
      "Epoch 408/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.0071 - val_loss: 794.0104\n",
      "Epoch 409/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.8351 - val_loss: 698.2333\n",
      "Epoch 410/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.0108 - val_loss: 758.4524\n",
      "Epoch 411/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.3648 - val_loss: 692.1072\n",
      "Epoch 412/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.3040 - val_loss: 694.5825\n",
      "Epoch 413/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 1159.8398 - val_loss: 691.4614\n",
      "Epoch 414/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 318.6748 - val_loss: 677.4979\n",
      "Epoch 415/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 326.0266 - val_loss: 660.3676\n",
      "Epoch 416/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 326.4814 - val_loss: 741.6959\n",
      "Epoch 417/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 333.0350 - val_loss: 885.9889\n",
      "Epoch 418/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 317.5450 - val_loss: 640.2834\n",
      "Epoch 419/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 335.2834 - val_loss: 627.1198\n",
      "Epoch 420/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 331.2966 - val_loss: 687.6663\n",
      "Epoch 421/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 317.8094 - val_loss: 944.1266\n",
      "Epoch 422/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 328.4569 - val_loss: 633.7443\n",
      "Epoch 423/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 328.1771 - val_loss: 716.7654\n",
      "Epoch 424/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 329.0355 - val_loss: 665.3213\n",
      "Epoch 425/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.7867 - val_loss: 713.2968\n",
      "Epoch 426/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.9187 - val_loss: 710.5898\n",
      "Epoch 427/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.7839 - val_loss: 744.4609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.6033 - val_loss: 767.3253\n",
      "Epoch 429/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.1553 - val_loss: 719.6146\n",
      "Epoch 430/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.6790 - val_loss: 829.9402\n",
      "Epoch 431/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.6384 - val_loss: 723.1408\n",
      "Epoch 432/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.7419 - val_loss: 718.8771\n",
      "Epoch 433/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.9703 - val_loss: 660.2146\n",
      "Epoch 434/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 294.0524 - val_loss: 724.6358\n",
      "Epoch 435/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.2052 - val_loss: 702.8673\n",
      "Epoch 436/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.8671 - val_loss: 677.1450\n",
      "Epoch 437/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.6225 - val_loss: 705.1319\n",
      "Epoch 438/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.0765 - val_loss: 663.3918\n",
      "Epoch 439/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.2226 - val_loss: 698.9408\n",
      "Epoch 440/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 296.9225 - val_loss: 668.2355\n",
      "Epoch 441/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.9877 - val_loss: 684.2440\n",
      "Epoch 442/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.7986 - val_loss: 654.7937\n",
      "Epoch 443/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.6336 - val_loss: 690.2898\n",
      "Epoch 444/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 295.0708 - val_loss: 711.9479\n",
      "Epoch 445/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.5880 - val_loss: 673.7399\n",
      "Epoch 446/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.9865 - val_loss: 726.6735\n",
      "Epoch 447/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 459.4211 - val_loss: 1074.4323\n",
      "Epoch 448/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 315.0965 - val_loss: 819.5339\n",
      "Epoch 449/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 320.7086 - val_loss: 627.2656\n",
      "Epoch 450/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 315.0715 - val_loss: 697.7253\n",
      "Epoch 451/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 302.7247 - val_loss: 845.3484\n",
      "Epoch 452/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 302.8297 - val_loss: 630.3099\n",
      "Epoch 453/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 297.5445 - val_loss: 671.7398\n",
      "Epoch 454/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.5662 - val_loss: 678.6016\n",
      "Epoch 455/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 295.2172 - val_loss: 696.4628\n",
      "Epoch 456/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 293.5343 - val_loss: 686.8939\n",
      "Epoch 457/1000\n",
      "290/290 [==============================] - 0s 940us/step - loss: 292.0324 - val_loss: 672.6257\n",
      "Epoch 458/1000\n",
      "290/290 [==============================] - 0s 869us/step - loss: 293.8168 - val_loss: 778.0956\n",
      "Epoch 459/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 293.9758 - val_loss: 673.7147\n",
      "Epoch 460/1000\n",
      "290/290 [==============================] - 0s 874us/step - loss: 293.7322 - val_loss: 740.5921\n",
      "Epoch 461/1000\n",
      "290/290 [==============================] - 0s 861us/step - loss: 293.9565 - val_loss: 705.3076\n",
      "Epoch 462/1000\n",
      "290/290 [==============================] - 0s 821us/step - loss: 292.3784 - val_loss: 654.8914\n",
      "Epoch 463/1000\n",
      "290/290 [==============================] - 0s 875us/step - loss: 293.9582 - val_loss: 683.6533\n",
      "Epoch 464/1000\n",
      "290/290 [==============================] - 0s 826us/step - loss: 293.1155 - val_loss: 640.8730\n",
      "Epoch 465/1000\n",
      "290/290 [==============================] - 0s 832us/step - loss: 293.4362 - val_loss: 680.2900\n",
      "Epoch 466/1000\n",
      "290/290 [==============================] - 0s 859us/step - loss: 293.6189 - val_loss: 666.5383\n",
      "Epoch 467/1000\n",
      "290/290 [==============================] - 0s 958us/step - loss: 292.4524 - val_loss: 702.7752\n",
      "Epoch 468/1000\n",
      "290/290 [==============================] - 0s 871us/step - loss: 293.1228 - val_loss: 715.1879\n",
      "Epoch 469/1000\n",
      "290/290 [==============================] - 0s 959us/step - loss: 293.5660 - val_loss: 687.0393\n",
      "Epoch 470/1000\n",
      "290/290 [==============================] - 0s 829us/step - loss: 294.4677 - val_loss: 656.9193\n",
      "Epoch 471/1000\n",
      "290/290 [==============================] - 0s 938us/step - loss: 293.8334 - val_loss: 661.8231\n",
      "Epoch 472/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 295.4747 - val_loss: 737.6505\n",
      "Epoch 473/1000\n",
      "290/290 [==============================] - 0s 863us/step - loss: 294.5011 - val_loss: 750.1451\n",
      "Epoch 474/1000\n",
      "290/290 [==============================] - 0s 890us/step - loss: 295.2534 - val_loss: 744.4891\n",
      "Epoch 475/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 294.4740 - val_loss: 798.0731\n",
      "Epoch 476/1000\n",
      "290/290 [==============================] - 0s 929us/step - loss: 296.0359 - val_loss: 716.8609\n",
      "Epoch 477/1000\n",
      "290/290 [==============================] - 0s 847us/step - loss: 294.9011 - val_loss: 679.9835\n",
      "Epoch 478/1000\n",
      "290/290 [==============================] - 0s 897us/step - loss: 294.2708 - val_loss: 726.9850\n",
      "Epoch 479/1000\n",
      "290/290 [==============================] - 0s 836us/step - loss: 293.4669 - val_loss: 674.5690\n",
      "Epoch 480/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 347.5372 - val_loss: 713.1761\n",
      "Epoch 481/1000\n",
      "290/290 [==============================] - 0s 889us/step - loss: 292.5623 - val_loss: 704.2286\n",
      "Epoch 482/1000\n",
      "290/290 [==============================] - 0s 921us/step - loss: 292.9141 - val_loss: 703.8328\n",
      "Epoch 483/1000\n",
      "290/290 [==============================] - 0s 811us/step - loss: 292.1468 - val_loss: 673.0632\n",
      "Epoch 484/1000\n",
      "290/290 [==============================] - 0s 797us/step - loss: 294.3198 - val_loss: 696.4776\n",
      "Epoch 485/1000\n",
      "290/290 [==============================] - 0s 907us/step - loss: 293.0346 - val_loss: 718.0616\n",
      "Epoch 486/1000\n",
      "290/290 [==============================] - 0s 906us/step - loss: 293.3845 - val_loss: 694.2693\n",
      "Epoch 487/1000\n",
      "290/290 [==============================] - 0s 896us/step - loss: 293.3095 - val_loss: 759.5157\n",
      "Epoch 488/1000\n",
      "290/290 [==============================] - 0s 848us/step - loss: 292.6692 - val_loss: 649.2134\n",
      "Epoch 489/1000\n",
      "290/290 [==============================] - 0s 922us/step - loss: 293.9897 - val_loss: 753.4271\n",
      "Epoch 490/1000\n",
      "290/290 [==============================] - 0s 846us/step - loss: 293.4930 - val_loss: 715.2083\n",
      "Epoch 491/1000\n",
      "290/290 [==============================] - 0s 928us/step - loss: 294.2886 - val_loss: 712.9879\n",
      "Epoch 492/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 293.2517 - val_loss: 701.7505\n",
      "Epoch 493/1000\n",
      "290/290 [==============================] - 0s 861us/step - loss: 292.9267 - val_loss: 680.4115\n",
      "Epoch 494/1000\n",
      "290/290 [==============================] - 0s 915us/step - loss: 295.1690 - val_loss: 707.6920\n",
      "Epoch 495/1000\n",
      "290/290 [==============================] - 0s 829us/step - loss: 294.8855 - val_loss: 689.2905\n",
      "Epoch 496/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 294.7502 - val_loss: 697.6178\n",
      "Epoch 497/1000\n",
      "290/290 [==============================] - 0s 890us/step - loss: 293.9895 - val_loss: 716.4066\n",
      "Epoch 498/1000\n",
      "290/290 [==============================] - 0s 920us/step - loss: 294.9405 - val_loss: 735.7161\n",
      "Epoch 499/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 294.0357 - val_loss: 654.4865\n",
      "Epoch 500/1000\n",
      "290/290 [==============================] - 0s 846us/step - loss: 292.5680 - val_loss: 722.7193\n",
      "Epoch 501/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 295.4321 - val_loss: 666.4571\n",
      "Epoch 502/1000\n",
      "290/290 [==============================] - 0s 892us/step - loss: 295.0119 - val_loss: 648.4330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 503/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 294.3881 - val_loss: 802.4255\n",
      "Epoch 504/1000\n",
      "290/290 [==============================] - 0s 994us/step - loss: 292.9307 - val_loss: 668.8182\n",
      "Epoch 505/1000\n",
      "290/290 [==============================] - 0s 866us/step - loss: 294.3481 - val_loss: 715.1595\n",
      "Epoch 506/1000\n",
      "290/290 [==============================] - 0s 868us/step - loss: 292.7096 - val_loss: 684.9177\n",
      "Epoch 507/1000\n",
      "290/290 [==============================] - 0s 860us/step - loss: 295.4781 - val_loss: 752.3219\n",
      "Epoch 508/1000\n",
      "290/290 [==============================] - 0s 828us/step - loss: 303.6305 - val_loss: 689.2891\n",
      "Epoch 509/1000\n",
      "290/290 [==============================] - 0s 939us/step - loss: 292.9412 - val_loss: 766.0663\n",
      "Epoch 510/1000\n",
      "290/290 [==============================] - 0s 911us/step - loss: 293.2224 - val_loss: 732.5042\n",
      "Epoch 511/1000\n",
      "290/290 [==============================] - 0s 950us/step - loss: 293.3116 - val_loss: 655.8837\n",
      "Epoch 512/1000\n",
      "290/290 [==============================] - 0s 865us/step - loss: 292.1888 - val_loss: 682.5674\n",
      "Epoch 513/1000\n",
      "290/290 [==============================] - 0s 923us/step - loss: 292.9276 - val_loss: 663.0027\n",
      "Epoch 514/1000\n",
      "290/290 [==============================] - 0s 892us/step - loss: 292.5425 - val_loss: 701.6221\n",
      "Epoch 515/1000\n",
      "290/290 [==============================] - 0s 928us/step - loss: 293.4330 - val_loss: 724.5226\n",
      "Epoch 516/1000\n",
      "290/290 [==============================] - 0s 815us/step - loss: 293.3315 - val_loss: 659.3950\n",
      "Epoch 517/1000\n",
      "290/290 [==============================] - 0s 841us/step - loss: 293.3997 - val_loss: 697.1013\n",
      "Epoch 518/1000\n",
      "290/290 [==============================] - 0s 923us/step - loss: 294.8098 - val_loss: 789.4695\n",
      "Epoch 519/1000\n",
      "290/290 [==============================] - 0s 884us/step - loss: 292.1404 - val_loss: 688.5096\n",
      "Epoch 520/1000\n",
      "290/290 [==============================] - 0s 865us/step - loss: 292.9977 - val_loss: 742.1190\n",
      "Epoch 521/1000\n",
      "290/290 [==============================] - 0s 864us/step - loss: 293.3467 - val_loss: 703.9844\n",
      "Epoch 522/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 292.6350 - val_loss: 710.5734\n",
      "Epoch 523/1000\n",
      "290/290 [==============================] - 0s 865us/step - loss: 293.7961 - val_loss: 765.2505\n",
      "Epoch 524/1000\n",
      "290/290 [==============================] - 0s 829us/step - loss: 292.3990 - val_loss: 694.6152\n",
      "Epoch 525/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 302.6852 - val_loss: 735.0961\n",
      "Epoch 526/1000\n",
      "290/290 [==============================] - 0s 874us/step - loss: 294.1488 - val_loss: 686.4317\n",
      "Epoch 527/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 293.2949 - val_loss: 756.1904\n",
      "Epoch 528/1000\n",
      "290/290 [==============================] - 0s 909us/step - loss: 292.0258 - val_loss: 748.0076\n",
      "Epoch 529/1000\n",
      "290/290 [==============================] - 0s 940us/step - loss: 293.3423 - val_loss: 720.3251\n",
      "Epoch 530/1000\n",
      "290/290 [==============================] - 0s 835us/step - loss: 294.3068 - val_loss: 767.5573\n",
      "Epoch 531/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 293.6706 - val_loss: 729.1343\n",
      "Epoch 532/1000\n",
      "290/290 [==============================] - 0s 871us/step - loss: 292.6075 - val_loss: 672.5414\n",
      "Epoch 533/1000\n",
      "290/290 [==============================] - 0s 891us/step - loss: 293.1410 - val_loss: 708.6257\n",
      "Epoch 534/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 292.5358 - val_loss: 732.4366\n",
      "Epoch 535/1000\n",
      "290/290 [==============================] - 0s 908us/step - loss: 293.0586 - val_loss: 754.4684\n",
      "Epoch 536/1000\n",
      "290/290 [==============================] - 0s 921us/step - loss: 292.1708 - val_loss: 678.8308\n",
      "Epoch 537/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 292.9468 - val_loss: 646.2770\n",
      "Epoch 538/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 292.2642 - val_loss: 672.8690\n",
      "Epoch 539/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 293.2438 - val_loss: 690.5310\n",
      "Epoch 540/1000\n",
      "290/290 [==============================] - 0s 879us/step - loss: 293.3660 - val_loss: 722.0078\n",
      "Epoch 541/1000\n",
      "290/290 [==============================] - 0s 888us/step - loss: 292.0220 - val_loss: 666.2023\n",
      "Epoch 542/1000\n",
      "290/290 [==============================] - 0s 839us/step - loss: 292.5470 - val_loss: 669.8758\n",
      "Epoch 543/1000\n",
      "290/290 [==============================] - 0s 985us/step - loss: 291.9449 - val_loss: 656.9439\n",
      "Epoch 544/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 292.1071 - val_loss: 769.8329\n",
      "Epoch 545/1000\n",
      "290/290 [==============================] - 0s 921us/step - loss: 294.4782 - val_loss: 704.3994\n",
      "Epoch 546/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 292.5858 - val_loss: 697.8576\n",
      "Epoch 547/1000\n",
      "290/290 [==============================] - 0s 943us/step - loss: 294.2643 - val_loss: 699.6121\n",
      "Epoch 548/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 293.1818 - val_loss: 720.5121\n",
      "Epoch 549/1000\n",
      "290/290 [==============================] - 0s 860us/step - loss: 292.5338 - val_loss: 721.2114\n",
      "Epoch 550/1000\n",
      "290/290 [==============================] - 0s 861us/step - loss: 293.7209 - val_loss: 668.6641\n",
      "Epoch 551/1000\n",
      "290/290 [==============================] - 0s 924us/step - loss: 293.5096 - val_loss: 691.1829\n",
      "Epoch 552/1000\n",
      "290/290 [==============================] - 0s 862us/step - loss: 292.8496 - val_loss: 684.9758\n",
      "Epoch 553/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 292.4388 - val_loss: 721.9261\n",
      "Epoch 554/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 292.9293 - val_loss: 720.8340\n",
      "Epoch 555/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 293.2690 - val_loss: 757.8909\n",
      "Epoch 556/1000\n",
      "290/290 [==============================] - 0s 913us/step - loss: 293.1273 - val_loss: 677.5569\n",
      "Epoch 557/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 293.1856 - val_loss: 703.3388\n",
      "Epoch 558/1000\n",
      "290/290 [==============================] - 0s 878us/step - loss: 293.2221 - val_loss: 749.5115\n",
      "Epoch 559/1000\n",
      "290/290 [==============================] - 0s 885us/step - loss: 293.5568 - val_loss: 655.6876\n",
      "Epoch 560/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 293.0718 - val_loss: 674.2469\n",
      "Epoch 561/1000\n",
      "290/290 [==============================] - 0s 893us/step - loss: 292.9575 - val_loss: 750.2622\n",
      "Epoch 562/1000\n",
      "290/290 [==============================] - 0s 887us/step - loss: 293.6926 - val_loss: 706.7682\n",
      "Epoch 563/1000\n",
      "290/290 [==============================] - 0s 933us/step - loss: 293.2610 - val_loss: 741.8936\n",
      "Epoch 564/1000\n",
      "290/290 [==============================] - 0s 861us/step - loss: 292.2979 - val_loss: 711.9260\n",
      "Epoch 565/1000\n",
      "290/290 [==============================] - 0s 924us/step - loss: 293.7947 - val_loss: 685.0676\n",
      "Epoch 566/1000\n",
      "290/290 [==============================] - 0s 850us/step - loss: 291.7198 - val_loss: 714.8354\n",
      "Epoch 567/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 294.3063 - val_loss: 727.7163\n",
      "Epoch 568/1000\n",
      "290/290 [==============================] - 0s 909us/step - loss: 293.4127 - val_loss: 676.4846\n",
      "Epoch 569/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 292.4817 - val_loss: 700.5017\n",
      "Epoch 570/1000\n",
      "290/290 [==============================] - 0s 864us/step - loss: 294.1974 - val_loss: 659.7146\n",
      "Epoch 571/1000\n",
      "290/290 [==============================] - 0s 925us/step - loss: 292.8985 - val_loss: 754.0397\n",
      "Epoch 572/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 292.8606 - val_loss: 713.1472\n",
      "Epoch 573/1000\n",
      "290/290 [==============================] - 0s 896us/step - loss: 293.0331 - val_loss: 663.7802\n",
      "Epoch 574/1000\n",
      "290/290 [==============================] - 0s 883us/step - loss: 292.7802 - val_loss: 720.0759\n",
      "Epoch 575/1000\n",
      "290/290 [==============================] - 0s 898us/step - loss: 293.2105 - val_loss: 679.3917\n",
      "Epoch 576/1000\n",
      "290/290 [==============================] - 0s 929us/step - loss: 291.9925 - val_loss: 729.4694\n",
      "Epoch 577/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 0s 845us/step - loss: 292.2238 - val_loss: 718.9926\n",
      "Epoch 578/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 291.9751 - val_loss: 767.7231\n",
      "Epoch 579/1000\n",
      "290/290 [==============================] - 0s 885us/step - loss: 292.5426 - val_loss: 685.4666\n",
      "Epoch 580/1000\n",
      "290/290 [==============================] - 0s 913us/step - loss: 294.9507 - val_loss: 721.6780\n",
      "Epoch 581/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 292.5025 - val_loss: 700.7040\n",
      "Epoch 582/1000\n",
      "290/290 [==============================] - 0s 865us/step - loss: 292.0879 - val_loss: 679.4053\n",
      "Epoch 583/1000\n",
      "290/290 [==============================] - 0s 926us/step - loss: 292.3428 - val_loss: 707.4781\n",
      "Epoch 584/1000\n",
      "290/290 [==============================] - 0s 878us/step - loss: 293.6310 - val_loss: 686.4215\n",
      "Epoch 585/1000\n",
      "290/290 [==============================] - 0s 910us/step - loss: 293.1336 - val_loss: 679.6974\n",
      "Epoch 586/1000\n",
      "290/290 [==============================] - 0s 813us/step - loss: 292.1268 - val_loss: 717.5630\n",
      "Epoch 587/1000\n",
      "290/290 [==============================] - 0s 894us/step - loss: 292.6631 - val_loss: 663.6833\n",
      "Epoch 588/1000\n",
      "290/290 [==============================] - 0s 899us/step - loss: 293.4536 - val_loss: 668.9993\n",
      "Epoch 589/1000\n",
      "290/290 [==============================] - 0s 891us/step - loss: 293.8436 - val_loss: 727.6807\n",
      "Epoch 590/1000\n",
      "290/290 [==============================] - 0s 879us/step - loss: 292.3992 - val_loss: 705.9317\n",
      "Epoch 591/1000\n",
      "290/290 [==============================] - 0s 866us/step - loss: 292.5772 - val_loss: 759.0835\n",
      "Epoch 592/1000\n",
      "290/290 [==============================] - 0s 916us/step - loss: 315.7763 - val_loss: 758.7614\n",
      "Epoch 593/1000\n",
      "290/290 [==============================] - 0s 848us/step - loss: 295.9174 - val_loss: 727.7533\n",
      "Epoch 594/1000\n",
      "290/290 [==============================] - 0s 920us/step - loss: 296.0290 - val_loss: 661.5964\n",
      "Epoch 595/1000\n",
      "290/290 [==============================] - 0s 852us/step - loss: 295.7484 - val_loss: 711.4661\n",
      "Epoch 596/1000\n",
      "290/290 [==============================] - 0s 934us/step - loss: 293.3104 - val_loss: 745.6876\n",
      "Epoch 597/1000\n",
      "290/290 [==============================] - 0s 948us/step - loss: 298.0689 - val_loss: 670.2390\n",
      "Epoch 598/1000\n",
      "290/290 [==============================] - 0s 938us/step - loss: 294.6350 - val_loss: 699.3746\n",
      "Epoch 599/1000\n",
      "290/290 [==============================] - 0s 942us/step - loss: 294.1218 - val_loss: 647.8845\n",
      "Epoch 600/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 293.8740 - val_loss: 706.7641\n",
      "Epoch 601/1000\n",
      "290/290 [==============================] - 0s 851us/step - loss: 295.4155 - val_loss: 640.4237\n",
      "Epoch 602/1000\n",
      "290/290 [==============================] - 0s 894us/step - loss: 295.2836 - val_loss: 678.7811\n",
      "Epoch 603/1000\n",
      "290/290 [==============================] - 0s 867us/step - loss: 297.6505 - val_loss: 635.1580\n",
      "Epoch 604/1000\n",
      "290/290 [==============================] - 0s 838us/step - loss: 293.8756 - val_loss: 736.9548\n",
      "Epoch 605/1000\n",
      "290/290 [==============================] - 0s 868us/step - loss: 293.3273 - val_loss: 657.2549\n",
      "Epoch 606/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 293.8676 - val_loss: 736.8818\n",
      "Epoch 607/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 295.7881 - val_loss: 708.2618\n",
      "Epoch 608/1000\n",
      "290/290 [==============================] - 0s 901us/step - loss: 294.1707 - val_loss: 655.5684\n",
      "Epoch 609/1000\n",
      "290/290 [==============================] - 0s 886us/step - loss: 294.5043 - val_loss: 706.3521\n",
      "Epoch 610/1000\n",
      "290/290 [==============================] - 0s 890us/step - loss: 294.5627 - val_loss: 807.0849\n",
      "Epoch 611/1000\n",
      "290/290 [==============================] - 0s 901us/step - loss: 295.6338 - val_loss: 757.8323\n",
      "Epoch 612/1000\n",
      "290/290 [==============================] - 0s 898us/step - loss: 293.3151 - val_loss: 692.1565\n",
      "Epoch 613/1000\n",
      "290/290 [==============================] - 0s 828us/step - loss: 292.3850 - val_loss: 729.7576\n",
      "Epoch 614/1000\n",
      "290/290 [==============================] - 0s 898us/step - loss: 293.3017 - val_loss: 720.6013\n",
      "Epoch 615/1000\n",
      "290/290 [==============================] - 0s 891us/step - loss: 293.1897 - val_loss: 664.0690\n",
      "Epoch 616/1000\n",
      "290/290 [==============================] - 0s 920us/step - loss: 294.2371 - val_loss: 740.3235\n",
      "Epoch 617/1000\n",
      "290/290 [==============================] - 0s 831us/step - loss: 292.3745 - val_loss: 691.2911\n",
      "Epoch 618/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 293.6746 - val_loss: 656.6125\n",
      "Epoch 619/1000\n",
      "290/290 [==============================] - 0s 761us/step - loss: 294.0238 - val_loss: 733.5378\n",
      "Epoch 620/1000\n",
      "290/290 [==============================] - 0s 755us/step - loss: 293.7751 - val_loss: 733.4786\n",
      "Epoch 621/1000\n",
      "290/290 [==============================] - 0s 827us/step - loss: 293.6010 - val_loss: 698.1915\n",
      "Epoch 622/1000\n",
      "290/290 [==============================] - 0s 872us/step - loss: 292.3712 - val_loss: 754.4316\n",
      "Epoch 623/1000\n",
      "290/290 [==============================] - 0s 839us/step - loss: 294.0976 - val_loss: 748.7391\n",
      "Epoch 624/1000\n",
      "290/290 [==============================] - 0s 758us/step - loss: 294.3872 - val_loss: 664.5699\n",
      "Epoch 625/1000\n",
      "290/290 [==============================] - 0s 838us/step - loss: 292.9268 - val_loss: 696.5864\n",
      "Epoch 626/1000\n",
      "290/290 [==============================] - 0s 801us/step - loss: 293.8220 - val_loss: 668.3771\n",
      "Epoch 627/1000\n",
      "290/290 [==============================] - 0s 931us/step - loss: 293.6154 - val_loss: 696.6919\n",
      "Epoch 628/1000\n",
      "290/290 [==============================] - 0s 828us/step - loss: 292.4010 - val_loss: 685.6545\n",
      "Epoch 629/1000\n",
      "290/290 [==============================] - 0s 950us/step - loss: 292.6206 - val_loss: 698.5343\n",
      "Epoch 630/1000\n",
      "290/290 [==============================] - 0s 843us/step - loss: 292.7559 - val_loss: 723.4786\n",
      "Epoch 631/1000\n",
      "290/290 [==============================] - 0s 915us/step - loss: 292.0491 - val_loss: 694.6583\n",
      "Epoch 632/1000\n",
      "290/290 [==============================] - 0s 914us/step - loss: 293.4074 - val_loss: 688.4080\n",
      "Epoch 633/1000\n",
      "290/290 [==============================] - 0s 871us/step - loss: 292.9910 - val_loss: 675.6880\n",
      "Epoch 634/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 295.0055 - val_loss: 760.7746\n",
      "Epoch 635/1000\n",
      "290/290 [==============================] - 0s 846us/step - loss: 294.0158 - val_loss: 680.0983\n",
      "Epoch 636/1000\n",
      "290/290 [==============================] - 0s 947us/step - loss: 291.8389 - val_loss: 747.5835\n",
      "Epoch 637/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 292.2201 - val_loss: 730.3453\n",
      "Epoch 638/1000\n",
      "290/290 [==============================] - 0s 848us/step - loss: 291.7397 - val_loss: 661.4623\n",
      "Epoch 639/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 291.6399 - val_loss: 704.4426\n",
      "Epoch 640/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 292.1513 - val_loss: 731.5348\n",
      "Epoch 641/1000\n",
      "290/290 [==============================] - 0s 899us/step - loss: 292.9123 - val_loss: 689.6899\n",
      "Epoch 642/1000\n",
      "290/290 [==============================] - 0s 946us/step - loss: 293.1865 - val_loss: 701.2800\n",
      "Epoch 643/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 292.2952 - val_loss: 677.5405\n",
      "Epoch 644/1000\n",
      "290/290 [==============================] - 0s 890us/step - loss: 292.9295 - val_loss: 712.3873\n",
      "Epoch 645/1000\n",
      "290/290 [==============================] - 0s 852us/step - loss: 292.0711 - val_loss: 658.4117\n",
      "Epoch 646/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 293.9537 - val_loss: 719.9385\n",
      "Epoch 647/1000\n",
      "290/290 [==============================] - 0s 941us/step - loss: 292.2566 - val_loss: 753.3690\n",
      "Epoch 648/1000\n",
      "290/290 [==============================] - 0s 878us/step - loss: 293.4638 - val_loss: 679.6256\n",
      "Epoch 649/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 291.3310 - val_loss: 686.2721\n",
      "Epoch 650/1000\n",
      "290/290 [==============================] - 0s 851us/step - loss: 292.5341 - val_loss: 700.8611\n",
      "Epoch 651/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 0s 890us/step - loss: 292.1817 - val_loss: 697.5660\n",
      "Epoch 652/1000\n",
      "290/290 [==============================] - 0s 796us/step - loss: 292.3111 - val_loss: 717.2938\n",
      "Epoch 653/1000\n",
      "290/290 [==============================] - 0s 896us/step - loss: 292.0453 - val_loss: 739.4389\n",
      "Epoch 654/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 291.4945 - val_loss: 645.2106\n",
      "Epoch 655/1000\n",
      "290/290 [==============================] - 0s 917us/step - loss: 293.5187 - val_loss: 684.8438\n",
      "Epoch 656/1000\n",
      "290/290 [==============================] - 0s 857us/step - loss: 292.5301 - val_loss: 682.4213\n",
      "Epoch 657/1000\n",
      "290/290 [==============================] - 0s 847us/step - loss: 292.0275 - val_loss: 691.0539\n",
      "Epoch 658/1000\n",
      "290/290 [==============================] - 0s 950us/step - loss: 292.5101 - val_loss: 681.0288\n",
      "Epoch 659/1000\n",
      "290/290 [==============================] - 0s 883us/step - loss: 292.7765 - val_loss: 699.4392\n",
      "Epoch 660/1000\n",
      "290/290 [==============================] - 0s 871us/step - loss: 291.5024 - val_loss: 687.7823\n",
      "Epoch 661/1000\n",
      "290/290 [==============================] - 0s 938us/step - loss: 292.0465 - val_loss: 712.6378\n",
      "Epoch 662/1000\n",
      "290/290 [==============================] - 0s 859us/step - loss: 292.9185 - val_loss: 702.4390\n",
      "Epoch 663/1000\n",
      "290/290 [==============================] - 0s 946us/step - loss: 292.2708 - val_loss: 694.3490\n",
      "Epoch 664/1000\n",
      "290/290 [==============================] - 0s 866us/step - loss: 293.0251 - val_loss: 677.1663\n",
      "Epoch 665/1000\n",
      "290/290 [==============================] - 0s 826us/step - loss: 291.7473 - val_loss: 669.6612\n",
      "Epoch 666/1000\n",
      "290/290 [==============================] - 0s 905us/step - loss: 293.1208 - val_loss: 688.2692\n",
      "Epoch 667/1000\n",
      "290/290 [==============================] - 0s 913us/step - loss: 292.3333 - val_loss: 780.4463\n",
      "Epoch 668/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 293.0209 - val_loss: 704.9725\n",
      "Epoch 669/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 291.7597 - val_loss: 688.9077\n",
      "Epoch 670/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 292.1228 - val_loss: 771.4836\n",
      "Epoch 671/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 292.9029 - val_loss: 688.2458\n",
      "Epoch 672/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 293.0419 - val_loss: 692.3478\n",
      "Epoch 673/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 293.3189 - val_loss: 700.4084\n",
      "Epoch 674/1000\n",
      "290/290 [==============================] - 0s 2ms/step - loss: 292.1055 - val_loss: 690.6287\n",
      "Epoch 675/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.5452 - val_loss: 660.8221\n",
      "Epoch 676/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.3546 - val_loss: 689.7803\n",
      "Epoch 677/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.1044 - val_loss: 717.6613\n",
      "Epoch 678/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.6286 - val_loss: 687.5138\n",
      "Epoch 679/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.5633 - val_loss: 692.9143\n",
      "Epoch 680/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.6583 - val_loss: 689.9280\n",
      "Epoch 681/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.2776 - val_loss: 719.9904\n",
      "Epoch 682/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.0688 - val_loss: 808.6176\n",
      "Epoch 683/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.8778 - val_loss: 707.7996\n",
      "Epoch 684/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.9191 - val_loss: 678.9259\n",
      "Epoch 685/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.9569 - val_loss: 684.9744\n",
      "Epoch 686/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.8289 - val_loss: 670.8513\n",
      "Epoch 687/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.0840 - val_loss: 698.1115\n",
      "Epoch 688/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.4796 - val_loss: 735.7918\n",
      "Epoch 689/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7579 - val_loss: 674.9612\n",
      "Epoch 690/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2383 - val_loss: 677.7129\n",
      "Epoch 691/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.4731 - val_loss: 760.3365\n",
      "Epoch 692/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.1130 - val_loss: 729.3720\n",
      "Epoch 693/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7507 - val_loss: 755.2610\n",
      "Epoch 694/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.5578 - val_loss: 746.3069\n",
      "Epoch 695/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.1965 - val_loss: 677.4160\n",
      "Epoch 696/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.7260 - val_loss: 718.4365\n",
      "Epoch 697/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.5266 - val_loss: 721.8287\n",
      "Epoch 698/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.5946 - val_loss: 676.1422\n",
      "Epoch 699/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.6662 - val_loss: 670.7808\n",
      "Epoch 700/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2892 - val_loss: 710.5563\n",
      "Epoch 701/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.3759 - val_loss: 729.3521\n",
      "Epoch 702/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.9995 - val_loss: 669.5790\n",
      "Epoch 703/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7956 - val_loss: 662.4912\n",
      "Epoch 704/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.0568 - val_loss: 720.3222\n",
      "Epoch 705/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.5443 - val_loss: 704.4709\n",
      "Epoch 706/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.8287 - val_loss: 712.5530\n",
      "Epoch 707/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2489 - val_loss: 701.7111\n",
      "Epoch 708/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.5158 - val_loss: 662.1132\n",
      "Epoch 709/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.0995 - val_loss: 701.3649\n",
      "Epoch 710/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.6285 - val_loss: 675.6216\n",
      "Epoch 711/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 292.4183 - val_loss: 741.9295\n",
      "Epoch 712/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7796 - val_loss: 702.7968\n",
      "Epoch 713/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 293.3376 - val_loss: 717.3719\n",
      "Epoch 714/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 292.1604 - val_loss: 714.1203\n",
      "Epoch 715/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.5989 - val_loss: 725.4736\n",
      "Epoch 716/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.3418 - val_loss: 729.1464\n",
      "Epoch 717/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 293.7098 - val_loss: 703.0965\n",
      "Epoch 718/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 292.2819 - val_loss: 732.5963\n",
      "Epoch 719/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.0902 - val_loss: 718.1686\n",
      "Epoch 720/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.6898 - val_loss: 690.7908\n",
      "Epoch 721/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.1175 - val_loss: 678.6022\n",
      "Epoch 722/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.3276 - val_loss: 718.1152\n",
      "Epoch 723/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2440 - val_loss: 718.6144\n",
      "Epoch 724/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.0447 - val_loss: 677.1321\n",
      "Epoch 725/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.9015 - val_loss: 707.3397\n",
      "Epoch 726/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 1s 2ms/step - loss: 291.5058 - val_loss: 713.6265\n",
      "Epoch 727/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7960 - val_loss: 686.9681\n",
      "Epoch 728/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.4828 - val_loss: 676.8329\n",
      "Epoch 729/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.7832 - val_loss: 714.2757\n",
      "Epoch 730/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.0706 - val_loss: 700.3833\n",
      "Epoch 731/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.8728 - val_loss: 713.5625\n",
      "Epoch 732/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.0787 - val_loss: 700.2120\n",
      "Epoch 733/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7347 - val_loss: 720.1639\n",
      "Epoch 734/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.5251 - val_loss: 712.3069\n",
      "Epoch 735/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.4534 - val_loss: 686.9822\n",
      "Epoch 736/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.6314 - val_loss: 701.5130\n",
      "Epoch 737/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.1194 - val_loss: 702.4330\n",
      "Epoch 738/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.6033 - val_loss: 705.4579\n",
      "Epoch 739/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.1021 - val_loss: 748.2188\n",
      "Epoch 740/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.6443 - val_loss: 709.2120\n",
      "Epoch 741/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.5347 - val_loss: 660.7188\n",
      "Epoch 742/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 292.2097 - val_loss: 718.8403\n",
      "Epoch 743/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.8349 - val_loss: 680.3472\n",
      "Epoch 744/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2550 - val_loss: 690.1164\n",
      "Epoch 745/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7531 - val_loss: 712.9297\n",
      "Epoch 746/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.4256 - val_loss: 707.0621\n",
      "Epoch 747/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.6587 - val_loss: 750.6049\n",
      "Epoch 748/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.3040 - val_loss: 681.2545\n",
      "Epoch 749/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2194 - val_loss: 670.7557\n",
      "Epoch 750/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2262 - val_loss: 695.8163\n",
      "Epoch 751/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.6234 - val_loss: 703.2339\n",
      "Epoch 752/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.4285 - val_loss: 674.7653\n",
      "Epoch 753/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7354 - val_loss: 679.3768\n",
      "Epoch 754/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2832 - val_loss: 771.8468\n",
      "Epoch 755/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.6294 - val_loss: 732.7063\n",
      "Epoch 756/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.3969 - val_loss: 652.5782\n",
      "Epoch 757/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 294.2260 - val_loss: 702.6696\n",
      "Epoch 758/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.5429 - val_loss: 669.7703\n",
      "Epoch 759/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.1672 - val_loss: 738.0922\n",
      "Epoch 760/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.3967 - val_loss: 705.5435\n",
      "Epoch 761/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.8819 - val_loss: 709.5956\n",
      "Epoch 762/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.8624 - val_loss: 711.7708\n",
      "Epoch 763/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.7055 - val_loss: 747.7471\n",
      "Epoch 764/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.3756 - val_loss: 731.0020\n",
      "Epoch 765/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.9903 - val_loss: 691.3549\n",
      "Epoch 766/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.2923 - val_loss: 687.6255\n",
      "Epoch 767/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.8558 - val_loss: 684.6453\n",
      "Epoch 768/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2520 - val_loss: 705.4858\n",
      "Epoch 769/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.1098 - val_loss: 691.0164\n",
      "Epoch 770/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.1408 - val_loss: 682.1299\n",
      "Epoch 771/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.5011 - val_loss: 701.0364\n",
      "Epoch 772/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.9652 - val_loss: 718.2617\n",
      "Epoch 773/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.2162 - val_loss: 714.1420\n",
      "Epoch 774/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7341 - val_loss: 720.8282\n",
      "Epoch 775/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.1125 - val_loss: 667.9301\n",
      "Epoch 776/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 293.8840 - val_loss: 696.3195\n",
      "Epoch 777/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.6819 - val_loss: 730.4155\n",
      "Epoch 778/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.0027 - val_loss: 697.0730\n",
      "Epoch 779/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 292.1010 - val_loss: 676.7167\n",
      "Epoch 780/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 292.5875 - val_loss: 666.7277\n",
      "Epoch 781/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.4800 - val_loss: 686.0472\n",
      "Epoch 782/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 291.9325 - val_loss: 724.2709\n",
      "Epoch 783/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 293.0526 - val_loss: 698.1968\n",
      "Epoch 784/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2363 - val_loss: 708.1349\n",
      "Epoch 785/1000\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 291.7893 - val_loss: 707.0579\n",
      "Epoch 786/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.5861 - val_loss: 765.1711\n",
      "Epoch 787/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.3239 - val_loss: 765.4492\n",
      "Epoch 788/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.1558 - val_loss: 709.7451\n",
      "Epoch 789/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 292.6631 - val_loss: 694.5746\n",
      "Epoch 790/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 293.7920 - val_loss: 754.2170\n",
      "Epoch 791/1000\n",
      "290/290 [==============================] - 0s 976us/step - loss: 292.3759 - val_loss: 710.8069\n",
      "Epoch 792/1000\n",
      "290/290 [==============================] - 0s 837us/step - loss: 292.9122 - val_loss: 693.3665\n",
      "Epoch 793/1000\n",
      "290/290 [==============================] - 0s 841us/step - loss: 291.4024 - val_loss: 704.5303\n",
      "Epoch 794/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 291.5439 - val_loss: 729.0938\n",
      "Epoch 795/1000\n",
      "290/290 [==============================] - 0s 812us/step - loss: 292.9242 - val_loss: 689.0543\n",
      "Epoch 796/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 292.2538 - val_loss: 738.8877\n",
      "Epoch 797/1000\n",
      "290/290 [==============================] - 0s 805us/step - loss: 292.6642 - val_loss: 704.9111\n",
      "Epoch 798/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 292.4436 - val_loss: 673.9329\n",
      "Epoch 799/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 292.2600 - val_loss: 695.0971\n",
      "Epoch 800/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 292.1329 - val_loss: 686.0523\n",
      "Epoch 801/1000\n",
      "290/290 [==============================] - 0s 837us/step - loss: 291.4217 - val_loss: 646.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 802/1000\n",
      "290/290 [==============================] - 0s 829us/step - loss: 292.9695 - val_loss: 718.9929\n",
      "Epoch 803/1000\n",
      "290/290 [==============================] - 0s 839us/step - loss: 292.6673 - val_loss: 735.0552\n",
      "Epoch 804/1000\n",
      "290/290 [==============================] - 0s 874us/step - loss: 292.3454 - val_loss: 718.9680\n",
      "Epoch 805/1000\n",
      "290/290 [==============================] - 0s 857us/step - loss: 293.1689 - val_loss: 705.3664\n",
      "Epoch 806/1000\n",
      "290/290 [==============================] - 0s 818us/step - loss: 291.9916 - val_loss: 717.2382\n",
      "Epoch 807/1000\n",
      "290/290 [==============================] - 0s 828us/step - loss: 292.3218 - val_loss: 688.8231\n",
      "Epoch 808/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 292.2013 - val_loss: 764.1367\n",
      "Epoch 809/1000\n",
      "290/290 [==============================] - 0s 843us/step - loss: 291.9166 - val_loss: 668.3226\n",
      "Epoch 810/1000\n",
      "290/290 [==============================] - 0s 869us/step - loss: 291.8892 - val_loss: 712.7438\n",
      "Epoch 811/1000\n",
      "290/290 [==============================] - 0s 831us/step - loss: 293.0471 - val_loss: 721.7562\n",
      "Epoch 812/1000\n",
      "290/290 [==============================] - 0s 863us/step - loss: 293.0714 - val_loss: 648.4180\n",
      "Epoch 813/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 292.4464 - val_loss: 689.2682\n",
      "Epoch 814/1000\n",
      "290/290 [==============================] - 0s 869us/step - loss: 292.9674 - val_loss: 692.6500\n",
      "Epoch 815/1000\n",
      "290/290 [==============================] - 0s 886us/step - loss: 291.6187 - val_loss: 697.3840\n",
      "Epoch 816/1000\n",
      "290/290 [==============================] - 0s 897us/step - loss: 293.0617 - val_loss: 755.8141\n",
      "Epoch 817/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 292.6105 - val_loss: 681.2952\n",
      "Epoch 818/1000\n",
      "290/290 [==============================] - 0s 837us/step - loss: 292.4607 - val_loss: 698.9626\n",
      "Epoch 819/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 292.3861 - val_loss: 689.6691\n",
      "Epoch 820/1000\n",
      "290/290 [==============================] - 0s 911us/step - loss: 292.5642 - val_loss: 669.5775\n",
      "Epoch 821/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 292.0930 - val_loss: 738.3446\n",
      "Epoch 822/1000\n",
      "290/290 [==============================] - 0s 876us/step - loss: 292.0022 - val_loss: 753.1025\n",
      "Epoch 823/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 292.1294 - val_loss: 702.2232\n",
      "Epoch 824/1000\n",
      "290/290 [==============================] - 0s 805us/step - loss: 292.6713 - val_loss: 663.1938\n",
      "Epoch 825/1000\n",
      "290/290 [==============================] - 0s 899us/step - loss: 292.0168 - val_loss: 751.9525\n",
      "Epoch 826/1000\n",
      "290/290 [==============================] - 0s 898us/step - loss: 293.4069 - val_loss: 674.0860\n",
      "Epoch 827/1000\n",
      "290/290 [==============================] - 0s 838us/step - loss: 292.2001 - val_loss: 665.0370\n",
      "Epoch 828/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 293.8106 - val_loss: 731.1680\n",
      "Epoch 829/1000\n",
      "290/290 [==============================] - 0s 936us/step - loss: 292.8033 - val_loss: 682.1981\n",
      "Epoch 830/1000\n",
      "290/290 [==============================] - 0s 841us/step - loss: 292.2127 - val_loss: 716.1442\n",
      "Epoch 831/1000\n",
      "290/290 [==============================] - 0s 897us/step - loss: 292.3584 - val_loss: 727.1689\n",
      "Epoch 832/1000\n",
      "290/290 [==============================] - 0s 869us/step - loss: 292.1553 - val_loss: 654.7350\n",
      "Epoch 833/1000\n",
      "290/290 [==============================] - 0s 883us/step - loss: 291.5279 - val_loss: 690.2543\n",
      "Epoch 834/1000\n",
      "290/290 [==============================] - 0s 862us/step - loss: 292.5067 - val_loss: 700.7654\n",
      "Epoch 835/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 291.5402 - val_loss: 688.4974\n",
      "Epoch 836/1000\n",
      "290/290 [==============================] - 0s 849us/step - loss: 292.8659 - val_loss: 719.3439\n",
      "Epoch 837/1000\n",
      "290/290 [==============================] - 0s 910us/step - loss: 291.6272 - val_loss: 759.9549\n",
      "Epoch 838/1000\n",
      "290/290 [==============================] - 0s 852us/step - loss: 292.1814 - val_loss: 678.6715\n",
      "Epoch 839/1000\n",
      "290/290 [==============================] - 0s 938us/step - loss: 291.9727 - val_loss: 689.4998\n",
      "Epoch 840/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 292.6369 - val_loss: 713.8693\n",
      "Epoch 841/1000\n",
      "290/290 [==============================] - 0s 845us/step - loss: 291.8215 - val_loss: 699.9365\n",
      "Epoch 842/1000\n",
      "290/290 [==============================] - 0s 831us/step - loss: 291.8760 - val_loss: 692.9902\n",
      "Epoch 843/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 292.5737 - val_loss: 722.9327\n",
      "Epoch 844/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 291.9752 - val_loss: 676.6165\n",
      "Epoch 845/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 293.4914 - val_loss: 677.5493\n",
      "Epoch 846/1000\n",
      "290/290 [==============================] - 0s 947us/step - loss: 292.1153 - val_loss: 663.4001\n",
      "Epoch 847/1000\n",
      "290/290 [==============================] - 0s 862us/step - loss: 293.0236 - val_loss: 668.8713\n",
      "Epoch 848/1000\n",
      "290/290 [==============================] - 0s 882us/step - loss: 292.2943 - val_loss: 730.9482\n",
      "Epoch 849/1000\n",
      "290/290 [==============================] - 0s 933us/step - loss: 292.9501 - val_loss: 705.7144\n",
      "Epoch 850/1000\n",
      "290/290 [==============================] - 0s 884us/step - loss: 292.3741 - val_loss: 690.7469\n",
      "Epoch 851/1000\n",
      "290/290 [==============================] - 0s 843us/step - loss: 291.4085 - val_loss: 672.0507\n",
      "Epoch 852/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 292.6778 - val_loss: 667.0262\n",
      "Epoch 853/1000\n",
      "290/290 [==============================] - 0s 821us/step - loss: 292.0566 - val_loss: 659.7683\n",
      "Epoch 854/1000\n",
      "290/290 [==============================] - 0s 940us/step - loss: 292.0542 - val_loss: 714.4410\n",
      "Epoch 855/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 293.0050 - val_loss: 703.6594\n",
      "Epoch 856/1000\n",
      "290/290 [==============================] - 0s 864us/step - loss: 292.4518 - val_loss: 702.0285\n",
      "Epoch 857/1000\n",
      "290/290 [==============================] - 0s 892us/step - loss: 292.0698 - val_loss: 711.3466\n",
      "Epoch 858/1000\n",
      "290/290 [==============================] - 0s 873us/step - loss: 292.2427 - val_loss: 724.0543\n",
      "Epoch 859/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 291.8125 - val_loss: 708.4869\n",
      "Epoch 860/1000\n",
      "290/290 [==============================] - 0s 847us/step - loss: 291.7765 - val_loss: 691.2995\n",
      "Epoch 861/1000\n",
      "290/290 [==============================] - 0s 868us/step - loss: 292.3163 - val_loss: 744.1052\n",
      "Epoch 862/1000\n",
      "290/290 [==============================] - 0s 867us/step - loss: 292.2823 - val_loss: 693.8204\n",
      "Epoch 863/1000\n",
      "290/290 [==============================] - 0s 852us/step - loss: 292.1129 - val_loss: 689.4140\n",
      "Epoch 864/1000\n",
      "290/290 [==============================] - 0s 808us/step - loss: 292.0134 - val_loss: 682.1697\n",
      "Epoch 865/1000\n",
      "290/290 [==============================] - 0s 897us/step - loss: 291.5444 - val_loss: 676.0793\n",
      "Epoch 866/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 293.0942 - val_loss: 692.5353\n",
      "Epoch 867/1000\n",
      "290/290 [==============================] - 0s 832us/step - loss: 293.0147 - val_loss: 713.6918\n",
      "Epoch 868/1000\n",
      "290/290 [==============================] - 0s 887us/step - loss: 292.3162 - val_loss: 697.7193\n",
      "Epoch 869/1000\n",
      "290/290 [==============================] - 0s 908us/step - loss: 292.3332 - val_loss: 715.4241\n",
      "Epoch 870/1000\n",
      "290/290 [==============================] - 0s 826us/step - loss: 293.2710 - val_loss: 688.4193\n",
      "Epoch 871/1000\n",
      "290/290 [==============================] - 0s 857us/step - loss: 292.2350 - val_loss: 750.9847\n",
      "Epoch 872/1000\n",
      "290/290 [==============================] - 0s 939us/step - loss: 292.1904 - val_loss: 674.8655\n",
      "Epoch 873/1000\n",
      "290/290 [==============================] - 0s 854us/step - loss: 292.2622 - val_loss: 720.1698\n",
      "Epoch 874/1000\n",
      "290/290 [==============================] - 0s 862us/step - loss: 292.0748 - val_loss: 701.3619\n",
      "Epoch 875/1000\n",
      "290/290 [==============================] - 0s 922us/step - loss: 291.5269 - val_loss: 681.0612\n",
      "Epoch 876/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 0s 930us/step - loss: 292.2815 - val_loss: 710.2930\n",
      "Epoch 877/1000\n",
      "290/290 [==============================] - 0s 895us/step - loss: 292.5175 - val_loss: 696.2996\n",
      "Epoch 878/1000\n",
      "290/290 [==============================] - 0s 938us/step - loss: 292.7867 - val_loss: 703.2609\n",
      "Epoch 879/1000\n",
      "290/290 [==============================] - 0s 866us/step - loss: 292.2787 - val_loss: 740.7402\n",
      "Epoch 880/1000\n",
      "290/290 [==============================] - 0s 843us/step - loss: 291.8734 - val_loss: 690.1770\n",
      "Epoch 881/1000\n",
      "290/290 [==============================] - 0s 826us/step - loss: 291.8805 - val_loss: 715.5399\n",
      "Epoch 882/1000\n",
      "290/290 [==============================] - 0s 883us/step - loss: 292.1590 - val_loss: 684.4164\n",
      "Epoch 883/1000\n",
      "290/290 [==============================] - 0s 954us/step - loss: 291.7686 - val_loss: 681.4687\n",
      "Epoch 884/1000\n",
      "290/290 [==============================] - 0s 857us/step - loss: 292.0153 - val_loss: 674.2922\n",
      "Epoch 885/1000\n",
      "290/290 [==============================] - 0s 904us/step - loss: 291.9534 - val_loss: 719.7094\n",
      "Epoch 886/1000\n",
      "290/290 [==============================] - 0s 860us/step - loss: 292.1063 - val_loss: 742.6047\n",
      "Epoch 887/1000\n",
      "290/290 [==============================] - 0s 828us/step - loss: 292.2160 - val_loss: 678.2314\n",
      "Epoch 888/1000\n",
      "290/290 [==============================] - 0s 848us/step - loss: 292.5329 - val_loss: 685.1824\n",
      "Epoch 889/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 292.1735 - val_loss: 738.5838\n",
      "Epoch 890/1000\n",
      "290/290 [==============================] - 0s 863us/step - loss: 292.7338 - val_loss: 718.6779\n",
      "Epoch 891/1000\n",
      "290/290 [==============================] - 0s 896us/step - loss: 291.6353 - val_loss: 686.7501\n",
      "Epoch 892/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 292.6112 - val_loss: 684.5181\n",
      "Epoch 893/1000\n",
      "290/290 [==============================] - 0s 887us/step - loss: 292.3990 - val_loss: 663.7073\n",
      "Epoch 894/1000\n",
      "290/290 [==============================] - 0s 918us/step - loss: 292.1136 - val_loss: 727.6351\n",
      "Epoch 895/1000\n",
      "290/290 [==============================] - 0s 891us/step - loss: 291.7426 - val_loss: 723.6262\n",
      "Epoch 896/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 292.6454 - val_loss: 734.9571\n",
      "Epoch 897/1000\n",
      "290/290 [==============================] - 0s 844us/step - loss: 292.4625 - val_loss: 720.8918\n",
      "Epoch 898/1000\n",
      "290/290 [==============================] - 0s 950us/step - loss: 292.4175 - val_loss: 723.6151\n",
      "Epoch 899/1000\n",
      "290/290 [==============================] - 0s 832us/step - loss: 292.8282 - val_loss: 666.8788\n",
      "Epoch 900/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 292.6976 - val_loss: 716.7055\n",
      "Epoch 901/1000\n",
      "290/290 [==============================] - 0s 885us/step - loss: 291.6786 - val_loss: 653.9299\n",
      "Epoch 902/1000\n",
      "290/290 [==============================] - 0s 923us/step - loss: 292.6504 - val_loss: 719.5910\n",
      "Epoch 903/1000\n",
      "290/290 [==============================] - 0s 826us/step - loss: 292.6938 - val_loss: 694.4744\n",
      "Epoch 904/1000\n",
      "290/290 [==============================] - 0s 814us/step - loss: 291.6419 - val_loss: 696.1181\n",
      "Epoch 905/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 292.1019 - val_loss: 660.1962\n",
      "Epoch 906/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 292.8131 - val_loss: 736.4689\n",
      "Epoch 907/1000\n",
      "290/290 [==============================] - 0s 927us/step - loss: 292.6954 - val_loss: 699.4928\n",
      "Epoch 908/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 291.6980 - val_loss: 704.6704\n",
      "Epoch 909/1000\n",
      "290/290 [==============================] - 0s 851us/step - loss: 291.5921 - val_loss: 741.1220\n",
      "Epoch 910/1000\n",
      "290/290 [==============================] - 0s 855us/step - loss: 291.7520 - val_loss: 750.4764\n",
      "Epoch 911/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 292.5924 - val_loss: 732.6659\n",
      "Epoch 912/1000\n",
      "290/290 [==============================] - 0s 839us/step - loss: 291.9717 - val_loss: 685.6154\n",
      "Epoch 913/1000\n",
      "290/290 [==============================] - 0s 850us/step - loss: 292.4100 - val_loss: 667.4279\n",
      "Epoch 914/1000\n",
      "290/290 [==============================] - 0s 829us/step - loss: 292.5739 - val_loss: 717.2567\n",
      "Epoch 915/1000\n",
      "290/290 [==============================] - 0s 830us/step - loss: 292.8090 - val_loss: 694.1110\n",
      "Epoch 916/1000\n",
      "290/290 [==============================] - 0s 856us/step - loss: 291.8794 - val_loss: 732.6399\n",
      "Epoch 917/1000\n",
      "290/290 [==============================] - 0s 924us/step - loss: 292.5080 - val_loss: 694.9974\n",
      "Epoch 918/1000\n",
      "290/290 [==============================] - 0s 906us/step - loss: 292.5187 - val_loss: 747.5162\n",
      "Epoch 919/1000\n",
      "290/290 [==============================] - 0s 924us/step - loss: 291.4649 - val_loss: 661.0038\n",
      "Epoch 920/1000\n",
      "290/290 [==============================] - 0s 918us/step - loss: 292.6683 - val_loss: 727.4028\n",
      "Epoch 921/1000\n",
      "290/290 [==============================] - 0s 800us/step - loss: 292.6769 - val_loss: 703.2391\n",
      "Epoch 922/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 292.6192 - val_loss: 749.1583\n",
      "Epoch 923/1000\n",
      "290/290 [==============================] - 0s 840us/step - loss: 291.7560 - val_loss: 708.7877\n",
      "Epoch 924/1000\n",
      "290/290 [==============================] - 0s 935us/step - loss: 293.9299 - val_loss: 768.6599\n",
      "Epoch 925/1000\n",
      "290/290 [==============================] - 0s 891us/step - loss: 292.8636 - val_loss: 702.8873\n",
      "Epoch 926/1000\n",
      "290/290 [==============================] - 0s 952us/step - loss: 291.6161 - val_loss: 750.3116\n",
      "Epoch 927/1000\n",
      "290/290 [==============================] - 0s 873us/step - loss: 293.6967 - val_loss: 723.1534\n",
      "Epoch 928/1000\n",
      "290/290 [==============================] - 0s 828us/step - loss: 292.9988 - val_loss: 702.0936\n",
      "Epoch 929/1000\n",
      "290/290 [==============================] - 0s 883us/step - loss: 292.2816 - val_loss: 662.1315\n",
      "Epoch 930/1000\n",
      "290/290 [==============================] - 0s 842us/step - loss: 293.5721 - val_loss: 718.6445\n",
      "Epoch 931/1000\n",
      "290/290 [==============================] - 0s 826us/step - loss: 293.2655 - val_loss: 693.4917\n",
      "Epoch 932/1000\n",
      "290/290 [==============================] - 0s 885us/step - loss: 292.9659 - val_loss: 725.6522\n",
      "Epoch 933/1000\n",
      "290/290 [==============================] - 0s 903us/step - loss: 292.3648 - val_loss: 685.0840\n",
      "Epoch 934/1000\n",
      "290/290 [==============================] - 0s 901us/step - loss: 292.6689 - val_loss: 660.5230\n",
      "Epoch 935/1000\n",
      "290/290 [==============================] - 0s 895us/step - loss: 291.9305 - val_loss: 699.8729\n",
      "Epoch 936/1000\n",
      "290/290 [==============================] - 0s 865us/step - loss: 292.0367 - val_loss: 675.6196\n",
      "Epoch 937/1000\n",
      "290/290 [==============================] - 0s 862us/step - loss: 292.0901 - val_loss: 691.2957\n",
      "Epoch 938/1000\n",
      "290/290 [==============================] - 0s 843us/step - loss: 291.5990 - val_loss: 669.7635\n",
      "Epoch 939/1000\n",
      "290/290 [==============================] - 0s 859us/step - loss: 293.8625 - val_loss: 725.0028\n",
      "Epoch 940/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 292.2995 - val_loss: 717.0862\n",
      "Epoch 941/1000\n",
      "290/290 [==============================] - 0s 869us/step - loss: 292.5529 - val_loss: 709.8975\n",
      "Epoch 942/1000\n",
      "290/290 [==============================] - 0s 887us/step - loss: 292.7534 - val_loss: 732.6166\n",
      "Epoch 943/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 292.0589 - val_loss: 700.6436\n",
      "Epoch 944/1000\n",
      "290/290 [==============================] - 0s 900us/step - loss: 291.8685 - val_loss: 706.7942\n",
      "Epoch 945/1000\n",
      "290/290 [==============================] - 0s 865us/step - loss: 293.0371 - val_loss: 697.9120\n",
      "Epoch 946/1000\n",
      "290/290 [==============================] - 0s 870us/step - loss: 292.5436 - val_loss: 689.9469\n",
      "Epoch 947/1000\n",
      "290/290 [==============================] - 0s 879us/step - loss: 292.0709 - val_loss: 668.5057\n",
      "Epoch 948/1000\n",
      "290/290 [==============================] - 0s 835us/step - loss: 292.6463 - val_loss: 702.6090\n",
      "Epoch 949/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 293.0928 - val_loss: 682.1133\n",
      "Epoch 950/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290/290 [==============================] - 0s 819us/step - loss: 292.3617 - val_loss: 709.4805\n",
      "Epoch 951/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 292.2983 - val_loss: 696.5425\n",
      "Epoch 952/1000\n",
      "290/290 [==============================] - 0s 877us/step - loss: 292.9046 - val_loss: 743.1049\n",
      "Epoch 953/1000\n",
      "290/290 [==============================] - 0s 860us/step - loss: 292.1715 - val_loss: 693.9470\n",
      "Epoch 954/1000\n",
      "290/290 [==============================] - 0s 838us/step - loss: 293.9998 - val_loss: 742.1894\n",
      "Epoch 955/1000\n",
      "290/290 [==============================] - 0s 853us/step - loss: 292.2617 - val_loss: 711.6453\n",
      "Epoch 956/1000\n",
      "290/290 [==============================] - 0s 906us/step - loss: 291.4835 - val_loss: 700.1593\n",
      "Epoch 957/1000\n",
      "290/290 [==============================] - 0s 858us/step - loss: 292.2393 - val_loss: 723.8990\n",
      "Epoch 958/1000\n",
      "290/290 [==============================] - 0s 886us/step - loss: 292.1685 - val_loss: 670.9709\n",
      "Epoch 959/1000\n",
      "290/290 [==============================] - 0s 835us/step - loss: 291.8649 - val_loss: 704.8348\n",
      "Epoch 960/1000\n",
      "290/290 [==============================] - 0s 861us/step - loss: 292.0709 - val_loss: 722.3790\n",
      "Epoch 961/1000\n",
      "290/290 [==============================] - 0s 883us/step - loss: 293.9478 - val_loss: 695.8531\n",
      "Epoch 962/1000\n",
      "290/290 [==============================] - 0s 811us/step - loss: 291.5505 - val_loss: 665.6203\n",
      "Epoch 963/1000\n",
      "290/290 [==============================] - 0s 906us/step - loss: 292.6489 - val_loss: 689.5752\n",
      "Epoch 964/1000\n",
      "290/290 [==============================] - 0s 843us/step - loss: 293.3715 - val_loss: 686.7994\n",
      "Epoch 965/1000\n",
      "290/290 [==============================] - 0s 949us/step - loss: 291.3904 - val_loss: 667.9794\n",
      "Epoch 966/1000\n",
      "290/290 [==============================] - 0s 848us/step - loss: 292.5101 - val_loss: 679.3596\n",
      "Epoch 967/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 292.9028 - val_loss: 722.6280\n",
      "Epoch 968/1000\n",
      "290/290 [==============================] - 0s 961us/step - loss: 291.8633 - val_loss: 720.8226\n",
      "Epoch 969/1000\n",
      "290/290 [==============================] - 0s 926us/step - loss: 292.2534 - val_loss: 679.8846\n",
      "Epoch 970/1000\n",
      "290/290 [==============================] - 0s 880us/step - loss: 292.7780 - val_loss: 709.7116\n",
      "Epoch 971/1000\n",
      "290/290 [==============================] - 0s 848us/step - loss: 292.9005 - val_loss: 721.3317\n",
      "Epoch 972/1000\n",
      "290/290 [==============================] - 0s 851us/step - loss: 291.8994 - val_loss: 697.3552\n",
      "Epoch 973/1000\n",
      "290/290 [==============================] - 0s 948us/step - loss: 292.6209 - val_loss: 733.1324\n",
      "Epoch 974/1000\n",
      "290/290 [==============================] - 0s 879us/step - loss: 291.4946 - val_loss: 732.5539\n",
      "Epoch 975/1000\n",
      "290/290 [==============================] - 0s 918us/step - loss: 292.6439 - val_loss: 754.5135\n",
      "Epoch 976/1000\n",
      "290/290 [==============================] - 0s 867us/step - loss: 291.5730 - val_loss: 689.7297\n",
      "Epoch 977/1000\n",
      "290/290 [==============================] - 0s 862us/step - loss: 293.3175 - val_loss: 701.3152\n",
      "Epoch 978/1000\n",
      "290/290 [==============================] - 0s 839us/step - loss: 292.3386 - val_loss: 744.6310\n",
      "Epoch 979/1000\n",
      "290/290 [==============================] - 0s 895us/step - loss: 291.9891 - val_loss: 731.3814\n",
      "Epoch 980/1000\n",
      "290/290 [==============================] - 0s 878us/step - loss: 291.4746 - val_loss: 748.6952\n",
      "Epoch 981/1000\n",
      "290/290 [==============================] - 0s 896us/step - loss: 293.1326 - val_loss: 676.5831\n",
      "Epoch 982/1000\n",
      "290/290 [==============================] - 0s 918us/step - loss: 292.1838 - val_loss: 693.8769\n",
      "Epoch 983/1000\n",
      "290/290 [==============================] - 0s 920us/step - loss: 291.1865 - val_loss: 734.7008\n",
      "Epoch 984/1000\n",
      "290/290 [==============================] - 0s 927us/step - loss: 292.8601 - val_loss: 699.6923\n",
      "Epoch 985/1000\n",
      "290/290 [==============================] - 0s 910us/step - loss: 292.7791 - val_loss: 720.9907\n",
      "Epoch 986/1000\n",
      "290/290 [==============================] - 0s 852us/step - loss: 292.0573 - val_loss: 665.1287\n",
      "Epoch 987/1000\n",
      "290/290 [==============================] - 0s 831us/step - loss: 293.0860 - val_loss: 668.2715\n",
      "Epoch 988/1000\n",
      "290/290 [==============================] - 0s 862us/step - loss: 292.2666 - val_loss: 678.5313\n",
      "Epoch 989/1000\n",
      "290/290 [==============================] - 0s 932us/step - loss: 292.5746 - val_loss: 706.7794\n",
      "Epoch 990/1000\n",
      "290/290 [==============================] - 0s 998us/step - loss: 292.8386 - val_loss: 673.1509\n",
      "Epoch 991/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 291.8604 - val_loss: 702.8273\n",
      "Epoch 992/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 292.7384 - val_loss: 690.0541\n",
      "Epoch 993/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 291.8852 - val_loss: 720.2710\n",
      "Epoch 994/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 292.3759 - val_loss: 672.9521\n",
      "Epoch 995/1000\n",
      "290/290 [==============================] - 0s 1ms/step - loss: 292.8209 - val_loss: 676.9725\n",
      "Epoch 996/1000\n",
      "290/290 [==============================] - 0s 2ms/step - loss: 292.2404 - val_loss: 672.5501\n",
      "Epoch 997/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.2322 - val_loss: 731.4782\n",
      "Epoch 998/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.6716 - val_loss: 719.1714\n",
      "Epoch 999/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.7843 - val_loss: 724.8088\n",
      "Epoch 1000/1000\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 292.1266 - val_loss: 687.1047\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "1373035 successful\n",
      "Epoch 1/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 24664476.0000 - val_loss: 639.0869\n",
      "Epoch 2/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 373.6955 - val_loss: 615.6558\n",
      "Epoch 3/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 376.7850 - val_loss: 825.7573\n",
      "Epoch 4/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 378.1118 - val_loss: 594.8398\n",
      "Epoch 5/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 398.3166 - val_loss: 636.0682\n",
      "Epoch 6/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 427.3532 - val_loss: 602.5717\n",
      "Epoch 7/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 418.2115 - val_loss: 712.8991\n",
      "Epoch 8/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 442.3783 - val_loss: 875.8776\n",
      "Epoch 9/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 405.0166 - val_loss: 662.8386\n",
      "Epoch 10/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 490.7977 - val_loss: 1011.6969\n",
      "Epoch 11/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 508.1732 - val_loss: 872.5288\n",
      "Epoch 12/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 638.9139 - val_loss: 602.0145\n",
      "Epoch 13/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 586.4519 - val_loss: 606.4576\n",
      "Epoch 14/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 852.1267 - val_loss: 1483.5038\n",
      "Epoch 15/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1329.4746 - val_loss: 761.0671\n",
      "Epoch 16/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 9003.8662 - val_loss: 27794.1523\n",
      "Epoch 17/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 44506.7617 - val_loss: 9890.5361\n",
      "Epoch 18/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 47271.0586 - val_loss: 30168.0801\n",
      "Epoch 19/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 43263.8828 - val_loss: 2848.0442\n",
      "Epoch 20/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 44087.8438 - val_loss: 9053.7871\n",
      "Epoch 21/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 44214.1133 - val_loss: 38583.8477\n",
      "Epoch 22/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 41777.9727 - val_loss: 35025.9180\n",
      "Epoch 23/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 46515.8672 - val_loss: 23277.1953\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 3ms/step - loss: 39644.4297 - val_loss: 133112.8750\n",
      "Epoch 25/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 45359.4023 - val_loss: 103381.1016\n",
      "Epoch 26/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 36559.1680 - val_loss: 76425.2656\n",
      "Epoch 27/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 37830.5938 - val_loss: 259590.6250\n",
      "Epoch 28/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 42028.9102 - val_loss: 5268.6323\n",
      "Epoch 29/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 36435.4453 - val_loss: 17676.8301\n",
      "Epoch 30/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 37765.5078 - val_loss: 1402.8513\n",
      "Epoch 31/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 34439.0625 - val_loss: 4238.5269\n",
      "Epoch 32/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 31959.7305 - val_loss: 3868.6519\n",
      "Epoch 33/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 37865.3516 - val_loss: 3306.1567\n",
      "Epoch 34/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 34532.8008 - val_loss: 12373.0254\n",
      "Epoch 35/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 29344.2871 - val_loss: 33248.6445\n",
      "Epoch 36/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 35008.4492 - val_loss: 1569.0328\n",
      "Epoch 37/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 27884.7793 - val_loss: 126352.1719\n",
      "Epoch 38/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 31441.2246 - val_loss: 12338.8936\n",
      "Epoch 39/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 30617.4629 - val_loss: 8076.3774\n",
      "Epoch 40/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 27767.0586 - val_loss: 45186.9297\n",
      "Epoch 41/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 1392069.1250 - val_loss: 1337.2869\n",
      "Epoch 42/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 416.6158 - val_loss: 658.8080\n",
      "Epoch 43/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 415.6377 - val_loss: 939.8362\n",
      "Epoch 44/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 465.5345 - val_loss: 628.7222\n",
      "Epoch 45/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 489.6269 - val_loss: 722.9790\n",
      "Epoch 46/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 517.8525 - val_loss: 696.7888\n",
      "Epoch 47/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 540.5659 - val_loss: 1034.6914\n",
      "Epoch 48/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 716.0140 - val_loss: 995.7262\n",
      "Epoch 49/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1049.5123 - val_loss: 770.8054\n",
      "Epoch 50/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1400.5814 - val_loss: 890.0750\n",
      "Epoch 51/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 12858.5469 - val_loss: 99484.6484\n",
      "Epoch 52/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 20343.2012 - val_loss: 58218.3984\n",
      "Epoch 53/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 22299.6230 - val_loss: 7236.2168\n",
      "Epoch 54/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 19855.8027 - val_loss: 24280.3027\n",
      "Epoch 55/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 20961.6348 - val_loss: 4281.0107\n",
      "Epoch 56/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 19387.3516 - val_loss: 40356.5625\n",
      "Epoch 57/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 18460.2773 - val_loss: 52763.5000\n",
      "Epoch 58/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 21357.6074 - val_loss: 17794.3594\n",
      "Epoch 59/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 15932.6680 - val_loss: 32193.8945\n",
      "Epoch 60/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 18144.8828 - val_loss: 3361.6931\n",
      "Epoch 61/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 19771.3125 - val_loss: 86286.0859\n",
      "Epoch 62/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 19080.6973 - val_loss: 23210.0859\n",
      "Epoch 63/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 12559.1455 - val_loss: 2262.7329\n",
      "Epoch 64/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 17385.6816 - val_loss: 4189.0391\n",
      "Epoch 65/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 15505.8564 - val_loss: 27127.5391\n",
      "Epoch 66/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 15652.4434 - val_loss: 34376.6055\n",
      "Epoch 67/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 252736.0156 - val_loss: 90050.2500\n",
      "Epoch 68/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 26666.5801 - val_loss: 1180.0529\n",
      "Epoch 69/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 696.4290 - val_loss: 3779.3857\n",
      "Epoch 70/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 731.8204 - val_loss: 1896.4121\n",
      "Epoch 71/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 593.1953 - val_loss: 1108.0170\n",
      "Epoch 72/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 918.2421 - val_loss: 648.7538\n",
      "Epoch 73/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 1486.6002 - val_loss: 5357.8325\n",
      "Epoch 74/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 8456.9844 - val_loss: 12708.6377\n",
      "Epoch 75/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 13765.9248 - val_loss: 5783.7993\n",
      "Epoch 76/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 11446.6104 - val_loss: 4937.0068\n",
      "Epoch 77/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 12371.2686 - val_loss: 1009.0247\n",
      "Epoch 78/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 12566.5449 - val_loss: 1349.1520\n",
      "Epoch 79/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 12451.0176 - val_loss: 711.3732\n",
      "Epoch 80/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 11049.0576 - val_loss: 1104.6969\n",
      "Epoch 81/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 10191.8301 - val_loss: 12042.2529\n",
      "Epoch 82/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 12946.3096 - val_loss: 29001.8984\n",
      "Epoch 83/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 10118.3057 - val_loss: 6312.6353\n",
      "Epoch 84/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 10501.4219 - val_loss: 2958.2595\n",
      "Epoch 85/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 10560.0566 - val_loss: 23559.2910\n",
      "Epoch 86/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 9084.7725 - val_loss: 1783.6167\n",
      "Epoch 87/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9537.0508 - val_loss: 17980.0312\n",
      "Epoch 88/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 9148.4395 - val_loss: 8478.1162\n",
      "Epoch 89/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 10203.0820 - val_loss: 14012.8428\n",
      "Epoch 90/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 7968.0801 - val_loss: 29500.6641\n",
      "Epoch 91/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 9634.2002 - val_loss: 7995.8364\n",
      "Epoch 92/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 8621.3760 - val_loss: 592.4765\n",
      "Epoch 93/1000\n",
      "322/322 [==============================] - 0s 979us/step - loss: 37828.7891 - val_loss: 1593.5725\n",
      "Epoch 94/1000\n",
      "322/322 [==============================] - 0s 883us/step - loss: 641.1730 - val_loss: 1077.8219\n",
      "Epoch 95/1000\n",
      "322/322 [==============================] - 0s 858us/step - loss: 1022.2481 - val_loss: 593.4796\n",
      "Epoch 96/1000\n",
      "322/322 [==============================] - 0s 889us/step - loss: 1960.6637 - val_loss: 1199.2667\n",
      "Epoch 97/1000\n",
      "322/322 [==============================] - 0s 907us/step - loss: 3870.9636 - val_loss: 13859.6123\n",
      "Epoch 98/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 847us/step - loss: 7243.3638 - val_loss: 11473.8701\n",
      "Epoch 99/1000\n",
      "322/322 [==============================] - 0s 852us/step - loss: 5359.4336 - val_loss: 699.2726\n",
      "Epoch 100/1000\n",
      "322/322 [==============================] - 0s 832us/step - loss: 5630.8896 - val_loss: 1114.6696\n",
      "Epoch 101/1000\n",
      "322/322 [==============================] - 0s 793us/step - loss: 6092.9922 - val_loss: 865.3406\n",
      "Epoch 102/1000\n",
      "322/322 [==============================] - 0s 841us/step - loss: 6775.7666 - val_loss: 981.6812\n",
      "Epoch 103/1000\n",
      "322/322 [==============================] - 0s 891us/step - loss: 5366.0093 - val_loss: 766.9891\n",
      "Epoch 104/1000\n",
      "322/322 [==============================] - 0s 902us/step - loss: 5421.2583 - val_loss: 1924.1501\n",
      "Epoch 105/1000\n",
      "322/322 [==============================] - 0s 894us/step - loss: 6136.0195 - val_loss: 1775.4965\n",
      "Epoch 106/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 5307.6313 - val_loss: 1765.5280\n",
      "Epoch 107/1000\n",
      "322/322 [==============================] - 0s 901us/step - loss: 4383.5225 - val_loss: 3682.4470\n",
      "Epoch 108/1000\n",
      "322/322 [==============================] - 0s 849us/step - loss: 5241.7026 - val_loss: 1347.1465\n",
      "Epoch 109/1000\n",
      "322/322 [==============================] - 0s 924us/step - loss: 5159.3604 - val_loss: 5694.3770\n",
      "Epoch 110/1000\n",
      "322/322 [==============================] - 0s 918us/step - loss: 5619.7349 - val_loss: 839.2207\n",
      "Epoch 111/1000\n",
      "322/322 [==============================] - 0s 839us/step - loss: 4962.2944 - val_loss: 6012.7339\n",
      "Epoch 112/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 3857.6069 - val_loss: 7962.8252\n",
      "Epoch 113/1000\n",
      "322/322 [==============================] - 0s 863us/step - loss: 4864.8530 - val_loss: 29500.5898\n",
      "Epoch 114/1000\n",
      "322/322 [==============================] - 0s 817us/step - loss: 3903.9067 - val_loss: 632.6672\n",
      "Epoch 115/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 5014.0938 - val_loss: 2259.9441\n",
      "Epoch 116/1000\n",
      "322/322 [==============================] - 0s 830us/step - loss: 3879.2996 - val_loss: 1517.8961\n",
      "Epoch 117/1000\n",
      "322/322 [==============================] - 0s 910us/step - loss: 3522.0967 - val_loss: 610.9308\n",
      "Epoch 118/1000\n",
      "322/322 [==============================] - 0s 881us/step - loss: 3483.4355 - val_loss: 13695.8008\n",
      "Epoch 119/1000\n",
      "322/322 [==============================] - 0s 859us/step - loss: 5338.8540 - val_loss: 1353.1078\n",
      "Epoch 120/1000\n",
      "322/322 [==============================] - 0s 896us/step - loss: 3321.5474 - val_loss: 5697.3442\n",
      "Epoch 121/1000\n",
      "322/322 [==============================] - 0s 873us/step - loss: 3508.8547 - val_loss: 1348.7009\n",
      "Epoch 122/1000\n",
      "322/322 [==============================] - 0s 819us/step - loss: 3599.6821 - val_loss: 11360.2930\n",
      "Epoch 123/1000\n",
      "322/322 [==============================] - 0s 877us/step - loss: 3519.0149 - val_loss: 3223.8809\n",
      "Epoch 124/1000\n",
      "322/322 [==============================] - 0s 880us/step - loss: 3201.9277 - val_loss: 26363.2637\n",
      "Epoch 125/1000\n",
      "322/322 [==============================] - 0s 826us/step - loss: 3404.7012 - val_loss: 748.7927\n",
      "Epoch 126/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 3021.1172 - val_loss: 3687.3843\n",
      "Epoch 127/1000\n",
      "322/322 [==============================] - 0s 849us/step - loss: 3113.3601 - val_loss: 8943.4092\n",
      "Epoch 128/1000\n",
      "322/322 [==============================] - 0s 924us/step - loss: 2580.9404 - val_loss: 694.4655\n",
      "Epoch 129/1000\n",
      "322/322 [==============================] - 0s 862us/step - loss: 3441.0046 - val_loss: 596.3186\n",
      "Epoch 130/1000\n",
      "322/322 [==============================] - 0s 866us/step - loss: 3574.8899 - val_loss: 644.7324\n",
      "Epoch 131/1000\n",
      "322/322 [==============================] - 0s 887us/step - loss: 2321.5383 - val_loss: 8585.6865\n",
      "Epoch 132/1000\n",
      "322/322 [==============================] - 0s 820us/step - loss: 2281.8416 - val_loss: 959.0233\n",
      "Epoch 133/1000\n",
      "322/322 [==============================] - 0s 825us/step - loss: 2135.7603 - val_loss: 1222.0651\n",
      "Epoch 134/1000\n",
      "322/322 [==============================] - 0s 904us/step - loss: 2346.1384 - val_loss: 620.2060\n",
      "Epoch 135/1000\n",
      "322/322 [==============================] - 0s 885us/step - loss: 1323.4332 - val_loss: 2483.6235\n",
      "Epoch 136/1000\n",
      "322/322 [==============================] - 0s 855us/step - loss: 2332.4744 - val_loss: 730.8242\n",
      "Epoch 137/1000\n",
      "322/322 [==============================] - 0s 881us/step - loss: 1740.1805 - val_loss: 5341.9756\n",
      "Epoch 138/1000\n",
      "322/322 [==============================] - 0s 879us/step - loss: 2354.0955 - val_loss: 9240.0596\n",
      "Epoch 139/1000\n",
      "322/322 [==============================] - 0s 844us/step - loss: 2021.8230 - val_loss: 1479.1693\n",
      "Epoch 140/1000\n",
      "322/322 [==============================] - 0s 858us/step - loss: 2207.3342 - val_loss: 1728.7751\n",
      "Epoch 141/1000\n",
      "322/322 [==============================] - 0s 835us/step - loss: 1828.4733 - val_loss: 718.2403\n",
      "Epoch 142/1000\n",
      "322/322 [==============================] - 0s 879us/step - loss: 1388.5092 - val_loss: 625.0977\n",
      "Epoch 143/1000\n",
      "322/322 [==============================] - 0s 821us/step - loss: 2343.3044 - val_loss: 6093.6299\n",
      "Epoch 144/1000\n",
      "322/322 [==============================] - 0s 845us/step - loss: 1514.3385 - val_loss: 2813.7417\n",
      "Epoch 145/1000\n",
      "322/322 [==============================] - 0s 862us/step - loss: 2269.6614 - val_loss: 641.2281\n",
      "Epoch 146/1000\n",
      "322/322 [==============================] - 0s 865us/step - loss: 2106.0669 - val_loss: 1223.6144\n",
      "Epoch 147/1000\n",
      "322/322 [==============================] - 0s 875us/step - loss: 1262.4014 - val_loss: 11603.4648\n",
      "Epoch 148/1000\n",
      "322/322 [==============================] - 0s 907us/step - loss: 1662.2340 - val_loss: 3903.1208\n",
      "Epoch 149/1000\n",
      "322/322 [==============================] - 0s 839us/step - loss: 1634.6698 - val_loss: 1487.8224\n",
      "Epoch 150/1000\n",
      "322/322 [==============================] - 0s 817us/step - loss: 1697.0771 - val_loss: 15825.6611\n",
      "Epoch 151/1000\n",
      "322/322 [==============================] - 0s 876us/step - loss: 2095.8999 - val_loss: 590.0386\n",
      "Epoch 152/1000\n",
      "322/322 [==============================] - 0s 868us/step - loss: 1501.9215 - val_loss: 7961.9609\n",
      "Epoch 153/1000\n",
      "322/322 [==============================] - 0s 966us/step - loss: 1550.7281 - val_loss: 712.4147\n",
      "Epoch 154/1000\n",
      "322/322 [==============================] - 0s 913us/step - loss: 2118.5859 - val_loss: 1032.0500\n",
      "Epoch 155/1000\n",
      "322/322 [==============================] - 0s 904us/step - loss: 1278.0103 - val_loss: 588.9128\n",
      "Epoch 156/1000\n",
      "322/322 [==============================] - 0s 927us/step - loss: 1464.4889 - val_loss: 825.2040\n",
      "Epoch 157/1000\n",
      "322/322 [==============================] - 0s 923us/step - loss: 90513.0859 - val_loss: 662.0981\n",
      "Epoch 158/1000\n",
      "322/322 [==============================] - 0s 861us/step - loss: 453.8135 - val_loss: 605.5959\n",
      "Epoch 159/1000\n",
      "322/322 [==============================] - 0s 893us/step - loss: 432.2263 - val_loss: 687.9712\n",
      "Epoch 160/1000\n",
      "322/322 [==============================] - 0s 914us/step - loss: 495.1906 - val_loss: 696.5095\n",
      "Epoch 161/1000\n",
      "322/322 [==============================] - 0s 837us/step - loss: 564.8568 - val_loss: 960.5870\n",
      "Epoch 162/1000\n",
      "322/322 [==============================] - 0s 918us/step - loss: 568.8261 - val_loss: 1022.3910\n",
      "Epoch 163/1000\n",
      "322/322 [==============================] - 0s 904us/step - loss: 607.9249 - val_loss: 2572.1401\n",
      "Epoch 164/1000\n",
      "322/322 [==============================] - 0s 893us/step - loss: 958.5404 - val_loss: 817.1280\n",
      "Epoch 165/1000\n",
      "322/322 [==============================] - 0s 866us/step - loss: 949.7128 - val_loss: 2863.2686\n",
      "Epoch 166/1000\n",
      "322/322 [==============================] - 0s 924us/step - loss: 926.4680 - val_loss: 4229.7432\n",
      "Epoch 167/1000\n",
      "322/322 [==============================] - 0s 859us/step - loss: 1373.9751 - val_loss: 2318.2065\n",
      "Epoch 168/1000\n",
      "322/322 [==============================] - 0s 895us/step - loss: 1548.8226 - val_loss: 2886.3843\n",
      "Epoch 169/1000\n",
      "322/322 [==============================] - 0s 865us/step - loss: 1614.9362 - val_loss: 664.1710\n",
      "Epoch 170/1000\n",
      "322/322 [==============================] - 0s 832us/step - loss: 1402.8820 - val_loss: 889.7743\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 856us/step - loss: 1647.6860 - val_loss: 589.6570\n",
      "Epoch 172/1000\n",
      "322/322 [==============================] - 0s 901us/step - loss: 1474.9006 - val_loss: 4401.7964\n",
      "Epoch 173/1000\n",
      "322/322 [==============================] - 0s 890us/step - loss: 1868.9993 - val_loss: 588.3553\n",
      "Epoch 174/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 1165.6230 - val_loss: 1266.1069\n",
      "Epoch 175/1000\n",
      "322/322 [==============================] - 0s 925us/step - loss: 1455.1191 - val_loss: 670.3231\n",
      "Epoch 176/1000\n",
      "322/322 [==============================] - 0s 983us/step - loss: 1352.1749 - val_loss: 622.9576\n",
      "Epoch 177/1000\n",
      "322/322 [==============================] - 0s 818us/step - loss: 1161.6479 - val_loss: 9534.0244\n",
      "Epoch 178/1000\n",
      "322/322 [==============================] - 0s 932us/step - loss: 1672.0673 - val_loss: 1002.0243\n",
      "Epoch 179/1000\n",
      "322/322 [==============================] - 0s 825us/step - loss: 1344.8043 - val_loss: 3857.6143\n",
      "Epoch 180/1000\n",
      "322/322 [==============================] - 0s 809us/step - loss: 1462.3070 - val_loss: 589.5298\n",
      "Epoch 181/1000\n",
      "322/322 [==============================] - 0s 835us/step - loss: 1204.1108 - val_loss: 3084.5183\n",
      "Epoch 182/1000\n",
      "322/322 [==============================] - 0s 836us/step - loss: 1321.7333 - val_loss: 3474.9214\n",
      "Epoch 183/1000\n",
      "322/322 [==============================] - 0s 842us/step - loss: 1376.2712 - val_loss: 626.7728\n",
      "Epoch 184/1000\n",
      "322/322 [==============================] - 0s 937us/step - loss: 773.6287 - val_loss: 1804.8971\n",
      "Epoch 185/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 1338.1022 - val_loss: 645.5568\n",
      "Epoch 186/1000\n",
      "322/322 [==============================] - 0s 911us/step - loss: 1103.8173 - val_loss: 1325.6412\n",
      "Epoch 187/1000\n",
      "322/322 [==============================] - 0s 828us/step - loss: 998.4448 - val_loss: 3813.0149\n",
      "Epoch 188/1000\n",
      "322/322 [==============================] - 0s 921us/step - loss: 1481.3788 - val_loss: 1480.7758\n",
      "Epoch 189/1000\n",
      "322/322 [==============================] - 0s 827us/step - loss: 839.5762 - val_loss: 1054.2695\n",
      "Epoch 190/1000\n",
      "322/322 [==============================] - 0s 855us/step - loss: 1004.5032 - val_loss: 2506.6946\n",
      "Epoch 191/1000\n",
      "322/322 [==============================] - 0s 841us/step - loss: 1232.3772 - val_loss: 868.5316\n",
      "Epoch 192/1000\n",
      "322/322 [==============================] - 0s 881us/step - loss: 1002.2947 - val_loss: 1881.1019\n",
      "Epoch 193/1000\n",
      "322/322 [==============================] - 0s 905us/step - loss: 1025.3300 - val_loss: 671.1802\n",
      "Epoch 194/1000\n",
      "322/322 [==============================] - 0s 899us/step - loss: 1008.9208 - val_loss: 675.7262\n",
      "Epoch 195/1000\n",
      "322/322 [==============================] - 0s 916us/step - loss: 900.1207 - val_loss: 2044.3024\n",
      "Epoch 196/1000\n",
      "322/322 [==============================] - 0s 909us/step - loss: 1083.8873 - val_loss: 589.2437\n",
      "Epoch 197/1000\n",
      "322/322 [==============================] - 0s 835us/step - loss: 927.4796 - val_loss: 940.5590\n",
      "Epoch 198/1000\n",
      "322/322 [==============================] - 0s 840us/step - loss: 1070.2378 - val_loss: 2000.1239\n",
      "Epoch 199/1000\n",
      "322/322 [==============================] - 0s 790us/step - loss: 920.4083 - val_loss: 1054.8141\n",
      "Epoch 200/1000\n",
      "322/322 [==============================] - 0s 887us/step - loss: 912.6390 - val_loss: 696.9448\n",
      "Epoch 201/1000\n",
      "322/322 [==============================] - 0s 842us/step - loss: 858.1423 - val_loss: 1958.8145\n",
      "Epoch 202/1000\n",
      "322/322 [==============================] - 0s 869us/step - loss: 767.5970 - val_loss: 1545.2096\n",
      "Epoch 203/1000\n",
      "322/322 [==============================] - 0s 890us/step - loss: 908.9469 - val_loss: 837.8625\n",
      "Epoch 204/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 868.2200 - val_loss: 699.8062\n",
      "Epoch 205/1000\n",
      "322/322 [==============================] - 0s 823us/step - loss: 891.4600 - val_loss: 607.7101\n",
      "Epoch 206/1000\n",
      "322/322 [==============================] - 0s 954us/step - loss: 723.1246 - val_loss: 597.1268\n",
      "Epoch 207/1000\n",
      "322/322 [==============================] - 0s 833us/step - loss: 601.4426 - val_loss: 1606.8845\n",
      "Epoch 208/1000\n",
      "322/322 [==============================] - 0s 897us/step - loss: 799.3821 - val_loss: 838.1412\n",
      "Epoch 209/1000\n",
      "322/322 [==============================] - 0s 925us/step - loss: 702.7496 - val_loss: 598.4160\n",
      "Epoch 210/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 804.0835 - val_loss: 992.5947\n",
      "Epoch 211/1000\n",
      "322/322 [==============================] - 0s 987us/step - loss: 651.5884 - val_loss: 2456.1926\n",
      "Epoch 212/1000\n",
      "322/322 [==============================] - 0s 861us/step - loss: 735.2398 - val_loss: 1716.3397\n",
      "Epoch 213/1000\n",
      "322/322 [==============================] - 0s 917us/step - loss: 693.3791 - val_loss: 656.1644\n",
      "Epoch 214/1000\n",
      "322/322 [==============================] - 0s 830us/step - loss: 661.4083 - val_loss: 1020.9265\n",
      "Epoch 215/1000\n",
      "322/322 [==============================] - 0s 821us/step - loss: 588.2219 - val_loss: 1003.1913\n",
      "Epoch 216/1000\n",
      "322/322 [==============================] - 0s 921us/step - loss: 623.3456 - val_loss: 609.1542\n",
      "Epoch 217/1000\n",
      "322/322 [==============================] - 0s 978us/step - loss: 608.5985 - val_loss: 1086.9735\n",
      "Epoch 218/1000\n",
      "322/322 [==============================] - 0s 838us/step - loss: 567.7423 - val_loss: 671.7198\n",
      "Epoch 219/1000\n",
      "322/322 [==============================] - 0s 881us/step - loss: 657.7775 - val_loss: 604.3850\n",
      "Epoch 220/1000\n",
      "322/322 [==============================] - 0s 965us/step - loss: 626.1968 - val_loss: 763.0145\n",
      "Epoch 221/1000\n",
      "322/322 [==============================] - 0s 897us/step - loss: 588.4532 - val_loss: 917.9987\n",
      "Epoch 222/1000\n",
      "322/322 [==============================] - 0s 896us/step - loss: 527.0539 - val_loss: 620.3700\n",
      "Epoch 223/1000\n",
      "322/322 [==============================] - 0s 887us/step - loss: 481.7017 - val_loss: 624.9941\n",
      "Epoch 224/1000\n",
      "322/322 [==============================] - 0s 851us/step - loss: 558.0394 - val_loss: 631.2310\n",
      "Epoch 225/1000\n",
      "322/322 [==============================] - 0s 839us/step - loss: 479.8271 - val_loss: 600.1949\n",
      "Epoch 226/1000\n",
      "322/322 [==============================] - 0s 871us/step - loss: 557.5225 - val_loss: 626.7350\n",
      "Epoch 227/1000\n",
      "322/322 [==============================] - 0s 856us/step - loss: 454.8669 - val_loss: 751.6973\n",
      "Epoch 228/1000\n",
      "322/322 [==============================] - 0s 909us/step - loss: 468.7821 - val_loss: 877.4093\n",
      "Epoch 229/1000\n",
      "322/322 [==============================] - 0s 866us/step - loss: 466.2277 - val_loss: 598.7343\n",
      "Epoch 230/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 432.6419 - val_loss: 598.6627\n",
      "Epoch 231/1000\n",
      "322/322 [==============================] - 0s 880us/step - loss: 417.5758 - val_loss: 592.4299\n",
      "Epoch 232/1000\n",
      "322/322 [==============================] - 0s 851us/step - loss: 409.7904 - val_loss: 653.4470\n",
      "Epoch 233/1000\n",
      "322/322 [==============================] - 0s 923us/step - loss: 406.1420 - val_loss: 723.7870\n",
      "Epoch 234/1000\n",
      "322/322 [==============================] - 0s 846us/step - loss: 383.7964 - val_loss: 592.4763\n",
      "Epoch 235/1000\n",
      "322/322 [==============================] - 0s 883us/step - loss: 374.4319 - val_loss: 634.3419\n",
      "Epoch 236/1000\n",
      "322/322 [==============================] - 0s 816us/step - loss: 371.8032 - val_loss: 663.7957\n",
      "Epoch 237/1000\n",
      "322/322 [==============================] - 0s 913us/step - loss: 363.9638 - val_loss: 676.9064\n",
      "Epoch 238/1000\n",
      "322/322 [==============================] - 0s 842us/step - loss: 358.9711 - val_loss: 597.2896\n",
      "Epoch 239/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 362.1256 - val_loss: 652.3150\n",
      "Epoch 240/1000\n",
      "322/322 [==============================] - 0s 881us/step - loss: 362.1379 - val_loss: 652.5609\n",
      "Epoch 241/1000\n",
      "322/322 [==============================] - 0s 844us/step - loss: 361.1329 - val_loss: 654.3012\n",
      "Epoch 242/1000\n",
      "322/322 [==============================] - 0s 863us/step - loss: 365.3701 - val_loss: 600.1413\n",
      "Epoch 243/1000\n",
      "322/322 [==============================] - 0s 926us/step - loss: 368.2820 - val_loss: 639.3809\n",
      "Epoch 244/1000\n",
      "322/322 [==============================] - 0s 843us/step - loss: 366.0573 - val_loss: 625.7017\n",
      "Epoch 245/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 922us/step - loss: 368.1914 - val_loss: 622.8882\n",
      "Epoch 246/1000\n",
      "322/322 [==============================] - 0s 868us/step - loss: 369.5207 - val_loss: 619.0448\n",
      "Epoch 247/1000\n",
      "322/322 [==============================] - 0s 875us/step - loss: 368.0540 - val_loss: 611.0216\n",
      "Epoch 248/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 371.8049 - val_loss: 654.0281\n",
      "Epoch 249/1000\n",
      "322/322 [==============================] - 0s 847us/step - loss: 380.4728 - val_loss: 649.8409\n",
      "Epoch 250/1000\n",
      "322/322 [==============================] - 0s 850us/step - loss: 368.9879 - val_loss: 675.4279\n",
      "Epoch 251/1000\n",
      "322/322 [==============================] - 0s 863us/step - loss: 365.9653 - val_loss: 635.0643\n",
      "Epoch 252/1000\n",
      "322/322 [==============================] - 0s 820us/step - loss: 364.5882 - val_loss: 611.4453\n",
      "Epoch 253/1000\n",
      "322/322 [==============================] - 0s 851us/step - loss: 369.4598 - val_loss: 647.3684\n",
      "Epoch 254/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 367.7087 - val_loss: 661.6517\n",
      "Epoch 255/1000\n",
      "322/322 [==============================] - 0s 975us/step - loss: 369.6007 - val_loss: 637.3699\n",
      "Epoch 256/1000\n",
      "322/322 [==============================] - 0s 894us/step - loss: 370.8529 - val_loss: 589.5036\n",
      "Epoch 257/1000\n",
      "322/322 [==============================] - 0s 924us/step - loss: 443.9657 - val_loss: 671.7863\n",
      "Epoch 258/1000\n",
      "322/322 [==============================] - 0s 871us/step - loss: 364.3210 - val_loss: 620.6168\n",
      "Epoch 259/1000\n",
      "322/322 [==============================] - 0s 893us/step - loss: 362.3675 - val_loss: 716.8621\n",
      "Epoch 260/1000\n",
      "322/322 [==============================] - 0s 870us/step - loss: 363.9092 - val_loss: 611.8550\n",
      "Epoch 261/1000\n",
      "322/322 [==============================] - 0s 868us/step - loss: 366.2917 - val_loss: 635.3364\n",
      "Epoch 262/1000\n",
      "322/322 [==============================] - 0s 940us/step - loss: 367.9673 - val_loss: 689.2415\n",
      "Epoch 263/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 366.1389 - val_loss: 672.1791\n",
      "Epoch 264/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 369.5695 - val_loss: 607.7844\n",
      "Epoch 265/1000\n",
      "322/322 [==============================] - 0s 918us/step - loss: 370.2213 - val_loss: 646.5461\n",
      "Epoch 266/1000\n",
      "322/322 [==============================] - 0s 860us/step - loss: 367.5545 - val_loss: 618.8483\n",
      "Epoch 267/1000\n",
      "322/322 [==============================] - 0s 903us/step - loss: 364.6185 - val_loss: 645.6290\n",
      "Epoch 268/1000\n",
      "322/322 [==============================] - 0s 894us/step - loss: 366.8964 - val_loss: 595.0449\n",
      "Epoch 269/1000\n",
      "322/322 [==============================] - 0s 893us/step - loss: 365.4897 - val_loss: 661.5419\n",
      "Epoch 270/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 366.8059 - val_loss: 679.0992\n",
      "Epoch 271/1000\n",
      "322/322 [==============================] - 0s 858us/step - loss: 369.0556 - val_loss: 646.1827\n",
      "Epoch 272/1000\n",
      "322/322 [==============================] - 0s 859us/step - loss: 370.9388 - val_loss: 650.5172\n",
      "Epoch 273/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 371.4766 - val_loss: 609.8202\n",
      "Epoch 274/1000\n",
      "322/322 [==============================] - 0s 846us/step - loss: 371.0457 - val_loss: 643.9179\n",
      "Epoch 275/1000\n",
      "322/322 [==============================] - 0s 847us/step - loss: 367.3044 - val_loss: 697.3068\n",
      "Epoch 276/1000\n",
      "322/322 [==============================] - 0s 913us/step - loss: 368.8485 - val_loss: 677.5870\n",
      "Epoch 277/1000\n",
      "322/322 [==============================] - 0s 923us/step - loss: 368.4253 - val_loss: 666.1642\n",
      "Epoch 278/1000\n",
      "322/322 [==============================] - 0s 838us/step - loss: 367.0045 - val_loss: 591.7108\n",
      "Epoch 279/1000\n",
      "322/322 [==============================] - 0s 959us/step - loss: 369.7724 - val_loss: 730.0589\n",
      "Epoch 280/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 366.4327 - val_loss: 589.6805\n",
      "Epoch 281/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 375.8381 - val_loss: 594.7870\n",
      "Epoch 282/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 365.5981 - val_loss: 689.4546\n",
      "Epoch 283/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 368.2070 - val_loss: 665.6130\n",
      "Epoch 284/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 368.8503 - val_loss: 696.6337\n",
      "Epoch 285/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 375.2209 - val_loss: 589.3091\n",
      "Epoch 286/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.8602 - val_loss: 789.0073\n",
      "Epoch 287/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 372.6968 - val_loss: 683.5453\n",
      "Epoch 288/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 367.8102 - val_loss: 742.9468\n",
      "Epoch 289/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 371.8073 - val_loss: 668.2151\n",
      "Epoch 290/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 370.3677 - val_loss: 603.1603\n",
      "Epoch 291/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 375.0186 - val_loss: 677.9554\n",
      "Epoch 292/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 363.8149 - val_loss: 625.0291\n",
      "Epoch 293/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 362.8331 - val_loss: 645.0340\n",
      "Epoch 294/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 365.9998 - val_loss: 653.5040\n",
      "Epoch 295/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 366.8646 - val_loss: 610.2372\n",
      "Epoch 296/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.2481 - val_loss: 710.1144\n",
      "Epoch 297/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 370.9166 - val_loss: 659.8605\n",
      "Epoch 298/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.1931 - val_loss: 613.9841\n",
      "Epoch 299/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 369.1954 - val_loss: 694.9764\n",
      "Epoch 300/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 371.8763 - val_loss: 679.7434\n",
      "Epoch 301/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 369.2210 - val_loss: 694.6735\n",
      "Epoch 302/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 368.1696 - val_loss: 609.5961\n",
      "Epoch 303/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 372.2151 - val_loss: 595.4848\n",
      "Epoch 304/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 362.7662 - val_loss: 627.6818\n",
      "Epoch 305/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.1559 - val_loss: 709.2147\n",
      "Epoch 306/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 370.5330 - val_loss: 598.3983\n",
      "Epoch 307/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 369.1484 - val_loss: 682.1422\n",
      "Epoch 308/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.2676 - val_loss: 588.7847\n",
      "Epoch 309/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 367.6707 - val_loss: 606.6778\n",
      "Epoch 310/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.9480 - val_loss: 738.6623\n",
      "Epoch 311/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 369.4638 - val_loss: 653.4789\n",
      "Epoch 312/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 366.3209 - val_loss: 729.2599\n",
      "Epoch 313/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 365.5971 - val_loss: 610.0601\n",
      "Epoch 314/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 366.3683 - val_loss: 594.0355\n",
      "Epoch 315/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 365.0758 - val_loss: 666.5276\n",
      "Epoch 316/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.5349 - val_loss: 646.2618\n",
      "Epoch 317/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 365.2631 - val_loss: 614.5012\n",
      "Epoch 318/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 366.9133 - val_loss: 588.7515\n",
      "Epoch 319/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 372.0401 - val_loss: 765.7492\n",
      "Epoch 320/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 2ms/step - loss: 363.8883 - val_loss: 628.0909\n",
      "Epoch 321/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 368.7225 - val_loss: 592.7315\n",
      "Epoch 322/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.8782 - val_loss: 654.0247\n",
      "Epoch 323/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 367.4504 - val_loss: 603.3885\n",
      "Epoch 324/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 365.2664 - val_loss: 615.9206\n",
      "Epoch 325/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 370.9008 - val_loss: 640.1337\n",
      "Epoch 326/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.1639 - val_loss: 657.7055\n",
      "Epoch 327/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.3086 - val_loss: 692.5721\n",
      "Epoch 328/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.7745 - val_loss: 613.7823\n",
      "Epoch 329/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 369.8228 - val_loss: 602.2489\n",
      "Epoch 330/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 553.8819 - val_loss: 681.5274\n",
      "Epoch 331/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 360.7116 - val_loss: 644.5707\n",
      "Epoch 332/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.9546 - val_loss: 670.3276\n",
      "Epoch 333/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 362.0687 - val_loss: 620.1357\n",
      "Epoch 334/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 362.4794 - val_loss: 683.3768\n",
      "Epoch 335/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 362.5980 - val_loss: 638.5650\n",
      "Epoch 336/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 362.9109 - val_loss: 591.4597\n",
      "Epoch 337/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.0635 - val_loss: 654.7486\n",
      "Epoch 338/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 361.1911 - val_loss: 668.6364\n",
      "Epoch 339/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 365.3170 - val_loss: 767.0388\n",
      "Epoch 340/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.0615 - val_loss: 641.5637\n",
      "Epoch 341/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 365.1778 - val_loss: 593.5945\n",
      "Epoch 342/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 366.3811 - val_loss: 640.4482\n",
      "Epoch 343/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.4221 - val_loss: 650.0123\n",
      "Epoch 344/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 365.1276 - val_loss: 623.5654\n",
      "Epoch 345/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 364.6292 - val_loss: 642.5463\n",
      "Epoch 346/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 366.0217 - val_loss: 694.4238\n",
      "Epoch 347/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.0311 - val_loss: 604.4066\n",
      "Epoch 348/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 363.6238 - val_loss: 621.8588\n",
      "Epoch 349/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 362.3709 - val_loss: 708.2562\n",
      "Epoch 350/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.4001 - val_loss: 666.1627\n",
      "Epoch 351/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.0876 - val_loss: 662.2327\n",
      "Epoch 352/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.1809 - val_loss: 679.7654\n",
      "Epoch 353/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 365.1069 - val_loss: 623.4541\n",
      "Epoch 354/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.4031 - val_loss: 634.1779\n",
      "Epoch 355/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.0349 - val_loss: 656.5214\n",
      "Epoch 356/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.4946 - val_loss: 739.5803\n",
      "Epoch 357/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.6973 - val_loss: 650.9452\n",
      "Epoch 358/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 367.3817 - val_loss: 653.0594\n",
      "Epoch 359/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 366.1901 - val_loss: 635.4590\n",
      "Epoch 360/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 363.2433 - val_loss: 657.5308\n",
      "Epoch 361/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.9762 - val_loss: 653.3771\n",
      "Epoch 362/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.3690 - val_loss: 613.7348\n",
      "Epoch 363/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 368.3089 - val_loss: 590.9697\n",
      "Epoch 364/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 362.9387 - val_loss: 639.6290\n",
      "Epoch 365/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 364.2984 - val_loss: 651.3073\n",
      "Epoch 366/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.4511 - val_loss: 695.6165\n",
      "Epoch 367/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.1838 - val_loss: 676.9330\n",
      "Epoch 368/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 364.8499 - val_loss: 706.2578\n",
      "Epoch 369/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.6939 - val_loss: 659.5482\n",
      "Epoch 370/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 365.4558 - val_loss: 607.7684\n",
      "Epoch 371/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 365.9270 - val_loss: 590.3712\n",
      "Epoch 372/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.6461 - val_loss: 674.6063\n",
      "Epoch 373/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 362.1385 - val_loss: 772.0166\n",
      "Epoch 374/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 364.0342 - val_loss: 750.9593\n",
      "Epoch 375/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 363.9105 - val_loss: 625.6032\n",
      "Epoch 376/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 362.2848 - val_loss: 606.2617\n",
      "Epoch 377/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 361.4750 - val_loss: 618.7751\n",
      "Epoch 378/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 364.7480 - val_loss: 633.5473\n",
      "Epoch 379/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 361.1517 - val_loss: 651.8015\n",
      "Epoch 380/1000\n",
      "322/322 [==============================] - 0s 995us/step - loss: 362.5401 - val_loss: 626.6435\n",
      "Epoch 381/1000\n",
      "322/322 [==============================] - 0s 824us/step - loss: 362.2389 - val_loss: 644.4100\n",
      "Epoch 382/1000\n",
      "322/322 [==============================] - 0s 877us/step - loss: 363.0103 - val_loss: 589.4929\n",
      "Epoch 383/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 363.4452 - val_loss: 619.3529\n",
      "Epoch 384/1000\n",
      "322/322 [==============================] - 0s 903us/step - loss: 360.6360 - val_loss: 645.4838\n",
      "Epoch 385/1000\n",
      "322/322 [==============================] - 0s 858us/step - loss: 359.9551 - val_loss: 686.4357\n",
      "Epoch 386/1000\n",
      "322/322 [==============================] - 0s 817us/step - loss: 362.3659 - val_loss: 595.2059\n",
      "Epoch 387/1000\n",
      "322/322 [==============================] - 0s 832us/step - loss: 360.7946 - val_loss: 626.7307\n",
      "Epoch 388/1000\n",
      "322/322 [==============================] - 0s 829us/step - loss: 359.5532 - val_loss: 646.0078\n",
      "Epoch 389/1000\n",
      "322/322 [==============================] - 0s 924us/step - loss: 362.7320 - val_loss: 680.3398\n",
      "Epoch 390/1000\n",
      "322/322 [==============================] - 0s 883us/step - loss: 361.5685 - val_loss: 671.4351\n",
      "Epoch 391/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 361.3928 - val_loss: 643.8084\n",
      "Epoch 392/1000\n",
      "322/322 [==============================] - 0s 842us/step - loss: 359.3346 - val_loss: 629.1161\n",
      "Epoch 393/1000\n",
      "322/322 [==============================] - 0s 827us/step - loss: 359.7546 - val_loss: 601.8544\n",
      "Epoch 394/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 359.9196 - val_loss: 630.3669\n",
      "Epoch 395/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 848us/step - loss: 360.8601 - val_loss: 620.5186\n",
      "Epoch 396/1000\n",
      "322/322 [==============================] - 0s 906us/step - loss: 359.5461 - val_loss: 682.3517\n",
      "Epoch 397/1000\n",
      "322/322 [==============================] - 0s 901us/step - loss: 359.8323 - val_loss: 611.5460\n",
      "Epoch 398/1000\n",
      "322/322 [==============================] - 0s 889us/step - loss: 359.1657 - val_loss: 648.1011\n",
      "Epoch 399/1000\n",
      "322/322 [==============================] - 0s 862us/step - loss: 360.3421 - val_loss: 651.7162\n",
      "Epoch 400/1000\n",
      "322/322 [==============================] - 0s 890us/step - loss: 361.5132 - val_loss: 609.4497\n",
      "Epoch 401/1000\n",
      "322/322 [==============================] - 0s 834us/step - loss: 360.9306 - val_loss: 640.8173\n",
      "Epoch 402/1000\n",
      "322/322 [==============================] - 0s 839us/step - loss: 361.0266 - val_loss: 659.9038\n",
      "Epoch 403/1000\n",
      "322/322 [==============================] - 0s 828us/step - loss: 359.8849 - val_loss: 623.9370\n",
      "Epoch 404/1000\n",
      "322/322 [==============================] - 0s 862us/step - loss: 360.6095 - val_loss: 652.3721\n",
      "Epoch 405/1000\n",
      "322/322 [==============================] - 0s 850us/step - loss: 362.1841 - val_loss: 624.1971\n",
      "Epoch 406/1000\n",
      "322/322 [==============================] - 0s 849us/step - loss: 359.4760 - val_loss: 704.2781\n",
      "Epoch 407/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 360.0757 - val_loss: 629.4839\n",
      "Epoch 408/1000\n",
      "322/322 [==============================] - 0s 889us/step - loss: 359.0004 - val_loss: 635.1812\n",
      "Epoch 409/1000\n",
      "322/322 [==============================] - 0s 870us/step - loss: 359.5495 - val_loss: 608.4471\n",
      "Epoch 410/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 359.6824 - val_loss: 633.8505\n",
      "Epoch 411/1000\n",
      "322/322 [==============================] - 0s 836us/step - loss: 359.2391 - val_loss: 627.8209\n",
      "Epoch 412/1000\n",
      "322/322 [==============================] - 0s 880us/step - loss: 360.9972 - val_loss: 618.5121\n",
      "Epoch 413/1000\n",
      "322/322 [==============================] - 0s 850us/step - loss: 361.9013 - val_loss: 633.1570\n",
      "Epoch 414/1000\n",
      "322/322 [==============================] - 0s 867us/step - loss: 363.1891 - val_loss: 648.3211\n",
      "Epoch 415/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 359.7975 - val_loss: 636.0839\n",
      "Epoch 416/1000\n",
      "322/322 [==============================] - 0s 860us/step - loss: 359.6191 - val_loss: 698.5967\n",
      "Epoch 417/1000\n",
      "322/322 [==============================] - 0s 849us/step - loss: 364.9523 - val_loss: 610.4164\n",
      "Epoch 418/1000\n",
      "322/322 [==============================] - 0s 859us/step - loss: 359.7223 - val_loss: 652.9818\n",
      "Epoch 419/1000\n",
      "322/322 [==============================] - 0s 834us/step - loss: 359.3280 - val_loss: 635.7009\n",
      "Epoch 420/1000\n",
      "322/322 [==============================] - 0s 837us/step - loss: 360.8541 - val_loss: 643.3798\n",
      "Epoch 421/1000\n",
      "322/322 [==============================] - 0s 901us/step - loss: 360.3940 - val_loss: 629.2551\n",
      "Epoch 422/1000\n",
      "322/322 [==============================] - 0s 869us/step - loss: 359.7763 - val_loss: 665.4379\n",
      "Epoch 423/1000\n",
      "322/322 [==============================] - 0s 881us/step - loss: 359.3670 - val_loss: 652.2188\n",
      "Epoch 424/1000\n",
      "322/322 [==============================] - 0s 883us/step - loss: 359.5526 - val_loss: 657.3566\n",
      "Epoch 425/1000\n",
      "322/322 [==============================] - 0s 834us/step - loss: 373.2718 - val_loss: 626.8596\n",
      "Epoch 426/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 359.5270 - val_loss: 621.8572\n",
      "Epoch 427/1000\n",
      "322/322 [==============================] - 0s 905us/step - loss: 359.4707 - val_loss: 672.7863\n",
      "Epoch 428/1000\n",
      "322/322 [==============================] - 0s 804us/step - loss: 358.7030 - val_loss: 642.9380\n",
      "Epoch 429/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 358.8439 - val_loss: 664.6505\n",
      "Epoch 430/1000\n",
      "322/322 [==============================] - 0s 901us/step - loss: 360.3572 - val_loss: 631.9272\n",
      "Epoch 431/1000\n",
      "322/322 [==============================] - 0s 841us/step - loss: 359.0462 - val_loss: 673.3832\n",
      "Epoch 432/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 360.2495 - val_loss: 624.8964\n",
      "Epoch 433/1000\n",
      "322/322 [==============================] - 0s 897us/step - loss: 358.6172 - val_loss: 609.4280\n",
      "Epoch 434/1000\n",
      "322/322 [==============================] - 0s 934us/step - loss: 358.5544 - val_loss: 632.7609\n",
      "Epoch 435/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 359.5358 - val_loss: 614.1256\n",
      "Epoch 436/1000\n",
      "322/322 [==============================] - 0s 843us/step - loss: 358.9365 - val_loss: 617.7051\n",
      "Epoch 437/1000\n",
      "322/322 [==============================] - 0s 814us/step - loss: 360.1631 - val_loss: 626.9451\n",
      "Epoch 438/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 359.7806 - val_loss: 686.3030\n",
      "Epoch 439/1000\n",
      "322/322 [==============================] - 0s 852us/step - loss: 360.5534 - val_loss: 677.3655\n",
      "Epoch 440/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 360.2804 - val_loss: 668.1808\n",
      "Epoch 441/1000\n",
      "322/322 [==============================] - 0s 831us/step - loss: 359.4032 - val_loss: 652.7721\n",
      "Epoch 442/1000\n",
      "322/322 [==============================] - 0s 831us/step - loss: 360.3989 - val_loss: 715.1365\n",
      "Epoch 443/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 359.7810 - val_loss: 671.8547\n",
      "Epoch 444/1000\n",
      "322/322 [==============================] - 0s 914us/step - loss: 358.6979 - val_loss: 668.7729\n",
      "Epoch 445/1000\n",
      "322/322 [==============================] - 0s 840us/step - loss: 360.3297 - val_loss: 616.2545\n",
      "Epoch 446/1000\n",
      "322/322 [==============================] - 0s 929us/step - loss: 358.7800 - val_loss: 675.2354\n",
      "Epoch 447/1000\n",
      "322/322 [==============================] - 0s 807us/step - loss: 367.6816 - val_loss: 665.9233\n",
      "Epoch 448/1000\n",
      "322/322 [==============================] - 0s 946us/step - loss: 358.7634 - val_loss: 633.7003\n",
      "Epoch 449/1000\n",
      "322/322 [==============================] - 0s 855us/step - loss: 360.1124 - val_loss: 625.9917\n",
      "Epoch 450/1000\n",
      "322/322 [==============================] - 0s 974us/step - loss: 358.5196 - val_loss: 631.9375\n",
      "Epoch 451/1000\n",
      "322/322 [==============================] - 0s 913us/step - loss: 359.3566 - val_loss: 668.0109\n",
      "Epoch 452/1000\n",
      "322/322 [==============================] - 0s 897us/step - loss: 359.4598 - val_loss: 625.3956\n",
      "Epoch 453/1000\n",
      "322/322 [==============================] - 0s 876us/step - loss: 359.2249 - val_loss: 644.7080\n",
      "Epoch 454/1000\n",
      "322/322 [==============================] - 0s 849us/step - loss: 359.2275 - val_loss: 613.7590\n",
      "Epoch 455/1000\n",
      "322/322 [==============================] - 0s 880us/step - loss: 359.6572 - val_loss: 639.4323\n",
      "Epoch 456/1000\n",
      "322/322 [==============================] - 0s 886us/step - loss: 358.5677 - val_loss: 657.3400\n",
      "Epoch 457/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 359.1151 - val_loss: 648.2925\n",
      "Epoch 458/1000\n",
      "322/322 [==============================] - 0s 845us/step - loss: 359.3293 - val_loss: 621.5925\n",
      "Epoch 459/1000\n",
      "322/322 [==============================] - 0s 865us/step - loss: 358.3557 - val_loss: 673.1777\n",
      "Epoch 460/1000\n",
      "322/322 [==============================] - 0s 843us/step - loss: 359.5328 - val_loss: 673.3725\n",
      "Epoch 461/1000\n",
      "322/322 [==============================] - 0s 901us/step - loss: 359.6074 - val_loss: 685.3649\n",
      "Epoch 462/1000\n",
      "322/322 [==============================] - 0s 837us/step - loss: 359.9303 - val_loss: 619.2504\n",
      "Epoch 463/1000\n",
      "322/322 [==============================] - 0s 840us/step - loss: 359.3843 - val_loss: 647.1250\n",
      "Epoch 464/1000\n",
      "322/322 [==============================] - 0s 867us/step - loss: 358.7093 - val_loss: 682.1846\n",
      "Epoch 465/1000\n",
      "322/322 [==============================] - 0s 875us/step - loss: 359.8008 - val_loss: 668.9274\n",
      "Epoch 466/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 360.3586 - val_loss: 588.9101\n",
      "Epoch 467/1000\n",
      "322/322 [==============================] - 0s 870us/step - loss: 359.9887 - val_loss: 605.5596\n",
      "Epoch 468/1000\n",
      "322/322 [==============================] - 0s 943us/step - loss: 359.6092 - val_loss: 648.2633\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 850us/step - loss: 359.1735 - val_loss: 638.5169\n",
      "Epoch 470/1000\n",
      "322/322 [==============================] - 0s 873us/step - loss: 359.1177 - val_loss: 645.9619\n",
      "Epoch 471/1000\n",
      "322/322 [==============================] - 0s 896us/step - loss: 358.9577 - val_loss: 653.5436\n",
      "Epoch 472/1000\n",
      "322/322 [==============================] - 0s 910us/step - loss: 360.0155 - val_loss: 648.0203\n",
      "Epoch 473/1000\n",
      "322/322 [==============================] - 0s 902us/step - loss: 360.7078 - val_loss: 629.1007\n",
      "Epoch 474/1000\n",
      "322/322 [==============================] - 0s 885us/step - loss: 358.4542 - val_loss: 636.1057\n",
      "Epoch 475/1000\n",
      "322/322 [==============================] - 0s 882us/step - loss: 360.2787 - val_loss: 615.0470\n",
      "Epoch 476/1000\n",
      "322/322 [==============================] - 0s 912us/step - loss: 359.1999 - val_loss: 661.7882\n",
      "Epoch 477/1000\n",
      "322/322 [==============================] - 0s 875us/step - loss: 360.5934 - val_loss: 626.4170\n",
      "Epoch 478/1000\n",
      "322/322 [==============================] - 0s 890us/step - loss: 359.9818 - val_loss: 644.6562\n",
      "Epoch 479/1000\n",
      "322/322 [==============================] - 0s 888us/step - loss: 359.5946 - val_loss: 640.8730\n",
      "Epoch 480/1000\n",
      "322/322 [==============================] - 0s 851us/step - loss: 359.8738 - val_loss: 608.9817\n",
      "Epoch 481/1000\n",
      "322/322 [==============================] - 0s 903us/step - loss: 359.9814 - val_loss: 652.0773\n",
      "Epoch 482/1000\n",
      "322/322 [==============================] - 0s 860us/step - loss: 359.8074 - val_loss: 640.2482\n",
      "Epoch 483/1000\n",
      "322/322 [==============================] - 0s 896us/step - loss: 358.8332 - val_loss: 643.6766\n",
      "Epoch 484/1000\n",
      "322/322 [==============================] - 0s 848us/step - loss: 361.4121 - val_loss: 641.0058\n",
      "Epoch 485/1000\n",
      "322/322 [==============================] - 0s 889us/step - loss: 359.1743 - val_loss: 672.4393\n",
      "Epoch 486/1000\n",
      "322/322 [==============================] - 0s 855us/step - loss: 358.7778 - val_loss: 612.0754\n",
      "Epoch 487/1000\n",
      "322/322 [==============================] - 0s 838us/step - loss: 359.7643 - val_loss: 610.3345\n",
      "Epoch 488/1000\n",
      "322/322 [==============================] - 0s 818us/step - loss: 358.6960 - val_loss: 640.2223\n",
      "Epoch 489/1000\n",
      "322/322 [==============================] - 0s 875us/step - loss: 359.0788 - val_loss: 628.4316\n",
      "Epoch 490/1000\n",
      "322/322 [==============================] - 0s 861us/step - loss: 359.7685 - val_loss: 589.7587\n",
      "Epoch 491/1000\n",
      "322/322 [==============================] - 0s 890us/step - loss: 359.6400 - val_loss: 645.3782\n",
      "Epoch 492/1000\n",
      "322/322 [==============================] - 0s 864us/step - loss: 359.1636 - val_loss: 659.0147\n",
      "Epoch 493/1000\n",
      "322/322 [==============================] - 0s 842us/step - loss: 359.6619 - val_loss: 628.2054\n",
      "Epoch 494/1000\n",
      "322/322 [==============================] - 0s 881us/step - loss: 359.8745 - val_loss: 606.9224\n",
      "Epoch 495/1000\n",
      "322/322 [==============================] - 0s 848us/step - loss: 359.2085 - val_loss: 640.2287\n",
      "Epoch 496/1000\n",
      "322/322 [==============================] - 0s 921us/step - loss: 358.4072 - val_loss: 665.2432\n",
      "Epoch 497/1000\n",
      "322/322 [==============================] - 0s 875us/step - loss: 358.6279 - val_loss: 601.1096\n",
      "Epoch 498/1000\n",
      "322/322 [==============================] - 0s 879us/step - loss: 360.6507 - val_loss: 655.9964\n",
      "Epoch 499/1000\n",
      "322/322 [==============================] - 0s 905us/step - loss: 358.4621 - val_loss: 619.8195\n",
      "Epoch 500/1000\n",
      "322/322 [==============================] - 0s 880us/step - loss: 359.1747 - val_loss: 644.5966\n",
      "Epoch 501/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 359.7611 - val_loss: 622.0479\n",
      "Epoch 502/1000\n",
      "322/322 [==============================] - 0s 913us/step - loss: 359.4986 - val_loss: 620.0282\n",
      "Epoch 503/1000\n",
      "322/322 [==============================] - 0s 921us/step - loss: 360.0211 - val_loss: 613.7040\n",
      "Epoch 504/1000\n",
      "322/322 [==============================] - 0s 935us/step - loss: 359.0968 - val_loss: 619.5209\n",
      "Epoch 505/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 358.9235 - val_loss: 616.5450\n",
      "Epoch 506/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 359.1929 - val_loss: 670.2898\n",
      "Epoch 507/1000\n",
      "322/322 [==============================] - 0s 891us/step - loss: 359.3630 - val_loss: 648.0002\n",
      "Epoch 508/1000\n",
      "322/322 [==============================] - 0s 966us/step - loss: 359.9873 - val_loss: 641.0186\n",
      "Epoch 509/1000\n",
      "322/322 [==============================] - 0s 845us/step - loss: 358.6495 - val_loss: 630.5518\n",
      "Epoch 510/1000\n",
      "322/322 [==============================] - 0s 887us/step - loss: 358.7998 - val_loss: 620.8065\n",
      "Epoch 511/1000\n",
      "322/322 [==============================] - 0s 882us/step - loss: 359.5649 - val_loss: 668.0363\n",
      "Epoch 512/1000\n",
      "322/322 [==============================] - 0s 896us/step - loss: 359.8708 - val_loss: 623.5978\n",
      "Epoch 513/1000\n",
      "322/322 [==============================] - 0s 832us/step - loss: 358.7510 - val_loss: 649.6138\n",
      "Epoch 514/1000\n",
      "322/322 [==============================] - 0s 847us/step - loss: 358.9074 - val_loss: 610.4091\n",
      "Epoch 515/1000\n",
      "322/322 [==============================] - 0s 935us/step - loss: 358.6948 - val_loss: 592.9420\n",
      "Epoch 516/1000\n",
      "322/322 [==============================] - 0s 842us/step - loss: 358.9993 - val_loss: 615.5413\n",
      "Epoch 517/1000\n",
      "322/322 [==============================] - 0s 883us/step - loss: 358.3032 - val_loss: 605.7484\n",
      "Epoch 518/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 359.1025 - val_loss: 666.4477\n",
      "Epoch 519/1000\n",
      "322/322 [==============================] - 0s 845us/step - loss: 359.7864 - val_loss: 636.4068\n",
      "Epoch 520/1000\n",
      "322/322 [==============================] - 0s 834us/step - loss: 360.5687 - val_loss: 630.9160\n",
      "Epoch 521/1000\n",
      "322/322 [==============================] - 0s 859us/step - loss: 358.8414 - val_loss: 623.6777\n",
      "Epoch 522/1000\n",
      "322/322 [==============================] - 0s 877us/step - loss: 360.0761 - val_loss: 621.9841\n",
      "Epoch 523/1000\n",
      "322/322 [==============================] - 0s 863us/step - loss: 358.7325 - val_loss: 651.6082\n",
      "Epoch 524/1000\n",
      "322/322 [==============================] - 0s 850us/step - loss: 359.6925 - val_loss: 653.0005\n",
      "Epoch 525/1000\n",
      "322/322 [==============================] - 0s 928us/step - loss: 361.0094 - val_loss: 627.0558\n",
      "Epoch 526/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 358.6355 - val_loss: 635.9571\n",
      "Epoch 527/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 359.0000 - val_loss: 651.8835\n",
      "Epoch 528/1000\n",
      "322/322 [==============================] - 0s 848us/step - loss: 359.3218 - val_loss: 619.5673\n",
      "Epoch 529/1000\n",
      "322/322 [==============================] - 0s 829us/step - loss: 358.7149 - val_loss: 647.9628\n",
      "Epoch 530/1000\n",
      "322/322 [==============================] - 0s 846us/step - loss: 360.2359 - val_loss: 602.8182\n",
      "Epoch 531/1000\n",
      "322/322 [==============================] - 0s 897us/step - loss: 359.5189 - val_loss: 652.0521\n",
      "Epoch 532/1000\n",
      "322/322 [==============================] - 0s 896us/step - loss: 358.7518 - val_loss: 603.3864\n",
      "Epoch 533/1000\n",
      "322/322 [==============================] - 0s 844us/step - loss: 359.0812 - val_loss: 680.1380\n",
      "Epoch 534/1000\n",
      "322/322 [==============================] - 0s 881us/step - loss: 358.7424 - val_loss: 647.0360\n",
      "Epoch 535/1000\n",
      "322/322 [==============================] - 0s 830us/step - loss: 359.4849 - val_loss: 635.7798\n",
      "Epoch 536/1000\n",
      "322/322 [==============================] - 0s 937us/step - loss: 359.5080 - val_loss: 639.8538\n",
      "Epoch 537/1000\n",
      "322/322 [==============================] - 0s 912us/step - loss: 358.9343 - val_loss: 705.9489\n",
      "Epoch 538/1000\n",
      "322/322 [==============================] - 0s 845us/step - loss: 359.0763 - val_loss: 628.1293\n",
      "Epoch 539/1000\n",
      "322/322 [==============================] - 0s 865us/step - loss: 359.9474 - val_loss: 614.6985\n",
      "Epoch 540/1000\n",
      "322/322 [==============================] - 0s 860us/step - loss: 360.1345 - val_loss: 658.1603\n",
      "Epoch 541/1000\n",
      "322/322 [==============================] - 0s 893us/step - loss: 359.1404 - val_loss: 632.7523\n",
      "Epoch 542/1000\n",
      "322/322 [==============================] - 0s 870us/step - loss: 358.7774 - val_loss: 635.6342\n",
      "Epoch 543/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 896us/step - loss: 358.2869 - val_loss: 627.4796\n",
      "Epoch 544/1000\n",
      "322/322 [==============================] - 0s 875us/step - loss: 359.1979 - val_loss: 640.1038\n",
      "Epoch 545/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 360.8279 - val_loss: 668.9827\n",
      "Epoch 546/1000\n",
      "322/322 [==============================] - 0s 891us/step - loss: 359.0097 - val_loss: 678.1650\n",
      "Epoch 547/1000\n",
      "322/322 [==============================] - 0s 885us/step - loss: 358.7185 - val_loss: 665.5671\n",
      "Epoch 548/1000\n",
      "322/322 [==============================] - 0s 888us/step - loss: 359.2400 - val_loss: 627.7552\n",
      "Epoch 549/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 359.2917 - val_loss: 609.7057\n",
      "Epoch 550/1000\n",
      "322/322 [==============================] - 0s 851us/step - loss: 358.8013 - val_loss: 629.9097\n",
      "Epoch 551/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 359.5717 - val_loss: 610.8016\n",
      "Epoch 552/1000\n",
      "322/322 [==============================] - 0s 957us/step - loss: 358.6905 - val_loss: 620.6669\n",
      "Epoch 553/1000\n",
      "322/322 [==============================] - 0s 882us/step - loss: 360.2207 - val_loss: 682.9876\n",
      "Epoch 554/1000\n",
      "322/322 [==============================] - 0s 848us/step - loss: 359.9091 - val_loss: 617.7802\n",
      "Epoch 555/1000\n",
      "322/322 [==============================] - 0s 847us/step - loss: 358.6354 - val_loss: 673.6831\n",
      "Epoch 556/1000\n",
      "322/322 [==============================] - 0s 871us/step - loss: 360.6267 - val_loss: 625.2260\n",
      "Epoch 557/1000\n",
      "322/322 [==============================] - 0s 930us/step - loss: 358.6841 - val_loss: 676.0711\n",
      "Epoch 558/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 359.3542 - val_loss: 610.5413\n",
      "Epoch 559/1000\n",
      "322/322 [==============================] - 0s 876us/step - loss: 359.2606 - val_loss: 644.1512\n",
      "Epoch 560/1000\n",
      "322/322 [==============================] - 0s 882us/step - loss: 358.5327 - val_loss: 642.1328\n",
      "Epoch 561/1000\n",
      "322/322 [==============================] - 0s 825us/step - loss: 358.8384 - val_loss: 626.5465\n",
      "Epoch 562/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 357.8779 - val_loss: 607.9049\n",
      "Epoch 563/1000\n",
      "322/322 [==============================] - 0s 882us/step - loss: 359.2549 - val_loss: 629.9296\n",
      "Epoch 564/1000\n",
      "322/322 [==============================] - 0s 842us/step - loss: 359.1411 - val_loss: 667.1230\n",
      "Epoch 565/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 358.1466 - val_loss: 641.5970\n",
      "Epoch 566/1000\n",
      "322/322 [==============================] - 0s 958us/step - loss: 359.5756 - val_loss: 608.9506\n",
      "Epoch 567/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 359.2232 - val_loss: 603.4337\n",
      "Epoch 568/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.6601 - val_loss: 616.7401\n",
      "Epoch 569/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.7949 - val_loss: 667.0790\n",
      "Epoch 570/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.7195 - val_loss: 611.2313\n",
      "Epoch 571/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 359.5887 - val_loss: 645.0916\n",
      "Epoch 572/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5974 - val_loss: 618.0225\n",
      "Epoch 573/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.4122 - val_loss: 617.6375\n",
      "Epoch 574/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2965 - val_loss: 675.4283\n",
      "Epoch 575/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2080 - val_loss: 648.3256\n",
      "Epoch 576/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.9967 - val_loss: 623.4932\n",
      "Epoch 577/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6728 - val_loss: 657.1952\n",
      "Epoch 578/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0821 - val_loss: 636.7462\n",
      "Epoch 579/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 361.1556 - val_loss: 664.3600\n",
      "Epoch 580/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2882 - val_loss: 624.3001\n",
      "Epoch 581/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.5165 - val_loss: 639.5522\n",
      "Epoch 582/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.4629 - val_loss: 647.3727\n",
      "Epoch 583/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.2230 - val_loss: 658.0551\n",
      "Epoch 584/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.8157 - val_loss: 659.5534\n",
      "Epoch 585/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.8048 - val_loss: 613.3481\n",
      "Epoch 586/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0096 - val_loss: 650.7209\n",
      "Epoch 587/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5783 - val_loss: 640.2599\n",
      "Epoch 588/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.4472 - val_loss: 623.7273\n",
      "Epoch 589/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.9896 - val_loss: 620.9524\n",
      "Epoch 590/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5016 - val_loss: 616.4171\n",
      "Epoch 591/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.6178 - val_loss: 684.1712\n",
      "Epoch 592/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 361.5616 - val_loss: 642.0098\n",
      "Epoch 593/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.2591 - val_loss: 667.9036\n",
      "Epoch 594/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.6481 - val_loss: 637.0035\n",
      "Epoch 595/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2836 - val_loss: 663.7697\n",
      "Epoch 596/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.6274 - val_loss: 639.3405\n",
      "Epoch 597/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.7546 - val_loss: 627.8156\n",
      "Epoch 598/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.9522 - val_loss: 674.7185\n",
      "Epoch 599/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 360.3233 - val_loss: 651.2966\n",
      "Epoch 600/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.2900 - val_loss: 610.3209\n",
      "Epoch 601/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.8507 - val_loss: 690.0474\n",
      "Epoch 602/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.8466 - val_loss: 597.8211\n",
      "Epoch 603/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.9468 - val_loss: 626.6428\n",
      "Epoch 604/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.8754 - val_loss: 659.2569\n",
      "Epoch 605/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.7398 - val_loss: 668.7975\n",
      "Epoch 606/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.8566 - val_loss: 620.8355\n",
      "Epoch 607/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.1596 - val_loss: 654.6835\n",
      "Epoch 608/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.6789 - val_loss: 649.4697\n",
      "Epoch 609/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6725 - val_loss: 609.0324\n",
      "Epoch 610/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 360.0070 - val_loss: 639.8219\n",
      "Epoch 611/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6174 - val_loss: 616.5666\n",
      "Epoch 612/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.9418 - val_loss: 657.8610\n",
      "Epoch 613/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.2187 - val_loss: 637.2799\n",
      "Epoch 614/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.6335 - val_loss: 613.1537\n",
      "Epoch 615/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.9058 - val_loss: 629.6226\n",
      "Epoch 616/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.3943 - val_loss: 630.2604\n",
      "Epoch 617/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.4397 - val_loss: 632.0126\n",
      "Epoch 618/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 1s 2ms/step - loss: 359.5596 - val_loss: 621.6992\n",
      "Epoch 619/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 361.3473 - val_loss: 668.3065\n",
      "Epoch 620/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.6811 - val_loss: 618.6863\n",
      "Epoch 621/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7760 - val_loss: 615.7314\n",
      "Epoch 622/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.3038 - val_loss: 657.4213\n",
      "Epoch 623/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2344 - val_loss: 669.7677\n",
      "Epoch 624/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.9667 - val_loss: 626.5588\n",
      "Epoch 625/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.9579 - val_loss: 614.8535\n",
      "Epoch 626/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6041 - val_loss: 628.5654\n",
      "Epoch 627/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.1911 - val_loss: 645.2439\n",
      "Epoch 628/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.4164 - val_loss: 638.6974\n",
      "Epoch 629/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.6002 - val_loss: 618.1376\n",
      "Epoch 630/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.9404 - val_loss: 617.3282\n",
      "Epoch 631/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.6321 - val_loss: 642.4061\n",
      "Epoch 632/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.9735 - val_loss: 631.9057\n",
      "Epoch 633/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.4677 - val_loss: 618.9810\n",
      "Epoch 634/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0171 - val_loss: 609.3759\n",
      "Epoch 635/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6522 - val_loss: 641.8047\n",
      "Epoch 636/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.3088 - val_loss: 611.3691\n",
      "Epoch 637/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7747 - val_loss: 666.2047\n",
      "Epoch 638/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.2400 - val_loss: 620.1071\n",
      "Epoch 639/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.9850 - val_loss: 610.6733\n",
      "Epoch 640/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.5610 - val_loss: 637.8842\n",
      "Epoch 641/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.8438 - val_loss: 688.1315\n",
      "Epoch 642/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.1160 - val_loss: 647.0765\n",
      "Epoch 643/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0167 - val_loss: 631.4438\n",
      "Epoch 644/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.8659 - val_loss: 677.9372\n",
      "Epoch 645/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.1178 - val_loss: 599.4279\n",
      "Epoch 646/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6714 - val_loss: 632.8360\n",
      "Epoch 647/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 357.9618 - val_loss: 640.9189\n",
      "Epoch 648/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6014 - val_loss: 679.9121\n",
      "Epoch 649/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.3498 - val_loss: 636.3062\n",
      "Epoch 650/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.8912 - val_loss: 655.5652\n",
      "Epoch 651/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.2875 - val_loss: 607.8357\n",
      "Epoch 652/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.5156 - val_loss: 647.7693\n",
      "Epoch 653/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.8183 - val_loss: 655.0527\n",
      "Epoch 654/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.4998 - val_loss: 664.9301\n",
      "Epoch 655/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 360.0631 - val_loss: 657.4559\n",
      "Epoch 656/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.8743 - val_loss: 645.0030\n",
      "Epoch 657/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0226 - val_loss: 664.2202\n",
      "Epoch 658/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0694 - val_loss: 612.7317\n",
      "Epoch 659/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.1917 - val_loss: 647.7222\n",
      "Epoch 660/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.3147 - val_loss: 667.8846\n",
      "Epoch 661/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.1223 - val_loss: 635.8428\n",
      "Epoch 662/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.9999 - val_loss: 635.8729\n",
      "Epoch 663/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 359.3802 - val_loss: 625.6822\n",
      "Epoch 664/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.4477 - val_loss: 635.2436\n",
      "Epoch 665/1000\n",
      "322/322 [==============================] - 0s 973us/step - loss: 358.4426 - val_loss: 634.3912\n",
      "Epoch 666/1000\n",
      "322/322 [==============================] - 0s 971us/step - loss: 359.7801 - val_loss: 644.7609\n",
      "Epoch 667/1000\n",
      "322/322 [==============================] - 0s 865us/step - loss: 359.5395 - val_loss: 625.4763\n",
      "Epoch 668/1000\n",
      "322/322 [==============================] - 0s 891us/step - loss: 359.0084 - val_loss: 639.5604\n",
      "Epoch 669/1000\n",
      "322/322 [==============================] - 0s 859us/step - loss: 358.7847 - val_loss: 649.9963\n",
      "Epoch 670/1000\n",
      "322/322 [==============================] - 0s 864us/step - loss: 360.8141 - val_loss: 680.6685\n",
      "Epoch 671/1000\n",
      "322/322 [==============================] - 0s 857us/step - loss: 358.6244 - val_loss: 673.7518\n",
      "Epoch 672/1000\n",
      "322/322 [==============================] - 0s 835us/step - loss: 358.6117 - val_loss: 626.5429\n",
      "Epoch 673/1000\n",
      "322/322 [==============================] - 0s 836us/step - loss: 359.4651 - val_loss: 654.6818\n",
      "Epoch 674/1000\n",
      "322/322 [==============================] - 0s 791us/step - loss: 359.6861 - val_loss: 621.5543\n",
      "Epoch 675/1000\n",
      "322/322 [==============================] - 0s 838us/step - loss: 358.8257 - val_loss: 611.7757\n",
      "Epoch 676/1000\n",
      "322/322 [==============================] - 0s 832us/step - loss: 359.5658 - val_loss: 707.9178\n",
      "Epoch 677/1000\n",
      "322/322 [==============================] - 0s 847us/step - loss: 359.3018 - val_loss: 638.9882\n",
      "Epoch 678/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 359.0984 - val_loss: 632.8657\n",
      "Epoch 679/1000\n",
      "322/322 [==============================] - 0s 913us/step - loss: 359.3071 - val_loss: 654.7431\n",
      "Epoch 680/1000\n",
      "322/322 [==============================] - 0s 841us/step - loss: 359.0056 - val_loss: 675.8850\n",
      "Epoch 681/1000\n",
      "322/322 [==============================] - 0s 909us/step - loss: 359.8877 - val_loss: 644.3634\n",
      "Epoch 682/1000\n",
      "322/322 [==============================] - 0s 882us/step - loss: 358.9103 - val_loss: 637.0005\n",
      "Epoch 683/1000\n",
      "322/322 [==============================] - 0s 869us/step - loss: 359.4961 - val_loss: 635.6444\n",
      "Epoch 684/1000\n",
      "322/322 [==============================] - 0s 865us/step - loss: 359.1538 - val_loss: 622.8303\n",
      "Epoch 685/1000\n",
      "322/322 [==============================] - 0s 840us/step - loss: 359.6553 - val_loss: 668.5129\n",
      "Epoch 686/1000\n",
      "322/322 [==============================] - 0s 815us/step - loss: 359.0546 - val_loss: 609.5154\n",
      "Epoch 687/1000\n",
      "322/322 [==============================] - 0s 836us/step - loss: 360.0937 - val_loss: 663.4128\n",
      "Epoch 688/1000\n",
      "322/322 [==============================] - 0s 873us/step - loss: 360.3072 - val_loss: 639.7664\n",
      "Epoch 689/1000\n",
      "322/322 [==============================] - 0s 892us/step - loss: 358.4678 - val_loss: 626.6542\n",
      "Epoch 690/1000\n",
      "322/322 [==============================] - 0s 873us/step - loss: 358.9178 - val_loss: 618.6371\n",
      "Epoch 691/1000\n",
      "322/322 [==============================] - 0s 910us/step - loss: 358.4062 - val_loss: 634.1835\n",
      "Epoch 692/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 357.8841 - val_loss: 622.2679\n",
      "Epoch 693/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 899us/step - loss: 360.3257 - val_loss: 685.6129\n",
      "Epoch 694/1000\n",
      "322/322 [==============================] - 0s 822us/step - loss: 359.1282 - val_loss: 676.6490\n",
      "Epoch 695/1000\n",
      "322/322 [==============================] - 0s 850us/step - loss: 359.2609 - val_loss: 675.7836\n",
      "Epoch 696/1000\n",
      "322/322 [==============================] - 0s 899us/step - loss: 360.4304 - val_loss: 644.6609\n",
      "Epoch 697/1000\n",
      "322/322 [==============================] - 0s 892us/step - loss: 359.1051 - val_loss: 645.4989\n",
      "Epoch 698/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 358.5224 - val_loss: 638.3775\n",
      "Epoch 699/1000\n",
      "322/322 [==============================] - 0s 920us/step - loss: 359.9014 - val_loss: 663.6018\n",
      "Epoch 700/1000\n",
      "322/322 [==============================] - 0s 843us/step - loss: 359.7610 - val_loss: 629.9641\n",
      "Epoch 701/1000\n",
      "322/322 [==============================] - 0s 928us/step - loss: 358.7866 - val_loss: 630.8344\n",
      "Epoch 702/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 359.1898 - val_loss: 614.2990\n",
      "Epoch 703/1000\n",
      "322/322 [==============================] - 0s 868us/step - loss: 360.4490 - val_loss: 631.7667\n",
      "Epoch 704/1000\n",
      "322/322 [==============================] - 0s 823us/step - loss: 359.7078 - val_loss: 619.5104\n",
      "Epoch 705/1000\n",
      "322/322 [==============================] - 0s 904us/step - loss: 358.6566 - val_loss: 614.4273\n",
      "Epoch 706/1000\n",
      "322/322 [==============================] - 0s 922us/step - loss: 358.8276 - val_loss: 657.2504\n",
      "Epoch 707/1000\n",
      "322/322 [==============================] - 0s 858us/step - loss: 358.7922 - val_loss: 611.1082\n",
      "Epoch 708/1000\n",
      "322/322 [==============================] - 0s 944us/step - loss: 359.8684 - val_loss: 620.6703\n",
      "Epoch 709/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 359.1156 - val_loss: 630.1901\n",
      "Epoch 710/1000\n",
      "322/322 [==============================] - 0s 896us/step - loss: 359.2246 - val_loss: 627.8386\n",
      "Epoch 711/1000\n",
      "322/322 [==============================] - 0s 969us/step - loss: 359.5073 - val_loss: 660.1432\n",
      "Epoch 712/1000\n",
      "322/322 [==============================] - 0s 903us/step - loss: 359.3325 - val_loss: 618.8706\n",
      "Epoch 713/1000\n",
      "322/322 [==============================] - 0s 904us/step - loss: 358.7544 - val_loss: 632.6940\n",
      "Epoch 714/1000\n",
      "322/322 [==============================] - 0s 895us/step - loss: 358.8117 - val_loss: 672.3268\n",
      "Epoch 715/1000\n",
      "322/322 [==============================] - 0s 844us/step - loss: 358.8858 - val_loss: 615.6840\n",
      "Epoch 716/1000\n",
      "322/322 [==============================] - 0s 852us/step - loss: 360.2765 - val_loss: 622.5445\n",
      "Epoch 717/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 358.3714 - val_loss: 616.0247\n",
      "Epoch 718/1000\n",
      "322/322 [==============================] - 0s 909us/step - loss: 358.5454 - val_loss: 648.0624\n",
      "Epoch 719/1000\n",
      "322/322 [==============================] - 0s 959us/step - loss: 359.1417 - val_loss: 620.0288\n",
      "Epoch 720/1000\n",
      "322/322 [==============================] - 0s 833us/step - loss: 358.2139 - val_loss: 656.3658\n",
      "Epoch 721/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.0872 - val_loss: 600.2244\n",
      "Epoch 722/1000\n",
      "322/322 [==============================] - 0s 897us/step - loss: 358.8427 - val_loss: 596.3218\n",
      "Epoch 723/1000\n",
      "322/322 [==============================] - 0s 899us/step - loss: 359.8993 - val_loss: 626.0866\n",
      "Epoch 724/1000\n",
      "322/322 [==============================] - 0s 892us/step - loss: 358.7642 - val_loss: 677.0972\n",
      "Epoch 725/1000\n",
      "322/322 [==============================] - 0s 823us/step - loss: 358.6184 - val_loss: 668.9740\n",
      "Epoch 726/1000\n",
      "322/322 [==============================] - 0s 994us/step - loss: 358.2830 - val_loss: 659.6653\n",
      "Epoch 727/1000\n",
      "322/322 [==============================] - 0s 840us/step - loss: 359.3628 - val_loss: 646.1485\n",
      "Epoch 728/1000\n",
      "322/322 [==============================] - 0s 931us/step - loss: 359.9110 - val_loss: 662.8185\n",
      "Epoch 729/1000\n",
      "322/322 [==============================] - 0s 907us/step - loss: 358.6354 - val_loss: 645.1880\n",
      "Epoch 730/1000\n",
      "322/322 [==============================] - 0s 889us/step - loss: 359.5821 - val_loss: 624.9116\n",
      "Epoch 731/1000\n",
      "322/322 [==============================] - 0s 838us/step - loss: 358.5727 - val_loss: 648.6718\n",
      "Epoch 732/1000\n",
      "322/322 [==============================] - 0s 887us/step - loss: 358.6858 - val_loss: 673.6337\n",
      "Epoch 733/1000\n",
      "322/322 [==============================] - 0s 855us/step - loss: 359.1418 - val_loss: 588.6052\n",
      "Epoch 734/1000\n",
      "322/322 [==============================] - 0s 878us/step - loss: 359.1457 - val_loss: 642.7214\n",
      "Epoch 735/1000\n",
      "322/322 [==============================] - 0s 959us/step - loss: 360.3564 - val_loss: 634.1582\n",
      "Epoch 736/1000\n",
      "322/322 [==============================] - 0s 958us/step - loss: 358.7393 - val_loss: 669.1987\n",
      "Epoch 737/1000\n",
      "322/322 [==============================] - 0s 926us/step - loss: 359.6185 - val_loss: 647.9969\n",
      "Epoch 738/1000\n",
      "322/322 [==============================] - 0s 870us/step - loss: 358.5870 - val_loss: 665.2422\n",
      "Epoch 739/1000\n",
      "322/322 [==============================] - 0s 964us/step - loss: 359.0552 - val_loss: 635.8069\n",
      "Epoch 740/1000\n",
      "322/322 [==============================] - 0s 934us/step - loss: 358.9294 - val_loss: 655.1175\n",
      "Epoch 741/1000\n",
      "322/322 [==============================] - 0s 908us/step - loss: 358.6537 - val_loss: 651.9877\n",
      "Epoch 742/1000\n",
      "322/322 [==============================] - 0s 809us/step - loss: 359.0684 - val_loss: 665.6826\n",
      "Epoch 743/1000\n",
      "322/322 [==============================] - 0s 861us/step - loss: 359.0577 - val_loss: 621.1155\n",
      "Epoch 744/1000\n",
      "322/322 [==============================] - 0s 907us/step - loss: 359.2409 - val_loss: 656.1387\n",
      "Epoch 745/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 358.4929 - val_loss: 664.7300\n",
      "Epoch 746/1000\n",
      "322/322 [==============================] - 0s 891us/step - loss: 359.4678 - val_loss: 648.9441\n",
      "Epoch 747/1000\n",
      "322/322 [==============================] - 0s 841us/step - loss: 359.2111 - val_loss: 675.6353\n",
      "Epoch 748/1000\n",
      "322/322 [==============================] - 0s 867us/step - loss: 358.6692 - val_loss: 693.9709\n",
      "Epoch 749/1000\n",
      "322/322 [==============================] - 0s 855us/step - loss: 359.4158 - val_loss: 656.0111\n",
      "Epoch 750/1000\n",
      "322/322 [==============================] - 0s 844us/step - loss: 359.1391 - val_loss: 626.7724\n",
      "Epoch 751/1000\n",
      "322/322 [==============================] - 0s 945us/step - loss: 358.5292 - val_loss: 639.5587\n",
      "Epoch 752/1000\n",
      "322/322 [==============================] - 0s 841us/step - loss: 359.6617 - val_loss: 665.7085\n",
      "Epoch 753/1000\n",
      "322/322 [==============================] - 0s 867us/step - loss: 359.0854 - val_loss: 683.5654\n",
      "Epoch 754/1000\n",
      "322/322 [==============================] - 0s 825us/step - loss: 358.7874 - val_loss: 649.9843\n",
      "Epoch 755/1000\n",
      "322/322 [==============================] - 0s 837us/step - loss: 359.5124 - val_loss: 633.4952\n",
      "Epoch 756/1000\n",
      "322/322 [==============================] - 0s 862us/step - loss: 357.6920 - val_loss: 612.1951\n",
      "Epoch 757/1000\n",
      "322/322 [==============================] - 0s 889us/step - loss: 358.9854 - val_loss: 651.8961\n",
      "Epoch 758/1000\n",
      "322/322 [==============================] - 0s 890us/step - loss: 360.3167 - val_loss: 623.8768\n",
      "Epoch 759/1000\n",
      "322/322 [==============================] - 0s 893us/step - loss: 359.3374 - val_loss: 665.8300\n",
      "Epoch 760/1000\n",
      "322/322 [==============================] - 0s 913us/step - loss: 359.0812 - val_loss: 680.5004\n",
      "Epoch 761/1000\n",
      "322/322 [==============================] - 0s 967us/step - loss: 359.2845 - val_loss: 640.8586\n",
      "Epoch 762/1000\n",
      "322/322 [==============================] - 0s 863us/step - loss: 358.7857 - val_loss: 685.7261\n",
      "Epoch 763/1000\n",
      "322/322 [==============================] - 0s 934us/step - loss: 360.7177 - val_loss: 660.0938\n",
      "Epoch 764/1000\n",
      "322/322 [==============================] - 0s 852us/step - loss: 359.0623 - val_loss: 636.2269\n",
      "Epoch 765/1000\n",
      "322/322 [==============================] - 0s 879us/step - loss: 358.8037 - val_loss: 623.4776\n",
      "Epoch 766/1000\n",
      "322/322 [==============================] - 0s 846us/step - loss: 359.1213 - val_loss: 626.5931\n",
      "Epoch 767/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 895us/step - loss: 358.6451 - val_loss: 589.3610\n",
      "Epoch 768/1000\n",
      "322/322 [==============================] - 0s 851us/step - loss: 359.2296 - val_loss: 625.5616\n",
      "Epoch 769/1000\n",
      "322/322 [==============================] - 0s 911us/step - loss: 358.9014 - val_loss: 637.9769\n",
      "Epoch 770/1000\n",
      "322/322 [==============================] - 0s 898us/step - loss: 359.2211 - val_loss: 632.6981\n",
      "Epoch 771/1000\n",
      "322/322 [==============================] - 0s 857us/step - loss: 359.8354 - val_loss: 606.7847\n",
      "Epoch 772/1000\n",
      "322/322 [==============================] - 0s 851us/step - loss: 359.7005 - val_loss: 648.2293\n",
      "Epoch 773/1000\n",
      "322/322 [==============================] - 0s 967us/step - loss: 359.1957 - val_loss: 618.7039\n",
      "Epoch 774/1000\n",
      "322/322 [==============================] - 0s 961us/step - loss: 359.2373 - val_loss: 644.8159\n",
      "Epoch 775/1000\n",
      "322/322 [==============================] - 0s 855us/step - loss: 359.9868 - val_loss: 640.9093\n",
      "Epoch 776/1000\n",
      "322/322 [==============================] - 0s 842us/step - loss: 357.7392 - val_loss: 654.9805\n",
      "Epoch 777/1000\n",
      "322/322 [==============================] - 0s 890us/step - loss: 358.9356 - val_loss: 616.3964\n",
      "Epoch 778/1000\n",
      "322/322 [==============================] - 0s 839us/step - loss: 358.4016 - val_loss: 653.4888\n",
      "Epoch 779/1000\n",
      "322/322 [==============================] - 0s 887us/step - loss: 358.4936 - val_loss: 650.2982\n",
      "Epoch 780/1000\n",
      "322/322 [==============================] - 0s 927us/step - loss: 359.5582 - val_loss: 611.1925\n",
      "Epoch 781/1000\n",
      "322/322 [==============================] - 0s 919us/step - loss: 358.5570 - val_loss: 647.8517\n",
      "Epoch 782/1000\n",
      "322/322 [==============================] - 0s 870us/step - loss: 358.7384 - val_loss: 609.6956\n",
      "Epoch 783/1000\n",
      "322/322 [==============================] - 0s 895us/step - loss: 359.3546 - val_loss: 642.3221\n",
      "Epoch 784/1000\n",
      "322/322 [==============================] - 0s 844us/step - loss: 359.4165 - val_loss: 616.7068\n",
      "Epoch 785/1000\n",
      "322/322 [==============================] - 0s 853us/step - loss: 359.0085 - val_loss: 642.4193\n",
      "Epoch 786/1000\n",
      "322/322 [==============================] - 0s 883us/step - loss: 359.6371 - val_loss: 657.3151\n",
      "Epoch 787/1000\n",
      "322/322 [==============================] - 0s 834us/step - loss: 359.4296 - val_loss: 652.2565\n",
      "Epoch 788/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 359.2273 - val_loss: 651.8940\n",
      "Epoch 789/1000\n",
      "322/322 [==============================] - 0s 908us/step - loss: 359.0666 - val_loss: 672.9934\n",
      "Epoch 790/1000\n",
      "322/322 [==============================] - 0s 840us/step - loss: 359.0126 - val_loss: 627.3941\n",
      "Epoch 791/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 361.3096 - val_loss: 658.6381\n",
      "Epoch 792/1000\n",
      "322/322 [==============================] - 0s 892us/step - loss: 358.5624 - val_loss: 645.0712\n",
      "Epoch 793/1000\n",
      "322/322 [==============================] - 0s 897us/step - loss: 359.1912 - val_loss: 685.2143\n",
      "Epoch 794/1000\n",
      "322/322 [==============================] - 0s 843us/step - loss: 359.8938 - val_loss: 619.5448\n",
      "Epoch 795/1000\n",
      "322/322 [==============================] - 0s 910us/step - loss: 360.0199 - val_loss: 655.0704\n",
      "Epoch 796/1000\n",
      "322/322 [==============================] - 0s 919us/step - loss: 359.2022 - val_loss: 679.5244\n",
      "Epoch 797/1000\n",
      "322/322 [==============================] - 0s 870us/step - loss: 359.8536 - val_loss: 678.8276\n",
      "Epoch 798/1000\n",
      "322/322 [==============================] - 0s 987us/step - loss: 357.8398 - val_loss: 663.7397\n",
      "Epoch 799/1000\n",
      "322/322 [==============================] - 0s 835us/step - loss: 359.1039 - val_loss: 673.4822\n",
      "Epoch 800/1000\n",
      "322/322 [==============================] - 0s 902us/step - loss: 359.7763 - val_loss: 624.2983\n",
      "Epoch 801/1000\n",
      "322/322 [==============================] - 0s 848us/step - loss: 358.6979 - val_loss: 643.7554\n",
      "Epoch 802/1000\n",
      "322/322 [==============================] - 0s 856us/step - loss: 359.1876 - val_loss: 659.1213\n",
      "Epoch 803/1000\n",
      "322/322 [==============================] - 0s 919us/step - loss: 360.0050 - val_loss: 627.6094\n",
      "Epoch 804/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 358.4941 - val_loss: 646.9179\n",
      "Epoch 805/1000\n",
      "322/322 [==============================] - 0s 905us/step - loss: 358.2025 - val_loss: 610.7216\n",
      "Epoch 806/1000\n",
      "322/322 [==============================] - 0s 886us/step - loss: 359.3941 - val_loss: 670.9162\n",
      "Epoch 807/1000\n",
      "322/322 [==============================] - 0s 865us/step - loss: 361.0133 - val_loss: 627.8337\n",
      "Epoch 808/1000\n",
      "322/322 [==============================] - 0s 898us/step - loss: 358.7169 - val_loss: 619.3630\n",
      "Epoch 809/1000\n",
      "322/322 [==============================] - 0s 915us/step - loss: 358.5374 - val_loss: 632.6581\n",
      "Epoch 810/1000\n",
      "322/322 [==============================] - 0s 877us/step - loss: 359.0843 - val_loss: 618.7188\n",
      "Epoch 811/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 358.8896 - val_loss: 642.4623\n",
      "Epoch 812/1000\n",
      "322/322 [==============================] - 0s 933us/step - loss: 358.9719 - val_loss: 651.8545\n",
      "Epoch 813/1000\n",
      "322/322 [==============================] - 0s 918us/step - loss: 358.7057 - val_loss: 622.4932\n",
      "Epoch 814/1000\n",
      "322/322 [==============================] - 0s 882us/step - loss: 357.9002 - val_loss: 657.8569\n",
      "Epoch 815/1000\n",
      "322/322 [==============================] - 0s 944us/step - loss: 358.2143 - val_loss: 634.0757\n",
      "Epoch 816/1000\n",
      "322/322 [==============================] - 0s 857us/step - loss: 359.6120 - val_loss: 648.4233\n",
      "Epoch 817/1000\n",
      "322/322 [==============================] - 0s 952us/step - loss: 358.7120 - val_loss: 606.0328\n",
      "Epoch 818/1000\n",
      "322/322 [==============================] - 0s 894us/step - loss: 359.2531 - val_loss: 641.4791\n",
      "Epoch 819/1000\n",
      "322/322 [==============================] - 0s 877us/step - loss: 359.3405 - val_loss: 623.5796\n",
      "Epoch 820/1000\n",
      "322/322 [==============================] - 0s 902us/step - loss: 359.6875 - val_loss: 629.5448\n",
      "Epoch 821/1000\n",
      "322/322 [==============================] - 0s 922us/step - loss: 358.9944 - val_loss: 641.7360\n",
      "Epoch 822/1000\n",
      "322/322 [==============================] - 0s 882us/step - loss: 359.4902 - val_loss: 662.1661\n",
      "Epoch 823/1000\n",
      "322/322 [==============================] - 0s 860us/step - loss: 357.8209 - val_loss: 634.8520\n",
      "Epoch 824/1000\n",
      "322/322 [==============================] - 0s 917us/step - loss: 359.8735 - val_loss: 604.9030\n",
      "Epoch 825/1000\n",
      "322/322 [==============================] - 0s 851us/step - loss: 360.3749 - val_loss: 672.7372\n",
      "Epoch 826/1000\n",
      "322/322 [==============================] - 0s 886us/step - loss: 360.2037 - val_loss: 606.9184\n",
      "Epoch 827/1000\n",
      "322/322 [==============================] - 0s 917us/step - loss: 359.0912 - val_loss: 686.5052\n",
      "Epoch 828/1000\n",
      "322/322 [==============================] - 0s 865us/step - loss: 358.9695 - val_loss: 592.7133\n",
      "Epoch 829/1000\n",
      "322/322 [==============================] - 0s 895us/step - loss: 358.8476 - val_loss: 617.0250\n",
      "Epoch 830/1000\n",
      "322/322 [==============================] - 0s 915us/step - loss: 359.3917 - val_loss: 624.6243\n",
      "Epoch 831/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 359.6239 - val_loss: 644.7592\n",
      "Epoch 832/1000\n",
      "322/322 [==============================] - 0s 859us/step - loss: 359.5952 - val_loss: 675.6605\n",
      "Epoch 833/1000\n",
      "322/322 [==============================] - 0s 893us/step - loss: 359.1183 - val_loss: 657.8667\n",
      "Epoch 834/1000\n",
      "322/322 [==============================] - 0s 916us/step - loss: 360.0058 - val_loss: 615.1614\n",
      "Epoch 835/1000\n",
      "322/322 [==============================] - 0s 856us/step - loss: 359.0896 - val_loss: 638.5776\n",
      "Epoch 836/1000\n",
      "322/322 [==============================] - 0s 883us/step - loss: 358.4959 - val_loss: 653.0754\n",
      "Epoch 837/1000\n",
      "322/322 [==============================] - 0s 988us/step - loss: 359.1809 - val_loss: 601.2021\n",
      "Epoch 838/1000\n",
      "322/322 [==============================] - 0s 863us/step - loss: 360.0793 - val_loss: 651.6887\n",
      "Epoch 839/1000\n",
      "322/322 [==============================] - 0s 878us/step - loss: 359.5354 - val_loss: 646.2592\n",
      "Epoch 840/1000\n",
      "322/322 [==============================] - 0s 835us/step - loss: 359.9535 - val_loss: 636.8304\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 939us/step - loss: 358.5409 - val_loss: 644.1544\n",
      "Epoch 842/1000\n",
      "322/322 [==============================] - 0s 879us/step - loss: 359.8195 - val_loss: 662.7571\n",
      "Epoch 843/1000\n",
      "322/322 [==============================] - 0s 848us/step - loss: 359.2523 - val_loss: 616.1589\n",
      "Epoch 844/1000\n",
      "322/322 [==============================] - 0s 896us/step - loss: 358.5104 - val_loss: 655.8486\n",
      "Epoch 845/1000\n",
      "322/322 [==============================] - 0s 840us/step - loss: 358.6751 - val_loss: 662.0349\n",
      "Epoch 846/1000\n",
      "322/322 [==============================] - 0s 847us/step - loss: 359.0146 - val_loss: 672.3159\n",
      "Epoch 847/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 358.8363 - val_loss: 672.8236\n",
      "Epoch 848/1000\n",
      "322/322 [==============================] - 0s 934us/step - loss: 358.0360 - val_loss: 688.8013\n",
      "Epoch 849/1000\n",
      "322/322 [==============================] - 0s 911us/step - loss: 358.8396 - val_loss: 609.5768\n",
      "Epoch 850/1000\n",
      "322/322 [==============================] - 0s 843us/step - loss: 358.9995 - val_loss: 642.5086\n",
      "Epoch 851/1000\n",
      "322/322 [==============================] - 0s 965us/step - loss: 358.7164 - val_loss: 664.0961\n",
      "Epoch 852/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.6496 - val_loss: 641.7936\n",
      "Epoch 853/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 359.4689 - val_loss: 637.4946\n",
      "Epoch 854/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.7030 - val_loss: 612.9862\n",
      "Epoch 855/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.2274 - val_loss: 609.2554\n",
      "Epoch 856/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.4871 - val_loss: 655.0471\n",
      "Epoch 857/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 359.4166 - val_loss: 601.9131\n",
      "Epoch 858/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7099 - val_loss: 655.4820\n",
      "Epoch 859/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.4777 - val_loss: 656.4554\n",
      "Epoch 860/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.8391 - val_loss: 619.7358\n",
      "Epoch 861/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 357.9224 - val_loss: 636.3400\n",
      "Epoch 862/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.5862 - val_loss: 657.0343\n",
      "Epoch 863/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.8132 - val_loss: 639.3025\n",
      "Epoch 864/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.1629 - val_loss: 640.3776\n",
      "Epoch 865/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6206 - val_loss: 626.2529\n",
      "Epoch 866/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.7134 - val_loss: 637.1559\n",
      "Epoch 867/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.8708 - val_loss: 604.7090\n",
      "Epoch 868/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.9012 - val_loss: 636.9832\n",
      "Epoch 869/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0869 - val_loss: 625.7853\n",
      "Epoch 870/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 357.7798 - val_loss: 643.8773\n",
      "Epoch 871/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.4493 - val_loss: 665.0093\n",
      "Epoch 872/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.7775 - val_loss: 685.2936\n",
      "Epoch 873/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7821 - val_loss: 627.4762\n",
      "Epoch 874/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7086 - val_loss: 638.2134\n",
      "Epoch 875/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.9531 - val_loss: 616.5481\n",
      "Epoch 876/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.3239 - val_loss: 632.2031\n",
      "Epoch 877/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5652 - val_loss: 643.8367\n",
      "Epoch 878/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.6354 - val_loss: 621.4819\n",
      "Epoch 879/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.1765 - val_loss: 638.0881\n",
      "Epoch 880/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2577 - val_loss: 675.7787\n",
      "Epoch 881/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.7923 - val_loss: 639.7699\n",
      "Epoch 882/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.2846 - val_loss: 637.3098\n",
      "Epoch 883/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7136 - val_loss: 657.3994\n",
      "Epoch 884/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.6903 - val_loss: 611.3075\n",
      "Epoch 885/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 357.8894 - val_loss: 615.4040\n",
      "Epoch 886/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.2647 - val_loss: 613.1691\n",
      "Epoch 887/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2072 - val_loss: 639.0161\n",
      "Epoch 888/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.7653 - val_loss: 657.0816\n",
      "Epoch 889/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5633 - val_loss: 637.8935\n",
      "Epoch 890/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.1513 - val_loss: 622.8252\n",
      "Epoch 891/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.5946 - val_loss: 683.4406\n",
      "Epoch 892/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.1616 - val_loss: 634.7797\n",
      "Epoch 893/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2372 - val_loss: 653.7814\n",
      "Epoch 894/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.9426 - val_loss: 659.5953\n",
      "Epoch 895/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7678 - val_loss: 609.0865\n",
      "Epoch 896/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.8284 - val_loss: 624.1739\n",
      "Epoch 897/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.1988 - val_loss: 644.8620\n",
      "Epoch 898/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5186 - val_loss: 645.1035\n",
      "Epoch 899/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.4924 - val_loss: 666.9048\n",
      "Epoch 900/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2692 - val_loss: 663.2827\n",
      "Epoch 901/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5539 - val_loss: 609.2935\n",
      "Epoch 902/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.6623 - val_loss: 611.9212\n",
      "Epoch 903/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 361.0993 - val_loss: 667.5781\n",
      "Epoch 904/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.0927 - val_loss: 634.0415\n",
      "Epoch 905/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7133 - val_loss: 657.5887\n",
      "Epoch 906/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.5067 - val_loss: 629.4156\n",
      "Epoch 907/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.7510 - val_loss: 682.4941\n",
      "Epoch 908/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.3500 - val_loss: 651.9642\n",
      "Epoch 909/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0891 - val_loss: 606.1200\n",
      "Epoch 910/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.8237 - val_loss: 637.7391\n",
      "Epoch 911/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.2600 - val_loss: 659.6332\n",
      "Epoch 912/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7236 - val_loss: 626.2444\n",
      "Epoch 913/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7246 - val_loss: 655.5118\n",
      "Epoch 914/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.3302 - val_loss: 628.5228\n",
      "Epoch 915/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5226 - val_loss: 622.7504\n",
      "Epoch 916/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.5899 - val_loss: 646.3855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 917/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.4189 - val_loss: 655.0312\n",
      "Epoch 918/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.3393 - val_loss: 674.4078\n",
      "Epoch 919/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7535 - val_loss: 636.3082\n",
      "Epoch 920/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.5732 - val_loss: 638.8423\n",
      "Epoch 921/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.6152 - val_loss: 646.5752\n",
      "Epoch 922/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.5270 - val_loss: 618.3921\n",
      "Epoch 923/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.8037 - val_loss: 663.3488\n",
      "Epoch 924/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.4108 - val_loss: 679.4545\n",
      "Epoch 925/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.7630 - val_loss: 619.1450\n",
      "Epoch 926/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0712 - val_loss: 636.7585\n",
      "Epoch 927/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.3282 - val_loss: 666.9657\n",
      "Epoch 928/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.8246 - val_loss: 667.9227\n",
      "Epoch 929/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.1728 - val_loss: 655.1113\n",
      "Epoch 930/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.1595 - val_loss: 604.9240\n",
      "Epoch 931/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.2615 - val_loss: 596.1379\n",
      "Epoch 932/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.9218 - val_loss: 612.6103\n",
      "Epoch 933/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.3493 - val_loss: 663.3536\n",
      "Epoch 934/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7063 - val_loss: 627.3950\n",
      "Epoch 935/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.1276 - val_loss: 616.0023\n",
      "Epoch 936/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.5903 - val_loss: 629.4525\n",
      "Epoch 937/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 358.7598 - val_loss: 618.2771\n",
      "Epoch 938/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 357.9775 - val_loss: 628.5126\n",
      "Epoch 939/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.4009 - val_loss: 629.2783\n",
      "Epoch 940/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7955 - val_loss: 677.3711\n",
      "Epoch 941/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0100 - val_loss: 654.1814\n",
      "Epoch 942/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7458 - val_loss: 654.2994\n",
      "Epoch 943/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.2159 - val_loss: 676.9274\n",
      "Epoch 944/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 359.0452 - val_loss: 611.5081\n",
      "Epoch 945/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.3094 - val_loss: 656.5635\n",
      "Epoch 946/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.4951 - val_loss: 697.4551\n",
      "Epoch 947/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 358.7576 - val_loss: 620.2725\n",
      "Epoch 948/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 359.0372 - val_loss: 622.3268\n",
      "Epoch 949/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 360.4139 - val_loss: 660.6794\n",
      "Epoch 950/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 359.8803 - val_loss: 669.8782\n",
      "Epoch 951/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.8302 - val_loss: 647.7202\n",
      "Epoch 952/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 359.1602 - val_loss: 637.4658\n",
      "Epoch 953/1000\n",
      "322/322 [==============================] - 0s 892us/step - loss: 358.8100 - val_loss: 663.8477\n",
      "Epoch 954/1000\n",
      "322/322 [==============================] - 0s 950us/step - loss: 359.0536 - val_loss: 625.4113\n",
      "Epoch 955/1000\n",
      "322/322 [==============================] - 0s 893us/step - loss: 359.4586 - val_loss: 663.3399\n",
      "Epoch 956/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 359.0427 - val_loss: 614.5547\n",
      "Epoch 957/1000\n",
      "322/322 [==============================] - 0s 872us/step - loss: 359.7747 - val_loss: 634.8639\n",
      "Epoch 958/1000\n",
      "322/322 [==============================] - 0s 864us/step - loss: 358.5473 - val_loss: 628.3146\n",
      "Epoch 959/1000\n",
      "322/322 [==============================] - 0s 900us/step - loss: 358.9885 - val_loss: 629.5823\n",
      "Epoch 960/1000\n",
      "322/322 [==============================] - 0s 871us/step - loss: 359.4080 - val_loss: 624.5299\n",
      "Epoch 961/1000\n",
      "322/322 [==============================] - 0s 807us/step - loss: 358.5303 - val_loss: 636.4643\n",
      "Epoch 962/1000\n",
      "322/322 [==============================] - 0s 869us/step - loss: 358.3774 - val_loss: 626.3356\n",
      "Epoch 963/1000\n",
      "322/322 [==============================] - 0s 884us/step - loss: 358.8599 - val_loss: 641.5633\n",
      "Epoch 964/1000\n",
      "322/322 [==============================] - 0s 878us/step - loss: 359.0555 - val_loss: 632.7689\n",
      "Epoch 965/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 358.6547 - val_loss: 661.9595\n",
      "Epoch 966/1000\n",
      "322/322 [==============================] - 0s 811us/step - loss: 357.8819 - val_loss: 648.2663\n",
      "Epoch 967/1000\n",
      "322/322 [==============================] - 0s 856us/step - loss: 359.2083 - val_loss: 598.1157\n",
      "Epoch 968/1000\n",
      "322/322 [==============================] - 0s 854us/step - loss: 359.4618 - val_loss: 639.1614\n",
      "Epoch 969/1000\n",
      "322/322 [==============================] - 0s 868us/step - loss: 358.1882 - val_loss: 637.8120\n",
      "Epoch 970/1000\n",
      "322/322 [==============================] - 0s 870us/step - loss: 360.1261 - val_loss: 611.6497\n",
      "Epoch 971/1000\n",
      "322/322 [==============================] - 0s 802us/step - loss: 359.6374 - val_loss: 659.4091\n",
      "Epoch 972/1000\n",
      "322/322 [==============================] - 0s 897us/step - loss: 359.1931 - val_loss: 695.6031\n",
      "Epoch 973/1000\n",
      "322/322 [==============================] - 0s 803us/step - loss: 358.6735 - val_loss: 632.5944\n",
      "Epoch 974/1000\n",
      "322/322 [==============================] - 0s 910us/step - loss: 358.7245 - val_loss: 645.3533\n",
      "Epoch 975/1000\n",
      "322/322 [==============================] - 0s 789us/step - loss: 359.6122 - val_loss: 624.4052\n",
      "Epoch 976/1000\n",
      "322/322 [==============================] - 0s 809us/step - loss: 357.9967 - val_loss: 622.0966\n",
      "Epoch 977/1000\n",
      "322/322 [==============================] - 0s 874us/step - loss: 358.7718 - val_loss: 637.8526\n",
      "Epoch 978/1000\n",
      "322/322 [==============================] - 0s 862us/step - loss: 359.0031 - val_loss: 615.1935\n",
      "Epoch 979/1000\n",
      "322/322 [==============================] - 0s 850us/step - loss: 358.8246 - val_loss: 699.2317\n",
      "Epoch 980/1000\n",
      "322/322 [==============================] - 0s 912us/step - loss: 359.0953 - val_loss: 644.8160\n",
      "Epoch 981/1000\n",
      "322/322 [==============================] - 0s 913us/step - loss: 358.8932 - val_loss: 640.2683\n",
      "Epoch 982/1000\n",
      "322/322 [==============================] - 0s 895us/step - loss: 358.6568 - val_loss: 618.9846\n",
      "Epoch 983/1000\n",
      "322/322 [==============================] - 0s 920us/step - loss: 358.1098 - val_loss: 627.8279\n",
      "Epoch 984/1000\n",
      "322/322 [==============================] - 0s 841us/step - loss: 358.0683 - val_loss: 637.2872\n",
      "Epoch 985/1000\n",
      "322/322 [==============================] - 0s 820us/step - loss: 359.2017 - val_loss: 636.0812\n",
      "Epoch 986/1000\n",
      "322/322 [==============================] - 0s 888us/step - loss: 358.8222 - val_loss: 653.9111\n",
      "Epoch 987/1000\n",
      "322/322 [==============================] - 0s 907us/step - loss: 358.2832 - val_loss: 597.7031\n",
      "Epoch 988/1000\n",
      "322/322 [==============================] - 0s 852us/step - loss: 358.9494 - val_loss: 627.3102\n",
      "Epoch 989/1000\n",
      "322/322 [==============================] - 0s 852us/step - loss: 358.7339 - val_loss: 629.4728\n",
      "Epoch 990/1000\n",
      "322/322 [==============================] - 0s 883us/step - loss: 357.7081 - val_loss: 624.8785\n",
      "Epoch 991/1000\n",
      "322/322 [==============================] - 0s 953us/step - loss: 358.5627 - val_loss: 640.4780\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/322 [==============================] - 0s 875us/step - loss: 359.0369 - val_loss: 692.3579\n",
      "Epoch 993/1000\n",
      "322/322 [==============================] - 0s 927us/step - loss: 358.9448 - val_loss: 630.2707\n",
      "Epoch 994/1000\n",
      "322/322 [==============================] - 0s 917us/step - loss: 358.3387 - val_loss: 633.6419\n",
      "Epoch 995/1000\n",
      "322/322 [==============================] - 0s 866us/step - loss: 359.6127 - val_loss: 637.0771\n",
      "Epoch 996/1000\n",
      "322/322 [==============================] - 0s 818us/step - loss: 360.7292 - val_loss: 670.8555\n",
      "Epoch 997/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 358.9093 - val_loss: 647.1239\n",
      "Epoch 998/1000\n",
      "322/322 [==============================] - 0s 931us/step - loss: 358.2981 - val_loss: 614.1821\n",
      "Epoch 999/1000\n",
      "322/322 [==============================] - 0s 924us/step - loss: 359.1171 - val_loss: 654.2803\n",
      "Epoch 1000/1000\n",
      "322/322 [==============================] - 0s 847us/step - loss: 359.2221 - val_loss: 626.6668\n",
      "26/26 [==============================] - 0s 472us/step\n",
      "1373037 successful\n",
      "Epoch 1/1000\n",
      "307/307 [==============================] - 1s 1ms/step - loss: 74659528.0000 - val_loss: 722.2562\n",
      "Epoch 2/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 374.9112 - val_loss: 711.8353\n",
      "Epoch 3/1000\n",
      "307/307 [==============================] - 0s 897us/step - loss: 378.0179 - val_loss: 672.7897\n",
      "Epoch 4/1000\n",
      "307/307 [==============================] - 0s 922us/step - loss: 378.5967 - val_loss: 667.9946\n",
      "Epoch 5/1000\n",
      "307/307 [==============================] - 0s 879us/step - loss: 378.9236 - val_loss: 692.2888\n",
      "Epoch 6/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 383.8142 - val_loss: 730.2319\n",
      "Epoch 7/1000\n",
      "307/307 [==============================] - 0s 935us/step - loss: 389.9619 - val_loss: 918.8068\n",
      "Epoch 8/1000\n",
      "307/307 [==============================] - 0s 856us/step - loss: 393.1125 - val_loss: 792.2128\n",
      "Epoch 9/1000\n",
      "307/307 [==============================] - 0s 850us/step - loss: 389.6250 - val_loss: 718.1331\n",
      "Epoch 10/1000\n",
      "307/307 [==============================] - 0s 925us/step - loss: 401.8062 - val_loss: 689.9385\n",
      "Epoch 11/1000\n",
      "307/307 [==============================] - 0s 966us/step - loss: 397.3388 - val_loss: 729.4570\n",
      "Epoch 12/1000\n",
      "307/307 [==============================] - 0s 812us/step - loss: 423.2337 - val_loss: 663.2485\n",
      "Epoch 13/1000\n",
      "307/307 [==============================] - 0s 880us/step - loss: 451.5136 - val_loss: 824.3697\n",
      "Epoch 14/1000\n",
      "307/307 [==============================] - 0s 941us/step - loss: 459.7704 - val_loss: 656.1850\n",
      "Epoch 15/1000\n",
      "307/307 [==============================] - 0s 845us/step - loss: 464.0321 - val_loss: 654.5440\n",
      "Epoch 16/1000\n",
      "307/307 [==============================] - 0s 889us/step - loss: 467.2835 - val_loss: 653.9168\n",
      "Epoch 17/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 583.7596 - val_loss: 1184.6897\n",
      "Epoch 18/1000\n",
      "307/307 [==============================] - 0s 844us/step - loss: 540.3344 - val_loss: 894.0038\n",
      "Epoch 19/1000\n",
      "307/307 [==============================] - 0s 843us/step - loss: 602.6337 - val_loss: 661.2783\n",
      "Epoch 20/1000\n",
      "307/307 [==============================] - 0s 848us/step - loss: 970.0962 - val_loss: 895.4432\n",
      "Epoch 21/1000\n",
      "307/307 [==============================] - 0s 837us/step - loss: 996.0890 - val_loss: 6571.6440\n",
      "Epoch 22/1000\n",
      "307/307 [==============================] - 0s 825us/step - loss: 2804.4485 - val_loss: 21725.8672\n",
      "Epoch 23/1000\n",
      "307/307 [==============================] - 0s 845us/step - loss: 15855.6562 - val_loss: 28987.4629\n",
      "Epoch 24/1000\n",
      "307/307 [==============================] - 0s 911us/step - loss: 21665.8457 - val_loss: 8509.2881\n",
      "Epoch 25/1000\n",
      "307/307 [==============================] - 0s 843us/step - loss: 22426.5469 - val_loss: 11733.3652\n",
      "Epoch 26/1000\n",
      "307/307 [==============================] - 0s 925us/step - loss: 23048.6270 - val_loss: 71047.6328\n",
      "Epoch 27/1000\n",
      "307/307 [==============================] - 0s 886us/step - loss: 21871.4922 - val_loss: 6275.0405\n",
      "Epoch 28/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 24431.4668 - val_loss: 5755.4429\n",
      "Epoch 29/1000\n",
      "307/307 [==============================] - 0s 866us/step - loss: 20727.9453 - val_loss: 904.0244\n",
      "Epoch 30/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 21788.8730 - val_loss: 19248.8770\n",
      "Epoch 31/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 24573.7051 - val_loss: 23729.9355\n",
      "Epoch 32/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 20588.1367 - val_loss: 49074.1094\n",
      "Epoch 33/1000\n",
      "307/307 [==============================] - 0s 834us/step - loss: 25779.4141 - val_loss: 8682.7822\n",
      "Epoch 34/1000\n",
      "307/307 [==============================] - 0s 886us/step - loss: 20018.9082 - val_loss: 317636.0938\n",
      "Epoch 35/1000\n",
      "307/307 [==============================] - 0s 927us/step - loss: 18552.9512 - val_loss: 757.3192\n",
      "Epoch 36/1000\n",
      "307/307 [==============================] - 0s 829us/step - loss: 20833.6445 - val_loss: 1580.8823\n",
      "Epoch 37/1000\n",
      "307/307 [==============================] - 0s 884us/step - loss: 22526.8555 - val_loss: 1875.1853\n",
      "Epoch 38/1000\n",
      "307/307 [==============================] - 0s 887us/step - loss: 21285.0156 - val_loss: 36899.2148\n",
      "Epoch 39/1000\n",
      "307/307 [==============================] - 0s 906us/step - loss: 19377.1230 - val_loss: 3667.1145\n",
      "Epoch 40/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 20344.9922 - val_loss: 20193.2852\n",
      "Epoch 41/1000\n",
      "307/307 [==============================] - 0s 914us/step - loss: 17612.6875 - val_loss: 677.4714\n",
      "Epoch 42/1000\n",
      "307/307 [==============================] - 0s 782us/step - loss: 22836.9062 - val_loss: 18828.0547\n",
      "Epoch 43/1000\n",
      "307/307 [==============================] - 0s 910us/step - loss: 14923.2080 - val_loss: 23084.6973\n",
      "Epoch 44/1000\n",
      "307/307 [==============================] - 0s 917us/step - loss: 19853.2500 - val_loss: 1215.5297\n",
      "Epoch 45/1000\n",
      "307/307 [==============================] - 0s 881us/step - loss: 18606.0801 - val_loss: 6964.5278\n",
      "Epoch 46/1000\n",
      "307/307 [==============================] - 0s 936us/step - loss: 22165.6484 - val_loss: 16090.6270\n",
      "Epoch 47/1000\n",
      "307/307 [==============================] - 0s 831us/step - loss: 13583.7803 - val_loss: 4486.0723\n",
      "Epoch 48/1000\n",
      "307/307 [==============================] - 0s 856us/step - loss: 17474.9180 - val_loss: 5842.8306\n",
      "Epoch 49/1000\n",
      "307/307 [==============================] - 0s 893us/step - loss: 15909.5967 - val_loss: 18726.3047\n",
      "Epoch 50/1000\n",
      "307/307 [==============================] - 0s 933us/step - loss: 18227.6465 - val_loss: 2121.3086\n",
      "Epoch 51/1000\n",
      "307/307 [==============================] - 0s 847us/step - loss: 16457.6777 - val_loss: 2723.5867\n",
      "Epoch 52/1000\n",
      "307/307 [==============================] - 0s 909us/step - loss: 14158.0049 - val_loss: 15161.7363\n",
      "Epoch 53/1000\n",
      "307/307 [==============================] - 0s 907us/step - loss: 16450.1074 - val_loss: 24838.6934\n",
      "Epoch 54/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 15744.9736 - val_loss: 4479.2822\n",
      "Epoch 55/1000\n",
      "307/307 [==============================] - 0s 878us/step - loss: 16530.7559 - val_loss: 8915.7373\n",
      "Epoch 56/1000\n",
      "307/307 [==============================] - 0s 835us/step - loss: 14923.8281 - val_loss: 18618.3730\n",
      "Epoch 57/1000\n",
      "307/307 [==============================] - 0s 874us/step - loss: 13696.1611 - val_loss: 19690.7266\n",
      "Epoch 58/1000\n",
      "307/307 [==============================] - 0s 838us/step - loss: 15852.2520 - val_loss: 7444.8828\n",
      "Epoch 59/1000\n",
      "307/307 [==============================] - 0s 860us/step - loss: 12922.6279 - val_loss: 8739.3398\n",
      "Epoch 60/1000\n",
      "307/307 [==============================] - 0s 831us/step - loss: 14340.2646 - val_loss: 11675.3965\n",
      "Epoch 61/1000\n",
      "307/307 [==============================] - 0s 888us/step - loss: 12605.8662 - val_loss: 4689.6719\n",
      "Epoch 62/1000\n",
      "307/307 [==============================] - 0s 950us/step - loss: 13973.2139 - val_loss: 3852.3123\n",
      "Epoch 63/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 13738.6123 - val_loss: 682.2764\n",
      "Epoch 64/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 13651.4639 - val_loss: 695.1607\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 907us/step - loss: 12339.8545 - val_loss: 3775.6169\n",
      "Epoch 66/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 13317.8467 - val_loss: 15405.2051\n",
      "Epoch 67/1000\n",
      "307/307 [==============================] - 0s 896us/step - loss: 13762.6064 - val_loss: 6654.9155\n",
      "Epoch 68/1000\n",
      "307/307 [==============================] - 0s 897us/step - loss: 10465.7930 - val_loss: 20987.4141\n",
      "Epoch 69/1000\n",
      "307/307 [==============================] - 0s 853us/step - loss: 13298.8330 - val_loss: 8616.8174\n",
      "Epoch 70/1000\n",
      "307/307 [==============================] - 0s 907us/step - loss: 11811.5527 - val_loss: 2179.0959\n",
      "Epoch 71/1000\n",
      "307/307 [==============================] - 0s 918us/step - loss: 11029.5996 - val_loss: 5644.8735\n",
      "Epoch 72/1000\n",
      "307/307 [==============================] - 0s 912us/step - loss: 39990.2383 - val_loss: 184240.7031\n",
      "Epoch 73/1000\n",
      "307/307 [==============================] - 0s 888us/step - loss: 5696.6426 - val_loss: 756.3667\n",
      "Epoch 74/1000\n",
      "307/307 [==============================] - 0s 849us/step - loss: 2134.3931 - val_loss: 1394.4303\n",
      "Epoch 75/1000\n",
      "307/307 [==============================] - 0s 886us/step - loss: 7746.4194 - val_loss: 2374.5986\n",
      "Epoch 76/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 11494.8682 - val_loss: 1747.6069\n",
      "Epoch 77/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 9102.0801 - val_loss: 2003.5750\n",
      "Epoch 78/1000\n",
      "307/307 [==============================] - 0s 866us/step - loss: 11887.2822 - val_loss: 828.1003\n",
      "Epoch 79/1000\n",
      "307/307 [==============================] - 0s 875us/step - loss: 8592.9766 - val_loss: 4523.1021\n",
      "Epoch 80/1000\n",
      "307/307 [==============================] - 0s 859us/step - loss: 11802.0850 - val_loss: 5684.6211\n",
      "Epoch 81/1000\n",
      "307/307 [==============================] - 0s 851us/step - loss: 8996.3398 - val_loss: 34677.3945\n",
      "Epoch 82/1000\n",
      "307/307 [==============================] - 0s 862us/step - loss: 9993.0918 - val_loss: 991.1040\n",
      "Epoch 83/1000\n",
      "307/307 [==============================] - 0s 875us/step - loss: 10421.1182 - val_loss: 3550.7939\n",
      "Epoch 84/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 6942.2041 - val_loss: 21900.0742\n",
      "Epoch 85/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 10109.8623 - val_loss: 1699.3553\n",
      "Epoch 86/1000\n",
      "307/307 [==============================] - 0s 889us/step - loss: 9333.6748 - val_loss: 10294.5410\n",
      "Epoch 87/1000\n",
      "307/307 [==============================] - 0s 926us/step - loss: 7763.6357 - val_loss: 2076.7917\n",
      "Epoch 88/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 9102.7734 - val_loss: 1313.5349\n",
      "Epoch 89/1000\n",
      "307/307 [==============================] - 0s 894us/step - loss: 7360.0869 - val_loss: 27603.7402\n",
      "Epoch 90/1000\n",
      "307/307 [==============================] - 0s 821us/step - loss: 8652.1475 - val_loss: 797.4842\n",
      "Epoch 91/1000\n",
      "307/307 [==============================] - 0s 820us/step - loss: 8569.2920 - val_loss: 1080.2957\n",
      "Epoch 92/1000\n",
      "307/307 [==============================] - 0s 859us/step - loss: 7747.2715 - val_loss: 16236.1025\n",
      "Epoch 93/1000\n",
      "307/307 [==============================] - 0s 853us/step - loss: 6834.4531 - val_loss: 765.4450\n",
      "Epoch 94/1000\n",
      "307/307 [==============================] - 0s 863us/step - loss: 8295.1016 - val_loss: 2722.8555\n",
      "Epoch 95/1000\n",
      "307/307 [==============================] - 0s 882us/step - loss: 7692.3691 - val_loss: 739.2551\n",
      "Epoch 96/1000\n",
      "307/307 [==============================] - 0s 891us/step - loss: 7412.2031 - val_loss: 25250.9160\n",
      "Epoch 97/1000\n",
      "307/307 [==============================] - 0s 958us/step - loss: 5950.7285 - val_loss: 5234.9692\n",
      "Epoch 98/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 8336.4541 - val_loss: 1416.9518\n",
      "Epoch 99/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 6505.7109 - val_loss: 1152.0319\n",
      "Epoch 100/1000\n",
      "307/307 [==============================] - 0s 836us/step - loss: 8297.4395 - val_loss: 10327.4990\n",
      "Epoch 101/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 5410.0742 - val_loss: 20112.3711\n",
      "Epoch 102/1000\n",
      "307/307 [==============================] - 0s 878us/step - loss: 7356.4189 - val_loss: 21531.0742\n",
      "Epoch 103/1000\n",
      "307/307 [==============================] - 0s 902us/step - loss: 5284.2451 - val_loss: 2397.6199\n",
      "Epoch 104/1000\n",
      "307/307 [==============================] - 0s 882us/step - loss: 6265.5762 - val_loss: 11967.0830\n",
      "Epoch 105/1000\n",
      "307/307 [==============================] - 0s 851us/step - loss: 7564.0869 - val_loss: 2167.4094\n",
      "Epoch 106/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 4761.8799 - val_loss: 1812.5546\n",
      "Epoch 107/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 6044.5312 - val_loss: 7197.5889\n",
      "Epoch 108/1000\n",
      "307/307 [==============================] - 0s 862us/step - loss: 5563.6992 - val_loss: 5357.4595\n",
      "Epoch 109/1000\n",
      "307/307 [==============================] - 0s 881us/step - loss: 5405.8623 - val_loss: 660.3995\n",
      "Epoch 110/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 5053.2598 - val_loss: 1884.1708\n",
      "Epoch 111/1000\n",
      "307/307 [==============================] - 0s 910us/step - loss: 5398.1118 - val_loss: 2224.9631\n",
      "Epoch 112/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 5231.8530 - val_loss: 8199.1113\n",
      "Epoch 113/1000\n",
      "307/307 [==============================] - 0s 829us/step - loss: 5611.3667 - val_loss: 14506.6533\n",
      "Epoch 114/1000\n",
      "307/307 [==============================] - 0s 891us/step - loss: 4603.3867 - val_loss: 1241.3359\n",
      "Epoch 115/1000\n",
      "307/307 [==============================] - 0s 860us/step - loss: 3845.6760 - val_loss: 1685.9471\n",
      "Epoch 116/1000\n",
      "307/307 [==============================] - 0s 878us/step - loss: 5354.3223 - val_loss: 5677.4609\n",
      "Epoch 117/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 3588.2385 - val_loss: 8088.9546\n",
      "Epoch 118/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 4197.5171 - val_loss: 3504.6206\n",
      "Epoch 119/1000\n",
      "307/307 [==============================] - 0s 890us/step - loss: 4475.4658 - val_loss: 2807.6663\n",
      "Epoch 120/1000\n",
      "307/307 [==============================] - 0s 985us/step - loss: 3887.3103 - val_loss: 840.3911\n",
      "Epoch 121/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 4241.6021 - val_loss: 4518.7319\n",
      "Epoch 122/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 3641.8364 - val_loss: 2251.4609\n",
      "Epoch 123/1000\n",
      "307/307 [==============================] - 0s 922us/step - loss: 3904.2495 - val_loss: 1890.8661\n",
      "Epoch 124/1000\n",
      "307/307 [==============================] - 0s 915us/step - loss: 3683.0244 - val_loss: 2489.5603\n",
      "Epoch 125/1000\n",
      "307/307 [==============================] - 0s 847us/step - loss: 4166.0352 - val_loss: 2876.3684\n",
      "Epoch 126/1000\n",
      "307/307 [==============================] - 0s 814us/step - loss: 3360.1306 - val_loss: 8286.3701\n",
      "Epoch 127/1000\n",
      "307/307 [==============================] - 0s 860us/step - loss: 3799.0247 - val_loss: 929.7448\n",
      "Epoch 128/1000\n",
      "307/307 [==============================] - 0s 967us/step - loss: 3733.0627 - val_loss: 704.8978\n",
      "Epoch 129/1000\n",
      "307/307 [==============================] - 0s 865us/step - loss: 3915.4524 - val_loss: 1816.9082\n",
      "Epoch 130/1000\n",
      "307/307 [==============================] - 0s 874us/step - loss: 3715.2268 - val_loss: 13397.0781\n",
      "Epoch 131/1000\n",
      "307/307 [==============================] - 0s 860us/step - loss: 2623.6470 - val_loss: 6578.8208\n",
      "Epoch 132/1000\n",
      "307/307 [==============================] - 0s 927us/step - loss: 2899.0879 - val_loss: 1198.0186\n",
      "Epoch 133/1000\n",
      "307/307 [==============================] - 0s 875us/step - loss: 4357.2783 - val_loss: 3807.5964\n",
      "Epoch 134/1000\n",
      "307/307 [==============================] - 0s 886us/step - loss: 2477.3569 - val_loss: 2067.4585\n",
      "Epoch 135/1000\n",
      "307/307 [==============================] - 0s 926us/step - loss: 3645.3359 - val_loss: 3562.2529\n",
      "Epoch 136/1000\n",
      "307/307 [==============================] - 0s 842us/step - loss: 2686.1824 - val_loss: 6431.8228\n",
      "Epoch 137/1000\n",
      "307/307 [==============================] - 0s 896us/step - loss: 2924.9470 - val_loss: 666.6820\n",
      "Epoch 138/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 862us/step - loss: 2951.9167 - val_loss: 659.7001\n",
      "Epoch 139/1000\n",
      "307/307 [==============================] - 0s 895us/step - loss: 2518.3403 - val_loss: 2161.9182\n",
      "Epoch 140/1000\n",
      "307/307 [==============================] - 0s 867us/step - loss: 2823.0366 - val_loss: 677.0543\n",
      "Epoch 141/1000\n",
      "307/307 [==============================] - 0s 889us/step - loss: 3412.4309 - val_loss: 693.7379\n",
      "Epoch 142/1000\n",
      "307/307 [==============================] - 0s 881us/step - loss: 2562.0142 - val_loss: 2631.9983\n",
      "Epoch 143/1000\n",
      "307/307 [==============================] - 0s 850us/step - loss: 2602.6418 - val_loss: 655.5491\n",
      "Epoch 144/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 2825.6587 - val_loss: 885.9904\n",
      "Epoch 145/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 2236.8848 - val_loss: 5000.1338\n",
      "Epoch 146/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 2271.9695 - val_loss: 1251.5707\n",
      "Epoch 147/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 2386.0708 - val_loss: 2832.8252\n",
      "Epoch 148/1000\n",
      "307/307 [==============================] - 0s 987us/step - loss: 2330.1099 - val_loss: 1133.5757\n",
      "Epoch 149/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 2395.6318 - val_loss: 4435.4189\n",
      "Epoch 150/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 2589.5947 - val_loss: 727.8804\n",
      "Epoch 151/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 1508.0625 - val_loss: 4521.1343\n",
      "Epoch 152/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 2466.1301 - val_loss: 662.1478\n",
      "Epoch 153/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 2352.6587 - val_loss: 1273.4188\n",
      "Epoch 154/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1758.7913 - val_loss: 1756.2152\n",
      "Epoch 155/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1778.4878 - val_loss: 2852.1514\n",
      "Epoch 156/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 2063.3931 - val_loss: 5029.1777\n",
      "Epoch 157/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1376.5870 - val_loss: 10903.6680\n",
      "Epoch 158/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1624.0323 - val_loss: 1455.4318\n",
      "Epoch 159/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 2265.0896 - val_loss: 746.2690\n",
      "Epoch 160/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1266.7559 - val_loss: 898.4467\n",
      "Epoch 161/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 2025.5312 - val_loss: 1343.2068\n",
      "Epoch 162/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1493.7520 - val_loss: 1780.0034\n",
      "Epoch 163/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1563.9312 - val_loss: 1913.9188\n",
      "Epoch 164/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1226.2222 - val_loss: 1672.1090\n",
      "Epoch 165/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1171.7704 - val_loss: 3883.5044\n",
      "Epoch 166/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 1611.2314 - val_loss: 1278.8894\n",
      "Epoch 167/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1184.1785 - val_loss: 704.2770\n",
      "Epoch 168/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1149.0129 - val_loss: 880.2319\n",
      "Epoch 169/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1064.9421 - val_loss: 772.1958\n",
      "Epoch 170/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1213.1448 - val_loss: 672.0251\n",
      "Epoch 171/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 920.5436 - val_loss: 1725.8705\n",
      "Epoch 172/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1130.7858 - val_loss: 1151.9706\n",
      "Epoch 173/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 1254.8619 - val_loss: 654.9798\n",
      "Epoch 174/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 871.0217 - val_loss: 1347.3408\n",
      "Epoch 175/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 1035.0365 - val_loss: 1184.5580\n",
      "Epoch 176/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 785.4107 - val_loss: 746.4688\n",
      "Epoch 177/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 754.0292 - val_loss: 1505.4991\n",
      "Epoch 178/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 1000.2577 - val_loss: 2133.9780\n",
      "Epoch 179/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 832.2227 - val_loss: 666.0293\n",
      "Epoch 180/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 779.6270 - val_loss: 676.6932\n",
      "Epoch 181/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 779.6213 - val_loss: 960.8533\n",
      "Epoch 182/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 792.0679 - val_loss: 1472.7920\n",
      "Epoch 183/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 719.4254 - val_loss: 673.8930\n",
      "Epoch 184/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 675.3489 - val_loss: 891.5328\n",
      "Epoch 185/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 714.8211 - val_loss: 690.7520\n",
      "Epoch 186/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 597.2380 - val_loss: 943.5678\n",
      "Epoch 187/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 614.2656 - val_loss: 655.0198\n",
      "Epoch 188/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 628.3101 - val_loss: 935.0383\n",
      "Epoch 189/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 569.4415 - val_loss: 822.3187\n",
      "Epoch 190/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 530.7375 - val_loss: 685.1236\n",
      "Epoch 191/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 545.9465 - val_loss: 674.7479\n",
      "Epoch 192/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 516.8567 - val_loss: 990.5109\n",
      "Epoch 193/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 14024.1475 - val_loss: 714.0474\n",
      "Epoch 194/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.7110 - val_loss: 695.7415\n",
      "Epoch 195/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.6537 - val_loss: 712.4312\n",
      "Epoch 196/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 372.0903 - val_loss: 699.6871\n",
      "Epoch 197/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 372.2388 - val_loss: 688.8815\n",
      "Epoch 198/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 372.7971 - val_loss: 723.8145\n",
      "Epoch 199/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 372.5646 - val_loss: 678.3863\n",
      "Epoch 200/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.9893 - val_loss: 738.0242\n",
      "Epoch 201/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 372.4035 - val_loss: 682.7800\n",
      "Epoch 202/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 373.7087 - val_loss: 761.9905\n",
      "Epoch 203/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 373.1895 - val_loss: 712.9291\n",
      "Epoch 204/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 374.2840 - val_loss: 703.1913\n",
      "Epoch 205/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 374.5180 - val_loss: 699.5941\n",
      "Epoch 206/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 374.3727 - val_loss: 788.2611\n",
      "Epoch 207/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 377.7256 - val_loss: 729.3534\n",
      "Epoch 208/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 374.9742 - val_loss: 715.7835\n",
      "Epoch 209/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 378.1583 - val_loss: 697.7537\n",
      "Epoch 210/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 374.6745 - val_loss: 681.8188\n",
      "Epoch 211/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 378.0374 - val_loss: 713.0030\n",
      "Epoch 212/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 377.3175 - val_loss: 745.8195\n",
      "Epoch 213/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 1s 2ms/step - loss: 380.1570 - val_loss: 809.8624\n",
      "Epoch 214/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 384.5924 - val_loss: 692.9579\n",
      "Epoch 215/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 382.2820 - val_loss: 752.2089\n",
      "Epoch 216/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 388.2494 - val_loss: 773.4146\n",
      "Epoch 217/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 385.5802 - val_loss: 777.6210\n",
      "Epoch 218/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 384.5416 - val_loss: 747.2811\n",
      "Epoch 219/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 384.2676 - val_loss: 676.0543\n",
      "Epoch 220/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 386.7809 - val_loss: 732.3898\n",
      "Epoch 221/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 384.8453 - val_loss: 810.3812\n",
      "Epoch 222/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 396.0328 - val_loss: 689.4557\n",
      "Epoch 223/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 393.2378 - val_loss: 692.7424\n",
      "Epoch 224/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 387.0326 - val_loss: 680.2820\n",
      "Epoch 225/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 382.2562 - val_loss: 791.3030\n",
      "Epoch 226/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 394.7836 - val_loss: 796.7919\n",
      "Epoch 227/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 388.1863 - val_loss: 731.9842\n",
      "Epoch 228/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 392.9015 - val_loss: 707.7020\n",
      "Epoch 229/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 388.4919 - val_loss: 687.8902\n",
      "Epoch 230/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 392.1597 - val_loss: 717.6495\n",
      "Epoch 231/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 390.4424 - val_loss: 672.4130\n",
      "Epoch 232/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 388.0230 - val_loss: 704.3969\n",
      "Epoch 233/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 386.9798 - val_loss: 709.8572\n",
      "Epoch 234/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 389.5888 - val_loss: 712.5319\n",
      "Epoch 235/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 386.4272 - val_loss: 712.8018\n",
      "Epoch 236/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 391.0735 - val_loss: 708.3893\n",
      "Epoch 237/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 390.5412 - val_loss: 783.7089\n",
      "Epoch 238/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 395.9538 - val_loss: 673.3329\n",
      "Epoch 239/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 389.2437 - val_loss: 868.1782\n",
      "Epoch 240/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 391.2656 - val_loss: 657.6249\n",
      "Epoch 241/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 393.6477 - val_loss: 673.5681\n",
      "Epoch 242/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 389.9012 - val_loss: 698.0397\n",
      "Epoch 243/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 387.4557 - val_loss: 708.5602\n",
      "Epoch 244/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 392.7646 - val_loss: 666.3715\n",
      "Epoch 245/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 390.0201 - val_loss: 733.3921\n",
      "Epoch 246/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 391.7704 - val_loss: 755.4382\n",
      "Epoch 247/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 398.5405 - val_loss: 664.2549\n",
      "Epoch 248/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 388.5358 - val_loss: 662.9993\n",
      "Epoch 249/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 393.7731 - val_loss: 691.1212\n",
      "Epoch 250/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 388.4237 - val_loss: 737.5417\n",
      "Epoch 251/1000\n",
      "307/307 [==============================] - 0s 921us/step - loss: 392.0361 - val_loss: 654.3431\n",
      "Epoch 252/1000\n",
      "307/307 [==============================] - 0s 871us/step - loss: 385.2595 - val_loss: 711.5114\n",
      "Epoch 253/1000\n",
      "307/307 [==============================] - 0s 908us/step - loss: 394.0550 - val_loss: 665.4948\n",
      "Epoch 254/1000\n",
      "307/307 [==============================] - 0s 834us/step - loss: 389.1563 - val_loss: 667.6747\n",
      "Epoch 255/1000\n",
      "307/307 [==============================] - 0s 829us/step - loss: 1069.0074 - val_loss: 1529.2656\n",
      "Epoch 256/1000\n",
      "307/307 [==============================] - 0s 884us/step - loss: 863.8257 - val_loss: 1504.2297\n",
      "Epoch 257/1000\n",
      "307/307 [==============================] - 0s 834us/step - loss: 846.3807 - val_loss: 1482.6215\n",
      "Epoch 258/1000\n",
      "307/307 [==============================] - 0s 871us/step - loss: 830.8839 - val_loss: 1462.8301\n",
      "Epoch 259/1000\n",
      "307/307 [==============================] - 0s 851us/step - loss: 816.5619 - val_loss: 1444.2441\n",
      "Epoch 260/1000\n",
      "307/307 [==============================] - 0s 875us/step - loss: 803.0442 - val_loss: 1426.5254\n",
      "Epoch 261/1000\n",
      "307/307 [==============================] - 0s 812us/step - loss: 790.1317 - val_loss: 1409.4121\n",
      "Epoch 262/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 777.6988 - val_loss: 1392.8247\n",
      "Epoch 263/1000\n",
      "307/307 [==============================] - 0s 985us/step - loss: 765.6534 - val_loss: 1376.6455\n",
      "Epoch 264/1000\n",
      "307/307 [==============================] - 0s 838us/step - loss: 753.9233 - val_loss: 1360.8060\n",
      "Epoch 265/1000\n",
      "307/307 [==============================] - 0s 813us/step - loss: 742.4642 - val_loss: 1345.2615\n",
      "Epoch 266/1000\n",
      "307/307 [==============================] - 0s 912us/step - loss: 731.2538 - val_loss: 1329.9965\n",
      "Epoch 267/1000\n",
      "307/307 [==============================] - 0s 848us/step - loss: 720.2729 - val_loss: 1314.9028\n",
      "Epoch 268/1000\n",
      "307/307 [==============================] - 0s 851us/step - loss: 709.5082 - val_loss: 1300.1033\n",
      "Epoch 269/1000\n",
      "307/307 [==============================] - 0s 854us/step - loss: 698.9554 - val_loss: 1285.5270\n",
      "Epoch 270/1000\n",
      "307/307 [==============================] - 0s 819us/step - loss: 688.5988 - val_loss: 1271.1302\n",
      "Epoch 271/1000\n",
      "307/307 [==============================] - 0s 849us/step - loss: 678.4440 - val_loss: 1256.9471\n",
      "Epoch 272/1000\n",
      "307/307 [==============================] - 0s 899us/step - loss: 668.4713 - val_loss: 1242.9386\n",
      "Epoch 273/1000\n",
      "307/307 [==============================] - 0s 866us/step - loss: 658.6830 - val_loss: 1229.1309\n",
      "Epoch 274/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 649.0605 - val_loss: 1215.5142\n",
      "Epoch 275/1000\n",
      "307/307 [==============================] - 0s 829us/step - loss: 639.6315 - val_loss: 1202.0654\n",
      "Epoch 276/1000\n",
      "307/307 [==============================] - 0s 859us/step - loss: 630.3952 - val_loss: 1188.8401\n",
      "Epoch 277/1000\n",
      "307/307 [==============================] - 0s 872us/step - loss: 621.3268 - val_loss: 1175.7980\n",
      "Epoch 278/1000\n",
      "307/307 [==============================] - 0s 839us/step - loss: 612.4330 - val_loss: 1162.9415\n",
      "Epoch 279/1000\n",
      "307/307 [==============================] - 0s 899us/step - loss: 603.7012 - val_loss: 1150.2188\n",
      "Epoch 280/1000\n",
      "307/307 [==============================] - 0s 833us/step - loss: 595.1466 - val_loss: 1137.6921\n",
      "Epoch 281/1000\n",
      "307/307 [==============================] - 0s 894us/step - loss: 586.7858 - val_loss: 1125.3466\n",
      "Epoch 282/1000\n",
      "307/307 [==============================] - 0s 863us/step - loss: 578.6047 - val_loss: 1113.2804\n",
      "Epoch 283/1000\n",
      "307/307 [==============================] - 0s 838us/step - loss: 570.5973 - val_loss: 1101.3201\n",
      "Epoch 284/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 562.7640 - val_loss: 1089.5518\n",
      "Epoch 285/1000\n",
      "307/307 [==============================] - 0s 835us/step - loss: 555.1011 - val_loss: 1077.9689\n",
      "Epoch 286/1000\n",
      "307/307 [==============================] - 0s 864us/step - loss: 547.6138 - val_loss: 1066.5452\n",
      "Epoch 287/1000\n",
      "307/307 [==============================] - 0s 843us/step - loss: 540.2970 - val_loss: 1055.3109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/1000\n",
      "307/307 [==============================] - 0s 841us/step - loss: 533.1642 - val_loss: 1044.3364\n",
      "Epoch 289/1000\n",
      "307/307 [==============================] - 0s 923us/step - loss: 526.1879 - val_loss: 1033.4187\n",
      "Epoch 290/1000\n",
      "307/307 [==============================] - 0s 845us/step - loss: 519.3770 - val_loss: 1022.7434\n",
      "Epoch 291/1000\n",
      "307/307 [==============================] - 0s 997us/step - loss: 512.7469 - val_loss: 1012.2979\n",
      "Epoch 292/1000\n",
      "307/307 [==============================] - 0s 831us/step - loss: 506.2969 - val_loss: 1001.9309\n",
      "Epoch 293/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 500.0102 - val_loss: 991.8515\n",
      "Epoch 294/1000\n",
      "307/307 [==============================] - 0s 878us/step - loss: 493.8946 - val_loss: 981.8817\n",
      "Epoch 295/1000\n",
      "307/307 [==============================] - 0s 933us/step - loss: 487.9478 - val_loss: 972.1392\n",
      "Epoch 296/1000\n",
      "307/307 [==============================] - 0s 888us/step - loss: 482.1642 - val_loss: 962.5582\n",
      "Epoch 297/1000\n",
      "307/307 [==============================] - 0s 966us/step - loss: 476.5460 - val_loss: 953.1515\n",
      "Epoch 298/1000\n",
      "307/307 [==============================] - 0s 869us/step - loss: 471.0865 - val_loss: 943.9009\n",
      "Epoch 299/1000\n",
      "307/307 [==============================] - 0s 888us/step - loss: 465.7990 - val_loss: 934.8580\n",
      "Epoch 300/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 460.6818 - val_loss: 926.0089\n",
      "Epoch 301/1000\n",
      "307/307 [==============================] - 0s 807us/step - loss: 455.7242 - val_loss: 917.3339\n",
      "Epoch 302/1000\n",
      "307/307 [==============================] - 0s 854us/step - loss: 450.9305 - val_loss: 908.8267\n",
      "Epoch 303/1000\n",
      "307/307 [==============================] - 0s 813us/step - loss: 446.3034 - val_loss: 900.4657\n",
      "Epoch 304/1000\n",
      "307/307 [==============================] - 0s 923us/step - loss: 441.8346 - val_loss: 892.3289\n",
      "Epoch 305/1000\n",
      "307/307 [==============================] - 0s 944us/step - loss: 437.5302 - val_loss: 884.4089\n",
      "Epoch 306/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 433.3929 - val_loss: 876.6396\n",
      "Epoch 307/1000\n",
      "307/307 [==============================] - 0s 917us/step - loss: 429.4076 - val_loss: 869.0728\n",
      "Epoch 308/1000\n",
      "307/307 [==============================] - 0s 823us/step - loss: 425.5829 - val_loss: 861.6910\n",
      "Epoch 309/1000\n",
      "307/307 [==============================] - 0s 898us/step - loss: 421.9118 - val_loss: 854.4760\n",
      "Epoch 310/1000\n",
      "307/307 [==============================] - 0s 867us/step - loss: 418.3996 - val_loss: 847.4225\n",
      "Epoch 311/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 415.0487 - val_loss: 840.5945\n",
      "Epoch 312/1000\n",
      "307/307 [==============================] - 0s 814us/step - loss: 411.8459 - val_loss: 833.9661\n",
      "Epoch 313/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 408.7894 - val_loss: 827.4948\n",
      "Epoch 314/1000\n",
      "307/307 [==============================] - 0s 805us/step - loss: 405.8803 - val_loss: 821.1982\n",
      "Epoch 315/1000\n",
      "307/307 [==============================] - 0s 838us/step - loss: 403.1300 - val_loss: 815.1245\n",
      "Epoch 316/1000\n",
      "307/307 [==============================] - 0s 803us/step - loss: 400.5319 - val_loss: 809.2495\n",
      "Epoch 317/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 398.0735 - val_loss: 803.4981\n",
      "Epoch 318/1000\n",
      "307/307 [==============================] - 0s 899us/step - loss: 395.7555 - val_loss: 798.0053\n",
      "Epoch 319/1000\n",
      "307/307 [==============================] - 0s 852us/step - loss: 393.5781 - val_loss: 792.7150\n",
      "Epoch 320/1000\n",
      "307/307 [==============================] - 0s 835us/step - loss: 391.5383 - val_loss: 787.5762\n",
      "Epoch 321/1000\n",
      "307/307 [==============================] - 0s 940us/step - loss: 389.6353 - val_loss: 782.6450\n",
      "Epoch 322/1000\n",
      "307/307 [==============================] - 0s 947us/step - loss: 387.8577 - val_loss: 777.9662\n",
      "Epoch 323/1000\n",
      "307/307 [==============================] - 0s 871us/step - loss: 386.2084 - val_loss: 773.3923\n",
      "Epoch 324/1000\n",
      "307/307 [==============================] - 0s 843us/step - loss: 384.6764 - val_loss: 769.0133\n",
      "Epoch 325/1000\n",
      "307/307 [==============================] - 0s 891us/step - loss: 383.2628 - val_loss: 764.8763\n",
      "Epoch 326/1000\n",
      "307/307 [==============================] - 0s 862us/step - loss: 381.9674 - val_loss: 760.8892\n",
      "Epoch 327/1000\n",
      "307/307 [==============================] - 0s 824us/step - loss: 380.7764 - val_loss: 757.0645\n",
      "Epoch 328/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 379.6864 - val_loss: 753.4365\n",
      "Epoch 329/1000\n",
      "307/307 [==============================] - 0s 905us/step - loss: 378.6932 - val_loss: 750.0515\n",
      "Epoch 330/1000\n",
      "307/307 [==============================] - 0s 807us/step - loss: 377.7965 - val_loss: 746.7343\n",
      "Epoch 331/1000\n",
      "307/307 [==============================] - 0s 862us/step - loss: 376.9837 - val_loss: 743.7086\n",
      "Epoch 332/1000\n",
      "307/307 [==============================] - 0s 988us/step - loss: 376.2608 - val_loss: 740.7933\n",
      "Epoch 333/1000\n",
      "307/307 [==============================] - 0s 843us/step - loss: 375.6160 - val_loss: 738.0836\n",
      "Epoch 334/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 375.0396 - val_loss: 735.4833\n",
      "Epoch 335/1000\n",
      "307/307 [==============================] - 0s 844us/step - loss: 374.5302 - val_loss: 733.0925\n",
      "Epoch 336/1000\n",
      "307/307 [==============================] - 0s 922us/step - loss: 374.0822 - val_loss: 730.9314\n",
      "Epoch 337/1000\n",
      "307/307 [==============================] - 0s 816us/step - loss: 373.6915 - val_loss: 728.8180\n",
      "Epoch 338/1000\n",
      "307/307 [==============================] - 0s 869us/step - loss: 373.3544 - val_loss: 726.9269\n",
      "Epoch 339/1000\n",
      "307/307 [==============================] - 0s 921us/step - loss: 373.0627 - val_loss: 725.1392\n",
      "Epoch 340/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 372.8086 - val_loss: 723.5502\n",
      "Epoch 341/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 372.5883 - val_loss: 721.9905\n",
      "Epoch 342/1000\n",
      "307/307 [==============================] - 0s 914us/step - loss: 372.3998 - val_loss: 720.6445\n",
      "Epoch 343/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 372.2346 - val_loss: 719.3187\n",
      "Epoch 344/1000\n",
      "307/307 [==============================] - 0s 918us/step - loss: 372.0948 - val_loss: 718.1415\n",
      "Epoch 345/1000\n",
      "307/307 [==============================] - 0s 806us/step - loss: 371.9769 - val_loss: 717.0974\n",
      "Epoch 346/1000\n",
      "307/307 [==============================] - 0s 859us/step - loss: 371.8741 - val_loss: 716.0281\n",
      "Epoch 347/1000\n",
      "307/307 [==============================] - 0s 883us/step - loss: 371.7883 - val_loss: 715.1150\n",
      "Epoch 348/1000\n",
      "307/307 [==============================] - 0s 959us/step - loss: 371.7193 - val_loss: 714.2936\n",
      "Epoch 349/1000\n",
      "307/307 [==============================] - 0s 850us/step - loss: 371.6572 - val_loss: 713.5095\n",
      "Epoch 350/1000\n",
      "307/307 [==============================] - 0s 880us/step - loss: 371.6060 - val_loss: 712.8080\n",
      "Epoch 351/1000\n",
      "307/307 [==============================] - 0s 953us/step - loss: 371.5622 - val_loss: 712.2296\n",
      "Epoch 352/1000\n",
      "307/307 [==============================] - 0s 887us/step - loss: 371.5235 - val_loss: 711.5626\n",
      "Epoch 353/1000\n",
      "307/307 [==============================] - 0s 866us/step - loss: 371.4935 - val_loss: 711.0207\n",
      "Epoch 354/1000\n",
      "307/307 [==============================] - 0s 902us/step - loss: 371.4677 - val_loss: 710.5604\n",
      "Epoch 355/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 371.4484 - val_loss: 710.1175\n",
      "Epoch 356/1000\n",
      "307/307 [==============================] - 0s 966us/step - loss: 371.4267 - val_loss: 709.6733\n",
      "Epoch 357/1000\n",
      "307/307 [==============================] - 0s 898us/step - loss: 371.4113 - val_loss: 709.3635\n",
      "Epoch 358/1000\n",
      "307/307 [==============================] - 0s 864us/step - loss: 371.3999 - val_loss: 708.9546\n",
      "Epoch 359/1000\n",
      "307/307 [==============================] - 0s 849us/step - loss: 371.3877 - val_loss: 708.5999\n",
      "Epoch 360/1000\n",
      "307/307 [==============================] - 0s 882us/step - loss: 371.3792 - val_loss: 708.4062\n",
      "Epoch 361/1000\n",
      "307/307 [==============================] - 0s 888us/step - loss: 371.3725 - val_loss: 708.1486\n",
      "Epoch 362/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 882us/step - loss: 371.3650 - val_loss: 707.8727\n",
      "Epoch 363/1000\n",
      "307/307 [==============================] - 0s 860us/step - loss: 371.3604 - val_loss: 707.6669\n",
      "Epoch 364/1000\n",
      "307/307 [==============================] - 0s 900us/step - loss: 371.3568 - val_loss: 707.4837\n",
      "Epoch 365/1000\n",
      "307/307 [==============================] - 0s 847us/step - loss: 371.3518 - val_loss: 707.2998\n",
      "Epoch 366/1000\n",
      "307/307 [==============================] - 0s 850us/step - loss: 371.3494 - val_loss: 707.1690\n",
      "Epoch 367/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 371.3482 - val_loss: 706.9934\n",
      "Epoch 368/1000\n",
      "307/307 [==============================] - 0s 832us/step - loss: 371.3447 - val_loss: 706.8538\n",
      "Epoch 369/1000\n",
      "307/307 [==============================] - 0s 923us/step - loss: 371.3434 - val_loss: 706.7137\n",
      "Epoch 370/1000\n",
      "307/307 [==============================] - 0s 874us/step - loss: 371.3409 - val_loss: 706.6223\n",
      "Epoch 371/1000\n",
      "307/307 [==============================] - 0s 917us/step - loss: 371.3405 - val_loss: 706.5209\n",
      "Epoch 372/1000\n",
      "307/307 [==============================] - 0s 852us/step - loss: 371.3399 - val_loss: 706.4384\n",
      "Epoch 373/1000\n",
      "307/307 [==============================] - 0s 801us/step - loss: 371.3387 - val_loss: 706.3362\n",
      "Epoch 374/1000\n",
      "307/307 [==============================] - 0s 874us/step - loss: 371.3370 - val_loss: 706.2629\n",
      "Epoch 375/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 371.3377 - val_loss: 706.1906\n",
      "Epoch 376/1000\n",
      "307/307 [==============================] - 0s 856us/step - loss: 371.3369 - val_loss: 706.0859\n",
      "Epoch 377/1000\n",
      "307/307 [==============================] - 0s 888us/step - loss: 371.3362 - val_loss: 706.0154\n",
      "Epoch 378/1000\n",
      "307/307 [==============================] - 0s 844us/step - loss: 371.3358 - val_loss: 706.0075\n",
      "Epoch 379/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 371.3351 - val_loss: 705.9601\n",
      "Epoch 380/1000\n",
      "307/307 [==============================] - 0s 923us/step - loss: 371.3365 - val_loss: 705.8932\n",
      "Epoch 381/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 371.3341 - val_loss: 705.8862\n",
      "Epoch 382/1000\n",
      "307/307 [==============================] - 0s 822us/step - loss: 371.3356 - val_loss: 705.8809\n",
      "Epoch 383/1000\n",
      "307/307 [==============================] - 0s 887us/step - loss: 371.3382 - val_loss: 705.7670\n",
      "Epoch 384/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 371.3350 - val_loss: 705.7769\n",
      "Epoch 385/1000\n",
      "307/307 [==============================] - 0s 863us/step - loss: 371.3350 - val_loss: 705.7993\n",
      "Epoch 386/1000\n",
      "307/307 [==============================] - 0s 989us/step - loss: 371.3341 - val_loss: 705.6868\n",
      "Epoch 387/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 371.3344 - val_loss: 705.6785\n",
      "Epoch 388/1000\n",
      "307/307 [==============================] - 0s 864us/step - loss: 371.3346 - val_loss: 705.6865\n",
      "Epoch 389/1000\n",
      "307/307 [==============================] - 0s 893us/step - loss: 371.3362 - val_loss: 705.6764\n",
      "Epoch 390/1000\n",
      "307/307 [==============================] - 0s 965us/step - loss: 371.3355 - val_loss: 705.6331\n",
      "Epoch 391/1000\n",
      "307/307 [==============================] - 0s 891us/step - loss: 371.3348 - val_loss: 705.6461\n",
      "Epoch 392/1000\n",
      "307/307 [==============================] - 0s 909us/step - loss: 371.3344 - val_loss: 705.6055\n",
      "Epoch 393/1000\n",
      "307/307 [==============================] - 0s 970us/step - loss: 371.3337 - val_loss: 705.6257\n",
      "Epoch 394/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 371.3339 - val_loss: 705.5489\n",
      "Epoch 395/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 371.3355 - val_loss: 705.5943\n",
      "Epoch 396/1000\n",
      "307/307 [==============================] - 0s 863us/step - loss: 371.3346 - val_loss: 705.6028\n",
      "Epoch 397/1000\n",
      "307/307 [==============================] - 0s 848us/step - loss: 371.3334 - val_loss: 705.5511\n",
      "Epoch 398/1000\n",
      "307/307 [==============================] - 0s 929us/step - loss: 371.3347 - val_loss: 705.5252\n",
      "Epoch 399/1000\n",
      "307/307 [==============================] - 0s 818us/step - loss: 371.3340 - val_loss: 705.5506\n",
      "Epoch 400/1000\n",
      "307/307 [==============================] - 0s 898us/step - loss: 371.3340 - val_loss: 705.5240\n",
      "Epoch 401/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 371.3338 - val_loss: 705.5344\n",
      "Epoch 402/1000\n",
      "307/307 [==============================] - 0s 843us/step - loss: 371.3352 - val_loss: 705.4807\n",
      "Epoch 403/1000\n",
      "307/307 [==============================] - 0s 896us/step - loss: 371.3350 - val_loss: 705.4870\n",
      "Epoch 404/1000\n",
      "307/307 [==============================] - 0s 904us/step - loss: 371.3343 - val_loss: 705.4981\n",
      "Epoch 405/1000\n",
      "307/307 [==============================] - 0s 921us/step - loss: 371.3344 - val_loss: 705.4781\n",
      "Epoch 406/1000\n",
      "307/307 [==============================] - 0s 929us/step - loss: 371.3356 - val_loss: 705.4821\n",
      "Epoch 407/1000\n",
      "307/307 [==============================] - 0s 851us/step - loss: 371.3332 - val_loss: 705.5117\n",
      "Epoch 408/1000\n",
      "307/307 [==============================] - 0s 864us/step - loss: 371.3350 - val_loss: 705.5026\n",
      "Epoch 409/1000\n",
      "307/307 [==============================] - 0s 909us/step - loss: 371.3355 - val_loss: 705.4826\n",
      "Epoch 410/1000\n",
      "307/307 [==============================] - 0s 902us/step - loss: 371.3358 - val_loss: 705.5151\n",
      "Epoch 411/1000\n",
      "307/307 [==============================] - 0s 899us/step - loss: 371.3347 - val_loss: 705.4731\n",
      "Epoch 412/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 371.3341 - val_loss: 705.5022\n",
      "Epoch 413/1000\n",
      "307/307 [==============================] - 0s 938us/step - loss: 371.3347 - val_loss: 705.5244\n",
      "Epoch 414/1000\n",
      "307/307 [==============================] - 0s 907us/step - loss: 371.3341 - val_loss: 705.5009\n",
      "Epoch 415/1000\n",
      "307/307 [==============================] - 0s 918us/step - loss: 371.3342 - val_loss: 705.4819\n",
      "Epoch 416/1000\n",
      "307/307 [==============================] - 0s 860us/step - loss: 371.3348 - val_loss: 705.4297\n",
      "Epoch 417/1000\n",
      "307/307 [==============================] - 0s 938us/step - loss: 371.3347 - val_loss: 705.4714\n",
      "Epoch 418/1000\n",
      "307/307 [==============================] - 0s 834us/step - loss: 371.3344 - val_loss: 705.5131\n",
      "Epoch 419/1000\n",
      "307/307 [==============================] - 0s 971us/step - loss: 371.3341 - val_loss: 705.5195\n",
      "Epoch 420/1000\n",
      "307/307 [==============================] - 0s 905us/step - loss: 371.3360 - val_loss: 705.4351\n",
      "Epoch 421/1000\n",
      "307/307 [==============================] - 0s 911us/step - loss: 371.3342 - val_loss: 705.4822\n",
      "Epoch 422/1000\n",
      "307/307 [==============================] - 0s 898us/step - loss: 371.3351 - val_loss: 705.4932\n",
      "Epoch 423/1000\n",
      "307/307 [==============================] - 0s 853us/step - loss: 371.3341 - val_loss: 705.4495\n",
      "Epoch 424/1000\n",
      "307/307 [==============================] - 0s 897us/step - loss: 371.3347 - val_loss: 705.4410\n",
      "Epoch 425/1000\n",
      "307/307 [==============================] - 0s 919us/step - loss: 371.3359 - val_loss: 705.5092\n",
      "Epoch 426/1000\n",
      "307/307 [==============================] - 0s 811us/step - loss: 371.3359 - val_loss: 705.4387\n",
      "Epoch 427/1000\n",
      "307/307 [==============================] - 0s 918us/step - loss: 371.3342 - val_loss: 705.4683\n",
      "Epoch 428/1000\n",
      "307/307 [==============================] - 0s 839us/step - loss: 371.3342 - val_loss: 705.4247\n",
      "Epoch 429/1000\n",
      "307/307 [==============================] - 0s 905us/step - loss: 371.3339 - val_loss: 705.4492\n",
      "Epoch 430/1000\n",
      "307/307 [==============================] - 0s 925us/step - loss: 371.3338 - val_loss: 705.4333\n",
      "Epoch 431/1000\n",
      "307/307 [==============================] - 0s 966us/step - loss: 371.3341 - val_loss: 705.4496\n",
      "Epoch 432/1000\n",
      "307/307 [==============================] - 0s 959us/step - loss: 371.3341 - val_loss: 705.4614\n",
      "Epoch 433/1000\n",
      "307/307 [==============================] - 0s 874us/step - loss: 371.3350 - val_loss: 705.4658\n",
      "Epoch 434/1000\n",
      "307/307 [==============================] - 0s 867us/step - loss: 371.3339 - val_loss: 705.4035\n",
      "Epoch 435/1000\n",
      "307/307 [==============================] - 0s 894us/step - loss: 371.3345 - val_loss: 705.4312\n",
      "Epoch 436/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 883us/step - loss: 371.3341 - val_loss: 705.4132\n",
      "Epoch 437/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 371.3334 - val_loss: 705.4551\n",
      "Epoch 438/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 371.3351 - val_loss: 705.4910\n",
      "Epoch 439/1000\n",
      "307/307 [==============================] - 0s 887us/step - loss: 371.3346 - val_loss: 705.4132\n",
      "Epoch 440/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 371.3347 - val_loss: 705.4288\n",
      "Epoch 441/1000\n",
      "307/307 [==============================] - 0s 896us/step - loss: 371.3361 - val_loss: 705.4077\n",
      "Epoch 442/1000\n",
      "307/307 [==============================] - 0s 993us/step - loss: 371.3351 - val_loss: 705.4281\n",
      "Epoch 443/1000\n",
      "307/307 [==============================] - 0s 902us/step - loss: 371.3341 - val_loss: 705.4766\n",
      "Epoch 444/1000\n",
      "307/307 [==============================] - 0s 847us/step - loss: 371.3344 - val_loss: 705.4068\n",
      "Epoch 445/1000\n",
      "307/307 [==============================] - 0s 869us/step - loss: 371.3347 - val_loss: 705.4200\n",
      "Epoch 446/1000\n",
      "307/307 [==============================] - 0s 936us/step - loss: 371.3356 - val_loss: 705.4499\n",
      "Epoch 447/1000\n",
      "307/307 [==============================] - 0s 869us/step - loss: 371.3338 - val_loss: 705.4444\n",
      "Epoch 448/1000\n",
      "307/307 [==============================] - 0s 872us/step - loss: 371.3342 - val_loss: 705.4131\n",
      "Epoch 449/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 371.3341 - val_loss: 705.4612\n",
      "Epoch 450/1000\n",
      "307/307 [==============================] - 0s 910us/step - loss: 371.3353 - val_loss: 705.4622\n",
      "Epoch 451/1000\n",
      "307/307 [==============================] - 0s 882us/step - loss: 371.3340 - val_loss: 705.4306\n",
      "Epoch 452/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 371.3339 - val_loss: 705.4141\n",
      "Epoch 453/1000\n",
      "307/307 [==============================] - 0s 961us/step - loss: 371.3361 - val_loss: 705.4365\n",
      "Epoch 454/1000\n",
      "307/307 [==============================] - 0s 899us/step - loss: 371.3346 - val_loss: 705.4241\n",
      "Epoch 455/1000\n",
      "307/307 [==============================] - 0s 886us/step - loss: 371.3342 - val_loss: 705.4371\n",
      "Epoch 456/1000\n",
      "307/307 [==============================] - 0s 911us/step - loss: 371.3351 - val_loss: 705.4407\n",
      "Epoch 457/1000\n",
      "307/307 [==============================] - 0s 963us/step - loss: 371.3342 - val_loss: 705.4846\n",
      "Epoch 458/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3344 - val_loss: 705.4843\n",
      "Epoch 459/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3341 - val_loss: 705.4485\n",
      "Epoch 460/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3363 - val_loss: 705.4006\n",
      "Epoch 461/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3335 - val_loss: 705.4274\n",
      "Epoch 462/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3340 - val_loss: 705.4189\n",
      "Epoch 463/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3354 - val_loss: 705.5131\n",
      "Epoch 464/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3351 - val_loss: 705.4830\n",
      "Epoch 465/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3337 - val_loss: 705.4678\n",
      "Epoch 466/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3343 - val_loss: 705.4033\n",
      "Epoch 467/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3338 - val_loss: 705.4335\n",
      "Epoch 468/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3339 - val_loss: 705.4426\n",
      "Epoch 469/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4512\n",
      "Epoch 470/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3340 - val_loss: 705.4332\n",
      "Epoch 471/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4675\n",
      "Epoch 472/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3351 - val_loss: 705.4635\n",
      "Epoch 473/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3350 - val_loss: 705.4217\n",
      "Epoch 474/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3344 - val_loss: 705.3959\n",
      "Epoch 475/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4124\n",
      "Epoch 476/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3342 - val_loss: 705.4526\n",
      "Epoch 477/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4166\n",
      "Epoch 478/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3346 - val_loss: 705.3904\n",
      "Epoch 479/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3345 - val_loss: 705.3934\n",
      "Epoch 480/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4179\n",
      "Epoch 481/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3336 - val_loss: 705.4058\n",
      "Epoch 482/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3345 - val_loss: 705.4438\n",
      "Epoch 483/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3352 - val_loss: 705.4051\n",
      "Epoch 484/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3353 - val_loss: 705.4066\n",
      "Epoch 485/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3355 - val_loss: 705.4413\n",
      "Epoch 486/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4517\n",
      "Epoch 487/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3336 - val_loss: 705.3745\n",
      "Epoch 488/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3344 - val_loss: 705.4098\n",
      "Epoch 489/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4155\n",
      "Epoch 490/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3352 - val_loss: 705.3583\n",
      "Epoch 491/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3364 - val_loss: 705.3850\n",
      "Epoch 492/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.3988\n",
      "Epoch 493/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3356 - val_loss: 705.4294\n",
      "Epoch 494/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4508\n",
      "Epoch 495/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3340 - val_loss: 705.3895\n",
      "Epoch 496/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3361 - val_loss: 705.4806\n",
      "Epoch 497/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3350 - val_loss: 705.4498\n",
      "Epoch 498/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.3940\n",
      "Epoch 499/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3358 - val_loss: 705.4549\n",
      "Epoch 500/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3352 - val_loss: 705.3510\n",
      "Epoch 501/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3348 - val_loss: 705.3646\n",
      "Epoch 502/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3340 - val_loss: 705.3919\n",
      "Epoch 503/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3364 - val_loss: 705.4350\n",
      "Epoch 504/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3362 - val_loss: 705.4035\n",
      "Epoch 505/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3341 - val_loss: 705.3990\n",
      "Epoch 506/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3348 - val_loss: 705.3952\n",
      "Epoch 507/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4686\n",
      "Epoch 508/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3354 - val_loss: 705.4398\n",
      "Epoch 509/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3348 - val_loss: 705.4372\n",
      "Epoch 510/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3345 - val_loss: 705.4120\n",
      "Epoch 511/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3349 - val_loss: 705.4014\n",
      "Epoch 512/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3355 - val_loss: 705.3760\n",
      "Epoch 513/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3347 - val_loss: 705.3647\n",
      "Epoch 514/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3354 - val_loss: 705.4401\n",
      "Epoch 515/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4100\n",
      "Epoch 516/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3337 - val_loss: 705.3926\n",
      "Epoch 517/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3332 - val_loss: 705.4163\n",
      "Epoch 518/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3344 - val_loss: 705.3871\n",
      "Epoch 519/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3338 - val_loss: 705.4556\n",
      "Epoch 520/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4476\n",
      "Epoch 521/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3338 - val_loss: 705.4342\n",
      "Epoch 522/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4398\n",
      "Epoch 523/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3345 - val_loss: 705.4635\n",
      "Epoch 524/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4567\n",
      "Epoch 525/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3342 - val_loss: 705.4666\n",
      "Epoch 526/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3358 - val_loss: 705.4410\n",
      "Epoch 527/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3354 - val_loss: 705.4334\n",
      "Epoch 528/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3338 - val_loss: 705.4603\n",
      "Epoch 529/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.3820\n",
      "Epoch 530/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3336 - val_loss: 705.3980\n",
      "Epoch 531/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3334 - val_loss: 705.4318\n",
      "Epoch 532/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.4634\n",
      "Epoch 533/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3364 - val_loss: 705.4268\n",
      "Epoch 534/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3340 - val_loss: 705.4468\n",
      "Epoch 535/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3349 - val_loss: 705.4715\n",
      "Epoch 536/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3353 - val_loss: 705.5023\n",
      "Epoch 537/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3330 - val_loss: 705.4540\n",
      "Epoch 538/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3350 - val_loss: 705.4658\n",
      "Epoch 539/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3348 - val_loss: 705.4156\n",
      "Epoch 540/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3359 - val_loss: 705.4373\n",
      "Epoch 541/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3354 - val_loss: 705.4799\n",
      "Epoch 542/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4133\n",
      "Epoch 543/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3341 - val_loss: 705.4446\n",
      "Epoch 544/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3338 - val_loss: 705.4467\n",
      "Epoch 545/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3336 - val_loss: 705.4548\n",
      "Epoch 546/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.4182\n",
      "Epoch 547/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3350 - val_loss: 705.4297\n",
      "Epoch 548/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3341 - val_loss: 705.4579\n",
      "Epoch 549/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3342 - val_loss: 705.4739\n",
      "Epoch 550/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.4366\n",
      "Epoch 551/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3340 - val_loss: 705.4286\n",
      "Epoch 552/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3364 - val_loss: 705.4182\n",
      "Epoch 553/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4478\n",
      "Epoch 554/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3350 - val_loss: 705.4243\n",
      "Epoch 555/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3345 - val_loss: 705.4604\n",
      "Epoch 556/1000\n",
      "307/307 [==============================] - 0s 928us/step - loss: 371.3342 - val_loss: 705.4230\n",
      "Epoch 557/1000\n",
      "307/307 [==============================] - 0s 830us/step - loss: 371.3344 - val_loss: 705.4894\n",
      "Epoch 558/1000\n",
      "307/307 [==============================] - 0s 925us/step - loss: 371.3347 - val_loss: 705.4323\n",
      "Epoch 559/1000\n",
      "307/307 [==============================] - 0s 917us/step - loss: 371.3335 - val_loss: 705.4220\n",
      "Epoch 560/1000\n",
      "307/307 [==============================] - 0s 908us/step - loss: 371.3344 - val_loss: 705.4258\n",
      "Epoch 561/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 371.3356 - val_loss: 705.4395\n",
      "Epoch 562/1000\n",
      "307/307 [==============================] - 0s 799us/step - loss: 371.3338 - val_loss: 705.4678\n",
      "Epoch 563/1000\n",
      "307/307 [==============================] - 0s 826us/step - loss: 371.3345 - val_loss: 705.4235\n",
      "Epoch 564/1000\n",
      "307/307 [==============================] - 0s 836us/step - loss: 371.3353 - val_loss: 705.4402\n",
      "Epoch 565/1000\n",
      "307/307 [==============================] - 0s 916us/step - loss: 371.3345 - val_loss: 705.4604\n",
      "Epoch 566/1000\n",
      "307/307 [==============================] - 0s 832us/step - loss: 371.3340 - val_loss: 705.4985\n",
      "Epoch 567/1000\n",
      "307/307 [==============================] - 0s 912us/step - loss: 371.3344 - val_loss: 705.4835\n",
      "Epoch 568/1000\n",
      "307/307 [==============================] - 0s 894us/step - loss: 371.3351 - val_loss: 705.4273\n",
      "Epoch 569/1000\n",
      "307/307 [==============================] - 0s 856us/step - loss: 371.3337 - val_loss: 705.4753\n",
      "Epoch 570/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 371.3331 - val_loss: 705.4268\n",
      "Epoch 571/1000\n",
      "307/307 [==============================] - 0s 827us/step - loss: 371.3340 - val_loss: 705.4716\n",
      "Epoch 572/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 371.3342 - val_loss: 705.4635\n",
      "Epoch 573/1000\n",
      "307/307 [==============================] - 0s 869us/step - loss: 371.3336 - val_loss: 705.4686\n",
      "Epoch 574/1000\n",
      "307/307 [==============================] - 0s 854us/step - loss: 371.3351 - val_loss: 705.4039\n",
      "Epoch 575/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 371.3343 - val_loss: 705.4151\n",
      "Epoch 576/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 371.3344 - val_loss: 705.4562\n",
      "Epoch 577/1000\n",
      "307/307 [==============================] - 0s 866us/step - loss: 371.3331 - val_loss: 705.4830\n",
      "Epoch 578/1000\n",
      "307/307 [==============================] - 0s 976us/step - loss: 371.3336 - val_loss: 705.4224\n",
      "Epoch 579/1000\n",
      "307/307 [==============================] - 0s 838us/step - loss: 371.3344 - val_loss: 705.4332\n",
      "Epoch 580/1000\n",
      "307/307 [==============================] - 0s 907us/step - loss: 371.3341 - val_loss: 705.4449\n",
      "Epoch 581/1000\n",
      "307/307 [==============================] - 0s 816us/step - loss: 371.3349 - val_loss: 705.4552\n",
      "Epoch 582/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 371.3358 - val_loss: 705.4294\n",
      "Epoch 583/1000\n",
      "307/307 [==============================] - 0s 807us/step - loss: 371.3339 - val_loss: 705.4572\n",
      "Epoch 584/1000\n",
      "307/307 [==============================] - 0s 803us/step - loss: 371.3339 - val_loss: 705.4609\n",
      "Epoch 585/1000\n",
      "307/307 [==============================] - 0s 843us/step - loss: 371.3344 - val_loss: 705.4297\n",
      "Epoch 586/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 862us/step - loss: 371.3344 - val_loss: 705.4517\n",
      "Epoch 587/1000\n",
      "307/307 [==============================] - 0s 929us/step - loss: 371.3352 - val_loss: 705.4346\n",
      "Epoch 588/1000\n",
      "307/307 [==============================] - 0s 831us/step - loss: 371.3345 - val_loss: 705.4199\n",
      "Epoch 589/1000\n",
      "307/307 [==============================] - 0s 880us/step - loss: 371.3349 - val_loss: 705.4725\n",
      "Epoch 590/1000\n",
      "307/307 [==============================] - 0s 881us/step - loss: 371.3348 - val_loss: 705.4605\n",
      "Epoch 591/1000\n",
      "307/307 [==============================] - 0s 899us/step - loss: 371.3338 - val_loss: 705.4294\n",
      "Epoch 592/1000\n",
      "307/307 [==============================] - 0s 891us/step - loss: 371.3343 - val_loss: 705.4193\n",
      "Epoch 593/1000\n",
      "307/307 [==============================] - 0s 819us/step - loss: 371.3349 - val_loss: 705.4229\n",
      "Epoch 594/1000\n",
      "307/307 [==============================] - 0s 854us/step - loss: 371.3338 - val_loss: 705.4483\n",
      "Epoch 595/1000\n",
      "307/307 [==============================] - 0s 847us/step - loss: 371.3351 - val_loss: 705.3730\n",
      "Epoch 596/1000\n",
      "307/307 [==============================] - 0s 883us/step - loss: 371.3344 - val_loss: 705.4290\n",
      "Epoch 597/1000\n",
      "307/307 [==============================] - 0s 925us/step - loss: 371.3340 - val_loss: 705.4828\n",
      "Epoch 598/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 371.3351 - val_loss: 705.4321\n",
      "Epoch 599/1000\n",
      "307/307 [==============================] - 0s 840us/step - loss: 371.3335 - val_loss: 705.4465\n",
      "Epoch 600/1000\n",
      "307/307 [==============================] - 0s 903us/step - loss: 371.3354 - val_loss: 705.4976\n",
      "Epoch 601/1000\n",
      "307/307 [==============================] - 0s 789us/step - loss: 371.3340 - val_loss: 705.4300\n",
      "Epoch 602/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 371.3357 - val_loss: 705.4753\n",
      "Epoch 603/1000\n",
      "307/307 [==============================] - 0s 884us/step - loss: 371.3338 - val_loss: 705.4655\n",
      "Epoch 604/1000\n",
      "307/307 [==============================] - 0s 856us/step - loss: 371.3347 - val_loss: 705.4361\n",
      "Epoch 605/1000\n",
      "307/307 [==============================] - 0s 820us/step - loss: 371.3340 - val_loss: 705.4243\n",
      "Epoch 606/1000\n",
      "307/307 [==============================] - 0s 907us/step - loss: 371.3365 - val_loss: 705.4192\n",
      "Epoch 607/1000\n",
      "307/307 [==============================] - 0s 836us/step - loss: 371.3336 - val_loss: 705.4471\n",
      "Epoch 608/1000\n",
      "307/307 [==============================] - 0s 848us/step - loss: 371.3345 - val_loss: 705.4377\n",
      "Epoch 609/1000\n",
      "307/307 [==============================] - 0s 864us/step - loss: 371.3355 - val_loss: 705.4470\n",
      "Epoch 610/1000\n",
      "307/307 [==============================] - 0s 949us/step - loss: 371.3351 - val_loss: 705.4924\n",
      "Epoch 611/1000\n",
      "307/307 [==============================] - 0s 828us/step - loss: 371.3333 - val_loss: 705.4567\n",
      "Epoch 612/1000\n",
      "307/307 [==============================] - 0s 928us/step - loss: 371.3353 - val_loss: 705.4378\n",
      "Epoch 613/1000\n",
      "307/307 [==============================] - 0s 853us/step - loss: 371.3344 - val_loss: 705.4459\n",
      "Epoch 614/1000\n",
      "307/307 [==============================] - 0s 921us/step - loss: 371.3335 - val_loss: 705.4652\n",
      "Epoch 615/1000\n",
      "307/307 [==============================] - 0s 878us/step - loss: 371.3348 - val_loss: 705.4565\n",
      "Epoch 616/1000\n",
      "307/307 [==============================] - 0s 867us/step - loss: 371.3340 - val_loss: 705.4548\n",
      "Epoch 617/1000\n",
      "307/307 [==============================] - 0s 869us/step - loss: 371.3333 - val_loss: 705.4432\n",
      "Epoch 618/1000\n",
      "307/307 [==============================] - 0s 906us/step - loss: 371.3338 - val_loss: 705.4559\n",
      "Epoch 619/1000\n",
      "307/307 [==============================] - 0s 859us/step - loss: 371.3349 - val_loss: 705.4510\n",
      "Epoch 620/1000\n",
      "307/307 [==============================] - 0s 855us/step - loss: 371.3346 - val_loss: 705.4525\n",
      "Epoch 621/1000\n",
      "307/307 [==============================] - 0s 912us/step - loss: 371.3354 - val_loss: 705.5232\n",
      "Epoch 622/1000\n",
      "307/307 [==============================] - 0s 884us/step - loss: 371.3345 - val_loss: 705.4557\n",
      "Epoch 623/1000\n",
      "307/307 [==============================] - 0s 859us/step - loss: 371.3340 - val_loss: 705.4985\n",
      "Epoch 624/1000\n",
      "307/307 [==============================] - 0s 934us/step - loss: 371.3350 - val_loss: 705.4214\n",
      "Epoch 625/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 371.3351 - val_loss: 705.4892\n",
      "Epoch 626/1000\n",
      "307/307 [==============================] - 0s 882us/step - loss: 371.3338 - val_loss: 705.4844\n",
      "Epoch 627/1000\n",
      "307/307 [==============================] - 0s 820us/step - loss: 371.3341 - val_loss: 705.4220\n",
      "Epoch 628/1000\n",
      "307/307 [==============================] - 0s 934us/step - loss: 371.3348 - val_loss: 705.4597\n",
      "Epoch 629/1000\n",
      "307/307 [==============================] - 0s 838us/step - loss: 371.3347 - val_loss: 705.4103\n",
      "Epoch 630/1000\n",
      "307/307 [==============================] - 0s 796us/step - loss: 371.3358 - val_loss: 705.5208\n",
      "Epoch 631/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 371.3347 - val_loss: 705.4644\n",
      "Epoch 632/1000\n",
      "307/307 [==============================] - 0s 869us/step - loss: 371.3344 - val_loss: 705.4744\n",
      "Epoch 633/1000\n",
      "307/307 [==============================] - 0s 865us/step - loss: 371.3339 - val_loss: 705.5049\n",
      "Epoch 634/1000\n",
      "307/307 [==============================] - 0s 908us/step - loss: 371.3345 - val_loss: 705.4677\n",
      "Epoch 635/1000\n",
      "307/307 [==============================] - 0s 818us/step - loss: 371.3349 - val_loss: 705.4220\n",
      "Epoch 636/1000\n",
      "307/307 [==============================] - 0s 879us/step - loss: 371.3344 - val_loss: 705.4436\n",
      "Epoch 637/1000\n",
      "307/307 [==============================] - 0s 815us/step - loss: 371.3344 - val_loss: 705.4429\n",
      "Epoch 638/1000\n",
      "307/307 [==============================] - 0s 928us/step - loss: 371.3345 - val_loss: 705.4357\n",
      "Epoch 639/1000\n",
      "307/307 [==============================] - 0s 871us/step - loss: 371.3369 - val_loss: 705.4266\n",
      "Epoch 640/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 371.3365 - val_loss: 705.5274\n",
      "Epoch 641/1000\n",
      "307/307 [==============================] - 0s 881us/step - loss: 371.3355 - val_loss: 705.4828\n",
      "Epoch 642/1000\n",
      "307/307 [==============================] - 0s 940us/step - loss: 371.3349 - val_loss: 705.4659\n",
      "Epoch 643/1000\n",
      "307/307 [==============================] - 0s 879us/step - loss: 371.3340 - val_loss: 705.4525\n",
      "Epoch 644/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 371.3351 - val_loss: 705.4526\n",
      "Epoch 645/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 371.3335 - val_loss: 705.4763\n",
      "Epoch 646/1000\n",
      "307/307 [==============================] - 0s 834us/step - loss: 371.3339 - val_loss: 705.4208\n",
      "Epoch 647/1000\n",
      "307/307 [==============================] - 0s 864us/step - loss: 371.3344 - val_loss: 705.4020\n",
      "Epoch 648/1000\n",
      "307/307 [==============================] - 0s 938us/step - loss: 371.3360 - val_loss: 705.4417\n",
      "Epoch 649/1000\n",
      "307/307 [==============================] - 0s 897us/step - loss: 371.3350 - val_loss: 705.3936\n",
      "Epoch 650/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 371.3348 - val_loss: 705.4935\n",
      "Epoch 651/1000\n",
      "307/307 [==============================] - 0s 893us/step - loss: 371.3337 - val_loss: 705.4350\n",
      "Epoch 652/1000\n",
      "307/307 [==============================] - 0s 883us/step - loss: 371.3336 - val_loss: 705.4066\n",
      "Epoch 653/1000\n",
      "307/307 [==============================] - 0s 850us/step - loss: 371.3351 - val_loss: 705.3473\n",
      "Epoch 654/1000\n",
      "307/307 [==============================] - 0s 886us/step - loss: 371.3337 - val_loss: 705.4125\n",
      "Epoch 655/1000\n",
      "307/307 [==============================] - 0s 808us/step - loss: 371.3354 - val_loss: 705.4372\n",
      "Epoch 656/1000\n",
      "307/307 [==============================] - 0s 930us/step - loss: 371.3338 - val_loss: 705.4976\n",
      "Epoch 657/1000\n",
      "307/307 [==============================] - 0s 872us/step - loss: 371.3336 - val_loss: 705.4548\n",
      "Epoch 658/1000\n",
      "307/307 [==============================] - 0s 827us/step - loss: 371.3359 - val_loss: 705.4168\n",
      "Epoch 659/1000\n",
      "307/307 [==============================] - 0s 900us/step - loss: 371.3362 - val_loss: 705.4735\n",
      "Epoch 660/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 879us/step - loss: 371.3362 - val_loss: 705.4587\n",
      "Epoch 661/1000\n",
      "307/307 [==============================] - 0s 837us/step - loss: 371.3346 - val_loss: 705.3942\n",
      "Epoch 662/1000\n",
      "307/307 [==============================] - 0s 880us/step - loss: 371.3335 - val_loss: 705.4220\n",
      "Epoch 663/1000\n",
      "307/307 [==============================] - 0s 889us/step - loss: 371.3341 - val_loss: 705.4199\n",
      "Epoch 664/1000\n",
      "307/307 [==============================] - 0s 794us/step - loss: 371.3346 - val_loss: 705.4177\n",
      "Epoch 665/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 371.3349 - val_loss: 705.3803\n",
      "Epoch 666/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 371.3360 - val_loss: 705.4029\n",
      "Epoch 667/1000\n",
      "307/307 [==============================] - 0s 871us/step - loss: 371.3358 - val_loss: 705.3770\n",
      "Epoch 668/1000\n",
      "307/307 [==============================] - 0s 878us/step - loss: 371.3345 - val_loss: 705.3684\n",
      "Epoch 669/1000\n",
      "307/307 [==============================] - 0s 856us/step - loss: 371.3341 - val_loss: 705.4198\n",
      "Epoch 670/1000\n",
      "307/307 [==============================] - 0s 902us/step - loss: 371.3370 - val_loss: 705.5142\n",
      "Epoch 671/1000\n",
      "307/307 [==============================] - 0s 906us/step - loss: 371.3372 - val_loss: 705.4107\n",
      "Epoch 672/1000\n",
      "307/307 [==============================] - 0s 966us/step - loss: 371.3345 - val_loss: 705.3932\n",
      "Epoch 673/1000\n",
      "307/307 [==============================] - 0s 914us/step - loss: 371.3345 - val_loss: 705.3668\n",
      "Epoch 674/1000\n",
      "307/307 [==============================] - 0s 952us/step - loss: 371.3333 - val_loss: 705.4045\n",
      "Epoch 675/1000\n",
      "307/307 [==============================] - 0s 993us/step - loss: 371.3339 - val_loss: 705.4626\n",
      "Epoch 676/1000\n",
      "307/307 [==============================] - 0s 917us/step - loss: 371.3342 - val_loss: 705.4134\n",
      "Epoch 677/1000\n",
      "307/307 [==============================] - 0s 893us/step - loss: 371.3351 - val_loss: 705.4294\n",
      "Epoch 678/1000\n",
      "307/307 [==============================] - 0s 867us/step - loss: 371.3347 - val_loss: 705.4102\n",
      "Epoch 679/1000\n",
      "307/307 [==============================] - 0s 918us/step - loss: 371.3348 - val_loss: 705.4476\n",
      "Epoch 680/1000\n",
      "307/307 [==============================] - 0s 936us/step - loss: 371.3351 - val_loss: 705.4628\n",
      "Epoch 681/1000\n",
      "307/307 [==============================] - 0s 903us/step - loss: 371.3347 - val_loss: 705.4426\n",
      "Epoch 682/1000\n",
      "307/307 [==============================] - 0s 911us/step - loss: 371.3346 - val_loss: 705.4869\n",
      "Epoch 683/1000\n",
      "307/307 [==============================] - 0s 796us/step - loss: 371.3356 - val_loss: 705.4294\n",
      "Epoch 684/1000\n",
      "307/307 [==============================] - 0s 824us/step - loss: 371.3343 - val_loss: 705.4475\n",
      "Epoch 685/1000\n",
      "307/307 [==============================] - 0s 864us/step - loss: 371.3349 - val_loss: 705.4601\n",
      "Epoch 686/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 371.3352 - val_loss: 705.4666\n",
      "Epoch 687/1000\n",
      "307/307 [==============================] - 0s 931us/step - loss: 371.3343 - val_loss: 705.4232\n",
      "Epoch 688/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 371.3349 - val_loss: 705.4454\n",
      "Epoch 689/1000\n",
      "307/307 [==============================] - 0s 898us/step - loss: 371.3351 - val_loss: 705.4272\n",
      "Epoch 690/1000\n",
      "307/307 [==============================] - 0s 865us/step - loss: 371.3348 - val_loss: 705.4207\n",
      "Epoch 691/1000\n",
      "307/307 [==============================] - 0s 890us/step - loss: 371.3354 - val_loss: 705.4785\n",
      "Epoch 692/1000\n",
      "307/307 [==============================] - 0s 912us/step - loss: 371.3337 - val_loss: 705.3881\n",
      "Epoch 693/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 371.3344 - val_loss: 705.4024\n",
      "Epoch 694/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 371.3346 - val_loss: 705.4146\n",
      "Epoch 695/1000\n",
      "307/307 [==============================] - 0s 893us/step - loss: 371.3330 - val_loss: 705.3915\n",
      "Epoch 696/1000\n",
      "307/307 [==============================] - 0s 854us/step - loss: 371.3339 - val_loss: 705.4342\n",
      "Epoch 697/1000\n",
      "307/307 [==============================] - 0s 985us/step - loss: 371.3341 - val_loss: 705.4212\n",
      "Epoch 698/1000\n",
      "307/307 [==============================] - 0s 882us/step - loss: 371.3351 - val_loss: 705.4290\n",
      "Epoch 699/1000\n",
      "307/307 [==============================] - 0s 883us/step - loss: 371.3343 - val_loss: 705.4429\n",
      "Epoch 700/1000\n",
      "307/307 [==============================] - 0s 834us/step - loss: 371.3339 - val_loss: 705.4197\n",
      "Epoch 701/1000\n",
      "307/307 [==============================] - 0s 879us/step - loss: 371.3344 - val_loss: 705.4471\n",
      "Epoch 702/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 371.3359 - val_loss: 705.4415\n",
      "Epoch 703/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 371.3336 - val_loss: 705.4333\n",
      "Epoch 704/1000\n",
      "307/307 [==============================] - 0s 951us/step - loss: 371.3338 - val_loss: 705.4294\n",
      "Epoch 705/1000\n",
      "307/307 [==============================] - 0s 867us/step - loss: 371.3346 - val_loss: 705.4296\n",
      "Epoch 706/1000\n",
      "307/307 [==============================] - 0s 934us/step - loss: 371.3342 - val_loss: 705.4756\n",
      "Epoch 707/1000\n",
      "307/307 [==============================] - 0s 832us/step - loss: 371.3345 - val_loss: 705.4253\n",
      "Epoch 708/1000\n",
      "307/307 [==============================] - 0s 854us/step - loss: 371.3338 - val_loss: 705.4395\n",
      "Epoch 709/1000\n",
      "307/307 [==============================] - 0s 887us/step - loss: 371.3344 - val_loss: 705.4732\n",
      "Epoch 710/1000\n",
      "307/307 [==============================] - 0s 891us/step - loss: 371.3335 - val_loss: 705.4799\n",
      "Epoch 711/1000\n",
      "307/307 [==============================] - 0s 895us/step - loss: 371.3351 - val_loss: 705.4549\n",
      "Epoch 712/1000\n",
      "307/307 [==============================] - 0s 883us/step - loss: 371.3349 - val_loss: 705.4582\n",
      "Epoch 713/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 371.3350 - val_loss: 705.4648\n",
      "Epoch 714/1000\n",
      "307/307 [==============================] - 0s 911us/step - loss: 371.3351 - val_loss: 705.4456\n",
      "Epoch 715/1000\n",
      "307/307 [==============================] - 0s 896us/step - loss: 371.3349 - val_loss: 705.4459\n",
      "Epoch 716/1000\n",
      "307/307 [==============================] - 0s 884us/step - loss: 371.3342 - val_loss: 705.4760\n",
      "Epoch 717/1000\n",
      "307/307 [==============================] - 0s 964us/step - loss: 371.3361 - val_loss: 705.4270\n",
      "Epoch 718/1000\n",
      "307/307 [==============================] - 0s 895us/step - loss: 371.3347 - val_loss: 705.4189\n",
      "Epoch 719/1000\n",
      "307/307 [==============================] - 0s 874us/step - loss: 371.3361 - val_loss: 705.4382\n",
      "Epoch 720/1000\n",
      "307/307 [==============================] - 0s 910us/step - loss: 371.3338 - val_loss: 705.3916\n",
      "Epoch 721/1000\n",
      "307/307 [==============================] - 0s 931us/step - loss: 371.3363 - val_loss: 705.3815\n",
      "Epoch 722/1000\n",
      "307/307 [==============================] - 0s 844us/step - loss: 371.3350 - val_loss: 705.4846\n",
      "Epoch 723/1000\n",
      "307/307 [==============================] - 0s 848us/step - loss: 371.3347 - val_loss: 705.4701\n",
      "Epoch 724/1000\n",
      "307/307 [==============================] - 0s 836us/step - loss: 371.3347 - val_loss: 705.4499\n",
      "Epoch 725/1000\n",
      "307/307 [==============================] - 0s 843us/step - loss: 371.3359 - val_loss: 705.4282\n",
      "Epoch 726/1000\n",
      "307/307 [==============================] - 0s 895us/step - loss: 371.3343 - val_loss: 705.4171\n",
      "Epoch 727/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 371.3349 - val_loss: 705.4103\n",
      "Epoch 728/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 371.3354 - val_loss: 705.4579\n",
      "Epoch 729/1000\n",
      "307/307 [==============================] - 0s 866us/step - loss: 371.3339 - val_loss: 705.4077\n",
      "Epoch 730/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 371.3351 - val_loss: 705.4449\n",
      "Epoch 731/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 371.3343 - val_loss: 705.4571\n",
      "Epoch 732/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 371.3335 - val_loss: 705.4566\n",
      "Epoch 733/1000\n",
      "307/307 [==============================] - 0s 866us/step - loss: 371.3340 - val_loss: 705.4940\n",
      "Epoch 734/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 865us/step - loss: 371.3348 - val_loss: 705.3890\n",
      "Epoch 735/1000\n",
      "307/307 [==============================] - 0s 925us/step - loss: 371.3346 - val_loss: 705.4348\n",
      "Epoch 736/1000\n",
      "307/307 [==============================] - 0s 893us/step - loss: 371.3340 - val_loss: 705.4693\n",
      "Epoch 737/1000\n",
      "307/307 [==============================] - 0s 828us/step - loss: 371.3347 - val_loss: 705.4614\n",
      "Epoch 738/1000\n",
      "307/307 [==============================] - 0s 951us/step - loss: 371.3344 - val_loss: 705.4711\n",
      "Epoch 739/1000\n",
      "307/307 [==============================] - 0s 879us/step - loss: 371.3350 - val_loss: 705.4135\n",
      "Epoch 740/1000\n",
      "307/307 [==============================] - 0s 952us/step - loss: 371.3343 - val_loss: 705.4459\n",
      "Epoch 741/1000\n",
      "307/307 [==============================] - 0s 891us/step - loss: 371.3359 - val_loss: 705.4563\n",
      "Epoch 742/1000\n",
      "307/307 [==============================] - 0s 891us/step - loss: 371.3337 - val_loss: 705.4186\n",
      "Epoch 743/1000\n",
      "307/307 [==============================] - 0s 853us/step - loss: 371.3348 - val_loss: 705.4146\n",
      "Epoch 744/1000\n",
      "307/307 [==============================] - 0s 888us/step - loss: 371.3362 - val_loss: 705.4519\n",
      "Epoch 745/1000\n",
      "307/307 [==============================] - 0s 833us/step - loss: 371.3355 - val_loss: 705.4581\n",
      "Epoch 746/1000\n",
      "307/307 [==============================] - 0s 832us/step - loss: 371.3348 - val_loss: 705.4387\n",
      "Epoch 747/1000\n",
      "307/307 [==============================] - 0s 862us/step - loss: 371.3344 - val_loss: 705.3766\n",
      "Epoch 748/1000\n",
      "307/307 [==============================] - 0s 944us/step - loss: 371.3362 - val_loss: 705.4771\n",
      "Epoch 749/1000\n",
      "307/307 [==============================] - 0s 905us/step - loss: 371.3346 - val_loss: 705.4089\n",
      "Epoch 750/1000\n",
      "307/307 [==============================] - 0s 898us/step - loss: 371.3340 - val_loss: 705.4446\n",
      "Epoch 751/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 371.3342 - val_loss: 705.4227\n",
      "Epoch 752/1000\n",
      "307/307 [==============================] - 0s 942us/step - loss: 371.3347 - val_loss: 705.4634\n",
      "Epoch 753/1000\n",
      "307/307 [==============================] - 0s 983us/step - loss: 371.3352 - val_loss: 705.4655\n",
      "Epoch 754/1000\n",
      "307/307 [==============================] - 0s 996us/step - loss: 371.3360 - val_loss: 705.3790\n",
      "Epoch 755/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3351 - val_loss: 705.4272\n",
      "Epoch 756/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3347 - val_loss: 705.4413\n",
      "Epoch 757/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3353 - val_loss: 705.4582\n",
      "Epoch 758/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3349 - val_loss: 705.4973\n",
      "Epoch 759/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3345 - val_loss: 705.4459\n",
      "Epoch 760/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3348 - val_loss: 705.4010\n",
      "Epoch 761/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4022\n",
      "Epoch 762/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3336 - val_loss: 705.4500\n",
      "Epoch 763/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3345 - val_loss: 705.4225\n",
      "Epoch 764/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3358 - val_loss: 705.5266\n",
      "Epoch 765/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3343 - val_loss: 705.4799\n",
      "Epoch 766/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3359 - val_loss: 705.3947\n",
      "Epoch 767/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3338 - val_loss: 705.4027\n",
      "Epoch 768/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4191\n",
      "Epoch 769/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3338 - val_loss: 705.4324\n",
      "Epoch 770/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3343 - val_loss: 705.4551\n",
      "Epoch 771/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3337 - val_loss: 705.3905\n",
      "Epoch 772/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3343 - val_loss: 705.4200\n",
      "Epoch 773/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3350 - val_loss: 705.4536\n",
      "Epoch 774/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4080\n",
      "Epoch 775/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3342 - val_loss: 705.4851\n",
      "Epoch 776/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3351 - val_loss: 705.4385\n",
      "Epoch 777/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3350 - val_loss: 705.4670\n",
      "Epoch 778/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4180\n",
      "Epoch 779/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3339 - val_loss: 705.4006\n",
      "Epoch 780/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3340 - val_loss: 705.4489\n",
      "Epoch 781/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3339 - val_loss: 705.4404\n",
      "Epoch 782/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.4030\n",
      "Epoch 783/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4819\n",
      "Epoch 784/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3356 - val_loss: 705.4551\n",
      "Epoch 785/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3348 - val_loss: 705.4312\n",
      "Epoch 786/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4457\n",
      "Epoch 787/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3337 - val_loss: 705.4667\n",
      "Epoch 788/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4392\n",
      "Epoch 789/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.4869\n",
      "Epoch 790/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3335 - val_loss: 705.4553\n",
      "Epoch 791/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3355 - val_loss: 705.4116\n",
      "Epoch 792/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4511\n",
      "Epoch 793/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3347 - val_loss: 705.4686\n",
      "Epoch 794/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3347 - val_loss: 705.4362\n",
      "Epoch 795/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4397\n",
      "Epoch 796/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3358 - val_loss: 705.4006\n",
      "Epoch 797/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3343 - val_loss: 705.4312\n",
      "Epoch 798/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3353 - val_loss: 705.4429\n",
      "Epoch 799/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3339 - val_loss: 705.4110\n",
      "Epoch 800/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3338 - val_loss: 705.4030\n",
      "Epoch 801/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3349 - val_loss: 705.4255\n",
      "Epoch 802/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3340 - val_loss: 705.4484\n",
      "Epoch 803/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3348 - val_loss: 705.4327\n",
      "Epoch 804/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3366 - val_loss: 705.3948\n",
      "Epoch 805/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3351 - val_loss: 705.4586\n",
      "Epoch 806/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3350 - val_loss: 705.3936\n",
      "Epoch 807/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3362 - val_loss: 705.4080\n",
      "Epoch 808/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3338 - val_loss: 705.4429\n",
      "Epoch 809/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4305\n",
      "Epoch 810/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3341 - val_loss: 705.4165\n",
      "Epoch 811/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4605\n",
      "Epoch 812/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3334 - val_loss: 705.4744\n",
      "Epoch 813/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4512\n",
      "Epoch 814/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3336 - val_loss: 705.4346\n",
      "Epoch 815/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3335 - val_loss: 705.4410\n",
      "Epoch 816/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3351 - val_loss: 705.4099\n",
      "Epoch 817/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3333 - val_loss: 705.4214\n",
      "Epoch 818/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3369 - val_loss: 705.4659\n",
      "Epoch 819/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3339 - val_loss: 705.4587\n",
      "Epoch 820/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4219\n",
      "Epoch 821/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3344 - val_loss: 705.4423\n",
      "Epoch 822/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3362 - val_loss: 705.4975\n",
      "Epoch 823/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3358 - val_loss: 705.4133\n",
      "Epoch 824/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4502\n",
      "Epoch 825/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3348 - val_loss: 705.4410\n",
      "Epoch 826/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4423\n",
      "Epoch 827/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3344 - val_loss: 705.4742\n",
      "Epoch 828/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3351 - val_loss: 705.4533\n",
      "Epoch 829/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3340 - val_loss: 705.4869\n",
      "Epoch 830/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3338 - val_loss: 705.4726\n",
      "Epoch 831/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4248\n",
      "Epoch 832/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3350 - val_loss: 705.5071\n",
      "Epoch 833/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4363\n",
      "Epoch 834/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3345 - val_loss: 705.4695\n",
      "Epoch 835/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3336 - val_loss: 705.4332\n",
      "Epoch 836/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4324\n",
      "Epoch 837/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3372 - val_loss: 705.4477\n",
      "Epoch 838/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4638\n",
      "Epoch 839/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3353 - val_loss: 705.4299\n",
      "Epoch 840/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.4792\n",
      "Epoch 841/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3342 - val_loss: 705.3964\n",
      "Epoch 842/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3344 - val_loss: 705.4655\n",
      "Epoch 843/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3354 - val_loss: 705.4533\n",
      "Epoch 844/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3343 - val_loss: 705.4586\n",
      "Epoch 845/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3344 - val_loss: 705.5234\n",
      "Epoch 846/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3348 - val_loss: 705.4321\n",
      "Epoch 847/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3342 - val_loss: 705.4842\n",
      "Epoch 848/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3339 - val_loss: 705.4735\n",
      "Epoch 849/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.4330\n",
      "Epoch 850/1000\n",
      "307/307 [==============================] - 1s 3ms/step - loss: 371.3344 - val_loss: 705.4487\n",
      "Epoch 851/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3352 - val_loss: 705.4470\n",
      "Epoch 852/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3347 - val_loss: 705.4785\n",
      "Epoch 853/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3351 - val_loss: 705.4174\n",
      "Epoch 854/1000\n",
      "307/307 [==============================] - 1s 2ms/step - loss: 371.3346 - val_loss: 705.4289\n",
      "Epoch 855/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3339 - val_loss: 705.4274\n",
      "Epoch 856/1000\n",
      "307/307 [==============================] - 0s 1ms/step - loss: 371.3354 - val_loss: 705.5111\n",
      "Epoch 857/1000\n",
      "307/307 [==============================] - 0s 933us/step - loss: 371.3344 - val_loss: 705.5129\n",
      "Epoch 858/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 371.3352 - val_loss: 705.4138\n",
      "Epoch 859/1000\n",
      "307/307 [==============================] - 0s 897us/step - loss: 371.3341 - val_loss: 705.4809\n",
      "Epoch 860/1000\n",
      "307/307 [==============================] - 0s 910us/step - loss: 371.3352 - val_loss: 705.4471\n",
      "Epoch 861/1000\n",
      "307/307 [==============================] - 0s 814us/step - loss: 371.3360 - val_loss: 705.3831\n",
      "Epoch 862/1000\n",
      "307/307 [==============================] - 0s 798us/step - loss: 371.3348 - val_loss: 705.4100\n",
      "Epoch 863/1000\n",
      "307/307 [==============================] - 0s 860us/step - loss: 371.3350 - val_loss: 705.4217\n",
      "Epoch 864/1000\n",
      "307/307 [==============================] - 0s 904us/step - loss: 371.3351 - val_loss: 705.4337\n",
      "Epoch 865/1000\n",
      "307/307 [==============================] - 0s 857us/step - loss: 371.3337 - val_loss: 705.3985\n",
      "Epoch 866/1000\n",
      "307/307 [==============================] - 0s 839us/step - loss: 371.3338 - val_loss: 705.3846\n",
      "Epoch 867/1000\n",
      "307/307 [==============================] - 0s 924us/step - loss: 371.3355 - val_loss: 705.4683\n",
      "Epoch 868/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 371.3346 - val_loss: 705.4188\n",
      "Epoch 869/1000\n",
      "307/307 [==============================] - 0s 887us/step - loss: 371.3336 - val_loss: 705.4178\n",
      "Epoch 870/1000\n",
      "307/307 [==============================] - 0s 897us/step - loss: 371.3346 - val_loss: 705.4262\n",
      "Epoch 871/1000\n",
      "307/307 [==============================] - 0s 886us/step - loss: 371.3346 - val_loss: 705.3967\n",
      "Epoch 872/1000\n",
      "307/307 [==============================] - 0s 906us/step - loss: 371.3345 - val_loss: 705.4240\n",
      "Epoch 873/1000\n",
      "307/307 [==============================] - 0s 798us/step - loss: 371.3351 - val_loss: 705.4179\n",
      "Epoch 874/1000\n",
      "307/307 [==============================] - 0s 769us/step - loss: 371.3347 - val_loss: 705.4151\n",
      "Epoch 875/1000\n",
      "307/307 [==============================] - 0s 829us/step - loss: 371.3344 - val_loss: 705.4189\n",
      "Epoch 876/1000\n",
      "307/307 [==============================] - 0s 879us/step - loss: 371.3345 - val_loss: 705.4142\n",
      "Epoch 877/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 371.3350 - val_loss: 705.3467\n",
      "Epoch 878/1000\n",
      "307/307 [==============================] - 0s 914us/step - loss: 371.3345 - val_loss: 705.3821\n",
      "Epoch 879/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 371.3357 - val_loss: 705.4318\n",
      "Epoch 880/1000\n",
      "307/307 [==============================] - 0s 901us/step - loss: 371.3336 - val_loss: 705.4303\n",
      "Epoch 881/1000\n",
      "307/307 [==============================] - 0s 889us/step - loss: 371.3347 - val_loss: 705.4719\n",
      "Epoch 882/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 371.3336 - val_loss: 705.3943\n",
      "Epoch 883/1000\n",
      "307/307 [==============================] - 0s 897us/step - loss: 371.3339 - val_loss: 705.4677\n",
      "Epoch 884/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 842us/step - loss: 371.3365 - val_loss: 705.3932\n",
      "Epoch 885/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 371.3339 - val_loss: 705.4125\n",
      "Epoch 886/1000\n",
      "307/307 [==============================] - 0s 862us/step - loss: 371.3344 - val_loss: 705.4143\n",
      "Epoch 887/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 371.3341 - val_loss: 705.4236\n",
      "Epoch 888/1000\n",
      "307/307 [==============================] - 0s 846us/step - loss: 371.3347 - val_loss: 705.4100\n",
      "Epoch 889/1000\n",
      "307/307 [==============================] - 0s 833us/step - loss: 371.3346 - val_loss: 705.4278\n",
      "Epoch 890/1000\n",
      "307/307 [==============================] - 0s 881us/step - loss: 371.3343 - val_loss: 705.3818\n",
      "Epoch 891/1000\n",
      "307/307 [==============================] - 0s 895us/step - loss: 371.3347 - val_loss: 705.3808\n",
      "Epoch 892/1000\n",
      "307/307 [==============================] - 0s 818us/step - loss: 371.3344 - val_loss: 705.4175\n",
      "Epoch 893/1000\n",
      "307/307 [==============================] - 0s 846us/step - loss: 371.3335 - val_loss: 705.4404\n",
      "Epoch 894/1000\n",
      "307/307 [==============================] - 0s 959us/step - loss: 371.3343 - val_loss: 705.4316\n",
      "Epoch 895/1000\n",
      "307/307 [==============================] - 0s 833us/step - loss: 371.3336 - val_loss: 705.4243\n",
      "Epoch 896/1000\n",
      "307/307 [==============================] - 0s 902us/step - loss: 371.3353 - val_loss: 705.3959\n",
      "Epoch 897/1000\n",
      "307/307 [==============================] - 0s 894us/step - loss: 371.3365 - val_loss: 705.4395\n",
      "Epoch 898/1000\n",
      "307/307 [==============================] - 0s 850us/step - loss: 371.3357 - val_loss: 705.4575\n",
      "Epoch 899/1000\n",
      "307/307 [==============================] - 0s 825us/step - loss: 371.3356 - val_loss: 705.4633\n",
      "Epoch 900/1000\n",
      "307/307 [==============================] - 0s 915us/step - loss: 371.3342 - val_loss: 705.4785\n",
      "Epoch 901/1000\n",
      "307/307 [==============================] - 0s 855us/step - loss: 371.3353 - val_loss: 705.5096\n",
      "Epoch 902/1000\n",
      "307/307 [==============================] - 0s 822us/step - loss: 371.3339 - val_loss: 705.4281\n",
      "Epoch 903/1000\n",
      "307/307 [==============================] - 0s 893us/step - loss: 371.3361 - val_loss: 705.4730\n",
      "Epoch 904/1000\n",
      "307/307 [==============================] - 0s 789us/step - loss: 371.3354 - val_loss: 705.4705\n",
      "Epoch 905/1000\n",
      "307/307 [==============================] - 0s 919us/step - loss: 371.3335 - val_loss: 705.4633\n",
      "Epoch 906/1000\n",
      "307/307 [==============================] - 0s 826us/step - loss: 371.3355 - val_loss: 705.5156\n",
      "Epoch 907/1000\n",
      "307/307 [==============================] - 0s 875us/step - loss: 371.3356 - val_loss: 705.4178\n",
      "Epoch 908/1000\n",
      "307/307 [==============================] - 0s 910us/step - loss: 371.3352 - val_loss: 705.5195\n",
      "Epoch 909/1000\n",
      "307/307 [==============================] - 0s 814us/step - loss: 371.3344 - val_loss: 705.4852\n",
      "Epoch 910/1000\n",
      "307/307 [==============================] - 0s 926us/step - loss: 371.3360 - val_loss: 705.4747\n",
      "Epoch 911/1000\n",
      "307/307 [==============================] - 0s 820us/step - loss: 371.3386 - val_loss: 705.4536\n",
      "Epoch 912/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 371.3338 - val_loss: 705.3909\n",
      "Epoch 913/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 371.3347 - val_loss: 705.4142\n",
      "Epoch 914/1000\n",
      "307/307 [==============================] - 0s 892us/step - loss: 371.3337 - val_loss: 705.4431\n",
      "Epoch 915/1000\n",
      "307/307 [==============================] - 0s 878us/step - loss: 371.3358 - val_loss: 705.4348\n",
      "Epoch 916/1000\n",
      "307/307 [==============================] - 0s 917us/step - loss: 371.3345 - val_loss: 705.4252\n",
      "Epoch 917/1000\n",
      "307/307 [==============================] - 0s 901us/step - loss: 371.3348 - val_loss: 705.4646\n",
      "Epoch 918/1000\n",
      "307/307 [==============================] - 0s 896us/step - loss: 371.3359 - val_loss: 705.3993\n",
      "Epoch 919/1000\n",
      "307/307 [==============================] - 0s 862us/step - loss: 371.3351 - val_loss: 705.4305\n",
      "Epoch 920/1000\n",
      "307/307 [==============================] - 0s 886us/step - loss: 371.3361 - val_loss: 705.4622\n",
      "Epoch 921/1000\n",
      "307/307 [==============================] - 0s 930us/step - loss: 371.3341 - val_loss: 705.4160\n",
      "Epoch 922/1000\n",
      "307/307 [==============================] - 0s 911us/step - loss: 371.3337 - val_loss: 705.4551\n",
      "Epoch 923/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 371.3337 - val_loss: 705.4125\n",
      "Epoch 924/1000\n",
      "307/307 [==============================] - 0s 846us/step - loss: 371.3350 - val_loss: 705.4579\n",
      "Epoch 925/1000\n",
      "307/307 [==============================] - 0s 900us/step - loss: 371.3336 - val_loss: 705.4385\n",
      "Epoch 926/1000\n",
      "307/307 [==============================] - 0s 805us/step - loss: 371.3355 - val_loss: 705.4142\n",
      "Epoch 927/1000\n",
      "307/307 [==============================] - 0s 905us/step - loss: 371.3349 - val_loss: 705.4511\n",
      "Epoch 928/1000\n",
      "307/307 [==============================] - 0s 955us/step - loss: 371.3334 - val_loss: 705.4673\n",
      "Epoch 929/1000\n",
      "307/307 [==============================] - 0s 917us/step - loss: 371.3341 - val_loss: 705.4102\n",
      "Epoch 930/1000\n",
      "307/307 [==============================] - 0s 805us/step - loss: 371.3340 - val_loss: 705.4305\n",
      "Epoch 931/1000\n",
      "307/307 [==============================] - 0s 841us/step - loss: 371.3345 - val_loss: 705.4265\n",
      "Epoch 932/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 371.3353 - val_loss: 705.4371\n",
      "Epoch 933/1000\n",
      "307/307 [==============================] - 0s 858us/step - loss: 371.3343 - val_loss: 705.4493\n",
      "Epoch 934/1000\n",
      "307/307 [==============================] - 0s 881us/step - loss: 371.3344 - val_loss: 705.4429\n",
      "Epoch 935/1000\n",
      "307/307 [==============================] - 0s 903us/step - loss: 371.3342 - val_loss: 705.4616\n",
      "Epoch 936/1000\n",
      "307/307 [==============================] - 0s 988us/step - loss: 371.3349 - val_loss: 705.4357\n",
      "Epoch 937/1000\n",
      "307/307 [==============================] - 0s 863us/step - loss: 371.3341 - val_loss: 705.4542\n",
      "Epoch 938/1000\n",
      "307/307 [==============================] - 0s 815us/step - loss: 371.3352 - val_loss: 705.4362\n",
      "Epoch 939/1000\n",
      "307/307 [==============================] - 0s 864us/step - loss: 371.3338 - val_loss: 705.4498\n",
      "Epoch 940/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 371.3345 - val_loss: 705.4750\n",
      "Epoch 941/1000\n",
      "307/307 [==============================] - 0s 851us/step - loss: 371.3335 - val_loss: 705.4074\n",
      "Epoch 942/1000\n",
      "307/307 [==============================] - 0s 851us/step - loss: 371.3338 - val_loss: 705.4518\n",
      "Epoch 943/1000\n",
      "307/307 [==============================] - 0s 889us/step - loss: 371.3349 - val_loss: 705.5144\n",
      "Epoch 944/1000\n",
      "307/307 [==============================] - 0s 837us/step - loss: 371.3352 - val_loss: 705.4269\n",
      "Epoch 945/1000\n",
      "307/307 [==============================] - 0s 852us/step - loss: 371.3340 - val_loss: 705.4229\n",
      "Epoch 946/1000\n",
      "307/307 [==============================] - 0s 875us/step - loss: 371.3343 - val_loss: 705.4379\n",
      "Epoch 947/1000\n",
      "307/307 [==============================] - 0s 848us/step - loss: 371.3346 - val_loss: 705.4703\n",
      "Epoch 948/1000\n",
      "307/307 [==============================] - 0s 848us/step - loss: 371.3351 - val_loss: 705.4399\n",
      "Epoch 949/1000\n",
      "307/307 [==============================] - 0s 859us/step - loss: 371.3345 - val_loss: 705.4132\n",
      "Epoch 950/1000\n",
      "307/307 [==============================] - 0s 876us/step - loss: 371.3350 - val_loss: 705.4617\n",
      "Epoch 951/1000\n",
      "307/307 [==============================] - 0s 879us/step - loss: 371.3348 - val_loss: 705.4278\n",
      "Epoch 952/1000\n",
      "307/307 [==============================] - 0s 867us/step - loss: 371.3345 - val_loss: 705.4885\n",
      "Epoch 953/1000\n",
      "307/307 [==============================] - 0s 917us/step - loss: 371.3345 - val_loss: 705.4834\n",
      "Epoch 954/1000\n",
      "307/307 [==============================] - 0s 914us/step - loss: 371.3355 - val_loss: 705.4432\n",
      "Epoch 955/1000\n",
      "307/307 [==============================] - 0s 913us/step - loss: 371.3355 - val_loss: 705.4576\n",
      "Epoch 956/1000\n",
      "307/307 [==============================] - 0s 914us/step - loss: 371.3348 - val_loss: 705.4576\n",
      "Epoch 957/1000\n",
      "307/307 [==============================] - 0s 873us/step - loss: 371.3355 - val_loss: 705.4155\n",
      "Epoch 958/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 0s 825us/step - loss: 371.3337 - val_loss: 705.4523\n",
      "Epoch 959/1000\n",
      "307/307 [==============================] - 0s 861us/step - loss: 371.3343 - val_loss: 705.4873\n",
      "Epoch 960/1000\n",
      "307/307 [==============================] - 0s 833us/step - loss: 371.3340 - val_loss: 705.4518\n",
      "Epoch 961/1000\n",
      "307/307 [==============================] - 0s 872us/step - loss: 371.3354 - val_loss: 705.4675\n",
      "Epoch 962/1000\n",
      "307/307 [==============================] - 0s 842us/step - loss: 371.3348 - val_loss: 705.4658\n",
      "Epoch 963/1000\n",
      "307/307 [==============================] - 0s 848us/step - loss: 371.3352 - val_loss: 705.4949\n",
      "Epoch 964/1000\n",
      "307/307 [==============================] - 0s 956us/step - loss: 371.3353 - val_loss: 705.4206\n",
      "Epoch 965/1000\n",
      "307/307 [==============================] - 0s 880us/step - loss: 371.3340 - val_loss: 705.5222\n",
      "Epoch 966/1000\n",
      "307/307 [==============================] - 0s 849us/step - loss: 371.3356 - val_loss: 705.4812\n",
      "Epoch 967/1000\n",
      "307/307 [==============================] - 0s 868us/step - loss: 371.3345 - val_loss: 705.4519\n",
      "Epoch 968/1000\n",
      "307/307 [==============================] - 0s 887us/step - loss: 371.3345 - val_loss: 705.4417\n",
      "Epoch 969/1000\n",
      "307/307 [==============================] - 0s 867us/step - loss: 371.3340 - val_loss: 705.4525\n",
      "Epoch 970/1000\n",
      "307/307 [==============================] - 0s 884us/step - loss: 371.3334 - val_loss: 705.4466\n",
      "Epoch 971/1000\n",
      "307/307 [==============================] - 0s 892us/step - loss: 371.3343 - val_loss: 705.4741\n",
      "Epoch 972/1000\n",
      "307/307 [==============================] - 0s 893us/step - loss: 371.3350 - val_loss: 705.4957\n",
      "Epoch 973/1000\n",
      "307/307 [==============================] - 0s 885us/step - loss: 371.3346 - val_loss: 705.4255\n",
      "Epoch 974/1000\n",
      "307/307 [==============================] - 0s 841us/step - loss: 371.3352 - val_loss: 705.4457\n",
      "Epoch 975/1000\n",
      "307/307 [==============================] - 0s 890us/step - loss: 371.3334 - val_loss: 705.4484\n",
      "Epoch 976/1000\n",
      "307/307 [==============================] - 0s 818us/step - loss: 371.3349 - val_loss: 705.4243\n",
      "Epoch 977/1000\n",
      "307/307 [==============================] - 0s 875us/step - loss: 371.3368 - val_loss: 705.4427\n",
      "Epoch 978/1000\n",
      "307/307 [==============================] - 0s 875us/step - loss: 371.3344 - val_loss: 705.4346\n",
      "Epoch 979/1000\n",
      "307/307 [==============================] - 0s 853us/step - loss: 371.3342 - val_loss: 705.4318\n",
      "Epoch 980/1000\n",
      "307/307 [==============================] - 0s 895us/step - loss: 371.3357 - val_loss: 705.4922\n",
      "Epoch 981/1000\n",
      "307/307 [==============================] - 0s 815us/step - loss: 371.3354 - val_loss: 705.4165\n",
      "Epoch 982/1000\n",
      "307/307 [==============================] - 0s 936us/step - loss: 371.3336 - val_loss: 705.4658\n",
      "Epoch 983/1000\n",
      "307/307 [==============================] - 0s 819us/step - loss: 371.3340 - val_loss: 705.4597\n",
      "Epoch 984/1000\n",
      "307/307 [==============================] - 0s 883us/step - loss: 371.3347 - val_loss: 705.4828\n",
      "Epoch 985/1000\n",
      "307/307 [==============================] - 0s 808us/step - loss: 371.3337 - val_loss: 705.4509\n",
      "Epoch 986/1000\n",
      "307/307 [==============================] - 0s 894us/step - loss: 371.3344 - val_loss: 705.4809\n",
      "Epoch 987/1000\n",
      "307/307 [==============================] - 0s 921us/step - loss: 371.3347 - val_loss: 705.4566\n",
      "Epoch 988/1000\n",
      "307/307 [==============================] - 0s 946us/step - loss: 371.3351 - val_loss: 705.3950\n",
      "Epoch 989/1000\n",
      "307/307 [==============================] - 0s 940us/step - loss: 371.3350 - val_loss: 705.3950\n",
      "Epoch 990/1000\n",
      "307/307 [==============================] - 0s 900us/step - loss: 371.3350 - val_loss: 705.4689\n",
      "Epoch 991/1000\n",
      "307/307 [==============================] - 0s 877us/step - loss: 371.3338 - val_loss: 705.4193\n",
      "Epoch 992/1000\n",
      "307/307 [==============================] - 0s 869us/step - loss: 371.3345 - val_loss: 705.4150\n",
      "Epoch 993/1000\n",
      "307/307 [==============================] - 0s 898us/step - loss: 371.3352 - val_loss: 705.4381\n",
      "Epoch 994/1000\n",
      "307/307 [==============================] - 0s 854us/step - loss: 371.3344 - val_loss: 705.4236\n",
      "Epoch 995/1000\n",
      "307/307 [==============================] - 0s 859us/step - loss: 371.3354 - val_loss: 705.4802\n",
      "Epoch 996/1000\n",
      "307/307 [==============================] - 0s 889us/step - loss: 371.3343 - val_loss: 705.4510\n",
      "Epoch 997/1000\n",
      "307/307 [==============================] - 0s 896us/step - loss: 371.3345 - val_loss: 705.4321\n",
      "Epoch 998/1000\n",
      "307/307 [==============================] - 0s 830us/step - loss: 371.3336 - val_loss: 705.4430\n",
      "Epoch 999/1000\n",
      "307/307 [==============================] - 0s 870us/step - loss: 371.3339 - val_loss: 705.3998\n",
      "Epoch 1000/1000\n",
      "307/307 [==============================] - 0s 871us/step - loss: 371.3335 - val_loss: 705.4108\n",
      "43/43 [==============================] - 0s 605us/step\n",
      "1373038 successful\n",
      "Epoch 1/1000\n",
      "317/317 [==============================] - 1s 1ms/step - loss: 10389192.0000 - val_loss: 453.1371\n",
      "Epoch 2/1000\n",
      "317/317 [==============================] - 0s 859us/step - loss: 412.3176 - val_loss: 505.0203\n",
      "Epoch 3/1000\n",
      "317/317 [==============================] - 0s 877us/step - loss: 427.9756 - val_loss: 448.1078\n",
      "Epoch 4/1000\n",
      "317/317 [==============================] - 0s 872us/step - loss: 438.2493 - val_loss: 516.4404\n",
      "Epoch 5/1000\n",
      "317/317 [==============================] - 0s 861us/step - loss: 470.6833 - val_loss: 824.0226\n",
      "Epoch 6/1000\n",
      "317/317 [==============================] - 0s 925us/step - loss: 528.4724 - val_loss: 517.7247\n",
      "Epoch 7/1000\n",
      "317/317 [==============================] - 0s 839us/step - loss: 521.9474 - val_loss: 706.9053\n",
      "Epoch 8/1000\n",
      "317/317 [==============================] - 0s 865us/step - loss: 689.9349 - val_loss: 742.6652\n",
      "Epoch 9/1000\n",
      "317/317 [==============================] - 0s 858us/step - loss: 640.8085 - val_loss: 2507.6174\n",
      "Epoch 10/1000\n",
      "317/317 [==============================] - 0s 910us/step - loss: 1173.4716 - val_loss: 1127.6390\n",
      "Epoch 11/1000\n",
      "317/317 [==============================] - 0s 919us/step - loss: 48265.6523 - val_loss: 12793.9365\n",
      "Epoch 12/1000\n",
      "317/317 [==============================] - 0s 981us/step - loss: 81979.0000 - val_loss: 38090.5156\n",
      "Epoch 13/1000\n",
      "317/317 [==============================] - 0s 872us/step - loss: 124506.9297 - val_loss: 443.9109\n",
      "Epoch 14/1000\n",
      "317/317 [==============================] - 0s 934us/step - loss: 74619.7422 - val_loss: 5056.9922\n",
      "Epoch 15/1000\n",
      "317/317 [==============================] - 0s 837us/step - loss: 115101.0781 - val_loss: 271657.0000\n",
      "Epoch 16/1000\n",
      "317/317 [==============================] - 0s 878us/step - loss: 74824.3750 - val_loss: 34909.9023\n",
      "Epoch 17/1000\n",
      "317/317 [==============================] - 0s 911us/step - loss: 88063.0391 - val_loss: 48525.4219\n",
      "Epoch 18/1000\n",
      "317/317 [==============================] - 0s 884us/step - loss: 89255.0312 - val_loss: 4724.5776\n",
      "Epoch 19/1000\n",
      "317/317 [==============================] - 0s 934us/step - loss: 85254.4062 - val_loss: 3329.6804\n",
      "Epoch 20/1000\n",
      "317/317 [==============================] - 0s 883us/step - loss: 72388.7422 - val_loss: 120676.9141\n",
      "Epoch 21/1000\n",
      "317/317 [==============================] - 0s 914us/step - loss: 88842.4531 - val_loss: 2079.3000\n",
      "Epoch 22/1000\n",
      "317/317 [==============================] - 0s 924us/step - loss: 69814.3281 - val_loss: 436.8708\n",
      "Epoch 23/1000\n",
      "317/317 [==============================] - 0s 892us/step - loss: 74789.9844 - val_loss: 6299.0693\n",
      "Epoch 24/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 65494.8008 - val_loss: 71162.0547\n",
      "Epoch 25/1000\n",
      "317/317 [==============================] - 0s 840us/step - loss: 39749.0781 - val_loss: 4518.1338\n",
      "Epoch 26/1000\n",
      "317/317 [==============================] - 0s 837us/step - loss: 59711.8359 - val_loss: 1598.2927\n",
      "Epoch 27/1000\n",
      "317/317 [==============================] - 0s 877us/step - loss: 64304.3789 - val_loss: 16889.4707\n",
      "Epoch 28/1000\n",
      "317/317 [==============================] - 0s 886us/step - loss: 47524.8672 - val_loss: 123843.5234\n",
      "Epoch 29/1000\n",
      "317/317 [==============================] - 0s 871us/step - loss: 51017.8477 - val_loss: 3730.3472\n",
      "Epoch 30/1000\n",
      "317/317 [==============================] - 0s 874us/step - loss: 59976.0664 - val_loss: 30457.7383\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 872us/step - loss: 51541.4492 - val_loss: 35333.1836\n",
      "Epoch 32/1000\n",
      "317/317 [==============================] - 0s 884us/step - loss: 47498.7422 - val_loss: 522.4927\n",
      "Epoch 33/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 47697.3203 - val_loss: 9218.0986\n",
      "Epoch 34/1000\n",
      "317/317 [==============================] - 0s 902us/step - loss: 44772.6250 - val_loss: 3163.5994\n",
      "Epoch 35/1000\n",
      "317/317 [==============================] - 0s 867us/step - loss: 56018.9844 - val_loss: 14790.5225\n",
      "Epoch 36/1000\n",
      "317/317 [==============================] - 0s 891us/step - loss: 35102.0039 - val_loss: 18721.6191\n",
      "Epoch 37/1000\n",
      "317/317 [==============================] - 0s 914us/step - loss: 40550.1211 - val_loss: 9150.8018\n",
      "Epoch 38/1000\n",
      "317/317 [==============================] - 0s 949us/step - loss: 42452.5703 - val_loss: 39018.6367\n",
      "Epoch 39/1000\n",
      "317/317 [==============================] - 0s 854us/step - loss: 40671.9570 - val_loss: 488.4069\n",
      "Epoch 40/1000\n",
      "317/317 [==============================] - 0s 882us/step - loss: 41216.9023 - val_loss: 99871.6875\n",
      "Epoch 41/1000\n",
      "317/317 [==============================] - 0s 869us/step - loss: 38709.9336 - val_loss: 15613.1973\n",
      "Epoch 42/1000\n",
      "317/317 [==============================] - 0s 852us/step - loss: 37646.1445 - val_loss: 43147.4570\n",
      "Epoch 43/1000\n",
      "317/317 [==============================] - 0s 862us/step - loss: 39788.2773 - val_loss: 31878.9766\n",
      "Epoch 44/1000\n",
      "317/317 [==============================] - 0s 859us/step - loss: 36704.5703 - val_loss: 622.1151\n",
      "Epoch 45/1000\n",
      "317/317 [==============================] - 0s 915us/step - loss: 31972.3438 - val_loss: 7976.9077\n",
      "Epoch 46/1000\n",
      "317/317 [==============================] - 0s 874us/step - loss: 794108.5000 - val_loss: 517463.8750\n",
      "Epoch 47/1000\n",
      "317/317 [==============================] - 0s 851us/step - loss: 10726.4023 - val_loss: 464.9468\n",
      "Epoch 48/1000\n",
      "317/317 [==============================] - 0s 889us/step - loss: 475.0636 - val_loss: 768.0676\n",
      "Epoch 49/1000\n",
      "317/317 [==============================] - 0s 842us/step - loss: 646.2553 - val_loss: 439.3428\n",
      "Epoch 50/1000\n",
      "317/317 [==============================] - 0s 907us/step - loss: 655.1060 - val_loss: 1000.2985\n",
      "Epoch 51/1000\n",
      "317/317 [==============================] - 0s 940us/step - loss: 744.2368 - val_loss: 473.2267\n",
      "Epoch 52/1000\n",
      "317/317 [==============================] - 0s 865us/step - loss: 828.1486 - val_loss: 1367.8562\n",
      "Epoch 53/1000\n",
      "317/317 [==============================] - 0s 938us/step - loss: 1615.4307 - val_loss: 4082.4438\n",
      "Epoch 54/1000\n",
      "317/317 [==============================] - 0s 817us/step - loss: 11280.3730 - val_loss: 3323.1675\n",
      "Epoch 55/1000\n",
      "317/317 [==============================] - 0s 883us/step - loss: 26471.9355 - val_loss: 2393.7385\n",
      "Epoch 56/1000\n",
      "317/317 [==============================] - 0s 964us/step - loss: 22938.5039 - val_loss: 477.7661\n",
      "Epoch 57/1000\n",
      "317/317 [==============================] - 0s 948us/step - loss: 26304.0469 - val_loss: 7728.0791\n",
      "Epoch 58/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 22151.2910 - val_loss: 563.4339\n",
      "Epoch 59/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 20363.4980 - val_loss: 3372.2200\n",
      "Epoch 60/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 22000.8496 - val_loss: 15875.0156\n",
      "Epoch 61/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 21866.2637 - val_loss: 32656.3945\n",
      "Epoch 62/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 20798.8145 - val_loss: 541.3351\n",
      "Epoch 63/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 23464.7285 - val_loss: 3713.3560\n",
      "Epoch 64/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 16001.9141 - val_loss: 9095.1279\n",
      "Epoch 65/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 20314.1016 - val_loss: 68804.0156\n",
      "Epoch 66/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 17789.0469 - val_loss: 898.5456\n",
      "Epoch 67/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 16739.2383 - val_loss: 1348.5504\n",
      "Epoch 68/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 20551.5195 - val_loss: 33714.6992\n",
      "Epoch 69/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 21561.1738 - val_loss: 8694.6035\n",
      "Epoch 70/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 12190.8555 - val_loss: 45238.7188\n",
      "Epoch 71/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 18316.6465 - val_loss: 16930.4258\n",
      "Epoch 72/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 65808.1641 - val_loss: 497140.1250\n",
      "Epoch 73/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 9446.0361 - val_loss: 839.6239\n",
      "Epoch 74/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 1394.6864 - val_loss: 4517.9092\n",
      "Epoch 75/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 5072.7734 - val_loss: 2033.2157\n",
      "Epoch 76/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 13919.7627 - val_loss: 23281.0703\n",
      "Epoch 77/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 14094.8271 - val_loss: 17408.3438\n",
      "Epoch 78/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 14512.4658 - val_loss: 7249.7930\n",
      "Epoch 79/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 14089.6455 - val_loss: 4047.9675\n",
      "Epoch 80/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 17613.2305 - val_loss: 795.2881\n",
      "Epoch 81/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 10799.9297 - val_loss: 4359.8755\n",
      "Epoch 82/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 11949.1826 - val_loss: 8168.3940\n",
      "Epoch 83/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 11786.2773 - val_loss: 40621.6641\n",
      "Epoch 84/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 12594.3125 - val_loss: 940.7343\n",
      "Epoch 85/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 12314.9004 - val_loss: 6775.7598\n",
      "Epoch 86/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 12319.9600 - val_loss: 2533.1741\n",
      "Epoch 87/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 10408.3887 - val_loss: 17957.7852\n",
      "Epoch 88/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 10808.1709 - val_loss: 477.5389\n",
      "Epoch 89/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 11770.6562 - val_loss: 8380.3984\n",
      "Epoch 90/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 10735.7695 - val_loss: 40053.1641\n",
      "Epoch 91/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 9748.0723 - val_loss: 16079.2402\n",
      "Epoch 92/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 9474.4717 - val_loss: 25892.0527\n",
      "Epoch 93/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 10241.0488 - val_loss: 13304.3350\n",
      "Epoch 94/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 9089.1299 - val_loss: 543.8274\n",
      "Epoch 95/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 8872.5469 - val_loss: 650.9586\n",
      "Epoch 96/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 10673.9824 - val_loss: 572.5051\n",
      "Epoch 97/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 8311.4551 - val_loss: 786.9235\n",
      "Epoch 98/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 8869.9893 - val_loss: 440.4468\n",
      "Epoch 99/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 8818.3066 - val_loss: 12687.6582\n",
      "Epoch 100/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 6655.7715 - val_loss: 3540.8582\n",
      "Epoch 101/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 9060.9482 - val_loss: 18096.2715\n",
      "Epoch 102/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 206660.9844 - val_loss: 615.5391\n",
      "Epoch 103/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 443.0377 - val_loss: 442.1004\n",
      "Epoch 104/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 567.0287 - val_loss: 532.2444\n",
      "Epoch 105/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 1s 3ms/step - loss: 625.8213 - val_loss: 459.2922\n",
      "Epoch 106/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 521.0554 - val_loss: 442.2708\n",
      "Epoch 107/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 821.0095 - val_loss: 2541.4497\n",
      "Epoch 108/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 916.1620 - val_loss: 1128.4971\n",
      "Epoch 109/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 1144.1433 - val_loss: 444.7108\n",
      "Epoch 110/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 2377.6436 - val_loss: 447.9362\n",
      "Epoch 111/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 6266.5347 - val_loss: 3226.5491\n",
      "Epoch 112/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 6247.4453 - val_loss: 8853.8438\n",
      "Epoch 113/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 6003.6807 - val_loss: 4740.9771\n",
      "Epoch 114/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 6482.4126 - val_loss: 534.9067\n",
      "Epoch 115/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 5373.3232 - val_loss: 3199.8032\n",
      "Epoch 116/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 5880.4932 - val_loss: 912.9608\n",
      "Epoch 117/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 5203.8159 - val_loss: 11422.9209\n",
      "Epoch 118/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 5515.7051 - val_loss: 502.4244\n",
      "Epoch 119/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 5606.9224 - val_loss: 933.4358\n",
      "Epoch 120/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 4594.1904 - val_loss: 18498.2480\n",
      "Epoch 121/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 5754.7388 - val_loss: 6363.8745\n",
      "Epoch 122/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 4516.3149 - val_loss: 795.4540\n",
      "Epoch 123/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 4219.7070 - val_loss: 4078.9731\n",
      "Epoch 124/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 5038.6401 - val_loss: 3007.3523\n",
      "Epoch 125/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 4452.8374 - val_loss: 1844.0220\n",
      "Epoch 126/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 4226.7466 - val_loss: 11091.5742\n",
      "Epoch 127/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 4772.8218 - val_loss: 2965.4910\n",
      "Epoch 128/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 4325.9897 - val_loss: 582.6865\n",
      "Epoch 129/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 4557.7754 - val_loss: 515.2023\n",
      "Epoch 130/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 1762.6840 - val_loss: 491.2224\n",
      "Epoch 131/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 3217.3088 - val_loss: 753.8781\n",
      "Epoch 132/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 3604.0522 - val_loss: 2421.8953\n",
      "Epoch 133/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2405.2490 - val_loss: 7879.6074\n",
      "Epoch 134/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 3649.2158 - val_loss: 5138.3965\n",
      "Epoch 135/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 3241.3247 - val_loss: 550.5288\n",
      "Epoch 136/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 2733.2629 - val_loss: 590.1400\n",
      "Epoch 137/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 3517.0569 - val_loss: 438.6308\n",
      "Epoch 138/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 2913.4092 - val_loss: 577.4493\n",
      "Epoch 139/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 3070.0046 - val_loss: 1021.2847\n",
      "Epoch 140/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2936.7832 - val_loss: 712.1668\n",
      "Epoch 141/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2578.9858 - val_loss: 917.6405\n",
      "Epoch 142/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2889.4084 - val_loss: 743.2190\n",
      "Epoch 143/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2598.8369 - val_loss: 440.5277\n",
      "Epoch 144/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2926.7437 - val_loss: 2510.3459\n",
      "Epoch 145/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2545.1526 - val_loss: 1644.0806\n",
      "Epoch 146/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 3304.1833 - val_loss: 469.2852\n",
      "Epoch 147/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2160.5686 - val_loss: 2046.6058\n",
      "Epoch 148/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2685.7461 - val_loss: 7510.9219\n",
      "Epoch 149/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2879.8210 - val_loss: 4115.8965\n",
      "Epoch 150/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2797.8938 - val_loss: 456.2589\n",
      "Epoch 151/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 2040.1421 - val_loss: 835.0633\n",
      "Epoch 152/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2470.2700 - val_loss: 683.0285\n",
      "Epoch 153/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 2599.0193 - val_loss: 6430.8970\n",
      "Epoch 154/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 2544.7212 - val_loss: 3668.3459\n",
      "Epoch 155/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 2243.5325 - val_loss: 4145.7261\n",
      "Epoch 156/1000\n",
      "317/317 [==============================] - 0s 937us/step - loss: 2491.9753 - val_loss: 872.0860\n",
      "Epoch 157/1000\n",
      "317/317 [==============================] - 0s 955us/step - loss: 79000.0000 - val_loss: 435.3968\n",
      "Epoch 158/1000\n",
      "317/317 [==============================] - 0s 810us/step - loss: 461.9427 - val_loss: 435.0893\n",
      "Epoch 159/1000\n",
      "317/317 [==============================] - 0s 881us/step - loss: 448.9142 - val_loss: 647.5399\n",
      "Epoch 160/1000\n",
      "317/317 [==============================] - 0s 849us/step - loss: 476.4243 - val_loss: 443.8784\n",
      "Epoch 161/1000\n",
      "317/317 [==============================] - 0s 872us/step - loss: 520.9962 - val_loss: 443.7864\n",
      "Epoch 162/1000\n",
      "317/317 [==============================] - 0s 837us/step - loss: 541.4404 - val_loss: 445.2596\n",
      "Epoch 163/1000\n",
      "317/317 [==============================] - 0s 792us/step - loss: 674.0742 - val_loss: 890.5678\n",
      "Epoch 164/1000\n",
      "317/317 [==============================] - 0s 837us/step - loss: 753.5931 - val_loss: 686.0783\n",
      "Epoch 165/1000\n",
      "317/317 [==============================] - 0s 830us/step - loss: 765.5118 - val_loss: 987.8940\n",
      "Epoch 166/1000\n",
      "317/317 [==============================] - 0s 882us/step - loss: 1172.3378 - val_loss: 1323.5573\n",
      "Epoch 167/1000\n",
      "317/317 [==============================] - 0s 829us/step - loss: 1477.1615 - val_loss: 818.7101\n",
      "Epoch 168/1000\n",
      "317/317 [==============================] - 0s 913us/step - loss: 1898.5581 - val_loss: 690.1008\n",
      "Epoch 169/1000\n",
      "317/317 [==============================] - 0s 866us/step - loss: 1525.2151 - val_loss: 507.7359\n",
      "Epoch 170/1000\n",
      "317/317 [==============================] - 0s 844us/step - loss: 1989.1560 - val_loss: 543.5635\n",
      "Epoch 171/1000\n",
      "317/317 [==============================] - 0s 835us/step - loss: 1839.5754 - val_loss: 522.5534\n",
      "Epoch 172/1000\n",
      "317/317 [==============================] - 0s 853us/step - loss: 1566.9393 - val_loss: 611.0669\n",
      "Epoch 173/1000\n",
      "317/317 [==============================] - 0s 870us/step - loss: 2441.9407 - val_loss: 3563.0730\n",
      "Epoch 174/1000\n",
      "317/317 [==============================] - 0s 851us/step - loss: 1651.5797 - val_loss: 771.2159\n",
      "Epoch 175/1000\n",
      "317/317 [==============================] - 0s 889us/step - loss: 1614.9594 - val_loss: 8503.2764\n",
      "Epoch 176/1000\n",
      "317/317 [==============================] - 0s 839us/step - loss: 1724.0089 - val_loss: 1743.4048\n",
      "Epoch 177/1000\n",
      "317/317 [==============================] - 0s 849us/step - loss: 1579.8400 - val_loss: 1187.1278\n",
      "Epoch 178/1000\n",
      "317/317 [==============================] - 0s 877us/step - loss: 1632.5538 - val_loss: 783.7860\n",
      "Epoch 179/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 881us/step - loss: 53193.8867 - val_loss: 480.7979\n",
      "Epoch 180/1000\n",
      "317/317 [==============================] - 0s 832us/step - loss: 446.1102 - val_loss: 611.3946\n",
      "Epoch 181/1000\n",
      "317/317 [==============================] - 0s 859us/step - loss: 443.3173 - val_loss: 448.4090\n",
      "Epoch 182/1000\n",
      "317/317 [==============================] - 0s 901us/step - loss: 465.8774 - val_loss: 543.3237\n",
      "Epoch 183/1000\n",
      "317/317 [==============================] - 0s 837us/step - loss: 467.2634 - val_loss: 777.4977\n",
      "Epoch 184/1000\n",
      "317/317 [==============================] - 0s 834us/step - loss: 518.9932 - val_loss: 644.1599\n",
      "Epoch 185/1000\n",
      "317/317 [==============================] - 0s 955us/step - loss: 575.8907 - val_loss: 634.5520\n",
      "Epoch 186/1000\n",
      "317/317 [==============================] - 0s 894us/step - loss: 644.5206 - val_loss: 485.4265\n",
      "Epoch 187/1000\n",
      "317/317 [==============================] - 0s 884us/step - loss: 704.0363 - val_loss: 1496.8824\n",
      "Epoch 188/1000\n",
      "317/317 [==============================] - 0s 901us/step - loss: 804.8903 - val_loss: 527.6746\n",
      "Epoch 189/1000\n",
      "317/317 [==============================] - 0s 882us/step - loss: 1321.6758 - val_loss: 762.8817\n",
      "Epoch 190/1000\n",
      "317/317 [==============================] - 0s 917us/step - loss: 1057.3781 - val_loss: 439.0124\n",
      "Epoch 191/1000\n",
      "317/317 [==============================] - 0s 825us/step - loss: 1335.9469 - val_loss: 458.6094\n",
      "Epoch 192/1000\n",
      "317/317 [==============================] - 0s 814us/step - loss: 1068.4756 - val_loss: 460.4309\n",
      "Epoch 193/1000\n",
      "317/317 [==============================] - 0s 829us/step - loss: 1282.3152 - val_loss: 3841.3965\n",
      "Epoch 194/1000\n",
      "317/317 [==============================] - 0s 860us/step - loss: 1178.5631 - val_loss: 751.4459\n",
      "Epoch 195/1000\n",
      "317/317 [==============================] - 0s 876us/step - loss: 1387.2922 - val_loss: 3943.7732\n",
      "Epoch 196/1000\n",
      "317/317 [==============================] - 0s 834us/step - loss: 1080.3364 - val_loss: 3033.4670\n",
      "Epoch 197/1000\n",
      "317/317 [==============================] - 0s 930us/step - loss: 1061.5520 - val_loss: 1678.9415\n",
      "Epoch 198/1000\n",
      "317/317 [==============================] - 0s 860us/step - loss: 930.4811 - val_loss: 445.6112\n",
      "Epoch 199/1000\n",
      "317/317 [==============================] - 0s 877us/step - loss: 950.1423 - val_loss: 2023.7129\n",
      "Epoch 200/1000\n",
      "317/317 [==============================] - 0s 842us/step - loss: 967.2361 - val_loss: 3007.3184\n",
      "Epoch 201/1000\n",
      "317/317 [==============================] - 0s 840us/step - loss: 965.4727 - val_loss: 447.4854\n",
      "Epoch 202/1000\n",
      "317/317 [==============================] - 0s 847us/step - loss: 866.2687 - val_loss: 2614.7166\n",
      "Epoch 203/1000\n",
      "317/317 [==============================] - 0s 885us/step - loss: 980.8658 - val_loss: 940.9177\n",
      "Epoch 204/1000\n",
      "317/317 [==============================] - 0s 927us/step - loss: 1214.0823 - val_loss: 546.4642\n",
      "Epoch 205/1000\n",
      "317/317 [==============================] - 0s 850us/step - loss: 998.0804 - val_loss: 562.1212\n",
      "Epoch 206/1000\n",
      "317/317 [==============================] - 0s 881us/step - loss: 853.2610 - val_loss: 543.9469\n",
      "Epoch 207/1000\n",
      "317/317 [==============================] - 0s 939us/step - loss: 983.4463 - val_loss: 664.8246\n",
      "Epoch 208/1000\n",
      "317/317 [==============================] - 0s 843us/step - loss: 863.3740 - val_loss: 3355.0952\n",
      "Epoch 209/1000\n",
      "317/317 [==============================] - 0s 840us/step - loss: 1145.2063 - val_loss: 1698.8235\n",
      "Epoch 210/1000\n",
      "317/317 [==============================] - 0s 888us/step - loss: 1006.6383 - val_loss: 647.2428\n",
      "Epoch 211/1000\n",
      "317/317 [==============================] - 0s 831us/step - loss: 736.8852 - val_loss: 555.2390\n",
      "Epoch 212/1000\n",
      "317/317 [==============================] - 0s 856us/step - loss: 704.5221 - val_loss: 892.0069\n",
      "Epoch 213/1000\n",
      "317/317 [==============================] - 0s 855us/step - loss: 991.4267 - val_loss: 490.7701\n",
      "Epoch 214/1000\n",
      "317/317 [==============================] - 0s 880us/step - loss: 853.0541 - val_loss: 560.5200\n",
      "Epoch 215/1000\n",
      "317/317 [==============================] - 0s 874us/step - loss: 954.9979 - val_loss: 2260.3137\n",
      "Epoch 216/1000\n",
      "317/317 [==============================] - 0s 853us/step - loss: 705.8327 - val_loss: 694.0513\n",
      "Epoch 217/1000\n",
      "317/317 [==============================] - 0s 841us/step - loss: 806.5991 - val_loss: 561.2495\n",
      "Epoch 218/1000\n",
      "317/317 [==============================] - 0s 881us/step - loss: 837.2318 - val_loss: 449.4947\n",
      "Epoch 219/1000\n",
      "317/317 [==============================] - 0s 898us/step - loss: 690.6679 - val_loss: 471.1205\n",
      "Epoch 220/1000\n",
      "317/317 [==============================] - 0s 807us/step - loss: 816.6232 - val_loss: 900.4232\n",
      "Epoch 221/1000\n",
      "317/317 [==============================] - 0s 877us/step - loss: 871.6417 - val_loss: 502.1586\n",
      "Epoch 222/1000\n",
      "317/317 [==============================] - 0s 839us/step - loss: 669.5673 - val_loss: 445.5637\n",
      "Epoch 223/1000\n",
      "317/317 [==============================] - 0s 876us/step - loss: 917.5848 - val_loss: 475.0819\n",
      "Epoch 224/1000\n",
      "317/317 [==============================] - 0s 895us/step - loss: 758.4969 - val_loss: 992.9269\n",
      "Epoch 225/1000\n",
      "317/317 [==============================] - 0s 887us/step - loss: 928.6815 - val_loss: 592.9361\n",
      "Epoch 226/1000\n",
      "317/317 [==============================] - 0s 912us/step - loss: 749.7180 - val_loss: 1683.4149\n",
      "Epoch 227/1000\n",
      "317/317 [==============================] - 0s 862us/step - loss: 724.6158 - val_loss: 1715.0764\n",
      "Epoch 228/1000\n",
      "317/317 [==============================] - 0s 904us/step - loss: 685.1489 - val_loss: 443.5365\n",
      "Epoch 229/1000\n",
      "317/317 [==============================] - 0s 815us/step - loss: 671.9044 - val_loss: 440.1251\n",
      "Epoch 230/1000\n",
      "317/317 [==============================] - 0s 848us/step - loss: 696.4735 - val_loss: 759.3655\n",
      "Epoch 231/1000\n",
      "317/317 [==============================] - 0s 877us/step - loss: 675.2422 - val_loss: 2007.5524\n",
      "Epoch 232/1000\n",
      "317/317 [==============================] - 0s 889us/step - loss: 732.5300 - val_loss: 435.9790\n",
      "Epoch 233/1000\n",
      "317/317 [==============================] - 0s 897us/step - loss: 708.7031 - val_loss: 435.2078\n",
      "Epoch 234/1000\n",
      "317/317 [==============================] - 0s 839us/step - loss: 636.9706 - val_loss: 494.4653\n",
      "Epoch 235/1000\n",
      "317/317 [==============================] - 0s 863us/step - loss: 612.9064 - val_loss: 1224.4617\n",
      "Epoch 236/1000\n",
      "317/317 [==============================] - 0s 840us/step - loss: 643.0704 - val_loss: 576.4995\n",
      "Epoch 237/1000\n",
      "317/317 [==============================] - 0s 876us/step - loss: 539.3180 - val_loss: 443.1930\n",
      "Epoch 238/1000\n",
      "317/317 [==============================] - 0s 888us/step - loss: 557.3806 - val_loss: 822.5367\n",
      "Epoch 239/1000\n",
      "317/317 [==============================] - 0s 902us/step - loss: 556.2662 - val_loss: 614.8663\n",
      "Epoch 240/1000\n",
      "317/317 [==============================] - 0s 849us/step - loss: 623.9606 - val_loss: 604.4786\n",
      "Epoch 241/1000\n",
      "317/317 [==============================] - 0s 842us/step - loss: 582.6124 - val_loss: 978.5918\n",
      "Epoch 242/1000\n",
      "317/317 [==============================] - 0s 914us/step - loss: 568.1907 - val_loss: 1113.1287\n",
      "Epoch 243/1000\n",
      "317/317 [==============================] - 0s 876us/step - loss: 520.2299 - val_loss: 436.8671\n",
      "Epoch 244/1000\n",
      "317/317 [==============================] - 0s 873us/step - loss: 491.3691 - val_loss: 555.2007\n",
      "Epoch 245/1000\n",
      "317/317 [==============================] - 0s 856us/step - loss: 450.3523 - val_loss: 466.7312\n",
      "Epoch 246/1000\n",
      "317/317 [==============================] - 0s 873us/step - loss: 507.3391 - val_loss: 487.3762\n",
      "Epoch 247/1000\n",
      "317/317 [==============================] - 0s 908us/step - loss: 506.8721 - val_loss: 468.5593\n",
      "Epoch 248/1000\n",
      "317/317 [==============================] - 0s 806us/step - loss: 496.7441 - val_loss: 451.9670\n",
      "Epoch 249/1000\n",
      "317/317 [==============================] - 0s 908us/step - loss: 445.8652 - val_loss: 602.4486\n",
      "Epoch 250/1000\n",
      "317/317 [==============================] - 0s 865us/step - loss: 495.3163 - val_loss: 485.6184\n",
      "Epoch 251/1000\n",
      "317/317 [==============================] - 0s 919us/step - loss: 430.4711 - val_loss: 637.6155\n",
      "Epoch 252/1000\n",
      "317/317 [==============================] - 0s 878us/step - loss: 428.3882 - val_loss: 435.7336\n",
      "Epoch 253/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 840us/step - loss: 413.2487 - val_loss: 479.0920\n",
      "Epoch 254/1000\n",
      "317/317 [==============================] - 0s 849us/step - loss: 407.2969 - val_loss: 495.9883\n",
      "Epoch 255/1000\n",
      "317/317 [==============================] - 0s 862us/step - loss: 392.7750 - val_loss: 442.1366\n",
      "Epoch 256/1000\n",
      "317/317 [==============================] - 0s 881us/step - loss: 386.2877 - val_loss: 434.9314\n",
      "Epoch 257/1000\n",
      "317/317 [==============================] - 0s 911us/step - loss: 386.9360 - val_loss: 434.8673\n",
      "Epoch 258/1000\n",
      "317/317 [==============================] - 0s 882us/step - loss: 387.1761 - val_loss: 439.3161\n",
      "Epoch 259/1000\n",
      "317/317 [==============================] - 0s 854us/step - loss: 384.1240 - val_loss: 436.4129\n",
      "Epoch 260/1000\n",
      "317/317 [==============================] - 0s 953us/step - loss: 384.5265 - val_loss: 453.1778\n",
      "Epoch 261/1000\n",
      "317/317 [==============================] - 0s 895us/step - loss: 384.5840 - val_loss: 436.1992\n",
      "Epoch 262/1000\n",
      "317/317 [==============================] - 0s 905us/step - loss: 389.3221 - val_loss: 442.0061\n",
      "Epoch 263/1000\n",
      "317/317 [==============================] - 0s 947us/step - loss: 386.8966 - val_loss: 438.1028\n",
      "Epoch 264/1000\n",
      "317/317 [==============================] - 0s 934us/step - loss: 386.1021 - val_loss: 445.2623\n",
      "Epoch 265/1000\n",
      "317/317 [==============================] - 0s 985us/step - loss: 387.7668 - val_loss: 442.8283\n",
      "Epoch 266/1000\n",
      "317/317 [==============================] - 0s 955us/step - loss: 387.5157 - val_loss: 440.7290\n",
      "Epoch 267/1000\n",
      "317/317 [==============================] - 0s 955us/step - loss: 388.8617 - val_loss: 452.8095\n",
      "Epoch 268/1000\n",
      "317/317 [==============================] - 0s 927us/step - loss: 394.9613 - val_loss: 452.8690\n",
      "Epoch 269/1000\n",
      "317/317 [==============================] - 0s 977us/step - loss: 390.6335 - val_loss: 437.1494\n",
      "Epoch 270/1000\n",
      "317/317 [==============================] - 0s 988us/step - loss: 390.4528 - val_loss: 450.3242\n",
      "Epoch 271/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 389.8704 - val_loss: 449.6294\n",
      "Epoch 272/1000\n",
      "317/317 [==============================] - 0s 911us/step - loss: 392.3853 - val_loss: 435.4738\n",
      "Epoch 273/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 386.0956 - val_loss: 457.3256\n",
      "Epoch 274/1000\n",
      "317/317 [==============================] - 0s 919us/step - loss: 392.5141 - val_loss: 435.8514\n",
      "Epoch 275/1000\n",
      "317/317 [==============================] - 0s 915us/step - loss: 400.5234 - val_loss: 449.2494\n",
      "Epoch 276/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 392.3318 - val_loss: 435.1251\n",
      "Epoch 277/1000\n",
      "317/317 [==============================] - 0s 953us/step - loss: 391.8317 - val_loss: 435.2703\n",
      "Epoch 278/1000\n",
      "317/317 [==============================] - 0s 834us/step - loss: 396.5969 - val_loss: 445.8427\n",
      "Epoch 279/1000\n",
      "317/317 [==============================] - 0s 910us/step - loss: 395.2011 - val_loss: 444.4885\n",
      "Epoch 280/1000\n",
      "317/317 [==============================] - 0s 890us/step - loss: 396.1374 - val_loss: 447.3543\n",
      "Epoch 281/1000\n",
      "317/317 [==============================] - 0s 906us/step - loss: 393.5223 - val_loss: 480.3910\n",
      "Epoch 282/1000\n",
      "317/317 [==============================] - 0s 936us/step - loss: 396.1420 - val_loss: 441.7744\n",
      "Epoch 283/1000\n",
      "317/317 [==============================] - 0s 930us/step - loss: 391.8714 - val_loss: 460.6958\n",
      "Epoch 284/1000\n",
      "317/317 [==============================] - 0s 854us/step - loss: 394.6594 - val_loss: 459.3126\n",
      "Epoch 285/1000\n",
      "317/317 [==============================] - 0s 937us/step - loss: 389.3689 - val_loss: 435.1033\n",
      "Epoch 286/1000\n",
      "317/317 [==============================] - 0s 889us/step - loss: 392.6424 - val_loss: 438.3110\n",
      "Epoch 287/1000\n",
      "317/317 [==============================] - 0s 935us/step - loss: 391.3185 - val_loss: 445.9070\n",
      "Epoch 288/1000\n",
      "317/317 [==============================] - 0s 978us/step - loss: 399.2062 - val_loss: 436.0502\n",
      "Epoch 289/1000\n",
      "317/317 [==============================] - 0s 914us/step - loss: 392.3109 - val_loss: 435.3593\n",
      "Epoch 290/1000\n",
      "317/317 [==============================] - 0s 981us/step - loss: 397.5069 - val_loss: 455.0970\n",
      "Epoch 291/1000\n",
      "317/317 [==============================] - 0s 857us/step - loss: 389.7608 - val_loss: 435.1176\n",
      "Epoch 292/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 5615.5684 - val_loss: 1007.5499\n",
      "Epoch 293/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 902.3386 - val_loss: 997.9742\n",
      "Epoch 294/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 892.7927 - val_loss: 987.6883\n",
      "Epoch 295/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 882.6288 - val_loss: 976.7935\n",
      "Epoch 296/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 871.9406 - val_loss: 965.4265\n",
      "Epoch 297/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 860.8134 - val_loss: 953.6329\n",
      "Epoch 298/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 849.3654 - val_loss: 941.5795\n",
      "Epoch 299/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 837.7040 - val_loss: 929.3011\n",
      "Epoch 300/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 825.9054 - val_loss: 916.9234\n",
      "Epoch 301/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 814.0427 - val_loss: 904.5383\n",
      "Epoch 302/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 802.1827 - val_loss: 892.1415\n",
      "Epoch 303/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 790.3630 - val_loss: 879.8124\n",
      "Epoch 304/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 778.6016 - val_loss: 867.5569\n",
      "Epoch 305/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 766.9623 - val_loss: 855.4227\n",
      "Epoch 306/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 755.4484 - val_loss: 843.4022\n",
      "Epoch 307/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 744.0721 - val_loss: 831.5903\n",
      "Epoch 308/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 732.8632 - val_loss: 819.8841\n",
      "Epoch 309/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 721.8151 - val_loss: 808.3984\n",
      "Epoch 310/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 710.9686 - val_loss: 797.0904\n",
      "Epoch 311/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 700.2979 - val_loss: 785.9323\n",
      "Epoch 312/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 689.7921 - val_loss: 774.9538\n",
      "Epoch 313/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 679.4854 - val_loss: 764.1893\n",
      "Epoch 314/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 669.3697 - val_loss: 753.6186\n",
      "Epoch 315/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 659.4282 - val_loss: 743.2007\n",
      "Epoch 316/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 649.6540 - val_loss: 732.9642\n",
      "Epoch 317/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 640.0507 - val_loss: 722.9067\n",
      "Epoch 318/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 630.6401 - val_loss: 713.0587\n",
      "Epoch 319/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 621.4276 - val_loss: 703.3796\n",
      "Epoch 320/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 612.3913 - val_loss: 693.8792\n",
      "Epoch 321/1000\n",
      "317/317 [==============================] - 0s 968us/step - loss: 603.5472 - val_loss: 684.5748\n",
      "Epoch 322/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 594.8732 - val_loss: 675.4601\n",
      "Epoch 323/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 586.3816 - val_loss: 666.5370\n",
      "Epoch 324/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 578.0778 - val_loss: 657.7469\n",
      "Epoch 325/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 569.9696 - val_loss: 649.2213\n",
      "Epoch 326/1000\n",
      "317/317 [==============================] - 0s 961us/step - loss: 562.0519 - val_loss: 640.8382\n",
      "Epoch 327/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 554.3283 - val_loss: 632.6843\n",
      "Epoch 328/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 1ms/step - loss: 546.7954 - val_loss: 624.7148\n",
      "Epoch 329/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 539.4398 - val_loss: 616.8875\n",
      "Epoch 330/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 532.2778 - val_loss: 609.2983\n",
      "Epoch 331/1000\n",
      "317/317 [==============================] - 0s 912us/step - loss: 525.2896 - val_loss: 601.8443\n",
      "Epoch 332/1000\n",
      "317/317 [==============================] - 0s 934us/step - loss: 518.4882 - val_loss: 594.6401\n",
      "Epoch 333/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 511.8732 - val_loss: 587.5546\n",
      "Epoch 334/1000\n",
      "317/317 [==============================] - 0s 958us/step - loss: 505.4138 - val_loss: 580.6725\n",
      "Epoch 335/1000\n",
      "317/317 [==============================] - 0s 992us/step - loss: 499.1364 - val_loss: 573.9529\n",
      "Epoch 336/1000\n",
      "317/317 [==============================] - 0s 988us/step - loss: 493.0804 - val_loss: 567.4645\n",
      "Epoch 337/1000\n",
      "317/317 [==============================] - 0s 991us/step - loss: 487.1981 - val_loss: 561.1432\n",
      "Epoch 338/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 481.4749 - val_loss: 554.9784\n",
      "Epoch 339/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 475.9283 - val_loss: 549.0143\n",
      "Epoch 340/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 470.5550 - val_loss: 543.2068\n",
      "Epoch 341/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 465.3643 - val_loss: 537.5988\n",
      "Epoch 342/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 460.3528 - val_loss: 532.1531\n",
      "Epoch 343/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 455.4979 - val_loss: 526.8770\n",
      "Epoch 344/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 450.8037 - val_loss: 521.7460\n",
      "Epoch 345/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 446.3002 - val_loss: 516.8511\n",
      "Epoch 346/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 441.9746 - val_loss: 512.0949\n",
      "Epoch 347/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 437.8079 - val_loss: 507.5119\n",
      "Epoch 348/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 433.8193 - val_loss: 503.1124\n",
      "Epoch 349/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 429.9935 - val_loss: 498.8940\n",
      "Epoch 350/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 426.3354 - val_loss: 494.8528\n",
      "Epoch 351/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 422.8523 - val_loss: 490.9664\n",
      "Epoch 352/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 419.5314 - val_loss: 487.2607\n",
      "Epoch 353/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 416.3740 - val_loss: 483.7047\n",
      "Epoch 354/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 413.3694 - val_loss: 480.3184\n",
      "Epoch 355/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 410.5307 - val_loss: 477.0946\n",
      "Epoch 356/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 407.8462 - val_loss: 474.0421\n",
      "Epoch 357/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 405.2984 - val_loss: 471.1073\n",
      "Epoch 358/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 402.8841 - val_loss: 468.3243\n",
      "Epoch 359/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 400.6128 - val_loss: 465.6859\n",
      "Epoch 360/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 398.5065 - val_loss: 463.2345\n",
      "Epoch 361/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 396.5521 - val_loss: 460.9436\n",
      "Epoch 362/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 394.7307 - val_loss: 458.7817\n",
      "Epoch 363/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 393.0491 - val_loss: 456.7606\n",
      "Epoch 364/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 391.4961 - val_loss: 454.9012\n",
      "Epoch 365/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 390.0530 - val_loss: 453.1332\n",
      "Epoch 366/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 388.7402 - val_loss: 451.4987\n",
      "Epoch 367/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 387.5350 - val_loss: 450.0221\n",
      "Epoch 368/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 386.4413 - val_loss: 448.6255\n",
      "Epoch 369/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 385.4461 - val_loss: 447.3407\n",
      "Epoch 370/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 384.5374 - val_loss: 446.1520\n",
      "Epoch 371/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 383.7379 - val_loss: 445.0913\n",
      "Epoch 372/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 383.0293 - val_loss: 444.1361\n",
      "Epoch 373/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 382.3881 - val_loss: 443.2481\n",
      "Epoch 374/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 381.8262 - val_loss: 442.4637\n",
      "Epoch 375/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 381.3362 - val_loss: 441.7512\n",
      "Epoch 376/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 380.9037 - val_loss: 441.1332\n",
      "Epoch 377/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 380.5193 - val_loss: 440.5307\n",
      "Epoch 378/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 380.1954 - val_loss: 440.0303\n",
      "Epoch 379/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 379.9119 - val_loss: 439.5756\n",
      "Epoch 380/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 379.6682 - val_loss: 439.1519\n",
      "Epoch 381/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 379.4593 - val_loss: 438.7945\n",
      "Epoch 382/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 379.2835 - val_loss: 438.4716\n",
      "Epoch 383/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 379.1352 - val_loss: 438.1916\n",
      "Epoch 384/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 379.0107 - val_loss: 437.9454\n",
      "Epoch 385/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.9038 - val_loss: 437.7406\n",
      "Epoch 386/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.8089 - val_loss: 437.5314\n",
      "Epoch 387/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.7310 - val_loss: 437.3600\n",
      "Epoch 388/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.6643 - val_loss: 437.1971\n",
      "Epoch 389/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.6082 - val_loss: 437.0540\n",
      "Epoch 390/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.5618 - val_loss: 436.9366\n",
      "Epoch 391/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.5221 - val_loss: 436.8201\n",
      "Epoch 392/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.4897 - val_loss: 436.7231\n",
      "Epoch 393/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.4628 - val_loss: 436.6285\n",
      "Epoch 394/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.4380 - val_loss: 436.5507\n",
      "Epoch 395/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.4193 - val_loss: 436.4895\n",
      "Epoch 396/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.4028 - val_loss: 436.4240\n",
      "Epoch 397/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3892 - val_loss: 436.3671\n",
      "Epoch 398/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3791 - val_loss: 436.3157\n",
      "Epoch 399/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3677 - val_loss: 436.2624\n",
      "Epoch 400/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3608 - val_loss: 436.2292\n",
      "Epoch 401/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3543 - val_loss: 436.1798\n",
      "Epoch 402/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3474 - val_loss: 436.1519\n",
      "Epoch 403/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3428 - val_loss: 436.1194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3400 - val_loss: 436.0945\n",
      "Epoch 405/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3351 - val_loss: 436.0680\n",
      "Epoch 406/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3342 - val_loss: 436.0460\n",
      "Epoch 407/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3311 - val_loss: 436.0245\n",
      "Epoch 408/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3298 - val_loss: 436.0109\n",
      "Epoch 409/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3276 - val_loss: 435.9872\n",
      "Epoch 410/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3266 - val_loss: 435.9712\n",
      "Epoch 411/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3264 - val_loss: 435.9617\n",
      "Epoch 412/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3241 - val_loss: 435.9476\n",
      "Epoch 413/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3237 - val_loss: 435.9411\n",
      "Epoch 414/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3248 - val_loss: 435.9280\n",
      "Epoch 415/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3237 - val_loss: 435.9239\n",
      "Epoch 416/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.9106\n",
      "Epoch 417/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.9076\n",
      "Epoch 418/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3218 - val_loss: 435.8944\n",
      "Epoch 419/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3219 - val_loss: 435.8944\n",
      "Epoch 420/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8788\n",
      "Epoch 421/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3214 - val_loss: 435.8772\n",
      "Epoch 422/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3216 - val_loss: 435.8776\n",
      "Epoch 423/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.8705\n",
      "Epoch 424/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3198 - val_loss: 435.8597\n",
      "Epoch 425/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3198 - val_loss: 435.8570\n",
      "Epoch 426/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8527\n",
      "Epoch 427/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8612\n",
      "Epoch 428/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.8538\n",
      "Epoch 429/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3199 - val_loss: 435.8469\n",
      "Epoch 430/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3216 - val_loss: 435.8502\n",
      "Epoch 431/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8474\n",
      "Epoch 432/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8475\n",
      "Epoch 433/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3199 - val_loss: 435.8437\n",
      "Epoch 434/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.8393\n",
      "Epoch 435/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8377\n",
      "Epoch 436/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3199 - val_loss: 435.8398\n",
      "Epoch 437/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3214 - val_loss: 435.8445\n",
      "Epoch 438/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8393\n",
      "Epoch 439/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8404\n",
      "Epoch 440/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3213 - val_loss: 435.8416\n",
      "Epoch 441/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3214 - val_loss: 435.8423\n",
      "Epoch 442/1000\n",
      "317/317 [==============================] - 0s 2ms/step - loss: 378.3236 - val_loss: 435.8394\n",
      "Epoch 443/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3224 - val_loss: 435.8425\n",
      "Epoch 444/1000\n",
      "317/317 [==============================] - 0s 945us/step - loss: 378.3208 - val_loss: 435.8392\n",
      "Epoch 445/1000\n",
      "317/317 [==============================] - 0s 985us/step - loss: 378.3217 - val_loss: 435.8333\n",
      "Epoch 446/1000\n",
      "317/317 [==============================] - 0s 959us/step - loss: 378.3195 - val_loss: 435.8350\n",
      "Epoch 447/1000\n",
      "317/317 [==============================] - 0s 993us/step - loss: 378.3207 - val_loss: 435.8372\n",
      "Epoch 448/1000\n",
      "317/317 [==============================] - 0s 908us/step - loss: 378.3218 - val_loss: 435.8335\n",
      "Epoch 449/1000\n",
      "317/317 [==============================] - 0s 940us/step - loss: 378.3201 - val_loss: 435.8400\n",
      "Epoch 450/1000\n",
      "317/317 [==============================] - 0s 855us/step - loss: 378.3224 - val_loss: 435.8265\n",
      "Epoch 451/1000\n",
      "317/317 [==============================] - 0s 941us/step - loss: 378.3213 - val_loss: 435.8298\n",
      "Epoch 452/1000\n",
      "317/317 [==============================] - 0s 983us/step - loss: 378.3207 - val_loss: 435.8310\n",
      "Epoch 453/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3206 - val_loss: 435.8329\n",
      "Epoch 454/1000\n",
      "317/317 [==============================] - 0s 961us/step - loss: 378.3216 - val_loss: 435.8297\n",
      "Epoch 455/1000\n",
      "317/317 [==============================] - 0s 899us/step - loss: 378.3198 - val_loss: 435.8190\n",
      "Epoch 456/1000\n",
      "317/317 [==============================] - 0s 898us/step - loss: 378.3210 - val_loss: 435.8178\n",
      "Epoch 457/1000\n",
      "317/317 [==============================] - 0s 945us/step - loss: 378.3214 - val_loss: 435.8262\n",
      "Epoch 458/1000\n",
      "317/317 [==============================] - 0s 934us/step - loss: 378.3211 - val_loss: 435.8234\n",
      "Epoch 459/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 378.3210 - val_loss: 435.8304\n",
      "Epoch 460/1000\n",
      "317/317 [==============================] - 0s 959us/step - loss: 378.3196 - val_loss: 435.8252\n",
      "Epoch 461/1000\n",
      "317/317 [==============================] - 0s 978us/step - loss: 378.3209 - val_loss: 435.8337\n",
      "Epoch 462/1000\n",
      "317/317 [==============================] - 0s 910us/step - loss: 378.3191 - val_loss: 435.8275\n",
      "Epoch 463/1000\n",
      "317/317 [==============================] - 0s 868us/step - loss: 378.3211 - val_loss: 435.8358\n",
      "Epoch 464/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3201 - val_loss: 435.8293\n",
      "Epoch 465/1000\n",
      "317/317 [==============================] - 0s 927us/step - loss: 378.3192 - val_loss: 435.8298\n",
      "Epoch 466/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3199 - val_loss: 435.8299\n",
      "Epoch 467/1000\n",
      "317/317 [==============================] - 0s 927us/step - loss: 378.3199 - val_loss: 435.8275\n",
      "Epoch 468/1000\n",
      "317/317 [==============================] - 0s 941us/step - loss: 378.3206 - val_loss: 435.8318\n",
      "Epoch 469/1000\n",
      "317/317 [==============================] - 0s 999us/step - loss: 378.3210 - val_loss: 435.8282\n",
      "Epoch 470/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3211 - val_loss: 435.8326\n",
      "Epoch 471/1000\n",
      "317/317 [==============================] - 0s 942us/step - loss: 378.3226 - val_loss: 435.8380\n",
      "Epoch 472/1000\n",
      "317/317 [==============================] - 0s 952us/step - loss: 378.3217 - val_loss: 435.8330\n",
      "Epoch 473/1000\n",
      "317/317 [==============================] - 0s 883us/step - loss: 378.3213 - val_loss: 435.8273\n",
      "Epoch 474/1000\n",
      "317/317 [==============================] - 0s 939us/step - loss: 378.3221 - val_loss: 435.8194\n",
      "Epoch 475/1000\n",
      "317/317 [==============================] - 0s 939us/step - loss: 378.3199 - val_loss: 435.8257\n",
      "Epoch 476/1000\n",
      "317/317 [==============================] - 0s 968us/step - loss: 378.3198 - val_loss: 435.8232\n",
      "Epoch 477/1000\n",
      "317/317 [==============================] - 0s 969us/step - loss: 378.3211 - val_loss: 435.8266\n",
      "Epoch 478/1000\n",
      "317/317 [==============================] - 0s 966us/step - loss: 378.3214 - val_loss: 435.8271\n",
      "Epoch 479/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 0s 862us/step - loss: 378.3221 - val_loss: 435.8324\n",
      "Epoch 480/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3226 - val_loss: 435.8340\n",
      "Epoch 481/1000\n",
      "317/317 [==============================] - 0s 895us/step - loss: 378.3206 - val_loss: 435.8192\n",
      "Epoch 482/1000\n",
      "317/317 [==============================] - 0s 974us/step - loss: 378.3221 - val_loss: 435.8277\n",
      "Epoch 483/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3199 - val_loss: 435.8228\n",
      "Epoch 484/1000\n",
      "317/317 [==============================] - 0s 895us/step - loss: 378.3217 - val_loss: 435.8291\n",
      "Epoch 485/1000\n",
      "317/317 [==============================] - 0s 971us/step - loss: 378.3207 - val_loss: 435.8317\n",
      "Epoch 486/1000\n",
      "317/317 [==============================] - 0s 975us/step - loss: 378.3200 - val_loss: 435.8296\n",
      "Epoch 487/1000\n",
      "317/317 [==============================] - 0s 882us/step - loss: 378.3209 - val_loss: 435.8312\n",
      "Epoch 488/1000\n",
      "317/317 [==============================] - 0s 957us/step - loss: 378.3204 - val_loss: 435.8248\n",
      "Epoch 489/1000\n",
      "317/317 [==============================] - 0s 960us/step - loss: 378.3211 - val_loss: 435.8239\n",
      "Epoch 490/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3198 - val_loss: 435.8177\n",
      "Epoch 491/1000\n",
      "317/317 [==============================] - 0s 985us/step - loss: 378.3213 - val_loss: 435.8223\n",
      "Epoch 492/1000\n",
      "317/317 [==============================] - 0s 942us/step - loss: 378.3210 - val_loss: 435.8241\n",
      "Epoch 493/1000\n",
      "317/317 [==============================] - 0s 975us/step - loss: 378.3202 - val_loss: 435.8169\n",
      "Epoch 494/1000\n",
      "317/317 [==============================] - 0s 955us/step - loss: 378.3207 - val_loss: 435.8208\n",
      "Epoch 495/1000\n",
      "317/317 [==============================] - 0s 998us/step - loss: 378.3213 - val_loss: 435.8197\n",
      "Epoch 496/1000\n",
      "317/317 [==============================] - 0s 990us/step - loss: 378.3214 - val_loss: 435.8157\n",
      "Epoch 497/1000\n",
      "317/317 [==============================] - 0s 952us/step - loss: 378.3205 - val_loss: 435.8211\n",
      "Epoch 498/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8256\n",
      "Epoch 499/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8349\n",
      "Epoch 500/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3224 - val_loss: 435.8315\n",
      "Epoch 501/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3200 - val_loss: 435.8307\n",
      "Epoch 502/1000\n",
      "317/317 [==============================] - 0s 999us/step - loss: 378.3206 - val_loss: 435.8269\n",
      "Epoch 503/1000\n",
      "317/317 [==============================] - 0s 967us/step - loss: 378.3202 - val_loss: 435.8289\n",
      "Epoch 504/1000\n",
      "317/317 [==============================] - 0s 963us/step - loss: 378.3196 - val_loss: 435.8333\n",
      "Epoch 505/1000\n",
      "317/317 [==============================] - 0s 968us/step - loss: 378.3225 - val_loss: 435.8326\n",
      "Epoch 506/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3216 - val_loss: 435.8307\n",
      "Epoch 507/1000\n",
      "317/317 [==============================] - 0s 912us/step - loss: 378.3205 - val_loss: 435.8173\n",
      "Epoch 508/1000\n",
      "317/317 [==============================] - 0s 942us/step - loss: 378.3200 - val_loss: 435.8157\n",
      "Epoch 509/1000\n",
      "317/317 [==============================] - 0s 923us/step - loss: 378.3216 - val_loss: 435.8166\n",
      "Epoch 510/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3220 - val_loss: 435.8244\n",
      "Epoch 511/1000\n",
      "317/317 [==============================] - 0s 919us/step - loss: 378.3203 - val_loss: 435.8175\n",
      "Epoch 512/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8134\n",
      "Epoch 513/1000\n",
      "317/317 [==============================] - 0s 975us/step - loss: 378.3209 - val_loss: 435.8200\n",
      "Epoch 514/1000\n",
      "317/317 [==============================] - 0s 895us/step - loss: 378.3213 - val_loss: 435.8142\n",
      "Epoch 515/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3210 - val_loss: 435.8142\n",
      "Epoch 516/1000\n",
      "317/317 [==============================] - 0s 940us/step - loss: 378.3211 - val_loss: 435.8257\n",
      "Epoch 517/1000\n",
      "317/317 [==============================] - 0s 960us/step - loss: 378.3199 - val_loss: 435.8281\n",
      "Epoch 518/1000\n",
      "317/317 [==============================] - 0s 983us/step - loss: 378.3204 - val_loss: 435.8330\n",
      "Epoch 519/1000\n",
      "317/317 [==============================] - 0s 988us/step - loss: 378.3223 - val_loss: 435.8344\n",
      "Epoch 520/1000\n",
      "317/317 [==============================] - 0s 908us/step - loss: 378.3211 - val_loss: 435.8279\n",
      "Epoch 521/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3206 - val_loss: 435.8233\n",
      "Epoch 522/1000\n",
      "317/317 [==============================] - 0s 999us/step - loss: 378.3206 - val_loss: 435.8286\n",
      "Epoch 523/1000\n",
      "317/317 [==============================] - 0s 999us/step - loss: 378.3200 - val_loss: 435.8320\n",
      "Epoch 524/1000\n",
      "317/317 [==============================] - 0s 989us/step - loss: 378.3201 - val_loss: 435.8326\n",
      "Epoch 525/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3201 - val_loss: 435.8409\n",
      "Epoch 526/1000\n",
      "317/317 [==============================] - 0s 983us/step - loss: 378.3207 - val_loss: 435.8237\n",
      "Epoch 527/1000\n",
      "317/317 [==============================] - 0s 971us/step - loss: 378.3198 - val_loss: 435.8310\n",
      "Epoch 528/1000\n",
      "317/317 [==============================] - 0s 993us/step - loss: 378.3194 - val_loss: 435.8348\n",
      "Epoch 529/1000\n",
      "317/317 [==============================] - 0s 962us/step - loss: 378.3215 - val_loss: 435.8315\n",
      "Epoch 530/1000\n",
      "317/317 [==============================] - 0s 970us/step - loss: 378.3210 - val_loss: 435.8358\n",
      "Epoch 531/1000\n",
      "317/317 [==============================] - 0s 969us/step - loss: 378.3203 - val_loss: 435.8318\n",
      "Epoch 532/1000\n",
      "317/317 [==============================] - 0s 944us/step - loss: 378.3212 - val_loss: 435.8293\n",
      "Epoch 533/1000\n",
      "317/317 [==============================] - 0s 962us/step - loss: 378.3223 - val_loss: 435.8303\n",
      "Epoch 534/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3195 - val_loss: 435.8297\n",
      "Epoch 535/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3210 - val_loss: 435.8263\n",
      "Epoch 536/1000\n",
      "317/317 [==============================] - 0s 980us/step - loss: 378.3205 - val_loss: 435.8307\n",
      "Epoch 537/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3221 - val_loss: 435.8371\n",
      "Epoch 538/1000\n",
      "317/317 [==============================] - 0s 914us/step - loss: 378.3201 - val_loss: 435.8326\n",
      "Epoch 539/1000\n",
      "317/317 [==============================] - 0s 936us/step - loss: 378.3205 - val_loss: 435.8422\n",
      "Epoch 540/1000\n",
      "317/317 [==============================] - 0s 970us/step - loss: 378.3221 - val_loss: 435.8310\n",
      "Epoch 541/1000\n",
      "317/317 [==============================] - 0s 960us/step - loss: 378.3202 - val_loss: 435.8366\n",
      "Epoch 542/1000\n",
      "317/317 [==============================] - 0s 947us/step - loss: 378.3201 - val_loss: 435.8427\n",
      "Epoch 543/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3205 - val_loss: 435.8378\n",
      "Epoch 544/1000\n",
      "317/317 [==============================] - 0s 978us/step - loss: 378.3208 - val_loss: 435.8417\n",
      "Epoch 545/1000\n",
      "317/317 [==============================] - 0s 937us/step - loss: 378.3207 - val_loss: 435.8338\n",
      "Epoch 546/1000\n",
      "317/317 [==============================] - 0s 926us/step - loss: 378.3244 - val_loss: 435.8405\n",
      "Epoch 547/1000\n",
      "317/317 [==============================] - 0s 983us/step - loss: 378.3220 - val_loss: 435.8425\n",
      "Epoch 548/1000\n",
      "317/317 [==============================] - 0s 980us/step - loss: 378.3201 - val_loss: 435.8282\n",
      "Epoch 549/1000\n",
      "317/317 [==============================] - 0s 927us/step - loss: 378.3213 - val_loss: 435.8286\n",
      "Epoch 550/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3219 - val_loss: 435.8258\n",
      "Epoch 551/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3209 - val_loss: 435.8396\n",
      "Epoch 552/1000\n",
      "317/317 [==============================] - 0s 952us/step - loss: 378.3215 - val_loss: 435.8344\n",
      "Epoch 553/1000\n",
      "317/317 [==============================] - 0s 960us/step - loss: 378.3197 - val_loss: 435.8377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 554/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 378.3207 - val_loss: 435.8358\n",
      "Epoch 555/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8310\n",
      "Epoch 556/1000\n",
      "317/317 [==============================] - 0s 939us/step - loss: 378.3203 - val_loss: 435.8322\n",
      "Epoch 557/1000\n",
      "317/317 [==============================] - 0s 997us/step - loss: 378.3207 - val_loss: 435.8304\n",
      "Epoch 558/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3209 - val_loss: 435.8341\n",
      "Epoch 559/1000\n",
      "317/317 [==============================] - 0s 976us/step - loss: 378.3201 - val_loss: 435.8345\n",
      "Epoch 560/1000\n",
      "317/317 [==============================] - 0s 907us/step - loss: 378.3205 - val_loss: 435.8351\n",
      "Epoch 561/1000\n",
      "317/317 [==============================] - 0s 967us/step - loss: 378.3210 - val_loss: 435.8384\n",
      "Epoch 562/1000\n",
      "317/317 [==============================] - 0s 954us/step - loss: 378.3204 - val_loss: 435.8429\n",
      "Epoch 563/1000\n",
      "317/317 [==============================] - 0s 995us/step - loss: 378.3212 - val_loss: 435.8427\n",
      "Epoch 564/1000\n",
      "317/317 [==============================] - 0s 951us/step - loss: 378.3204 - val_loss: 435.8389\n",
      "Epoch 565/1000\n",
      "317/317 [==============================] - 0s 936us/step - loss: 378.3215 - val_loss: 435.8361\n",
      "Epoch 566/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3224 - val_loss: 435.8401\n",
      "Epoch 567/1000\n",
      "317/317 [==============================] - 0s 970us/step - loss: 378.3210 - val_loss: 435.8367\n",
      "Epoch 568/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3205 - val_loss: 435.8316\n",
      "Epoch 569/1000\n",
      "317/317 [==============================] - 0s 973us/step - loss: 378.3201 - val_loss: 435.8322\n",
      "Epoch 570/1000\n",
      "317/317 [==============================] - 0s 962us/step - loss: 378.3195 - val_loss: 435.8327\n",
      "Epoch 571/1000\n",
      "317/317 [==============================] - 0s 991us/step - loss: 378.3206 - val_loss: 435.8311\n",
      "Epoch 572/1000\n",
      "317/317 [==============================] - 0s 964us/step - loss: 378.3217 - val_loss: 435.8295\n",
      "Epoch 573/1000\n",
      "317/317 [==============================] - 0s 991us/step - loss: 378.3232 - val_loss: 435.8313\n",
      "Epoch 574/1000\n",
      "317/317 [==============================] - 0s 944us/step - loss: 378.3207 - val_loss: 435.8377\n",
      "Epoch 575/1000\n",
      "317/317 [==============================] - 0s 944us/step - loss: 378.3202 - val_loss: 435.8394\n",
      "Epoch 576/1000\n",
      "317/317 [==============================] - 0s 974us/step - loss: 378.3209 - val_loss: 435.8348\n",
      "Epoch 577/1000\n",
      "317/317 [==============================] - 0s 938us/step - loss: 378.3200 - val_loss: 435.8347\n",
      "Epoch 578/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3197 - val_loss: 435.8316\n",
      "Epoch 579/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3215 - val_loss: 435.8315\n",
      "Epoch 580/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 378.3203 - val_loss: 435.8322\n",
      "Epoch 581/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3206 - val_loss: 435.8331\n",
      "Epoch 582/1000\n",
      "317/317 [==============================] - 0s 958us/step - loss: 378.3215 - val_loss: 435.8322\n",
      "Epoch 583/1000\n",
      "317/317 [==============================] - 0s 982us/step - loss: 378.3201 - val_loss: 435.8422\n",
      "Epoch 584/1000\n",
      "317/317 [==============================] - 0s 958us/step - loss: 378.3214 - val_loss: 435.8233\n",
      "Epoch 585/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3195 - val_loss: 435.8369\n",
      "Epoch 586/1000\n",
      "317/317 [==============================] - 0s 976us/step - loss: 378.3214 - val_loss: 435.8372\n",
      "Epoch 587/1000\n",
      "317/317 [==============================] - 0s 968us/step - loss: 378.3229 - val_loss: 435.8347\n",
      "Epoch 588/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3213 - val_loss: 435.8269\n",
      "Epoch 589/1000\n",
      "317/317 [==============================] - 0s 987us/step - loss: 378.3194 - val_loss: 435.8310\n",
      "Epoch 590/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3202 - val_loss: 435.8346\n",
      "Epoch 591/1000\n",
      "317/317 [==============================] - 0s 991us/step - loss: 378.3216 - val_loss: 435.8363\n",
      "Epoch 592/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3208 - val_loss: 435.8363\n",
      "Epoch 593/1000\n",
      "317/317 [==============================] - 0s 986us/step - loss: 378.3214 - val_loss: 435.8355\n",
      "Epoch 594/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3208 - val_loss: 435.8358\n",
      "Epoch 595/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3197 - val_loss: 435.8340\n",
      "Epoch 596/1000\n",
      "317/317 [==============================] - 0s 951us/step - loss: 378.3211 - val_loss: 435.8339\n",
      "Epoch 597/1000\n",
      "317/317 [==============================] - 0s 976us/step - loss: 378.3208 - val_loss: 435.8365\n",
      "Epoch 598/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 378.3210 - val_loss: 435.8370\n",
      "Epoch 599/1000\n",
      "317/317 [==============================] - 0s 978us/step - loss: 378.3206 - val_loss: 435.8287\n",
      "Epoch 600/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3202 - val_loss: 435.8289\n",
      "Epoch 601/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3199 - val_loss: 435.8389\n",
      "Epoch 602/1000\n",
      "317/317 [==============================] - 0s 941us/step - loss: 378.3219 - val_loss: 435.8343\n",
      "Epoch 603/1000\n",
      "317/317 [==============================] - 0s 964us/step - loss: 378.3216 - val_loss: 435.8466\n",
      "Epoch 604/1000\n",
      "317/317 [==============================] - 0s 918us/step - loss: 378.3228 - val_loss: 435.8411\n",
      "Epoch 605/1000\n",
      "317/317 [==============================] - 0s 945us/step - loss: 378.3207 - val_loss: 435.8323\n",
      "Epoch 606/1000\n",
      "317/317 [==============================] - 0s 993us/step - loss: 378.3212 - val_loss: 435.8418\n",
      "Epoch 607/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3212 - val_loss: 435.8307\n",
      "Epoch 608/1000\n",
      "317/317 [==============================] - 0s 976us/step - loss: 378.3210 - val_loss: 435.8369\n",
      "Epoch 609/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3207 - val_loss: 435.8338\n",
      "Epoch 610/1000\n",
      "317/317 [==============================] - 0s 927us/step - loss: 378.3208 - val_loss: 435.8362\n",
      "Epoch 611/1000\n",
      "317/317 [==============================] - 0s 950us/step - loss: 378.3208 - val_loss: 435.8352\n",
      "Epoch 612/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3214 - val_loss: 435.8384\n",
      "Epoch 613/1000\n",
      "317/317 [==============================] - 0s 926us/step - loss: 378.3201 - val_loss: 435.8383\n",
      "Epoch 614/1000\n",
      "317/317 [==============================] - 0s 953us/step - loss: 378.3224 - val_loss: 435.8329\n",
      "Epoch 615/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3217 - val_loss: 435.8339\n",
      "Epoch 616/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3216 - val_loss: 435.8354\n",
      "Epoch 617/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3198 - val_loss: 435.8376\n",
      "Epoch 618/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3201 - val_loss: 435.8419\n",
      "Epoch 619/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3213 - val_loss: 435.8340\n",
      "Epoch 620/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3209 - val_loss: 435.8481\n",
      "Epoch 621/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3201 - val_loss: 435.8356\n",
      "Epoch 622/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8402\n",
      "Epoch 623/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3226 - val_loss: 435.8373\n",
      "Epoch 624/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3204 - val_loss: 435.8444\n",
      "Epoch 625/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3216 - val_loss: 435.8365\n",
      "Epoch 626/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3212 - val_loss: 435.8321\n",
      "Epoch 627/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3213 - val_loss: 435.8397\n",
      "Epoch 628/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3209 - val_loss: 435.8358\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8295\n",
      "Epoch 630/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3199 - val_loss: 435.8339\n",
      "Epoch 631/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8311\n",
      "Epoch 632/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3222 - val_loss: 435.8324\n",
      "Epoch 633/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8277\n",
      "Epoch 634/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8296\n",
      "Epoch 635/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8299\n",
      "Epoch 636/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3228 - val_loss: 435.8262\n",
      "Epoch 637/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8223\n",
      "Epoch 638/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.8244\n",
      "Epoch 639/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8270\n",
      "Epoch 640/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8266\n",
      "Epoch 641/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8278\n",
      "Epoch 642/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8289\n",
      "Epoch 643/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3199 - val_loss: 435.8318\n",
      "Epoch 644/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3212 - val_loss: 435.8292\n",
      "Epoch 645/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8343\n",
      "Epoch 646/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8285\n",
      "Epoch 647/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3213 - val_loss: 435.8303\n",
      "Epoch 648/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8314\n",
      "Epoch 649/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3223 - val_loss: 435.8315\n",
      "Epoch 650/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8243\n",
      "Epoch 651/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3199 - val_loss: 435.8217\n",
      "Epoch 652/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8275\n",
      "Epoch 653/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3218 - val_loss: 435.8254\n",
      "Epoch 654/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3219 - val_loss: 435.8299\n",
      "Epoch 655/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8120\n",
      "Epoch 656/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3200 - val_loss: 435.8227\n",
      "Epoch 657/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3200 - val_loss: 435.8175\n",
      "Epoch 658/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3196 - val_loss: 435.8229\n",
      "Epoch 659/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8263\n",
      "Epoch 660/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3214 - val_loss: 435.8275\n",
      "Epoch 661/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3219 - val_loss: 435.8257\n",
      "Epoch 662/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3224 - val_loss: 435.8311\n",
      "Epoch 663/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8241\n",
      "Epoch 664/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3222 - val_loss: 435.8267\n",
      "Epoch 665/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8301\n",
      "Epoch 666/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8247\n",
      "Epoch 667/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3218 - val_loss: 435.8357\n",
      "Epoch 668/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3228 - val_loss: 435.8348\n",
      "Epoch 669/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8308\n",
      "Epoch 670/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3213 - val_loss: 435.8357\n",
      "Epoch 671/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8401\n",
      "Epoch 672/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8402\n",
      "Epoch 673/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8385\n",
      "Epoch 674/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8297\n",
      "Epoch 675/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8322\n",
      "Epoch 676/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8277\n",
      "Epoch 677/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8321\n",
      "Epoch 678/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.8354\n",
      "Epoch 679/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3214 - val_loss: 435.8316\n",
      "Epoch 680/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3216 - val_loss: 435.8302\n",
      "Epoch 681/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8303\n",
      "Epoch 682/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8291\n",
      "Epoch 683/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3198 - val_loss: 435.8315\n",
      "Epoch 684/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3214 - val_loss: 435.8373\n",
      "Epoch 685/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8307\n",
      "Epoch 686/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8300\n",
      "Epoch 687/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8325\n",
      "Epoch 688/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8260\n",
      "Epoch 689/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3200 - val_loss: 435.8315\n",
      "Epoch 690/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3213 - val_loss: 435.8286\n",
      "Epoch 691/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8286\n",
      "Epoch 692/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8315\n",
      "Epoch 693/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8305\n",
      "Epoch 694/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8311\n",
      "Epoch 695/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8293\n",
      "Epoch 696/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8335\n",
      "Epoch 697/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8288\n",
      "Epoch 698/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.8342\n",
      "Epoch 699/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8330\n",
      "Epoch 700/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3215 - val_loss: 435.8355\n",
      "Epoch 701/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3220 - val_loss: 435.8434\n",
      "Epoch 702/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3220 - val_loss: 435.8338\n",
      "Epoch 703/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8315\n",
      "Epoch 704/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3218 - val_loss: 435.8390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 705/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3222 - val_loss: 435.8376\n",
      "Epoch 706/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3227 - val_loss: 435.8298\n",
      "Epoch 707/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3209 - val_loss: 435.8269\n",
      "Epoch 708/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3198 - val_loss: 435.8323\n",
      "Epoch 709/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3221 - val_loss: 435.8358\n",
      "Epoch 710/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3196 - val_loss: 435.8354\n",
      "Epoch 711/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8320\n",
      "Epoch 712/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8306\n",
      "Epoch 713/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3199 - val_loss: 435.8343\n",
      "Epoch 714/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3205 - val_loss: 435.8381\n",
      "Epoch 715/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3213 - val_loss: 435.8332\n",
      "Epoch 716/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3198 - val_loss: 435.8346\n",
      "Epoch 717/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3207 - val_loss: 435.8300\n",
      "Epoch 718/1000\n",
      "317/317 [==============================] - 0s 931us/step - loss: 378.3203 - val_loss: 435.8318\n",
      "Epoch 719/1000\n",
      "317/317 [==============================] - 0s 966us/step - loss: 378.3202 - val_loss: 435.8321\n",
      "Epoch 720/1000\n",
      "317/317 [==============================] - 0s 956us/step - loss: 378.3215 - val_loss: 435.8322\n",
      "Epoch 721/1000\n",
      "317/317 [==============================] - 0s 931us/step - loss: 378.3203 - val_loss: 435.8315\n",
      "Epoch 722/1000\n",
      "317/317 [==============================] - 0s 951us/step - loss: 378.3210 - val_loss: 435.8313\n",
      "Epoch 723/1000\n",
      "317/317 [==============================] - 0s 944us/step - loss: 378.3202 - val_loss: 435.8229\n",
      "Epoch 724/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8271\n",
      "Epoch 725/1000\n",
      "317/317 [==============================] - 0s 955us/step - loss: 378.3219 - val_loss: 435.8326\n",
      "Epoch 726/1000\n",
      "317/317 [==============================] - 0s 978us/step - loss: 378.3204 - val_loss: 435.8201\n",
      "Epoch 727/1000\n",
      "317/317 [==============================] - 0s 946us/step - loss: 378.3199 - val_loss: 435.8273\n",
      "Epoch 728/1000\n",
      "317/317 [==============================] - 0s 893us/step - loss: 378.3202 - val_loss: 435.8304\n",
      "Epoch 729/1000\n",
      "317/317 [==============================] - 0s 897us/step - loss: 378.3203 - val_loss: 435.8303\n",
      "Epoch 730/1000\n",
      "317/317 [==============================] - 0s 932us/step - loss: 378.3199 - val_loss: 435.8267\n",
      "Epoch 731/1000\n",
      "317/317 [==============================] - 0s 940us/step - loss: 378.3213 - val_loss: 435.8283\n",
      "Epoch 732/1000\n",
      "317/317 [==============================] - 0s 934us/step - loss: 378.3220 - val_loss: 435.8297\n",
      "Epoch 733/1000\n",
      "317/317 [==============================] - 0s 888us/step - loss: 378.3201 - val_loss: 435.8234\n",
      "Epoch 734/1000\n",
      "317/317 [==============================] - 0s 954us/step - loss: 378.3217 - val_loss: 435.8246\n",
      "Epoch 735/1000\n",
      "317/317 [==============================] - 0s 972us/step - loss: 378.3206 - val_loss: 435.8267\n",
      "Epoch 736/1000\n",
      "317/317 [==============================] - 0s 951us/step - loss: 378.3210 - val_loss: 435.8267\n",
      "Epoch 737/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3208 - val_loss: 435.8292\n",
      "Epoch 738/1000\n",
      "317/317 [==============================] - 0s 939us/step - loss: 378.3211 - val_loss: 435.8318\n",
      "Epoch 739/1000\n",
      "317/317 [==============================] - 0s 937us/step - loss: 378.3211 - val_loss: 435.8254\n",
      "Epoch 740/1000\n",
      "317/317 [==============================] - 0s 993us/step - loss: 378.3202 - val_loss: 435.8303\n",
      "Epoch 741/1000\n",
      "317/317 [==============================] - 0s 912us/step - loss: 378.3201 - val_loss: 435.8314\n",
      "Epoch 742/1000\n",
      "317/317 [==============================] - 0s 868us/step - loss: 378.3210 - val_loss: 435.8318\n",
      "Epoch 743/1000\n",
      "317/317 [==============================] - 0s 997us/step - loss: 378.3207 - val_loss: 435.8251\n",
      "Epoch 744/1000\n",
      "317/317 [==============================] - 0s 952us/step - loss: 378.3201 - val_loss: 435.8189\n",
      "Epoch 745/1000\n",
      "317/317 [==============================] - 0s 939us/step - loss: 378.3207 - val_loss: 435.8266\n",
      "Epoch 746/1000\n",
      "317/317 [==============================] - 0s 921us/step - loss: 378.3214 - val_loss: 435.8196\n",
      "Epoch 747/1000\n",
      "317/317 [==============================] - 0s 898us/step - loss: 378.3200 - val_loss: 435.8174\n",
      "Epoch 748/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3222 - val_loss: 435.8222\n",
      "Epoch 749/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3196 - val_loss: 435.8180\n",
      "Epoch 750/1000\n",
      "317/317 [==============================] - 0s 853us/step - loss: 378.3215 - val_loss: 435.8218\n",
      "Epoch 751/1000\n",
      "317/317 [==============================] - 0s 927us/step - loss: 378.3209 - val_loss: 435.8176\n",
      "Epoch 752/1000\n",
      "317/317 [==============================] - 0s 972us/step - loss: 378.3224 - val_loss: 435.8269\n",
      "Epoch 753/1000\n",
      "317/317 [==============================] - 0s 915us/step - loss: 378.3211 - val_loss: 435.8215\n",
      "Epoch 754/1000\n",
      "317/317 [==============================] - 0s 955us/step - loss: 378.3216 - val_loss: 435.8239\n",
      "Epoch 755/1000\n",
      "317/317 [==============================] - 0s 874us/step - loss: 378.3207 - val_loss: 435.8282\n",
      "Epoch 756/1000\n",
      "317/317 [==============================] - 0s 916us/step - loss: 378.3207 - val_loss: 435.8239\n",
      "Epoch 757/1000\n",
      "317/317 [==============================] - 0s 997us/step - loss: 378.3207 - val_loss: 435.8178\n",
      "Epoch 758/1000\n",
      "317/317 [==============================] - 0s 953us/step - loss: 378.3221 - val_loss: 435.8307\n",
      "Epoch 759/1000\n",
      "317/317 [==============================] - 0s 998us/step - loss: 378.3202 - val_loss: 435.8306\n",
      "Epoch 760/1000\n",
      "317/317 [==============================] - 0s 941us/step - loss: 378.3199 - val_loss: 435.8278\n",
      "Epoch 761/1000\n",
      "317/317 [==============================] - 0s 966us/step - loss: 378.3210 - val_loss: 435.8250\n",
      "Epoch 762/1000\n",
      "317/317 [==============================] - 0s 957us/step - loss: 378.3218 - val_loss: 435.8204\n",
      "Epoch 763/1000\n",
      "317/317 [==============================] - 0s 969us/step - loss: 378.3203 - val_loss: 435.8283\n",
      "Epoch 764/1000\n",
      "317/317 [==============================] - 0s 956us/step - loss: 378.3203 - val_loss: 435.8278\n",
      "Epoch 765/1000\n",
      "317/317 [==============================] - 0s 939us/step - loss: 378.3211 - val_loss: 435.8339\n",
      "Epoch 766/1000\n",
      "317/317 [==============================] - 0s 941us/step - loss: 378.3215 - val_loss: 435.8314\n",
      "Epoch 767/1000\n",
      "317/317 [==============================] - 0s 936us/step - loss: 378.3194 - val_loss: 435.8324\n",
      "Epoch 768/1000\n",
      "317/317 [==============================] - 0s 972us/step - loss: 378.3201 - val_loss: 435.8322\n",
      "Epoch 769/1000\n",
      "317/317 [==============================] - 0s 948us/step - loss: 378.3193 - val_loss: 435.8340\n",
      "Epoch 770/1000\n",
      "317/317 [==============================] - 0s 989us/step - loss: 378.3215 - val_loss: 435.8320\n",
      "Epoch 771/1000\n",
      "317/317 [==============================] - 0s 984us/step - loss: 378.3226 - val_loss: 435.8351\n",
      "Epoch 772/1000\n",
      "317/317 [==============================] - 0s 969us/step - loss: 378.3206 - val_loss: 435.8390\n",
      "Epoch 773/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 378.3207 - val_loss: 435.8358\n",
      "Epoch 774/1000\n",
      "317/317 [==============================] - 0s 979us/step - loss: 378.3213 - val_loss: 435.8334\n",
      "Epoch 775/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3215 - val_loss: 435.8369\n",
      "Epoch 776/1000\n",
      "317/317 [==============================] - 0s 947us/step - loss: 378.3210 - val_loss: 435.8391\n",
      "Epoch 777/1000\n",
      "317/317 [==============================] - 0s 955us/step - loss: 378.3207 - val_loss: 435.8340\n",
      "Epoch 778/1000\n",
      "317/317 [==============================] - 0s 935us/step - loss: 378.3203 - val_loss: 435.8324\n",
      "Epoch 779/1000\n",
      "317/317 [==============================] - 0s 936us/step - loss: 378.3217 - val_loss: 435.8289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1000\n",
      "317/317 [==============================] - 0s 900us/step - loss: 378.3217 - val_loss: 435.8336\n",
      "Epoch 781/1000\n",
      "317/317 [==============================] - 0s 981us/step - loss: 378.3206 - val_loss: 435.8337\n",
      "Epoch 782/1000\n",
      "317/317 [==============================] - 0s 941us/step - loss: 378.3198 - val_loss: 435.8305\n",
      "Epoch 783/1000\n",
      "317/317 [==============================] - 0s 966us/step - loss: 378.3210 - val_loss: 435.8328\n",
      "Epoch 784/1000\n",
      "317/317 [==============================] - 0s 949us/step - loss: 378.3203 - val_loss: 435.8388\n",
      "Epoch 785/1000\n",
      "317/317 [==============================] - 0s 960us/step - loss: 378.3203 - val_loss: 435.8326\n",
      "Epoch 786/1000\n",
      "317/317 [==============================] - 0s 906us/step - loss: 378.3208 - val_loss: 435.8269\n",
      "Epoch 787/1000\n",
      "317/317 [==============================] - 0s 964us/step - loss: 378.3199 - val_loss: 435.8383\n",
      "Epoch 788/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3209 - val_loss: 435.8427\n",
      "Epoch 789/1000\n",
      "317/317 [==============================] - 0s 919us/step - loss: 378.3204 - val_loss: 435.8333\n",
      "Epoch 790/1000\n",
      "317/317 [==============================] - 0s 938us/step - loss: 378.3206 - val_loss: 435.8423\n",
      "Epoch 791/1000\n",
      "317/317 [==============================] - 0s 942us/step - loss: 378.3218 - val_loss: 435.8391\n",
      "Epoch 792/1000\n",
      "317/317 [==============================] - 0s 963us/step - loss: 378.3210 - val_loss: 435.8364\n",
      "Epoch 793/1000\n",
      "317/317 [==============================] - 0s 939us/step - loss: 378.3207 - val_loss: 435.8397\n",
      "Epoch 794/1000\n",
      "317/317 [==============================] - 0s 979us/step - loss: 378.3205 - val_loss: 435.8420\n",
      "Epoch 795/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3206 - val_loss: 435.8391\n",
      "Epoch 796/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3198 - val_loss: 435.8419\n",
      "Epoch 797/1000\n",
      "317/317 [==============================] - 0s 972us/step - loss: 378.3210 - val_loss: 435.8355\n",
      "Epoch 798/1000\n",
      "317/317 [==============================] - 0s 972us/step - loss: 378.3212 - val_loss: 435.8387\n",
      "Epoch 799/1000\n",
      "317/317 [==============================] - 0s 958us/step - loss: 378.3218 - val_loss: 435.8371\n",
      "Epoch 800/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3202 - val_loss: 435.8306\n",
      "Epoch 801/1000\n",
      "317/317 [==============================] - 0s 993us/step - loss: 378.3208 - val_loss: 435.8430\n",
      "Epoch 802/1000\n",
      "317/317 [==============================] - 0s 977us/step - loss: 378.3204 - val_loss: 435.8351\n",
      "Epoch 803/1000\n",
      "317/317 [==============================] - 0s 938us/step - loss: 378.3196 - val_loss: 435.8345\n",
      "Epoch 804/1000\n",
      "317/317 [==============================] - 0s 938us/step - loss: 378.3200 - val_loss: 435.8339\n",
      "Epoch 805/1000\n",
      "317/317 [==============================] - 0s 978us/step - loss: 378.3208 - val_loss: 435.8288\n",
      "Epoch 806/1000\n",
      "317/317 [==============================] - 0s 976us/step - loss: 378.3216 - val_loss: 435.8330\n",
      "Epoch 807/1000\n",
      "317/317 [==============================] - 0s 971us/step - loss: 378.3203 - val_loss: 435.8412\n",
      "Epoch 808/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3214 - val_loss: 435.8411\n",
      "Epoch 809/1000\n",
      "317/317 [==============================] - 0s 970us/step - loss: 378.3203 - val_loss: 435.8359\n",
      "Epoch 810/1000\n",
      "317/317 [==============================] - 0s 977us/step - loss: 378.3214 - val_loss: 435.8389\n",
      "Epoch 811/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3210 - val_loss: 435.8399\n",
      "Epoch 812/1000\n",
      "317/317 [==============================] - 0s 897us/step - loss: 378.3194 - val_loss: 435.8372\n",
      "Epoch 813/1000\n",
      "317/317 [==============================] - 0s 934us/step - loss: 378.3210 - val_loss: 435.8327\n",
      "Epoch 814/1000\n",
      "317/317 [==============================] - 0s 960us/step - loss: 378.3247 - val_loss: 435.8329\n",
      "Epoch 815/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 378.3212 - val_loss: 435.8331\n",
      "Epoch 816/1000\n",
      "317/317 [==============================] - 0s 968us/step - loss: 378.3201 - val_loss: 435.8316\n",
      "Epoch 817/1000\n",
      "317/317 [==============================] - 0s 926us/step - loss: 378.3212 - val_loss: 435.8363\n",
      "Epoch 818/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3207 - val_loss: 435.8311\n",
      "Epoch 819/1000\n",
      "317/317 [==============================] - 0s 894us/step - loss: 378.3210 - val_loss: 435.8315\n",
      "Epoch 820/1000\n",
      "317/317 [==============================] - 0s 980us/step - loss: 378.3210 - val_loss: 435.8363\n",
      "Epoch 821/1000\n",
      "317/317 [==============================] - 0s 951us/step - loss: 378.3210 - val_loss: 435.8313\n",
      "Epoch 822/1000\n",
      "317/317 [==============================] - 0s 935us/step - loss: 378.3211 - val_loss: 435.8370\n",
      "Epoch 823/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3212 - val_loss: 435.8434\n",
      "Epoch 824/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3198 - val_loss: 435.8426\n",
      "Epoch 825/1000\n",
      "317/317 [==============================] - 0s 984us/step - loss: 378.3197 - val_loss: 435.8394\n",
      "Epoch 826/1000\n",
      "317/317 [==============================] - 0s 953us/step - loss: 378.3211 - val_loss: 435.8490\n",
      "Epoch 827/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3204 - val_loss: 435.8372\n",
      "Epoch 828/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3206 - val_loss: 435.8371\n",
      "Epoch 829/1000\n",
      "317/317 [==============================] - 0s 941us/step - loss: 378.3212 - val_loss: 435.8379\n",
      "Epoch 830/1000\n",
      "317/317 [==============================] - 0s 997us/step - loss: 378.3197 - val_loss: 435.8425\n",
      "Epoch 831/1000\n",
      "317/317 [==============================] - 0s 968us/step - loss: 378.3212 - val_loss: 435.8300\n",
      "Epoch 832/1000\n",
      "317/317 [==============================] - 0s 889us/step - loss: 378.3204 - val_loss: 435.8402\n",
      "Epoch 833/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3214 - val_loss: 435.8315\n",
      "Epoch 834/1000\n",
      "317/317 [==============================] - 0s 932us/step - loss: 378.3200 - val_loss: 435.8398\n",
      "Epoch 835/1000\n",
      "317/317 [==============================] - 0s 938us/step - loss: 378.3210 - val_loss: 435.8357\n",
      "Epoch 836/1000\n",
      "317/317 [==============================] - 0s 959us/step - loss: 378.3203 - val_loss: 435.8326\n",
      "Epoch 837/1000\n",
      "317/317 [==============================] - 0s 905us/step - loss: 378.3206 - val_loss: 435.8363\n",
      "Epoch 838/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3200 - val_loss: 435.8385\n",
      "Epoch 839/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3197 - val_loss: 435.8384\n",
      "Epoch 840/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3232 - val_loss: 435.8379\n",
      "Epoch 841/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8359\n",
      "Epoch 842/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3207 - val_loss: 435.8430\n",
      "Epoch 843/1000\n",
      "317/317 [==============================] - 0s 968us/step - loss: 378.3203 - val_loss: 435.8329\n",
      "Epoch 844/1000\n",
      "317/317 [==============================] - 0s 965us/step - loss: 378.3201 - val_loss: 435.8413\n",
      "Epoch 845/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3202 - val_loss: 435.8461\n",
      "Epoch 846/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8400\n",
      "Epoch 847/1000\n",
      "317/317 [==============================] - 0s 949us/step - loss: 378.3210 - val_loss: 435.8430\n",
      "Epoch 848/1000\n",
      "317/317 [==============================] - 0s 973us/step - loss: 378.3207 - val_loss: 435.8421\n",
      "Epoch 849/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3217 - val_loss: 435.8353\n",
      "Epoch 850/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3214 - val_loss: 435.8397\n",
      "Epoch 851/1000\n",
      "317/317 [==============================] - 0s 953us/step - loss: 378.3220 - val_loss: 435.8369\n",
      "Epoch 852/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8353\n",
      "Epoch 853/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3228 - val_loss: 435.8370\n",
      "Epoch 854/1000\n",
      "317/317 [==============================] - 0s 988us/step - loss: 378.3216 - val_loss: 435.8398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/1000\n",
      "317/317 [==============================] - 0s 964us/step - loss: 378.3208 - val_loss: 435.8461\n",
      "Epoch 856/1000\n",
      "317/317 [==============================] - 0s 956us/step - loss: 378.3193 - val_loss: 435.8438\n",
      "Epoch 857/1000\n",
      "317/317 [==============================] - 0s 948us/step - loss: 378.3198 - val_loss: 435.8340\n",
      "Epoch 858/1000\n",
      "317/317 [==============================] - 0s 908us/step - loss: 378.3199 - val_loss: 435.8473\n",
      "Epoch 859/1000\n",
      "317/317 [==============================] - 0s 943us/step - loss: 378.3216 - val_loss: 435.8412\n",
      "Epoch 860/1000\n",
      "317/317 [==============================] - 0s 976us/step - loss: 378.3200 - val_loss: 435.8462\n",
      "Epoch 861/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3223 - val_loss: 435.8358\n",
      "Epoch 862/1000\n",
      "317/317 [==============================] - 0s 940us/step - loss: 378.3222 - val_loss: 435.8444\n",
      "Epoch 863/1000\n",
      "317/317 [==============================] - 0s 944us/step - loss: 378.3207 - val_loss: 435.8459\n",
      "Epoch 864/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3209 - val_loss: 435.8394\n",
      "Epoch 865/1000\n",
      "317/317 [==============================] - 0s 980us/step - loss: 378.3208 - val_loss: 435.8399\n",
      "Epoch 866/1000\n",
      "317/317 [==============================] - 0s 968us/step - loss: 378.3207 - val_loss: 435.8416\n",
      "Epoch 867/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3203 - val_loss: 435.8387\n",
      "Epoch 868/1000\n",
      "317/317 [==============================] - 0s 1000us/step - loss: 378.3197 - val_loss: 435.8395\n",
      "Epoch 869/1000\n",
      "317/317 [==============================] - 0s 942us/step - loss: 378.3208 - val_loss: 435.8386\n",
      "Epoch 870/1000\n",
      "317/317 [==============================] - 0s 937us/step - loss: 378.3205 - val_loss: 435.8373\n",
      "Epoch 871/1000\n",
      "317/317 [==============================] - 0s 983us/step - loss: 378.3204 - val_loss: 435.8394\n",
      "Epoch 872/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3201 - val_loss: 435.8429\n",
      "Epoch 873/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3221 - val_loss: 435.8372\n",
      "Epoch 874/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3220 - val_loss: 435.8351\n",
      "Epoch 875/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3202 - val_loss: 435.8426\n",
      "Epoch 876/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3205 - val_loss: 435.8434\n",
      "Epoch 877/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3212 - val_loss: 435.8411\n",
      "Epoch 878/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3224 - val_loss: 435.8389\n",
      "Epoch 879/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3210 - val_loss: 435.8384\n",
      "Epoch 880/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3210 - val_loss: 435.8365\n",
      "Epoch 881/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3196 - val_loss: 435.8333\n",
      "Epoch 882/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3199 - val_loss: 435.8313\n",
      "Epoch 883/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3211 - val_loss: 435.8358\n",
      "Epoch 884/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3235 - val_loss: 435.8411\n",
      "Epoch 885/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3202 - val_loss: 435.8297\n",
      "Epoch 886/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3208 - val_loss: 435.8241\n",
      "Epoch 887/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3243 - val_loss: 435.8374\n",
      "Epoch 888/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3204 - val_loss: 435.8299\n",
      "Epoch 889/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3208 - val_loss: 435.8367\n",
      "Epoch 890/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3216 - val_loss: 435.8322\n",
      "Epoch 891/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3224 - val_loss: 435.8282\n",
      "Epoch 892/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8361\n",
      "Epoch 893/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8350\n",
      "Epoch 894/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3209 - val_loss: 435.8345\n",
      "Epoch 895/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3192 - val_loss: 435.8338\n",
      "Epoch 896/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8357\n",
      "Epoch 897/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3209 - val_loss: 435.8310\n",
      "Epoch 898/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3195 - val_loss: 435.8279\n",
      "Epoch 899/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3198 - val_loss: 435.8319\n",
      "Epoch 900/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8374\n",
      "Epoch 901/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8388\n",
      "Epoch 902/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8394\n",
      "Epoch 903/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3223 - val_loss: 435.8315\n",
      "Epoch 904/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8273\n",
      "Epoch 905/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3209 - val_loss: 435.8327\n",
      "Epoch 906/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3215 - val_loss: 435.8303\n",
      "Epoch 907/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8384\n",
      "Epoch 908/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8346\n",
      "Epoch 909/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8347\n",
      "Epoch 910/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3212 - val_loss: 435.8305\n",
      "Epoch 911/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8347\n",
      "Epoch 912/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8322\n",
      "Epoch 913/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8440\n",
      "Epoch 914/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8345\n",
      "Epoch 915/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3223 - val_loss: 435.8460\n",
      "Epoch 916/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8407\n",
      "Epoch 917/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3204 - val_loss: 435.8412\n",
      "Epoch 918/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3195 - val_loss: 435.8417\n",
      "Epoch 919/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3213 - val_loss: 435.8422\n",
      "Epoch 920/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8396\n",
      "Epoch 921/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8430\n",
      "Epoch 922/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8362\n",
      "Epoch 923/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8351\n",
      "Epoch 924/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8365\n",
      "Epoch 925/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8343\n",
      "Epoch 926/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3215 - val_loss: 435.8390\n",
      "Epoch 927/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8345\n",
      "Epoch 928/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3207 - val_loss: 435.8351\n",
      "Epoch 929/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3224 - val_loss: 435.8375\n",
      "Epoch 930/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8466\n",
      "Epoch 931/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8438\n",
      "Epoch 932/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3224 - val_loss: 435.8387\n",
      "Epoch 933/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8455\n",
      "Epoch 934/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8517\n",
      "Epoch 935/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3217 - val_loss: 435.8424\n",
      "Epoch 936/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8459\n",
      "Epoch 937/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3198 - val_loss: 435.8446\n",
      "Epoch 938/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3204 - val_loss: 435.8358\n",
      "Epoch 939/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8394\n",
      "Epoch 940/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8387\n",
      "Epoch 941/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8449\n",
      "Epoch 942/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3200 - val_loss: 435.8390\n",
      "Epoch 943/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8354\n",
      "Epoch 944/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3200 - val_loss: 435.8377\n",
      "Epoch 945/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8430\n",
      "Epoch 946/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8366\n",
      "Epoch 947/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3204 - val_loss: 435.8414\n",
      "Epoch 948/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8373\n",
      "Epoch 949/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8438\n",
      "Epoch 950/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8437\n",
      "Epoch 951/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8374\n",
      "Epoch 952/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8469\n",
      "Epoch 953/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3215 - val_loss: 435.8397\n",
      "Epoch 954/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3204 - val_loss: 435.8344\n",
      "Epoch 955/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3209 - val_loss: 435.8306\n",
      "Epoch 956/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3212 - val_loss: 435.8364\n",
      "Epoch 957/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3198 - val_loss: 435.8352\n",
      "Epoch 958/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3210 - val_loss: 435.8438\n",
      "Epoch 959/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8401\n",
      "Epoch 960/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3199 - val_loss: 435.8328\n",
      "Epoch 961/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3223 - val_loss: 435.8325\n",
      "Epoch 962/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8343\n",
      "Epoch 963/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3207 - val_loss: 435.8311\n",
      "Epoch 964/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3197 - val_loss: 435.8286\n",
      "Epoch 965/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3204 - val_loss: 435.8316\n",
      "Epoch 966/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8268\n",
      "Epoch 967/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8316\n",
      "Epoch 968/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3205 - val_loss: 435.8353\n",
      "Epoch 969/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3197 - val_loss: 435.8311\n",
      "Epoch 970/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8257\n",
      "Epoch 971/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3208 - val_loss: 435.8326\n",
      "Epoch 972/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8296\n",
      "Epoch 973/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3207 - val_loss: 435.8269\n",
      "Epoch 974/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3211 - val_loss: 435.8354\n",
      "Epoch 975/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3213 - val_loss: 435.8345\n",
      "Epoch 976/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3212 - val_loss: 435.8333\n",
      "Epoch 977/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3216 - val_loss: 435.8357\n",
      "Epoch 978/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3201 - val_loss: 435.8441\n",
      "Epoch 979/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3189 - val_loss: 435.8348\n",
      "Epoch 980/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3206 - val_loss: 435.8441\n",
      "Epoch 981/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3200 - val_loss: 435.8370\n",
      "Epoch 982/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3203 - val_loss: 435.8418\n",
      "Epoch 983/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3209 - val_loss: 435.8445\n",
      "Epoch 984/1000\n",
      "317/317 [==============================] - 1s 3ms/step - loss: 378.3202 - val_loss: 435.8403\n",
      "Epoch 985/1000\n",
      "317/317 [==============================] - 1s 2ms/step - loss: 378.3212 - val_loss: 435.8397\n",
      "Epoch 986/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3210 - val_loss: 435.8354\n",
      "Epoch 987/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3213 - val_loss: 435.8366\n",
      "Epoch 988/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3201 - val_loss: 435.8401\n",
      "Epoch 989/1000\n",
      "317/317 [==============================] - 0s 984us/step - loss: 378.3206 - val_loss: 435.8352\n",
      "Epoch 990/1000\n",
      "317/317 [==============================] - 0s 873us/step - loss: 378.3202 - val_loss: 435.8327\n",
      "Epoch 991/1000\n",
      "317/317 [==============================] - 0s 920us/step - loss: 378.3207 - val_loss: 435.8383\n",
      "Epoch 992/1000\n",
      "317/317 [==============================] - 0s 940us/step - loss: 378.3192 - val_loss: 435.8383\n",
      "Epoch 993/1000\n",
      "317/317 [==============================] - 0s 904us/step - loss: 378.3203 - val_loss: 435.8345\n",
      "Epoch 994/1000\n",
      "317/317 [==============================] - 0s 1ms/step - loss: 378.3204 - val_loss: 435.8321\n",
      "Epoch 995/1000\n",
      "317/317 [==============================] - 0s 930us/step - loss: 378.3212 - val_loss: 435.8353\n",
      "Epoch 996/1000\n",
      "317/317 [==============================] - 0s 921us/step - loss: 378.3216 - val_loss: 435.8311\n",
      "Epoch 997/1000\n",
      "317/317 [==============================] - 0s 977us/step - loss: 378.3203 - val_loss: 435.8340\n",
      "Epoch 998/1000\n",
      "317/317 [==============================] - 0s 876us/step - loss: 378.3210 - val_loss: 435.8318\n",
      "Epoch 999/1000\n",
      "317/317 [==============================] - 0s 904us/step - loss: 378.3226 - val_loss: 435.8358\n",
      "Epoch 1000/1000\n",
      "317/317 [==============================] - 0s 884us/step - loss: 378.3210 - val_loss: 435.8365\n",
      "32/32 [==============================] - 0s 708us/step\n",
      "1373039 successful\n",
      "Epoch 1/1000\n",
      "315/315 [==============================] - 1s 1ms/step - loss: 5045384.0000 - val_loss: 398.5045\n",
      "Epoch 2/1000\n",
      "315/315 [==============================] - 0s 905us/step - loss: 428.2056 - val_loss: 758.3890\n",
      "Epoch 3/1000\n",
      "315/315 [==============================] - 0s 866us/step - loss: 477.2142 - val_loss: 422.1881\n",
      "Epoch 4/1000\n",
      "315/315 [==============================] - 0s 989us/step - loss: 540.5500 - val_loss: 405.9538\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 990us/step - loss: 513.1887 - val_loss: 1067.0945\n",
      "Epoch 6/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 786.6070 - val_loss: 2947.7927\n",
      "Epoch 7/1000\n",
      "315/315 [==============================] - 0s 908us/step - loss: 973.2203 - val_loss: 507.9983\n",
      "Epoch 8/1000\n",
      "315/315 [==============================] - 0s 949us/step - loss: 1434.6854 - val_loss: 406.1918\n",
      "Epoch 9/1000\n",
      "315/315 [==============================] - 0s 964us/step - loss: 50879.6484 - val_loss: 113959.4531\n",
      "Epoch 10/1000\n",
      "315/315 [==============================] - 0s 965us/step - loss: 105226.6250 - val_loss: 2372.1270\n",
      "Epoch 11/1000\n",
      "315/315 [==============================] - 0s 950us/step - loss: 107663.7500 - val_loss: 8838.5117\n",
      "Epoch 12/1000\n",
      "315/315 [==============================] - 0s 995us/step - loss: 104269.0469 - val_loss: 17759.5918\n",
      "Epoch 13/1000\n",
      "315/315 [==============================] - 0s 942us/step - loss: 85669.7734 - val_loss: 80913.6484\n",
      "Epoch 14/1000\n",
      "315/315 [==============================] - 0s 904us/step - loss: 101403.9922 - val_loss: 894607.1875\n",
      "Epoch 15/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 85260.0000 - val_loss: 59415.0156\n",
      "Epoch 16/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 116160.3281 - val_loss: 70968.3438\n",
      "Epoch 17/1000\n",
      "315/315 [==============================] - 0s 950us/step - loss: 66835.8125 - val_loss: 204162.1250\n",
      "Epoch 18/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 89320.0781 - val_loss: 44019.9531\n",
      "Epoch 19/1000\n",
      "315/315 [==============================] - 0s 976us/step - loss: 79114.8438 - val_loss: 8847.1963\n",
      "Epoch 20/1000\n",
      "315/315 [==============================] - 0s 965us/step - loss: 81017.7344 - val_loss: 29290.8828\n",
      "Epoch 21/1000\n",
      "315/315 [==============================] - 0s 986us/step - loss: 82174.2578 - val_loss: 18499.2617\n",
      "Epoch 22/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 70360.6016 - val_loss: 401734.7812\n",
      "Epoch 23/1000\n",
      "315/315 [==============================] - 0s 983us/step - loss: 77391.6406 - val_loss: 1346.6575\n",
      "Epoch 24/1000\n",
      "315/315 [==============================] - 0s 965us/step - loss: 72498.5859 - val_loss: 79946.1719\n",
      "Epoch 25/1000\n",
      "315/315 [==============================] - 0s 990us/step - loss: 80573.7656 - val_loss: 5789.3574\n",
      "Epoch 26/1000\n",
      "315/315 [==============================] - 0s 963us/step - loss: 84178.4609 - val_loss: 659.4877\n",
      "Epoch 27/1000\n",
      "315/315 [==============================] - 0s 995us/step - loss: 47785.7109 - val_loss: 4836.4194\n",
      "Epoch 28/1000\n",
      "315/315 [==============================] - 0s 952us/step - loss: 1552440.7500 - val_loss: 2629.9648\n",
      "Epoch 29/1000\n",
      "315/315 [==============================] - 0s 951us/step - loss: 492.1009 - val_loss: 915.1207\n",
      "Epoch 30/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 539.6486 - val_loss: 396.2661\n",
      "Epoch 31/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 541.6241 - val_loss: 519.9490\n",
      "Epoch 32/1000\n",
      "315/315 [==============================] - 0s 978us/step - loss: 666.9645 - val_loss: 2305.5547\n",
      "Epoch 33/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 590.3695 - val_loss: 647.7144\n",
      "Epoch 34/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 1150.1638 - val_loss: 2757.8601\n",
      "Epoch 35/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 2212.5718 - val_loss: 395.2062\n",
      "Epoch 36/1000\n",
      "315/315 [==============================] - 0s 974us/step - loss: 38212.6523 - val_loss: 12157.1055\n",
      "Epoch 37/1000\n",
      "315/315 [==============================] - 0s 998us/step - loss: 47136.8984 - val_loss: 553.5573\n",
      "Epoch 38/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 47578.6797 - val_loss: 48740.5508\n",
      "Epoch 39/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 53806.5234 - val_loss: 167057.9844\n",
      "Epoch 40/1000\n",
      "315/315 [==============================] - 0s 936us/step - loss: 23453.2129 - val_loss: 7807.9355\n",
      "Epoch 41/1000\n",
      "315/315 [==============================] - 0s 902us/step - loss: 34469.0977 - val_loss: 3142.1938\n",
      "Epoch 42/1000\n",
      "315/315 [==============================] - 0s 937us/step - loss: 53274.7539 - val_loss: 6768.8325\n",
      "Epoch 43/1000\n",
      "315/315 [==============================] - 0s 948us/step - loss: 21321.8535 - val_loss: 58186.8359\n",
      "Epoch 44/1000\n",
      "315/315 [==============================] - 0s 848us/step - loss: 38610.7383 - val_loss: 78846.7266\n",
      "Epoch 45/1000\n",
      "315/315 [==============================] - 0s 883us/step - loss: 32692.2207 - val_loss: 35038.7930\n",
      "Epoch 46/1000\n",
      "315/315 [==============================] - 0s 843us/step - loss: 32296.3672 - val_loss: 109412.3750\n",
      "Epoch 47/1000\n",
      "315/315 [==============================] - 0s 850us/step - loss: 39516.2578 - val_loss: 599.1315\n",
      "Epoch 48/1000\n",
      "315/315 [==============================] - 0s 877us/step - loss: 31180.0254 - val_loss: 374288.4062\n",
      "Epoch 49/1000\n",
      "315/315 [==============================] - 0s 881us/step - loss: 30027.6855 - val_loss: 5936.7520\n",
      "Epoch 50/1000\n",
      "315/315 [==============================] - 0s 893us/step - loss: 31079.0215 - val_loss: 521.9577\n",
      "Epoch 51/1000\n",
      "315/315 [==============================] - 0s 837us/step - loss: 35362.6133 - val_loss: 5185.0166\n",
      "Epoch 52/1000\n",
      "315/315 [==============================] - 0s 962us/step - loss: 28443.5645 - val_loss: 828.9270\n",
      "Epoch 53/1000\n",
      "315/315 [==============================] - 0s 826us/step - loss: 30120.5137 - val_loss: 81018.6797\n",
      "Epoch 54/1000\n",
      "315/315 [==============================] - 0s 911us/step - loss: 27184.9883 - val_loss: 15717.0596\n",
      "Epoch 55/1000\n",
      "315/315 [==============================] - 0s 874us/step - loss: 27411.1289 - val_loss: 94650.3672\n",
      "Epoch 56/1000\n",
      "315/315 [==============================] - 0s 858us/step - loss: 28071.3047 - val_loss: 589.0385\n",
      "Epoch 57/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 28676.7344 - val_loss: 8797.9814\n",
      "Epoch 58/1000\n",
      "315/315 [==============================] - 0s 855us/step - loss: 20855.0547 - val_loss: 21621.7148\n",
      "Epoch 59/1000\n",
      "315/315 [==============================] - 0s 928us/step - loss: 26710.3965 - val_loss: 2287.7339\n",
      "Epoch 60/1000\n",
      "315/315 [==============================] - 0s 908us/step - loss: 24461.7402 - val_loss: 85819.1172\n",
      "Epoch 61/1000\n",
      "315/315 [==============================] - 0s 832us/step - loss: 24623.0430 - val_loss: 1199.7672\n",
      "Epoch 62/1000\n",
      "315/315 [==============================] - 0s 851us/step - loss: 24598.8496 - val_loss: 681.9489\n",
      "Epoch 63/1000\n",
      "315/315 [==============================] - 0s 888us/step - loss: 20680.6074 - val_loss: 4037.4338\n",
      "Epoch 64/1000\n",
      "315/315 [==============================] - 0s 926us/step - loss: 22304.2441 - val_loss: 19568.0430\n",
      "Epoch 65/1000\n",
      "315/315 [==============================] - 0s 835us/step - loss: 23188.3613 - val_loss: 131542.9375\n",
      "Epoch 66/1000\n",
      "315/315 [==============================] - 0s 837us/step - loss: 17525.3770 - val_loss: 1956.4692\n",
      "Epoch 67/1000\n",
      "315/315 [==============================] - 0s 846us/step - loss: 23109.7910 - val_loss: 19055.2949\n",
      "Epoch 68/1000\n",
      "315/315 [==============================] - 0s 921us/step - loss: 16281.3594 - val_loss: 48418.6289\n",
      "Epoch 69/1000\n",
      "315/315 [==============================] - 0s 859us/step - loss: 18756.9414 - val_loss: 34914.6914\n",
      "Epoch 70/1000\n",
      "315/315 [==============================] - 0s 868us/step - loss: 17717.8691 - val_loss: 1919.7988\n",
      "Epoch 71/1000\n",
      "315/315 [==============================] - 0s 897us/step - loss: 18758.7520 - val_loss: 9733.8809\n",
      "Epoch 72/1000\n",
      "315/315 [==============================] - 0s 893us/step - loss: 18096.4336 - val_loss: 3123.8496\n",
      "Epoch 73/1000\n",
      "315/315 [==============================] - 0s 871us/step - loss: 15938.7949 - val_loss: 13003.2930\n",
      "Epoch 74/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 16540.9961 - val_loss: 413.4703\n",
      "Epoch 75/1000\n",
      "315/315 [==============================] - 0s 923us/step - loss: 17277.8066 - val_loss: 36553.9766\n",
      "Epoch 76/1000\n",
      "315/315 [==============================] - 0s 955us/step - loss: 21061.0215 - val_loss: 8659.8906\n",
      "Epoch 77/1000\n",
      "315/315 [==============================] - 0s 876us/step - loss: 15471.9189 - val_loss: 4279.1895\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 866us/step - loss: 18084.2812 - val_loss: 474.4780\n",
      "Epoch 79/1000\n",
      "315/315 [==============================] - 0s 817us/step - loss: 11893.7266 - val_loss: 2379.6140\n",
      "Epoch 80/1000\n",
      "315/315 [==============================] - 0s 850us/step - loss: 17127.3906 - val_loss: 829.2710\n",
      "Epoch 81/1000\n",
      "315/315 [==============================] - 0s 849us/step - loss: 14200.1885 - val_loss: 3007.5918\n",
      "Epoch 82/1000\n",
      "315/315 [==============================] - 0s 892us/step - loss: 14995.8604 - val_loss: 15347.5566\n",
      "Epoch 83/1000\n",
      "315/315 [==============================] - 0s 802us/step - loss: 13581.2480 - val_loss: 48931.7539\n",
      "Epoch 84/1000\n",
      "315/315 [==============================] - 0s 956us/step - loss: 562982.3125 - val_loss: 393.4130\n",
      "Epoch 85/1000\n",
      "315/315 [==============================] - 0s 912us/step - loss: 527.3558 - val_loss: 420.9507\n",
      "Epoch 86/1000\n",
      "315/315 [==============================] - 0s 820us/step - loss: 571.2345 - val_loss: 401.8927\n",
      "Epoch 87/1000\n",
      "315/315 [==============================] - 0s 866us/step - loss: 661.0952 - val_loss: 415.0341\n",
      "Epoch 88/1000\n",
      "315/315 [==============================] - 0s 910us/step - loss: 750.1308 - val_loss: 2661.5144\n",
      "Epoch 89/1000\n",
      "315/315 [==============================] - 0s 824us/step - loss: 1186.1515 - val_loss: 7654.7666\n",
      "Epoch 90/1000\n",
      "315/315 [==============================] - 0s 936us/step - loss: 3084.5500 - val_loss: 32722.8535\n",
      "Epoch 91/1000\n",
      "315/315 [==============================] - 0s 878us/step - loss: 5460.2969 - val_loss: 2589.4565\n",
      "Epoch 92/1000\n",
      "315/315 [==============================] - 0s 867us/step - loss: 8113.4707 - val_loss: 4707.1104\n",
      "Epoch 93/1000\n",
      "315/315 [==============================] - 0s 873us/step - loss: 11391.5459 - val_loss: 1986.6217\n",
      "Epoch 94/1000\n",
      "315/315 [==============================] - 0s 812us/step - loss: 10688.2979 - val_loss: 393.9862\n",
      "Epoch 95/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 12194.2783 - val_loss: 446.3840\n",
      "Epoch 96/1000\n",
      "315/315 [==============================] - 0s 864us/step - loss: 12763.5410 - val_loss: 58225.4805\n",
      "Epoch 97/1000\n",
      "315/315 [==============================] - 0s 889us/step - loss: 11347.8398 - val_loss: 49241.1797\n",
      "Epoch 98/1000\n",
      "315/315 [==============================] - 0s 919us/step - loss: 12262.8281 - val_loss: 4094.8452\n",
      "Epoch 99/1000\n",
      "315/315 [==============================] - 0s 874us/step - loss: 11820.5967 - val_loss: 1697.1176\n",
      "Epoch 100/1000\n",
      "315/315 [==============================] - 0s 858us/step - loss: 11545.4678 - val_loss: 12192.9043\n",
      "Epoch 101/1000\n",
      "315/315 [==============================] - 0s 796us/step - loss: 9949.4805 - val_loss: 2692.0967\n",
      "Epoch 102/1000\n",
      "315/315 [==============================] - 0s 951us/step - loss: 10570.4951 - val_loss: 41599.8203\n",
      "Epoch 103/1000\n",
      "315/315 [==============================] - 0s 844us/step - loss: 12783.8779 - val_loss: 444.8523\n",
      "Epoch 104/1000\n",
      "315/315 [==============================] - 0s 976us/step - loss: 9458.1660 - val_loss: 592.8388\n",
      "Epoch 105/1000\n",
      "315/315 [==============================] - 0s 860us/step - loss: 10092.5264 - val_loss: 1869.5898\n",
      "Epoch 106/1000\n",
      "315/315 [==============================] - 0s 877us/step - loss: 12667.2539 - val_loss: 1606.6041\n",
      "Epoch 107/1000\n",
      "315/315 [==============================] - 0s 898us/step - loss: 8039.8232 - val_loss: 399.2639\n",
      "Epoch 108/1000\n",
      "315/315 [==============================] - 0s 917us/step - loss: 10259.0361 - val_loss: 17513.2207\n",
      "Epoch 109/1000\n",
      "315/315 [==============================] - 0s 832us/step - loss: 8677.1221 - val_loss: 36619.8359\n",
      "Epoch 110/1000\n",
      "315/315 [==============================] - 0s 860us/step - loss: 10185.2588 - val_loss: 15326.7275\n",
      "Epoch 111/1000\n",
      "315/315 [==============================] - 0s 913us/step - loss: 9216.0947 - val_loss: 4145.5000\n",
      "Epoch 112/1000\n",
      "315/315 [==============================] - 0s 881us/step - loss: 8901.0781 - val_loss: 4809.6558\n",
      "Epoch 113/1000\n",
      "315/315 [==============================] - 0s 824us/step - loss: 9191.9072 - val_loss: 1974.5095\n",
      "Epoch 114/1000\n",
      "315/315 [==============================] - 0s 927us/step - loss: 7975.2637 - val_loss: 26726.2832\n",
      "Epoch 115/1000\n",
      "315/315 [==============================] - 0s 890us/step - loss: 9299.4775 - val_loss: 1933.0352\n",
      "Epoch 116/1000\n",
      "315/315 [==============================] - 0s 959us/step - loss: 9659.0068 - val_loss: 1683.3546\n",
      "Epoch 117/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 7395.9399 - val_loss: 511.0367\n",
      "Epoch 118/1000\n",
      "315/315 [==============================] - 0s 907us/step - loss: 7729.1953 - val_loss: 11380.9932\n",
      "Epoch 119/1000\n",
      "315/315 [==============================] - 0s 919us/step - loss: 7780.0337 - val_loss: 18579.6289\n",
      "Epoch 120/1000\n",
      "315/315 [==============================] - 0s 828us/step - loss: 7774.3872 - val_loss: 56281.1680\n",
      "Epoch 121/1000\n",
      "315/315 [==============================] - 0s 821us/step - loss: 7739.3906 - val_loss: 858.0563\n",
      "Epoch 122/1000\n",
      "315/315 [==============================] - 0s 990us/step - loss: 7876.8340 - val_loss: 4049.4824\n",
      "Epoch 123/1000\n",
      "315/315 [==============================] - 0s 857us/step - loss: 7366.3442 - val_loss: 528.4798\n",
      "Epoch 124/1000\n",
      "315/315 [==============================] - 0s 868us/step - loss: 7133.0669 - val_loss: 4705.2881\n",
      "Epoch 125/1000\n",
      "315/315 [==============================] - 0s 979us/step - loss: 7548.4595 - val_loss: 14766.6621\n",
      "Epoch 126/1000\n",
      "315/315 [==============================] - 0s 850us/step - loss: 7568.4961 - val_loss: 568.5240\n",
      "Epoch 127/1000\n",
      "315/315 [==============================] - 0s 860us/step - loss: 6316.8774 - val_loss: 12064.3896\n",
      "Epoch 128/1000\n",
      "315/315 [==============================] - 0s 818us/step - loss: 6031.3672 - val_loss: 2152.0393\n",
      "Epoch 129/1000\n",
      "315/315 [==============================] - 0s 846us/step - loss: 6915.2886 - val_loss: 2958.9753\n",
      "Epoch 130/1000\n",
      "315/315 [==============================] - 0s 909us/step - loss: 7137.7988 - val_loss: 11100.3545\n",
      "Epoch 131/1000\n",
      "315/315 [==============================] - 0s 832us/step - loss: 5855.0884 - val_loss: 1350.1550\n",
      "Epoch 132/1000\n",
      "315/315 [==============================] - 0s 853us/step - loss: 6310.1650 - val_loss: 1400.3667\n",
      "Epoch 133/1000\n",
      "315/315 [==============================] - 0s 884us/step - loss: 6943.5649 - val_loss: 3444.4041\n",
      "Epoch 134/1000\n",
      "315/315 [==============================] - 0s 859us/step - loss: 5899.6045 - val_loss: 1732.9396\n",
      "Epoch 135/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 74819.8750 - val_loss: 745780.4375\n",
      "Epoch 136/1000\n",
      "315/315 [==============================] - 0s 951us/step - loss: 16206.2021 - val_loss: 419.6857\n",
      "Epoch 137/1000\n",
      "315/315 [==============================] - 0s 896us/step - loss: 533.4969 - val_loss: 393.6226\n",
      "Epoch 138/1000\n",
      "315/315 [==============================] - 0s 902us/step - loss: 654.3651 - val_loss: 794.3799\n",
      "Epoch 139/1000\n",
      "315/315 [==============================] - 0s 910us/step - loss: 658.0338 - val_loss: 399.1434\n",
      "Epoch 140/1000\n",
      "315/315 [==============================] - 0s 866us/step - loss: 944.9902 - val_loss: 501.3541\n",
      "Epoch 141/1000\n",
      "315/315 [==============================] - 0s 875us/step - loss: 1714.0715 - val_loss: 3286.1055\n",
      "Epoch 142/1000\n",
      "315/315 [==============================] - 0s 899us/step - loss: 3126.9451 - val_loss: 4079.9932\n",
      "Epoch 143/1000\n",
      "315/315 [==============================] - 0s 866us/step - loss: 4462.6821 - val_loss: 3447.5742\n",
      "Epoch 144/1000\n",
      "315/315 [==============================] - 0s 895us/step - loss: 5247.6738 - val_loss: 10454.6406\n",
      "Epoch 145/1000\n",
      "315/315 [==============================] - 0s 834us/step - loss: 4865.4370 - val_loss: 705.7764\n",
      "Epoch 146/1000\n",
      "315/315 [==============================] - 0s 964us/step - loss: 4261.5771 - val_loss: 1870.4054\n",
      "Epoch 147/1000\n",
      "315/315 [==============================] - 0s 807us/step - loss: 4832.8848 - val_loss: 437.6528\n",
      "Epoch 148/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 4943.3242 - val_loss: 2935.4329\n",
      "Epoch 149/1000\n",
      "315/315 [==============================] - 0s 821us/step - loss: 3921.8403 - val_loss: 9112.6768\n",
      "Epoch 150/1000\n",
      "315/315 [==============================] - 0s 904us/step - loss: 4346.8354 - val_loss: 1150.0280\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 877us/step - loss: 3525.3040 - val_loss: 3162.2842\n",
      "Epoch 152/1000\n",
      "315/315 [==============================] - 0s 885us/step - loss: 4536.9175 - val_loss: 611.0144\n",
      "Epoch 153/1000\n",
      "315/315 [==============================] - 0s 842us/step - loss: 4341.2979 - val_loss: 14448.0332\n",
      "Epoch 154/1000\n",
      "315/315 [==============================] - 0s 860us/step - loss: 3645.2407 - val_loss: 1326.8376\n",
      "Epoch 155/1000\n",
      "315/315 [==============================] - 0s 992us/step - loss: 3125.6833 - val_loss: 1336.4196\n",
      "Epoch 156/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 4492.1274 - val_loss: 401.0735\n",
      "Epoch 157/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 4107.3140 - val_loss: 5868.8843\n",
      "Epoch 158/1000\n",
      "315/315 [==============================] - 0s 987us/step - loss: 2609.9824 - val_loss: 596.0478\n",
      "Epoch 159/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 4090.1807 - val_loss: 452.9393\n",
      "Epoch 160/1000\n",
      "315/315 [==============================] - 0s 944us/step - loss: 4070.4189 - val_loss: 4200.0864\n",
      "Epoch 161/1000\n",
      "315/315 [==============================] - 0s 995us/step - loss: 2906.0349 - val_loss: 589.6261\n",
      "Epoch 162/1000\n",
      "315/315 [==============================] - 0s 990us/step - loss: 3043.5632 - val_loss: 2830.2390\n",
      "Epoch 163/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 4199.8291 - val_loss: 3757.3228\n",
      "Epoch 164/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 2948.7639 - val_loss: 1652.5504\n",
      "Epoch 165/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 3278.6951 - val_loss: 532.7512\n",
      "Epoch 166/1000\n",
      "315/315 [==============================] - 0s 915us/step - loss: 5018.1357 - val_loss: 1224.0148\n",
      "Epoch 167/1000\n",
      "315/315 [==============================] - 0s 970us/step - loss: 2532.2021 - val_loss: 783.4327\n",
      "Epoch 168/1000\n",
      "315/315 [==============================] - 0s 986us/step - loss: 2777.8562 - val_loss: 407.0449\n",
      "Epoch 169/1000\n",
      "315/315 [==============================] - 0s 966us/step - loss: 3139.2229 - val_loss: 13649.6064\n",
      "Epoch 170/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 3168.8826 - val_loss: 473.3621\n",
      "Epoch 171/1000\n",
      "315/315 [==============================] - 0s 978us/step - loss: 3076.7605 - val_loss: 1248.9141\n",
      "Epoch 172/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 3151.3955 - val_loss: 1108.1747\n",
      "Epoch 173/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 2619.7017 - val_loss: 9032.3564\n",
      "Epoch 174/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 2945.5667 - val_loss: 441.5298\n",
      "Epoch 175/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 2677.1255 - val_loss: 1206.3168\n",
      "Epoch 176/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 2900.0271 - val_loss: 2746.5044\n",
      "Epoch 177/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 2558.2849 - val_loss: 3998.0183\n",
      "Epoch 178/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 3178.7886 - val_loss: 4612.8701\n",
      "Epoch 179/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2081.8254 - val_loss: 4075.0422\n",
      "Epoch 180/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2556.1260 - val_loss: 461.9946\n",
      "Epoch 181/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 3342.1895 - val_loss: 1104.5688\n",
      "Epoch 182/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2404.5789 - val_loss: 1620.8638\n",
      "Epoch 183/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1944.4873 - val_loss: 1585.8932\n",
      "Epoch 184/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2263.2463 - val_loss: 873.9772\n",
      "Epoch 185/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2310.7283 - val_loss: 402.8056\n",
      "Epoch 186/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2321.9253 - val_loss: 552.3987\n",
      "Epoch 187/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2387.7312 - val_loss: 1065.1399\n",
      "Epoch 188/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2044.0535 - val_loss: 1398.6742\n",
      "Epoch 189/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1903.9911 - val_loss: 1983.4487\n",
      "Epoch 190/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 3699.3169 - val_loss: 614.5457\n",
      "Epoch 191/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1211.4464 - val_loss: 441.9484\n",
      "Epoch 192/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2262.7332 - val_loss: 5171.4941\n",
      "Epoch 193/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1971.6357 - val_loss: 5439.3052\n",
      "Epoch 194/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1856.0986 - val_loss: 785.4680\n",
      "Epoch 195/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1752.1082 - val_loss: 3701.4832\n",
      "Epoch 196/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2001.1301 - val_loss: 459.6642\n",
      "Epoch 197/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 1696.4829 - val_loss: 678.7244\n",
      "Epoch 198/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1464.4938 - val_loss: 4451.5376\n",
      "Epoch 199/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2325.7378 - val_loss: 1136.9623\n",
      "Epoch 200/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1689.2174 - val_loss: 3467.5945\n",
      "Epoch 201/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1399.1187 - val_loss: 785.2427\n",
      "Epoch 202/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 1903.0435 - val_loss: 395.9224\n",
      "Epoch 203/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1663.8539 - val_loss: 11377.2617\n",
      "Epoch 204/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1626.6614 - val_loss: 2526.9883\n",
      "Epoch 205/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1680.3434 - val_loss: 437.0916\n",
      "Epoch 206/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1719.8113 - val_loss: 1075.7159\n",
      "Epoch 207/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2124.3206 - val_loss: 5194.0039\n",
      "Epoch 208/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1786.8943 - val_loss: 3204.3105\n",
      "Epoch 209/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1502.1487 - val_loss: 6336.9746\n",
      "Epoch 210/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1769.7473 - val_loss: 682.9314\n",
      "Epoch 211/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1132.2347 - val_loss: 2525.2471\n",
      "Epoch 212/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1524.2212 - val_loss: 1509.1027\n",
      "Epoch 213/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1165.5117 - val_loss: 475.2976\n",
      "Epoch 214/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1521.9750 - val_loss: 1638.0688\n",
      "Epoch 215/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1568.5590 - val_loss: 3819.6140\n",
      "Epoch 216/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1454.4691 - val_loss: 2434.1047\n",
      "Epoch 217/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1364.3885 - val_loss: 2633.7468\n",
      "Epoch 218/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1377.7612 - val_loss: 658.7407\n",
      "Epoch 219/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2044.8196 - val_loss: 493.6775\n",
      "Epoch 220/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 998.0062 - val_loss: 488.3522\n",
      "Epoch 221/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1303.6914 - val_loss: 1083.4858\n",
      "Epoch 222/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1041.5015 - val_loss: 397.1662\n",
      "Epoch 223/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1531.7817 - val_loss: 1705.2047\n",
      "Epoch 224/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1397.9237 - val_loss: 2146.4988\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 1s 3ms/step - loss: 1230.5125 - val_loss: 3210.1582\n",
      "Epoch 226/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1219.6827 - val_loss: 2546.3127\n",
      "Epoch 227/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 1286.8422 - val_loss: 425.8863\n",
      "Epoch 228/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1536.6472 - val_loss: 4495.0332\n",
      "Epoch 229/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1175.4930 - val_loss: 780.6700\n",
      "Epoch 230/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1324.9949 - val_loss: 1292.7616\n",
      "Epoch 231/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1322.3568 - val_loss: 447.8643\n",
      "Epoch 232/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1307.0865 - val_loss: 1755.4620\n",
      "Epoch 233/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1283.9438 - val_loss: 2099.1550\n",
      "Epoch 234/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1137.2052 - val_loss: 393.5183\n",
      "Epoch 235/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1110.7859 - val_loss: 410.8526\n",
      "Epoch 236/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1102.2303 - val_loss: 3440.5527\n",
      "Epoch 237/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1172.5814 - val_loss: 414.5609\n",
      "Epoch 238/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1311.3717 - val_loss: 3645.6301\n",
      "Epoch 239/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1192.3131 - val_loss: 1467.8497\n",
      "Epoch 240/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1028.4138 - val_loss: 444.4554\n",
      "Epoch 241/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1019.7307 - val_loss: 491.6588\n",
      "Epoch 242/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1649.7701 - val_loss: 556.6356\n",
      "Epoch 243/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 930.5084 - val_loss: 2072.4531\n",
      "Epoch 244/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 986.6104 - val_loss: 443.9195\n",
      "Epoch 245/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1182.1587 - val_loss: 1436.8569\n",
      "Epoch 246/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 954.9321 - val_loss: 634.9268\n",
      "Epoch 247/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1060.5444 - val_loss: 6770.4517\n",
      "Epoch 248/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1118.7196 - val_loss: 1364.9417\n",
      "Epoch 249/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1076.2809 - val_loss: 1014.7335\n",
      "Epoch 250/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1132.4625 - val_loss: 802.7246\n",
      "Epoch 251/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 892.9048 - val_loss: 444.4396\n",
      "Epoch 252/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 875.9733 - val_loss: 395.4788\n",
      "Epoch 253/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1269.3036 - val_loss: 430.3558\n",
      "Epoch 254/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 953.7133 - val_loss: 884.4800\n",
      "Epoch 255/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1067.0603 - val_loss: 730.7870\n",
      "Epoch 256/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1000.3550 - val_loss: 981.6625\n",
      "Epoch 257/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 878.0213 - val_loss: 860.3977\n",
      "Epoch 258/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 1022.7728 - val_loss: 593.1654\n",
      "Epoch 259/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 859.4355 - val_loss: 553.0069\n",
      "Epoch 260/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 938.7380 - val_loss: 4250.3862\n",
      "Epoch 261/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 788.4526 - val_loss: 404.4498\n",
      "Epoch 262/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 993.2773 - val_loss: 785.8852\n",
      "Epoch 263/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 989.7822 - val_loss: 564.7976\n",
      "Epoch 264/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 983.3635 - val_loss: 537.8402\n",
      "Epoch 265/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 807.5712 - val_loss: 415.1778\n",
      "Epoch 266/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 19312.4512 - val_loss: 417.0209\n",
      "Epoch 267/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 431.5055 - val_loss: 748.3280\n",
      "Epoch 268/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 461.4292 - val_loss: 404.1133\n",
      "Epoch 269/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 476.4571 - val_loss: 477.0051\n",
      "Epoch 270/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 483.1561 - val_loss: 413.9039\n",
      "Epoch 271/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 554.6946 - val_loss: 538.0928\n",
      "Epoch 272/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 606.3131 - val_loss: 3499.8762\n",
      "Epoch 273/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 567.7238 - val_loss: 1428.0464\n",
      "Epoch 274/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 608.5283 - val_loss: 399.6676\n",
      "Epoch 275/1000\n",
      "315/315 [==============================] - 0s 974us/step - loss: 679.9505 - val_loss: 513.3845\n",
      "Epoch 276/1000\n",
      "315/315 [==============================] - 0s 929us/step - loss: 735.8340 - val_loss: 983.9209\n",
      "Epoch 277/1000\n",
      "315/315 [==============================] - 0s 836us/step - loss: 833.7371 - val_loss: 393.4777\n",
      "Epoch 278/1000\n",
      "315/315 [==============================] - 0s 977us/step - loss: 683.9532 - val_loss: 723.0677\n",
      "Epoch 279/1000\n",
      "315/315 [==============================] - 0s 922us/step - loss: 728.3193 - val_loss: 2948.5132\n",
      "Epoch 280/1000\n",
      "315/315 [==============================] - 0s 942us/step - loss: 814.7755 - val_loss: 512.9034\n",
      "Epoch 281/1000\n",
      "315/315 [==============================] - 0s 976us/step - loss: 655.9431 - val_loss: 1155.6282\n",
      "Epoch 282/1000\n",
      "315/315 [==============================] - 0s 940us/step - loss: 643.0365 - val_loss: 1762.1992\n",
      "Epoch 283/1000\n",
      "315/315 [==============================] - 0s 942us/step - loss: 701.3271 - val_loss: 522.9168\n",
      "Epoch 284/1000\n",
      "315/315 [==============================] - 0s 950us/step - loss: 784.0253 - val_loss: 410.8992\n",
      "Epoch 285/1000\n",
      "315/315 [==============================] - 0s 939us/step - loss: 785.2952 - val_loss: 712.0723\n",
      "Epoch 286/1000\n",
      "315/315 [==============================] - 0s 950us/step - loss: 589.9850 - val_loss: 407.0586\n",
      "Epoch 287/1000\n",
      "315/315 [==============================] - 0s 926us/step - loss: 717.6852 - val_loss: 592.7990\n",
      "Epoch 288/1000\n",
      "315/315 [==============================] - 0s 982us/step - loss: 605.9231 - val_loss: 1024.6362\n",
      "Epoch 289/1000\n",
      "315/315 [==============================] - 0s 898us/step - loss: 591.0276 - val_loss: 411.8358\n",
      "Epoch 290/1000\n",
      "315/315 [==============================] - 0s 987us/step - loss: 565.8868 - val_loss: 581.8364\n",
      "Epoch 291/1000\n",
      "315/315 [==============================] - 0s 1000us/step - loss: 652.6942 - val_loss: 1315.0204\n",
      "Epoch 292/1000\n",
      "315/315 [==============================] - 0s 943us/step - loss: 713.4736 - val_loss: 804.2725\n",
      "Epoch 293/1000\n",
      "315/315 [==============================] - 0s 987us/step - loss: 654.5865 - val_loss: 500.3398\n",
      "Epoch 294/1000\n",
      "315/315 [==============================] - 0s 932us/step - loss: 9706.7793 - val_loss: 421.0403\n",
      "Epoch 295/1000\n",
      "315/315 [==============================] - 0s 919us/step - loss: 535.7585 - val_loss: 539.4039\n",
      "Epoch 296/1000\n",
      "315/315 [==============================] - 0s 938us/step - loss: 489.8590 - val_loss: 453.6235\n",
      "Epoch 297/1000\n",
      "315/315 [==============================] - 0s 993us/step - loss: 494.8499 - val_loss: 708.2699\n",
      "Epoch 298/1000\n",
      "315/315 [==============================] - 0s 909us/step - loss: 580.4023 - val_loss: 524.3286\n",
      "Epoch 299/1000\n",
      "315/315 [==============================] - 0s 970us/step - loss: 638.9546 - val_loss: 393.4596\n",
      "Epoch 300/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 907us/step - loss: 634.7653 - val_loss: 571.2924\n",
      "Epoch 301/1000\n",
      "315/315 [==============================] - 0s 941us/step - loss: 572.9700 - val_loss: 488.3302\n",
      "Epoch 302/1000\n",
      "315/315 [==============================] - 0s 946us/step - loss: 670.1643 - val_loss: 1272.9343\n",
      "Epoch 303/1000\n",
      "315/315 [==============================] - 0s 915us/step - loss: 789.8677 - val_loss: 446.5876\n",
      "Epoch 304/1000\n",
      "315/315 [==============================] - 0s 929us/step - loss: 562.1409 - val_loss: 752.0630\n",
      "Epoch 305/1000\n",
      "315/315 [==============================] - 0s 989us/step - loss: 673.0942 - val_loss: 1003.4179\n",
      "Epoch 306/1000\n",
      "315/315 [==============================] - 0s 927us/step - loss: 629.4363 - val_loss: 403.9626\n",
      "Epoch 307/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 693.3701 - val_loss: 495.8746\n",
      "Epoch 308/1000\n",
      "315/315 [==============================] - 0s 940us/step - loss: 666.0259 - val_loss: 396.2191\n",
      "Epoch 309/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 598.3347 - val_loss: 1847.6019\n",
      "Epoch 310/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 614.8679 - val_loss: 1157.1588\n",
      "Epoch 311/1000\n",
      "315/315 [==============================] - 0s 949us/step - loss: 670.2778 - val_loss: 525.5616\n",
      "Epoch 312/1000\n",
      "315/315 [==============================] - 0s 946us/step - loss: 639.8437 - val_loss: 1134.0793\n",
      "Epoch 313/1000\n",
      "315/315 [==============================] - 0s 991us/step - loss: 645.5018 - val_loss: 1077.6282\n",
      "Epoch 314/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 590.9865 - val_loss: 957.6144\n",
      "Epoch 315/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 699.9083 - val_loss: 807.8277\n",
      "Epoch 316/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 550.4943 - val_loss: 500.8186\n",
      "Epoch 317/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 609.1973 - val_loss: 687.1179\n",
      "Epoch 318/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 590.9408 - val_loss: 418.8486\n",
      "Epoch 319/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 595.8345 - val_loss: 516.9746\n",
      "Epoch 320/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 638.6143 - val_loss: 624.1163\n",
      "Epoch 321/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 624.6927 - val_loss: 1639.1544\n",
      "Epoch 322/1000\n",
      "315/315 [==============================] - 0s 969us/step - loss: 697.1917 - val_loss: 722.6503\n",
      "Epoch 323/1000\n",
      "315/315 [==============================] - 0s 931us/step - loss: 553.8128 - val_loss: 662.5641\n",
      "Epoch 324/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 531.0763 - val_loss: 602.6638\n",
      "Epoch 325/1000\n",
      "315/315 [==============================] - 0s 902us/step - loss: 570.4673 - val_loss: 639.3058\n",
      "Epoch 326/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 533.9833 - val_loss: 1631.1650\n",
      "Epoch 327/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 569.7902 - val_loss: 509.7892\n",
      "Epoch 328/1000\n",
      "315/315 [==============================] - 0s 972us/step - loss: 532.4285 - val_loss: 443.3056\n",
      "Epoch 329/1000\n",
      "315/315 [==============================] - 0s 929us/step - loss: 514.3011 - val_loss: 412.3488\n",
      "Epoch 330/1000\n",
      "315/315 [==============================] - 0s 934us/step - loss: 517.7174 - val_loss: 412.4030\n",
      "Epoch 331/1000\n",
      "315/315 [==============================] - 0s 907us/step - loss: 521.0298 - val_loss: 571.8378\n",
      "Epoch 332/1000\n",
      "315/315 [==============================] - 0s 978us/step - loss: 619.6119 - val_loss: 757.1548\n",
      "Epoch 333/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 471.2665 - val_loss: 525.4056\n",
      "Epoch 334/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 506.5327 - val_loss: 405.3341\n",
      "Epoch 335/1000\n",
      "315/315 [==============================] - 0s 933us/step - loss: 524.5858 - val_loss: 507.4673\n",
      "Epoch 336/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 494.7016 - val_loss: 1086.8939\n",
      "Epoch 337/1000\n",
      "315/315 [==============================] - 0s 931us/step - loss: 536.2321 - val_loss: 669.6314\n",
      "Epoch 338/1000\n",
      "315/315 [==============================] - 0s 913us/step - loss: 510.3176 - val_loss: 555.0363\n",
      "Epoch 339/1000\n",
      "315/315 [==============================] - 0s 900us/step - loss: 493.6032 - val_loss: 479.3169\n",
      "Epoch 340/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 513.9957 - val_loss: 565.4936\n",
      "Epoch 341/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 474.7197 - val_loss: 575.4625\n",
      "Epoch 342/1000\n",
      "315/315 [==============================] - 0s 917us/step - loss: 491.9337 - val_loss: 499.2990\n",
      "Epoch 343/1000\n",
      "315/315 [==============================] - 0s 930us/step - loss: 469.9522 - val_loss: 398.9024\n",
      "Epoch 344/1000\n",
      "315/315 [==============================] - 0s 935us/step - loss: 450.9706 - val_loss: 467.3538\n",
      "Epoch 345/1000\n",
      "315/315 [==============================] - 0s 897us/step - loss: 465.5175 - val_loss: 393.4314\n",
      "Epoch 346/1000\n",
      "315/315 [==============================] - 0s 882us/step - loss: 1349.9304 - val_loss: 393.4203\n",
      "Epoch 347/1000\n",
      "315/315 [==============================] - 0s 934us/step - loss: 408.9953 - val_loss: 468.6254\n",
      "Epoch 348/1000\n",
      "315/315 [==============================] - 0s 880us/step - loss: 404.8765 - val_loss: 394.8274\n",
      "Epoch 349/1000\n",
      "315/315 [==============================] - 0s 919us/step - loss: 396.9876 - val_loss: 421.5046\n",
      "Epoch 350/1000\n",
      "315/315 [==============================] - 0s 928us/step - loss: 394.7117 - val_loss: 449.1518\n",
      "Epoch 351/1000\n",
      "315/315 [==============================] - 0s 965us/step - loss: 397.6208 - val_loss: 396.4907\n",
      "Epoch 352/1000\n",
      "315/315 [==============================] - 0s 949us/step - loss: 397.0160 - val_loss: 394.3359\n",
      "Epoch 353/1000\n",
      "315/315 [==============================] - 0s 905us/step - loss: 391.1562 - val_loss: 408.5311\n",
      "Epoch 354/1000\n",
      "315/315 [==============================] - 0s 916us/step - loss: 389.3832 - val_loss: 396.4914\n",
      "Epoch 355/1000\n",
      "315/315 [==============================] - 0s 910us/step - loss: 384.1435 - val_loss: 393.7638\n",
      "Epoch 356/1000\n",
      "315/315 [==============================] - 0s 887us/step - loss: 385.4568 - val_loss: 400.8625\n",
      "Epoch 357/1000\n",
      "315/315 [==============================] - 0s 944us/step - loss: 382.4524 - val_loss: 394.1354\n",
      "Epoch 358/1000\n",
      "315/315 [==============================] - 0s 900us/step - loss: 384.9481 - val_loss: 394.4568\n",
      "Epoch 359/1000\n",
      "315/315 [==============================] - 0s 926us/step - loss: 383.0053 - val_loss: 410.0831\n",
      "Epoch 360/1000\n",
      "315/315 [==============================] - 0s 990us/step - loss: 382.8876 - val_loss: 393.5362\n",
      "Epoch 361/1000\n",
      "315/315 [==============================] - 0s 969us/step - loss: 386.1658 - val_loss: 442.4438\n",
      "Epoch 362/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 386.2802 - val_loss: 400.4476\n",
      "Epoch 363/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 385.1459 - val_loss: 393.3803\n",
      "Epoch 364/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 386.3676 - val_loss: 397.6227\n",
      "Epoch 365/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 385.1283 - val_loss: 396.2455\n",
      "Epoch 366/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 390.7737 - val_loss: 396.4495\n",
      "Epoch 367/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 384.3032 - val_loss: 405.1506\n",
      "Epoch 368/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 385.4061 - val_loss: 399.4825\n",
      "Epoch 369/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 386.1724 - val_loss: 409.5255\n",
      "Epoch 370/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 385.8880 - val_loss: 408.7629\n",
      "Epoch 371/1000\n",
      "315/315 [==============================] - 0s 979us/step - loss: 390.5921 - val_loss: 397.8753\n",
      "Epoch 372/1000\n",
      "315/315 [==============================] - 0s 981us/step - loss: 389.8583 - val_loss: 393.4218\n",
      "Epoch 373/1000\n",
      "315/315 [==============================] - 0s 905us/step - loss: 391.2314 - val_loss: 404.6592\n",
      "Epoch 374/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 385.8478 - val_loss: 406.6192\n",
      "Epoch 375/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 1ms/step - loss: 396.5405 - val_loss: 518.7675\n",
      "Epoch 376/1000\n",
      "315/315 [==============================] - 0s 919us/step - loss: 391.1079 - val_loss: 416.3689\n",
      "Epoch 377/1000\n",
      "315/315 [==============================] - 0s 878us/step - loss: 389.2722 - val_loss: 416.8693\n",
      "Epoch 378/1000\n",
      "315/315 [==============================] - 0s 970us/step - loss: 384.7782 - val_loss: 432.1366\n",
      "Epoch 379/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 385.7590 - val_loss: 412.5230\n",
      "Epoch 380/1000\n",
      "315/315 [==============================] - 0s 868us/step - loss: 390.6540 - val_loss: 393.5431\n",
      "Epoch 381/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 391.5308 - val_loss: 397.0362\n",
      "Epoch 382/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 391.0921 - val_loss: 401.9549\n",
      "Epoch 383/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 387.8734 - val_loss: 410.7504\n",
      "Epoch 384/1000\n",
      "315/315 [==============================] - 0s 976us/step - loss: 391.9529 - val_loss: 395.7404\n",
      "Epoch 385/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 1277.5570 - val_loss: 563.3448\n",
      "Epoch 386/1000\n",
      "315/315 [==============================] - 0s 922us/step - loss: 431.2527 - val_loss: 393.5032\n",
      "Epoch 387/1000\n",
      "315/315 [==============================] - 0s 867us/step - loss: 388.6018 - val_loss: 394.1009\n",
      "Epoch 388/1000\n",
      "315/315 [==============================] - 0s 999us/step - loss: 385.8130 - val_loss: 420.1723\n",
      "Epoch 389/1000\n",
      "315/315 [==============================] - 0s 950us/step - loss: 385.5882 - val_loss: 395.1052\n",
      "Epoch 390/1000\n",
      "315/315 [==============================] - 0s 932us/step - loss: 384.0982 - val_loss: 412.5734\n",
      "Epoch 391/1000\n",
      "315/315 [==============================] - 0s 877us/step - loss: 382.9654 - val_loss: 398.7854\n",
      "Epoch 392/1000\n",
      "315/315 [==============================] - 0s 882us/step - loss: 387.6118 - val_loss: 417.5119\n",
      "Epoch 393/1000\n",
      "315/315 [==============================] - 0s 883us/step - loss: 387.7932 - val_loss: 397.4421\n",
      "Epoch 394/1000\n",
      "315/315 [==============================] - 0s 995us/step - loss: 386.9993 - val_loss: 393.5558\n",
      "Epoch 395/1000\n",
      "315/315 [==============================] - 0s 973us/step - loss: 386.2516 - val_loss: 395.2554\n",
      "Epoch 396/1000\n",
      "315/315 [==============================] - 0s 912us/step - loss: 385.5438 - val_loss: 404.2627\n",
      "Epoch 397/1000\n",
      "315/315 [==============================] - 0s 991us/step - loss: 386.9105 - val_loss: 393.3893\n",
      "Epoch 398/1000\n",
      "315/315 [==============================] - 0s 932us/step - loss: 384.6417 - val_loss: 401.1516\n",
      "Epoch 399/1000\n",
      "315/315 [==============================] - 0s 895us/step - loss: 391.8421 - val_loss: 394.3271\n",
      "Epoch 400/1000\n",
      "315/315 [==============================] - 0s 967us/step - loss: 384.6973 - val_loss: 394.5106\n",
      "Epoch 401/1000\n",
      "315/315 [==============================] - 0s 951us/step - loss: 384.1792 - val_loss: 400.0516\n",
      "Epoch 402/1000\n",
      "315/315 [==============================] - 0s 939us/step - loss: 387.4346 - val_loss: 417.0203\n",
      "Epoch 403/1000\n",
      "315/315 [==============================] - 0s 966us/step - loss: 385.3650 - val_loss: 394.7887\n",
      "Epoch 404/1000\n",
      "315/315 [==============================] - 0s 983us/step - loss: 385.4458 - val_loss: 404.4398\n",
      "Epoch 405/1000\n",
      "315/315 [==============================] - 0s 903us/step - loss: 384.1845 - val_loss: 395.9760\n",
      "Epoch 406/1000\n",
      "315/315 [==============================] - 0s 934us/step - loss: 389.5838 - val_loss: 395.6041\n",
      "Epoch 407/1000\n",
      "315/315 [==============================] - 0s 958us/step - loss: 393.4236 - val_loss: 393.4338\n",
      "Epoch 408/1000\n",
      "315/315 [==============================] - 0s 940us/step - loss: 385.9773 - val_loss: 398.7585\n",
      "Epoch 409/1000\n",
      "315/315 [==============================] - 0s 928us/step - loss: 387.3440 - val_loss: 398.3107\n",
      "Epoch 410/1000\n",
      "315/315 [==============================] - 0s 965us/step - loss: 383.0645 - val_loss: 399.9077\n",
      "Epoch 411/1000\n",
      "315/315 [==============================] - 0s 896us/step - loss: 384.1674 - val_loss: 397.4561\n",
      "Epoch 412/1000\n",
      "315/315 [==============================] - 0s 909us/step - loss: 386.3563 - val_loss: 395.6601\n",
      "Epoch 413/1000\n",
      "315/315 [==============================] - 0s 999us/step - loss: 387.8055 - val_loss: 407.1812\n",
      "Epoch 414/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 387.6488 - val_loss: 393.5025\n",
      "Epoch 415/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 389.8387 - val_loss: 400.7498\n",
      "Epoch 416/1000\n",
      "315/315 [==============================] - 0s 924us/step - loss: 385.6538 - val_loss: 398.0363\n",
      "Epoch 417/1000\n",
      "315/315 [==============================] - 0s 835us/step - loss: 390.1459 - val_loss: 393.7739\n",
      "Epoch 418/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 389.3227 - val_loss: 396.0194\n",
      "Epoch 419/1000\n",
      "315/315 [==============================] - 0s 942us/step - loss: 388.1958 - val_loss: 397.2762\n",
      "Epoch 420/1000\n",
      "315/315 [==============================] - 0s 939us/step - loss: 389.4808 - val_loss: 396.9424\n",
      "Epoch 421/1000\n",
      "315/315 [==============================] - 0s 989us/step - loss: 387.8360 - val_loss: 393.7614\n",
      "Epoch 422/1000\n",
      "315/315 [==============================] - 0s 881us/step - loss: 386.2386 - val_loss: 416.1430\n",
      "Epoch 423/1000\n",
      "315/315 [==============================] - 0s 903us/step - loss: 387.9060 - val_loss: 397.4049\n",
      "Epoch 424/1000\n",
      "315/315 [==============================] - 0s 894us/step - loss: 389.1480 - val_loss: 417.1133\n",
      "Epoch 425/1000\n",
      "315/315 [==============================] - 0s 852us/step - loss: 390.0389 - val_loss: 445.6234\n",
      "Epoch 426/1000\n",
      "315/315 [==============================] - 0s 954us/step - loss: 386.8961 - val_loss: 394.3925\n",
      "Epoch 427/1000\n",
      "315/315 [==============================] - 0s 916us/step - loss: 388.6015 - val_loss: 394.0310\n",
      "Epoch 428/1000\n",
      "315/315 [==============================] - 0s 958us/step - loss: 388.9831 - val_loss: 419.0096\n",
      "Epoch 429/1000\n",
      "315/315 [==============================] - 0s 969us/step - loss: 385.8353 - val_loss: 393.4065\n",
      "Epoch 430/1000\n",
      "315/315 [==============================] - 0s 940us/step - loss: 389.0228 - val_loss: 400.3755\n",
      "Epoch 431/1000\n",
      "315/315 [==============================] - 0s 959us/step - loss: 390.1834 - val_loss: 414.7409\n",
      "Epoch 432/1000\n",
      "315/315 [==============================] - 0s 916us/step - loss: 386.3803 - val_loss: 400.3270\n",
      "Epoch 433/1000\n",
      "315/315 [==============================] - 0s 951us/step - loss: 389.7951 - val_loss: 398.4528\n",
      "Epoch 434/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 385.9569 - val_loss: 409.2525\n",
      "Epoch 435/1000\n",
      "315/315 [==============================] - 0s 906us/step - loss: 387.5956 - val_loss: 416.2761\n",
      "Epoch 436/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 390.7702 - val_loss: 424.1978\n",
      "Epoch 437/1000\n",
      "315/315 [==============================] - 0s 906us/step - loss: 389.4521 - val_loss: 393.8766\n",
      "Epoch 438/1000\n",
      "315/315 [==============================] - 0s 998us/step - loss: 390.6609 - val_loss: 413.7151\n",
      "Epoch 439/1000\n",
      "315/315 [==============================] - 0s 885us/step - loss: 385.6714 - val_loss: 396.9199\n",
      "Epoch 440/1000\n",
      "315/315 [==============================] - 0s 924us/step - loss: 383.7415 - val_loss: 396.0144\n",
      "Epoch 441/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 386.0919 - val_loss: 396.3063\n",
      "Epoch 442/1000\n",
      "315/315 [==============================] - 0s 967us/step - loss: 389.2622 - val_loss: 396.4916\n",
      "Epoch 443/1000\n",
      "315/315 [==============================] - 0s 962us/step - loss: 385.7830 - val_loss: 394.3848\n",
      "Epoch 444/1000\n",
      "315/315 [==============================] - 0s 983us/step - loss: 386.2167 - val_loss: 395.4883\n",
      "Epoch 445/1000\n",
      "315/315 [==============================] - 0s 910us/step - loss: 384.6173 - val_loss: 393.4400\n",
      "Epoch 446/1000\n",
      "315/315 [==============================] - 0s 913us/step - loss: 384.8458 - val_loss: 397.6716\n",
      "Epoch 447/1000\n",
      "315/315 [==============================] - 0s 989us/step - loss: 384.9484 - val_loss: 423.4121\n",
      "Epoch 448/1000\n",
      "315/315 [==============================] - 0s 969us/step - loss: 390.1125 - val_loss: 395.7655\n",
      "Epoch 449/1000\n",
      "315/315 [==============================] - 0s 934us/step - loss: 388.3327 - val_loss: 393.4514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 386.8805 - val_loss: 404.9673\n",
      "Epoch 451/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 386.5965 - val_loss: 394.6565\n",
      "Epoch 452/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 387.0682 - val_loss: 417.1263\n",
      "Epoch 453/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 386.6234 - val_loss: 394.0780\n",
      "Epoch 454/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 386.6365 - val_loss: 394.0679\n",
      "Epoch 455/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 385.3859 - val_loss: 398.5240\n",
      "Epoch 456/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 385.6158 - val_loss: 450.0956\n",
      "Epoch 457/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 385.9958 - val_loss: 408.7771\n",
      "Epoch 458/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 391.6836 - val_loss: 417.1969\n",
      "Epoch 459/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 388.3193 - val_loss: 393.3881\n",
      "Epoch 460/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 383.1775 - val_loss: 393.4940\n",
      "Epoch 461/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 384.2238 - val_loss: 399.6388\n",
      "Epoch 462/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 386.8747 - val_loss: 400.5876\n",
      "Epoch 463/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 386.1942 - val_loss: 404.3644\n",
      "Epoch 464/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 385.2934 - val_loss: 396.5481\n",
      "Epoch 465/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.8441 - val_loss: 403.2209\n",
      "Epoch 466/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.6751 - val_loss: 447.0090\n",
      "Epoch 467/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 386.3673 - val_loss: 399.0849\n",
      "Epoch 468/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 386.5210 - val_loss: 393.5804\n",
      "Epoch 469/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.9420 - val_loss: 404.7956\n",
      "Epoch 470/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 388.7411 - val_loss: 405.9803\n",
      "Epoch 471/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 384.2281 - val_loss: 401.2294\n",
      "Epoch 472/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.6866 - val_loss: 393.9956\n",
      "Epoch 473/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 410.1285 - val_loss: 406.7164\n",
      "Epoch 474/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.2590 - val_loss: 395.4445\n",
      "Epoch 475/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 384.3407 - val_loss: 395.4077\n",
      "Epoch 476/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.8227 - val_loss: 393.6351\n",
      "Epoch 477/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 382.0212 - val_loss: 395.5785\n",
      "Epoch 478/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 383.8998 - val_loss: 396.3832\n",
      "Epoch 479/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.6979 - val_loss: 395.6788\n",
      "Epoch 480/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.4147 - val_loss: 393.4072\n",
      "Epoch 481/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.5284 - val_loss: 403.3805\n",
      "Epoch 482/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.0057 - val_loss: 398.6678\n",
      "Epoch 483/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.4019 - val_loss: 393.6532\n",
      "Epoch 484/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.1039 - val_loss: 406.4216\n",
      "Epoch 485/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.6207 - val_loss: 401.5405\n",
      "Epoch 486/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 386.5458 - val_loss: 396.1655\n",
      "Epoch 487/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.3070 - val_loss: 394.7322\n",
      "Epoch 488/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.2200 - val_loss: 394.7367\n",
      "Epoch 489/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 382.7583 - val_loss: 393.6059\n",
      "Epoch 490/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 382.3615 - val_loss: 396.1940\n",
      "Epoch 491/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.6387 - val_loss: 411.1856\n",
      "Epoch 492/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.3599 - val_loss: 395.6324\n",
      "Epoch 493/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 382.0853 - val_loss: 393.4914\n",
      "Epoch 494/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.9690 - val_loss: 396.9022\n",
      "Epoch 495/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 384.4044 - val_loss: 395.2701\n",
      "Epoch 496/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.1782 - val_loss: 401.6745\n",
      "Epoch 497/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 385.3315 - val_loss: 395.8256\n",
      "Epoch 498/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 387.9920 - val_loss: 394.1619\n",
      "Epoch 499/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 382.4098 - val_loss: 393.4111\n",
      "Epoch 500/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.9806 - val_loss: 399.6592\n",
      "Epoch 501/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.4561 - val_loss: 395.7580\n",
      "Epoch 502/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 385.1589 - val_loss: 393.4839\n",
      "Epoch 503/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 382.5521 - val_loss: 393.5948\n",
      "Epoch 504/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.6644 - val_loss: 406.1568\n",
      "Epoch 505/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.1650 - val_loss: 393.4913\n",
      "Epoch 506/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.0127 - val_loss: 395.3293\n",
      "Epoch 507/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.0992 - val_loss: 402.5800\n",
      "Epoch 508/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 385.0627 - val_loss: 396.6492\n",
      "Epoch 509/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 385.2549 - val_loss: 409.4246\n",
      "Epoch 510/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 383.4660 - val_loss: 393.5996\n",
      "Epoch 511/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 384.2922 - val_loss: 393.3834\n",
      "Epoch 512/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.4393 - val_loss: 395.9289\n",
      "Epoch 513/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.4590 - val_loss: 400.1943\n",
      "Epoch 514/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 383.8415 - val_loss: 397.5847\n",
      "Epoch 515/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.9648 - val_loss: 405.1106\n",
      "Epoch 516/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 384.5773 - val_loss: 394.1964\n",
      "Epoch 517/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.2663 - val_loss: 396.1149\n",
      "Epoch 518/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.1988 - val_loss: 393.5769\n",
      "Epoch 519/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 383.9628 - val_loss: 393.6072\n",
      "Epoch 520/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 384.7113 - val_loss: 419.1420\n",
      "Epoch 521/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.5977 - val_loss: 398.8444\n",
      "Epoch 522/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.3567 - val_loss: 396.9622\n",
      "Epoch 523/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.9015 - val_loss: 393.4757\n",
      "Epoch 524/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.7714 - val_loss: 393.3976\n",
      "Epoch 525/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.0522 - val_loss: 394.3968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 526/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.1573 - val_loss: 404.9045\n",
      "Epoch 527/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.7614 - val_loss: 406.0268\n",
      "Epoch 528/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.0018 - val_loss: 394.7710\n",
      "Epoch 529/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.1143 - val_loss: 398.1942\n",
      "Epoch 530/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.9766 - val_loss: 396.7770\n",
      "Epoch 531/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.8483 - val_loss: 393.7268\n",
      "Epoch 532/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 382.0032 - val_loss: 396.6223\n",
      "Epoch 533/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.6605 - val_loss: 393.9634\n",
      "Epoch 534/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.0265 - val_loss: 393.7975\n",
      "Epoch 535/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.6509 - val_loss: 395.2514\n",
      "Epoch 536/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.8785 - val_loss: 393.5078\n",
      "Epoch 537/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.3181 - val_loss: 395.8198\n",
      "Epoch 538/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.0649 - val_loss: 394.7598\n",
      "Epoch 539/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.7599 - val_loss: 396.6369\n",
      "Epoch 540/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.1890 - val_loss: 396.8588\n",
      "Epoch 541/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.0352 - val_loss: 393.5919\n",
      "Epoch 542/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.5883 - val_loss: 393.8072\n",
      "Epoch 543/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 542.8248 - val_loss: 479.2819\n",
      "Epoch 544/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 395.5551 - val_loss: 436.5735\n",
      "Epoch 545/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 389.0620 - val_loss: 402.1378\n",
      "Epoch 546/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 386.4078 - val_loss: 400.1271\n",
      "Epoch 547/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 399.0388 - val_loss: 394.4442\n",
      "Epoch 548/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 391.0915 - val_loss: 400.2807\n",
      "Epoch 549/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 390.6415 - val_loss: 395.0850\n",
      "Epoch 550/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 385.6148 - val_loss: 394.2879\n",
      "Epoch 551/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 386.6454 - val_loss: 393.4140\n",
      "Epoch 552/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.0734 - val_loss: 393.4591\n",
      "Epoch 553/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.3570 - val_loss: 393.4375\n",
      "Epoch 554/1000\n",
      "315/315 [==============================] - 0s 991us/step - loss: 382.9534 - val_loss: 396.2444\n",
      "Epoch 555/1000\n",
      "315/315 [==============================] - 0s 885us/step - loss: 386.9694 - val_loss: 419.1216\n",
      "Epoch 556/1000\n",
      "315/315 [==============================] - 0s 854us/step - loss: 390.3397 - val_loss: 415.1485\n",
      "Epoch 557/1000\n",
      "315/315 [==============================] - 0s 939us/step - loss: 390.6339 - val_loss: 396.5365\n",
      "Epoch 558/1000\n",
      "315/315 [==============================] - 0s 930us/step - loss: 386.1659 - val_loss: 404.5254\n",
      "Epoch 559/1000\n",
      "315/315 [==============================] - 0s 970us/step - loss: 390.0392 - val_loss: 404.3312\n",
      "Epoch 560/1000\n",
      "315/315 [==============================] - 0s 845us/step - loss: 387.4062 - val_loss: 414.3336\n",
      "Epoch 561/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 385.4773 - val_loss: 395.8743\n",
      "Epoch 562/1000\n",
      "315/315 [==============================] - 0s 940us/step - loss: 384.4018 - val_loss: 411.3221\n",
      "Epoch 563/1000\n",
      "315/315 [==============================] - 0s 967us/step - loss: 385.5802 - val_loss: 394.7744\n",
      "Epoch 564/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 387.6561 - val_loss: 395.7475\n",
      "Epoch 565/1000\n",
      "315/315 [==============================] - 0s 950us/step - loss: 389.3790 - val_loss: 405.9845\n",
      "Epoch 566/1000\n",
      "315/315 [==============================] - 0s 939us/step - loss: 385.4016 - val_loss: 399.3556\n",
      "Epoch 567/1000\n",
      "315/315 [==============================] - 0s 886us/step - loss: 384.6812 - val_loss: 420.0133\n",
      "Epoch 568/1000\n",
      "315/315 [==============================] - 0s 878us/step - loss: 387.6758 - val_loss: 394.1806\n",
      "Epoch 569/1000\n",
      "315/315 [==============================] - 0s 891us/step - loss: 386.2971 - val_loss: 405.0451\n",
      "Epoch 570/1000\n",
      "315/315 [==============================] - 0s 982us/step - loss: 386.0992 - val_loss: 404.1384\n",
      "Epoch 571/1000\n",
      "315/315 [==============================] - 0s 877us/step - loss: 386.5212 - val_loss: 394.5563\n",
      "Epoch 572/1000\n",
      "315/315 [==============================] - 0s 846us/step - loss: 386.9011 - val_loss: 405.9539\n",
      "Epoch 573/1000\n",
      "315/315 [==============================] - 0s 837us/step - loss: 385.9623 - val_loss: 396.9277\n",
      "Epoch 574/1000\n",
      "315/315 [==============================] - 0s 859us/step - loss: 386.1481 - val_loss: 419.0924\n",
      "Epoch 575/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 388.8997 - val_loss: 414.4617\n",
      "Epoch 576/1000\n",
      "315/315 [==============================] - 0s 937us/step - loss: 386.0983 - val_loss: 400.4624\n",
      "Epoch 577/1000\n",
      "315/315 [==============================] - 0s 841us/step - loss: 390.2636 - val_loss: 396.1619\n",
      "Epoch 578/1000\n",
      "315/315 [==============================] - 0s 924us/step - loss: 385.4828 - val_loss: 393.4195\n",
      "Epoch 579/1000\n",
      "315/315 [==============================] - 0s 851us/step - loss: 384.2340 - val_loss: 399.7352\n",
      "Epoch 580/1000\n",
      "315/315 [==============================] - 0s 877us/step - loss: 387.7240 - val_loss: 393.4351\n",
      "Epoch 581/1000\n",
      "315/315 [==============================] - 0s 908us/step - loss: 386.4734 - val_loss: 394.8127\n",
      "Epoch 582/1000\n",
      "315/315 [==============================] - 0s 888us/step - loss: 384.6270 - val_loss: 399.7863\n",
      "Epoch 583/1000\n",
      "315/315 [==============================] - 0s 867us/step - loss: 385.2625 - val_loss: 393.4177\n",
      "Epoch 584/1000\n",
      "315/315 [==============================] - 0s 831us/step - loss: 387.8036 - val_loss: 393.3848\n",
      "Epoch 585/1000\n",
      "315/315 [==============================] - 0s 885us/step - loss: 382.0810 - val_loss: 404.6456\n",
      "Epoch 586/1000\n",
      "315/315 [==============================] - 0s 897us/step - loss: 384.1070 - val_loss: 393.4204\n",
      "Epoch 587/1000\n",
      "315/315 [==============================] - 0s 977us/step - loss: 386.4322 - val_loss: 410.6574\n",
      "Epoch 588/1000\n",
      "315/315 [==============================] - 0s 904us/step - loss: 384.2087 - val_loss: 399.4292\n",
      "Epoch 589/1000\n",
      "315/315 [==============================] - 0s 815us/step - loss: 384.9892 - val_loss: 393.4336\n",
      "Epoch 590/1000\n",
      "315/315 [==============================] - 0s 870us/step - loss: 384.2817 - val_loss: 398.8996\n",
      "Epoch 591/1000\n",
      "315/315 [==============================] - 0s 879us/step - loss: 387.4172 - val_loss: 408.9832\n",
      "Epoch 592/1000\n",
      "315/315 [==============================] - 0s 804us/step - loss: 386.3758 - val_loss: 413.1261\n",
      "Epoch 593/1000\n",
      "315/315 [==============================] - 0s 889us/step - loss: 384.8144 - val_loss: 408.0834\n",
      "Epoch 594/1000\n",
      "315/315 [==============================] - 0s 853us/step - loss: 385.1503 - val_loss: 396.4919\n",
      "Epoch 595/1000\n",
      "315/315 [==============================] - 0s 876us/step - loss: 384.5663 - val_loss: 396.7652\n",
      "Epoch 596/1000\n",
      "315/315 [==============================] - 0s 922us/step - loss: 385.1661 - val_loss: 393.7462\n",
      "Epoch 597/1000\n",
      "315/315 [==============================] - 0s 839us/step - loss: 385.1456 - val_loss: 397.0425\n",
      "Epoch 598/1000\n",
      "315/315 [==============================] - 0s 837us/step - loss: 383.2069 - val_loss: 394.1850\n",
      "Epoch 599/1000\n",
      "315/315 [==============================] - 0s 993us/step - loss: 383.9023 - val_loss: 393.3846\n",
      "Epoch 600/1000\n",
      "315/315 [==============================] - 0s 886us/step - loss: 385.7351 - val_loss: 398.7105\n",
      "Epoch 601/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 937us/step - loss: 385.1696 - val_loss: 406.1687\n",
      "Epoch 602/1000\n",
      "315/315 [==============================] - 0s 830us/step - loss: 383.6846 - val_loss: 395.9317\n",
      "Epoch 603/1000\n",
      "315/315 [==============================] - 0s 896us/step - loss: 385.4760 - val_loss: 404.2721\n",
      "Epoch 604/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 383.1717 - val_loss: 396.3758\n",
      "Epoch 605/1000\n",
      "315/315 [==============================] - 0s 910us/step - loss: 381.5885 - val_loss: 405.8046\n",
      "Epoch 606/1000\n",
      "315/315 [==============================] - 0s 893us/step - loss: 383.0737 - val_loss: 393.7845\n",
      "Epoch 607/1000\n",
      "315/315 [==============================] - 0s 835us/step - loss: 384.3058 - val_loss: 395.5914\n",
      "Epoch 608/1000\n",
      "315/315 [==============================] - 0s 927us/step - loss: 386.7384 - val_loss: 394.8762\n",
      "Epoch 609/1000\n",
      "315/315 [==============================] - 0s 908us/step - loss: 382.5875 - val_loss: 400.0420\n",
      "Epoch 610/1000\n",
      "315/315 [==============================] - 0s 864us/step - loss: 386.1241 - val_loss: 393.7696\n",
      "Epoch 611/1000\n",
      "315/315 [==============================] - 0s 878us/step - loss: 383.5684 - val_loss: 393.4284\n",
      "Epoch 612/1000\n",
      "315/315 [==============================] - 0s 941us/step - loss: 382.8181 - val_loss: 404.6937\n",
      "Epoch 613/1000\n",
      "315/315 [==============================] - 0s 919us/step - loss: 383.9034 - val_loss: 396.7797\n",
      "Epoch 614/1000\n",
      "315/315 [==============================] - 0s 857us/step - loss: 382.1463 - val_loss: 395.0199\n",
      "Epoch 615/1000\n",
      "315/315 [==============================] - 0s 869us/step - loss: 384.2925 - val_loss: 402.1900\n",
      "Epoch 616/1000\n",
      "315/315 [==============================] - 0s 868us/step - loss: 382.1494 - val_loss: 396.1794\n",
      "Epoch 617/1000\n",
      "315/315 [==============================] - 0s 912us/step - loss: 382.9059 - val_loss: 393.6646\n",
      "Epoch 618/1000\n",
      "315/315 [==============================] - 0s 927us/step - loss: 384.7296 - val_loss: 416.7510\n",
      "Epoch 619/1000\n",
      "315/315 [==============================] - 0s 888us/step - loss: 382.2971 - val_loss: 393.9373\n",
      "Epoch 620/1000\n",
      "315/315 [==============================] - 0s 853us/step - loss: 383.2144 - val_loss: 393.6196\n",
      "Epoch 621/1000\n",
      "315/315 [==============================] - 0s 868us/step - loss: 381.0752 - val_loss: 393.8850\n",
      "Epoch 622/1000\n",
      "315/315 [==============================] - 0s 902us/step - loss: 384.0077 - val_loss: 397.3091\n",
      "Epoch 623/1000\n",
      "315/315 [==============================] - 0s 880us/step - loss: 383.5260 - val_loss: 398.6151\n",
      "Epoch 624/1000\n",
      "315/315 [==============================] - 0s 920us/step - loss: 383.2267 - val_loss: 393.4222\n",
      "Epoch 625/1000\n",
      "315/315 [==============================] - 0s 881us/step - loss: 381.4412 - val_loss: 398.2808\n",
      "Epoch 626/1000\n",
      "315/315 [==============================] - 0s 890us/step - loss: 382.0728 - val_loss: 396.1584\n",
      "Epoch 627/1000\n",
      "315/315 [==============================] - 0s 852us/step - loss: 380.4490 - val_loss: 396.1719\n",
      "Epoch 628/1000\n",
      "315/315 [==============================] - 0s 898us/step - loss: 381.9746 - val_loss: 421.8924\n",
      "Epoch 629/1000\n",
      "315/315 [==============================] - 0s 841us/step - loss: 381.7631 - val_loss: 393.8463\n",
      "Epoch 630/1000\n",
      "315/315 [==============================] - 0s 910us/step - loss: 380.1301 - val_loss: 416.0952\n",
      "Epoch 631/1000\n",
      "315/315 [==============================] - 0s 849us/step - loss: 382.2898 - val_loss: 393.4932\n",
      "Epoch 632/1000\n",
      "315/315 [==============================] - 0s 863us/step - loss: 380.4667 - val_loss: 398.3768\n",
      "Epoch 633/1000\n",
      "315/315 [==============================] - 0s 840us/step - loss: 380.6345 - val_loss: 393.8337\n",
      "Epoch 634/1000\n",
      "315/315 [==============================] - 0s 901us/step - loss: 380.7682 - val_loss: 393.6065\n",
      "Epoch 635/1000\n",
      "315/315 [==============================] - 0s 805us/step - loss: 380.1126 - val_loss: 396.6787\n",
      "Epoch 636/1000\n",
      "315/315 [==============================] - 0s 889us/step - loss: 380.2495 - val_loss: 393.4203\n",
      "Epoch 637/1000\n",
      "315/315 [==============================] - 0s 915us/step - loss: 380.2780 - val_loss: 393.6142\n",
      "Epoch 638/1000\n",
      "315/315 [==============================] - 0s 922us/step - loss: 379.2597 - val_loss: 394.5700\n",
      "Epoch 639/1000\n",
      "315/315 [==============================] - 0s 929us/step - loss: 381.8342 - val_loss: 400.9239\n",
      "Epoch 640/1000\n",
      "315/315 [==============================] - 0s 885us/step - loss: 380.6039 - val_loss: 393.5421\n",
      "Epoch 641/1000\n",
      "315/315 [==============================] - 0s 916us/step - loss: 381.0474 - val_loss: 395.8314\n",
      "Epoch 642/1000\n",
      "315/315 [==============================] - 0s 907us/step - loss: 381.1763 - val_loss: 394.9486\n",
      "Epoch 643/1000\n",
      "315/315 [==============================] - 0s 841us/step - loss: 381.0481 - val_loss: 394.3848\n",
      "Epoch 644/1000\n",
      "315/315 [==============================] - 0s 900us/step - loss: 380.6174 - val_loss: 393.6109\n",
      "Epoch 645/1000\n",
      "315/315 [==============================] - 0s 870us/step - loss: 380.0644 - val_loss: 395.8880\n",
      "Epoch 646/1000\n",
      "315/315 [==============================] - 0s 967us/step - loss: 380.2339 - val_loss: 400.3380\n",
      "Epoch 647/1000\n",
      "315/315 [==============================] - 0s 907us/step - loss: 381.7511 - val_loss: 393.5192\n",
      "Epoch 648/1000\n",
      "315/315 [==============================] - 0s 893us/step - loss: 380.2131 - val_loss: 395.0032\n",
      "Epoch 649/1000\n",
      "315/315 [==============================] - 0s 882us/step - loss: 381.3943 - val_loss: 396.1754\n",
      "Epoch 650/1000\n",
      "315/315 [==============================] - 0s 986us/step - loss: 381.8952 - val_loss: 397.6598\n",
      "Epoch 651/1000\n",
      "315/315 [==============================] - 0s 904us/step - loss: 381.7177 - val_loss: 394.7644\n",
      "Epoch 652/1000\n",
      "315/315 [==============================] - 0s 942us/step - loss: 381.1755 - val_loss: 398.6989\n",
      "Epoch 653/1000\n",
      "315/315 [==============================] - 0s 894us/step - loss: 381.1063 - val_loss: 393.5336\n",
      "Epoch 654/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.5695 - val_loss: 400.8208\n",
      "Epoch 655/1000\n",
      "315/315 [==============================] - 0s 990us/step - loss: 379.7110 - val_loss: 398.6996\n",
      "Epoch 656/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 381.0083 - val_loss: 397.5148\n",
      "Epoch 657/1000\n",
      "315/315 [==============================] - 0s 906us/step - loss: 380.3554 - val_loss: 394.6274\n",
      "Epoch 658/1000\n",
      "315/315 [==============================] - 0s 913us/step - loss: 380.1224 - val_loss: 401.1831\n",
      "Epoch 659/1000\n",
      "315/315 [==============================] - 0s 971us/step - loss: 380.8268 - val_loss: 393.3889\n",
      "Epoch 660/1000\n",
      "315/315 [==============================] - 0s 924us/step - loss: 379.0783 - val_loss: 393.5292\n",
      "Epoch 661/1000\n",
      "315/315 [==============================] - 0s 844us/step - loss: 381.8012 - val_loss: 393.6942\n",
      "Epoch 662/1000\n",
      "315/315 [==============================] - 0s 966us/step - loss: 380.6516 - val_loss: 399.3350\n",
      "Epoch 663/1000\n",
      "315/315 [==============================] - 0s 824us/step - loss: 380.4151 - val_loss: 393.4012\n",
      "Epoch 664/1000\n",
      "315/315 [==============================] - 0s 855us/step - loss: 381.6470 - val_loss: 393.6116\n",
      "Epoch 665/1000\n",
      "315/315 [==============================] - 0s 923us/step - loss: 383.3385 - val_loss: 400.6485\n",
      "Epoch 666/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.6148 - val_loss: 393.7680\n",
      "Epoch 667/1000\n",
      "315/315 [==============================] - 0s 888us/step - loss: 382.1393 - val_loss: 393.7202\n",
      "Epoch 668/1000\n",
      "315/315 [==============================] - 0s 925us/step - loss: 380.1650 - val_loss: 397.7890\n",
      "Epoch 669/1000\n",
      "315/315 [==============================] - 0s 921us/step - loss: 380.4660 - val_loss: 394.1425\n",
      "Epoch 670/1000\n",
      "315/315 [==============================] - 0s 897us/step - loss: 380.4336 - val_loss: 398.4821\n",
      "Epoch 671/1000\n",
      "315/315 [==============================] - 0s 869us/step - loss: 380.5970 - val_loss: 395.7178\n",
      "Epoch 672/1000\n",
      "315/315 [==============================] - 0s 894us/step - loss: 382.4455 - val_loss: 398.9005\n",
      "Epoch 673/1000\n",
      "315/315 [==============================] - 0s 977us/step - loss: 382.4622 - val_loss: 397.3790\n",
      "Epoch 674/1000\n",
      "315/315 [==============================] - 0s 861us/step - loss: 381.2817 - val_loss: 394.0000\n",
      "Epoch 675/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 833us/step - loss: 381.2236 - val_loss: 393.8194\n",
      "Epoch 676/1000\n",
      "315/315 [==============================] - 0s 962us/step - loss: 380.3279 - val_loss: 394.4823\n",
      "Epoch 677/1000\n",
      "315/315 [==============================] - 0s 914us/step - loss: 381.0431 - val_loss: 399.0356\n",
      "Epoch 678/1000\n",
      "315/315 [==============================] - 0s 949us/step - loss: 381.1055 - val_loss: 394.3323\n",
      "Epoch 679/1000\n",
      "315/315 [==============================] - 0s 873us/step - loss: 380.7079 - val_loss: 397.1339\n",
      "Epoch 680/1000\n",
      "315/315 [==============================] - 0s 925us/step - loss: 380.4555 - val_loss: 393.8281\n",
      "Epoch 681/1000\n",
      "315/315 [==============================] - 0s 903us/step - loss: 379.9278 - val_loss: 393.6232\n",
      "Epoch 682/1000\n",
      "315/315 [==============================] - 0s 855us/step - loss: 379.6437 - val_loss: 394.1960\n",
      "Epoch 683/1000\n",
      "315/315 [==============================] - 0s 862us/step - loss: 381.4026 - val_loss: 396.7133\n",
      "Epoch 684/1000\n",
      "315/315 [==============================] - 0s 915us/step - loss: 379.6826 - val_loss: 404.8502\n",
      "Epoch 685/1000\n",
      "315/315 [==============================] - 0s 880us/step - loss: 381.6749 - val_loss: 400.2662\n",
      "Epoch 686/1000\n",
      "315/315 [==============================] - 0s 863us/step - loss: 381.2301 - val_loss: 393.4162\n",
      "Epoch 687/1000\n",
      "315/315 [==============================] - 0s 944us/step - loss: 381.0074 - val_loss: 393.4182\n",
      "Epoch 688/1000\n",
      "315/315 [==============================] - 0s 912us/step - loss: 380.5721 - val_loss: 397.1995\n",
      "Epoch 689/1000\n",
      "315/315 [==============================] - 0s 873us/step - loss: 380.2841 - val_loss: 395.4326\n",
      "Epoch 690/1000\n",
      "315/315 [==============================] - 0s 892us/step - loss: 381.6104 - val_loss: 393.4334\n",
      "Epoch 691/1000\n",
      "315/315 [==============================] - 0s 958us/step - loss: 380.8048 - val_loss: 395.8642\n",
      "Epoch 692/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.1757 - val_loss: 393.9510\n",
      "Epoch 693/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.0062 - val_loss: 393.7998\n",
      "Epoch 694/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.6665 - val_loss: 394.6945\n",
      "Epoch 695/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.1575 - val_loss: 398.3544\n",
      "Epoch 696/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.1184 - val_loss: 395.0931\n",
      "Epoch 697/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.1142 - val_loss: 396.8235\n",
      "Epoch 698/1000\n",
      "315/315 [==============================] - 0s 902us/step - loss: 380.9897 - val_loss: 394.1959\n",
      "Epoch 699/1000\n",
      "315/315 [==============================] - 0s 945us/step - loss: 380.1842 - val_loss: 396.2353\n",
      "Epoch 700/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.9120 - val_loss: 394.2439\n",
      "Epoch 701/1000\n",
      "315/315 [==============================] - 0s 871us/step - loss: 380.0737 - val_loss: 396.3895\n",
      "Epoch 702/1000\n",
      "315/315 [==============================] - 0s 907us/step - loss: 380.1384 - val_loss: 393.9324\n",
      "Epoch 703/1000\n",
      "315/315 [==============================] - 0s 868us/step - loss: 380.5884 - val_loss: 402.6639\n",
      "Epoch 704/1000\n",
      "315/315 [==============================] - 0s 914us/step - loss: 379.9546 - val_loss: 393.5101\n",
      "Epoch 705/1000\n",
      "315/315 [==============================] - 0s 851us/step - loss: 381.2931 - val_loss: 394.9726\n",
      "Epoch 706/1000\n",
      "315/315 [==============================] - 0s 939us/step - loss: 381.1054 - val_loss: 393.8228\n",
      "Epoch 707/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 379.6230 - val_loss: 393.3873\n",
      "Epoch 708/1000\n",
      "315/315 [==============================] - 0s 875us/step - loss: 380.2870 - val_loss: 405.8571\n",
      "Epoch 709/1000\n",
      "315/315 [==============================] - 0s 967us/step - loss: 381.3645 - val_loss: 393.4898\n",
      "Epoch 710/1000\n",
      "315/315 [==============================] - 0s 981us/step - loss: 380.5924 - val_loss: 394.4238\n",
      "Epoch 711/1000\n",
      "315/315 [==============================] - 0s 849us/step - loss: 379.8291 - val_loss: 393.4018\n",
      "Epoch 712/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.3723 - val_loss: 402.3606\n",
      "Epoch 713/1000\n",
      "315/315 [==============================] - 0s 926us/step - loss: 380.4444 - val_loss: 399.4577\n",
      "Epoch 714/1000\n",
      "315/315 [==============================] - 0s 875us/step - loss: 380.5895 - val_loss: 393.8274\n",
      "Epoch 715/1000\n",
      "315/315 [==============================] - 0s 925us/step - loss: 379.7542 - val_loss: 395.5841\n",
      "Epoch 716/1000\n",
      "315/315 [==============================] - 0s 930us/step - loss: 379.3014 - val_loss: 396.3693\n",
      "Epoch 717/1000\n",
      "315/315 [==============================] - 0s 949us/step - loss: 380.8013 - val_loss: 399.8464\n",
      "Epoch 718/1000\n",
      "315/315 [==============================] - 0s 938us/step - loss: 381.9259 - val_loss: 395.6123\n",
      "Epoch 719/1000\n",
      "315/315 [==============================] - 0s 923us/step - loss: 380.8774 - val_loss: 395.9607\n",
      "Epoch 720/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.0455 - val_loss: 394.7554\n",
      "Epoch 721/1000\n",
      "315/315 [==============================] - 0s 868us/step - loss: 380.9322 - val_loss: 418.5904\n",
      "Epoch 722/1000\n",
      "315/315 [==============================] - 0s 905us/step - loss: 380.9502 - val_loss: 394.1555\n",
      "Epoch 723/1000\n",
      "315/315 [==============================] - 0s 872us/step - loss: 382.0681 - val_loss: 394.3854\n",
      "Epoch 724/1000\n",
      "315/315 [==============================] - 0s 898us/step - loss: 380.2202 - val_loss: 393.8955\n",
      "Epoch 725/1000\n",
      "315/315 [==============================] - 0s 914us/step - loss: 381.4579 - val_loss: 394.9911\n",
      "Epoch 726/1000\n",
      "315/315 [==============================] - 0s 924us/step - loss: 380.4425 - val_loss: 419.8670\n",
      "Epoch 727/1000\n",
      "315/315 [==============================] - 0s 868us/step - loss: 380.1644 - val_loss: 396.5642\n",
      "Epoch 728/1000\n",
      "315/315 [==============================] - 0s 910us/step - loss: 380.1761 - val_loss: 395.7020\n",
      "Epoch 729/1000\n",
      "315/315 [==============================] - 0s 813us/step - loss: 380.0845 - val_loss: 394.8389\n",
      "Epoch 730/1000\n",
      "315/315 [==============================] - 0s 885us/step - loss: 379.4540 - val_loss: 395.9333\n",
      "Epoch 731/1000\n",
      "315/315 [==============================] - 0s 830us/step - loss: 381.1594 - val_loss: 393.3860\n",
      "Epoch 732/1000\n",
      "315/315 [==============================] - 0s 984us/step - loss: 380.9505 - val_loss: 393.3941\n",
      "Epoch 733/1000\n",
      "315/315 [==============================] - 0s 839us/step - loss: 379.4454 - val_loss: 398.4815\n",
      "Epoch 734/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 380.8503 - val_loss: 393.5955\n",
      "Epoch 735/1000\n",
      "315/315 [==============================] - 0s 903us/step - loss: 380.7624 - val_loss: 400.0691\n",
      "Epoch 736/1000\n",
      "315/315 [==============================] - 0s 875us/step - loss: 379.7348 - val_loss: 397.6281\n",
      "Epoch 737/1000\n",
      "315/315 [==============================] - 0s 823us/step - loss: 380.5306 - val_loss: 394.0925\n",
      "Epoch 738/1000\n",
      "315/315 [==============================] - 0s 898us/step - loss: 379.5976 - val_loss: 401.0176\n",
      "Epoch 739/1000\n",
      "315/315 [==============================] - 0s 864us/step - loss: 380.9680 - val_loss: 403.8604\n",
      "Epoch 740/1000\n",
      "315/315 [==============================] - 0s 860us/step - loss: 380.6721 - val_loss: 395.0872\n",
      "Epoch 741/1000\n",
      "315/315 [==============================] - 0s 900us/step - loss: 382.3676 - val_loss: 395.0688\n",
      "Epoch 742/1000\n",
      "315/315 [==============================] - 0s 977us/step - loss: 380.2294 - val_loss: 393.4085\n",
      "Epoch 743/1000\n",
      "315/315 [==============================] - 0s 907us/step - loss: 381.7004 - val_loss: 393.3954\n",
      "Epoch 744/1000\n",
      "315/315 [==============================] - 0s 922us/step - loss: 381.4598 - val_loss: 393.5172\n",
      "Epoch 745/1000\n",
      "315/315 [==============================] - 0s 857us/step - loss: 380.2373 - val_loss: 393.7393\n",
      "Epoch 746/1000\n",
      "315/315 [==============================] - 0s 851us/step - loss: 380.2470 - val_loss: 393.4582\n",
      "Epoch 747/1000\n",
      "315/315 [==============================] - 0s 944us/step - loss: 380.6840 - val_loss: 394.4501\n",
      "Epoch 748/1000\n",
      "315/315 [==============================] - 0s 986us/step - loss: 380.6269 - val_loss: 400.7154\n",
      "Epoch 749/1000\n",
      "315/315 [==============================] - 0s 957us/step - loss: 380.1432 - val_loss: 394.6085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 750/1000\n",
      "315/315 [==============================] - 0s 851us/step - loss: 380.8036 - val_loss: 408.2419\n",
      "Epoch 751/1000\n",
      "315/315 [==============================] - 0s 846us/step - loss: 380.4458 - val_loss: 393.6985\n",
      "Epoch 752/1000\n",
      "315/315 [==============================] - 0s 897us/step - loss: 380.7752 - val_loss: 394.7069\n",
      "Epoch 753/1000\n",
      "315/315 [==============================] - 0s 901us/step - loss: 380.0490 - val_loss: 393.7256\n",
      "Epoch 754/1000\n",
      "315/315 [==============================] - 0s 976us/step - loss: 380.7499 - val_loss: 394.0375\n",
      "Epoch 755/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.4152 - val_loss: 393.4211\n",
      "Epoch 756/1000\n",
      "315/315 [==============================] - 0s 993us/step - loss: 381.0882 - val_loss: 401.1212\n",
      "Epoch 757/1000\n",
      "315/315 [==============================] - 0s 962us/step - loss: 380.5895 - val_loss: 400.0974\n",
      "Epoch 758/1000\n",
      "315/315 [==============================] - 0s 931us/step - loss: 381.7116 - val_loss: 394.7275\n",
      "Epoch 759/1000\n",
      "315/315 [==============================] - 0s 972us/step - loss: 381.3078 - val_loss: 393.8353\n",
      "Epoch 760/1000\n",
      "315/315 [==============================] - 0s 873us/step - loss: 380.3695 - val_loss: 399.6172\n",
      "Epoch 761/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 379.8759 - val_loss: 395.9437\n",
      "Epoch 762/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.2826 - val_loss: 400.0941\n",
      "Epoch 763/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.5800 - val_loss: 397.3749\n",
      "Epoch 764/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.0219 - val_loss: 394.0629\n",
      "Epoch 765/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.6535 - val_loss: 401.3576\n",
      "Epoch 766/1000\n",
      "315/315 [==============================] - 0s 2ms/step - loss: 379.8929 - val_loss: 401.0898\n",
      "Epoch 767/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.8697 - val_loss: 393.9424\n",
      "Epoch 768/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.6355 - val_loss: 396.6628\n",
      "Epoch 769/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.2781 - val_loss: 398.7347\n",
      "Epoch 770/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.5024 - val_loss: 394.0070\n",
      "Epoch 771/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.6190 - val_loss: 393.8809\n",
      "Epoch 772/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.7321 - val_loss: 393.3951\n",
      "Epoch 773/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.2399 - val_loss: 393.9324\n",
      "Epoch 774/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.1526 - val_loss: 398.6657\n",
      "Epoch 775/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.3610 - val_loss: 402.7711\n",
      "Epoch 776/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.2763 - val_loss: 395.6275\n",
      "Epoch 777/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.8065 - val_loss: 394.2174\n",
      "Epoch 778/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.5003 - val_loss: 393.3903\n",
      "Epoch 779/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.3925 - val_loss: 394.0371\n",
      "Epoch 780/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.0397 - val_loss: 398.4796\n",
      "Epoch 781/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.1137 - val_loss: 395.4457\n",
      "Epoch 782/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.9745 - val_loss: 393.4064\n",
      "Epoch 783/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.0440 - val_loss: 393.6047\n",
      "Epoch 784/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.6744 - val_loss: 402.4173\n",
      "Epoch 785/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.6635 - val_loss: 396.4429\n",
      "Epoch 786/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.0399 - val_loss: 394.2531\n",
      "Epoch 787/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.4661 - val_loss: 394.1300\n",
      "Epoch 788/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.7973 - val_loss: 394.5965\n",
      "Epoch 789/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.6920 - val_loss: 395.2951\n",
      "Epoch 790/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.0349 - val_loss: 393.4815\n",
      "Epoch 791/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.7733 - val_loss: 393.4152\n",
      "Epoch 792/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.9233 - val_loss: 394.1023\n",
      "Epoch 793/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.5451 - val_loss: 396.4355\n",
      "Epoch 794/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.4929 - val_loss: 397.2070\n",
      "Epoch 795/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.8491 - val_loss: 394.4195\n",
      "Epoch 796/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.9130 - val_loss: 411.3923\n",
      "Epoch 797/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.2466 - val_loss: 394.9626\n",
      "Epoch 798/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.2966 - val_loss: 393.4088\n",
      "Epoch 799/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.7412 - val_loss: 397.8953\n",
      "Epoch 800/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.7165 - val_loss: 393.5331\n",
      "Epoch 801/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.5361 - val_loss: 393.7717\n",
      "Epoch 802/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.9394 - val_loss: 396.7412\n",
      "Epoch 803/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.0311 - val_loss: 393.4306\n",
      "Epoch 804/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.7130 - val_loss: 393.9180\n",
      "Epoch 805/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.3993 - val_loss: 394.4537\n",
      "Epoch 806/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.8520 - val_loss: 396.4700\n",
      "Epoch 807/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.7120 - val_loss: 394.0202\n",
      "Epoch 808/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.9003 - val_loss: 395.9122\n",
      "Epoch 809/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.9957 - val_loss: 394.3081\n",
      "Epoch 810/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.7148 - val_loss: 393.4498\n",
      "Epoch 811/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.8313 - val_loss: 396.6185\n",
      "Epoch 812/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 382.9323 - val_loss: 393.7987\n",
      "Epoch 813/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.6251 - val_loss: 396.1767\n",
      "Epoch 814/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.4513 - val_loss: 395.5601\n",
      "Epoch 815/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.0436 - val_loss: 401.7198\n",
      "Epoch 816/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.6964 - val_loss: 396.1797\n",
      "Epoch 817/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 381.1329 - val_loss: 394.3349\n",
      "Epoch 818/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.4829 - val_loss: 393.4115\n",
      "Epoch 819/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 382.0534 - val_loss: 399.5388\n",
      "Epoch 820/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.5381 - val_loss: 396.9219\n",
      "Epoch 821/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.3649 - val_loss: 394.5985\n",
      "Epoch 822/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.5660 - val_loss: 409.5280\n",
      "Epoch 823/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.2754 - val_loss: 393.9207\n",
      "Epoch 824/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.9721 - val_loss: 397.8533\n",
      "Epoch 825/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 1s 2ms/step - loss: 380.4994 - val_loss: 394.1856\n",
      "Epoch 826/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.0647 - val_loss: 394.1466\n",
      "Epoch 827/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.9471 - val_loss: 402.9354\n",
      "Epoch 828/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.7070 - val_loss: 393.4176\n",
      "Epoch 829/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.7802 - val_loss: 394.3173\n",
      "Epoch 830/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.0923 - val_loss: 395.2868\n",
      "Epoch 831/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.5560 - val_loss: 398.8377\n",
      "Epoch 832/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.4716 - val_loss: 393.5273\n",
      "Epoch 833/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.6982 - val_loss: 393.8778\n",
      "Epoch 834/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.5771 - val_loss: 394.1292\n",
      "Epoch 835/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.9707 - val_loss: 400.6713\n",
      "Epoch 836/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.6313 - val_loss: 404.7560\n",
      "Epoch 837/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.2066 - val_loss: 401.1545\n",
      "Epoch 838/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 379.8973 - val_loss: 403.3421\n",
      "Epoch 839/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.5852 - val_loss: 394.5708\n",
      "Epoch 840/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.1075 - val_loss: 394.8813\n",
      "Epoch 841/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.5298 - val_loss: 397.6365\n",
      "Epoch 842/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.9323 - val_loss: 396.7036\n",
      "Epoch 843/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 380.1820 - val_loss: 395.8777\n",
      "Epoch 844/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.5491 - val_loss: 419.8492\n",
      "Epoch 845/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.1202 - val_loss: 394.2310\n",
      "Epoch 846/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 379.7991 - val_loss: 394.6607\n",
      "Epoch 847/1000\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 381.0293 - val_loss: 393.7153\n",
      "Epoch 848/1000\n",
      "315/315 [==============================] - 1s 2ms/step - loss: 380.4612 - val_loss: 396.8824\n",
      "Epoch 849/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.2645 - val_loss: 396.1587\n",
      "Epoch 850/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 379.6389 - val_loss: 399.8621\n",
      "Epoch 851/1000\n",
      "315/315 [==============================] - 0s 998us/step - loss: 380.0732 - val_loss: 396.7290\n",
      "Epoch 852/1000\n",
      "315/315 [==============================] - 0s 876us/step - loss: 379.3936 - val_loss: 396.2327\n",
      "Epoch 853/1000\n",
      "315/315 [==============================] - 0s 861us/step - loss: 379.3739 - val_loss: 399.5513\n",
      "Epoch 854/1000\n",
      "315/315 [==============================] - 0s 827us/step - loss: 379.7199 - val_loss: 393.6936\n",
      "Epoch 855/1000\n",
      "315/315 [==============================] - 0s 948us/step - loss: 380.1756 - val_loss: 395.2810\n",
      "Epoch 856/1000\n",
      "315/315 [==============================] - 0s 916us/step - loss: 381.3046 - val_loss: 393.4580\n",
      "Epoch 857/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.7664 - val_loss: 402.1953\n",
      "Epoch 858/1000\n",
      "315/315 [==============================] - 0s 985us/step - loss: 381.1672 - val_loss: 393.5218\n",
      "Epoch 859/1000\n",
      "315/315 [==============================] - 0s 972us/step - loss: 379.4305 - val_loss: 399.2237\n",
      "Epoch 860/1000\n",
      "315/315 [==============================] - 0s 901us/step - loss: 380.7497 - val_loss: 394.2354\n",
      "Epoch 861/1000\n",
      "315/315 [==============================] - 0s 977us/step - loss: 380.7545 - val_loss: 393.8792\n",
      "Epoch 862/1000\n",
      "315/315 [==============================] - 0s 968us/step - loss: 379.3237 - val_loss: 402.9081\n",
      "Epoch 863/1000\n",
      "315/315 [==============================] - 0s 925us/step - loss: 381.4963 - val_loss: 393.9098\n",
      "Epoch 864/1000\n",
      "315/315 [==============================] - 0s 954us/step - loss: 380.7946 - val_loss: 393.5445\n",
      "Epoch 865/1000\n",
      "315/315 [==============================] - 0s 981us/step - loss: 379.7188 - val_loss: 393.3876\n",
      "Epoch 866/1000\n",
      "315/315 [==============================] - 0s 872us/step - loss: 381.2036 - val_loss: 395.9849\n",
      "Epoch 867/1000\n",
      "315/315 [==============================] - 0s 941us/step - loss: 380.7740 - val_loss: 393.8496\n",
      "Epoch 868/1000\n",
      "315/315 [==============================] - 0s 904us/step - loss: 380.6602 - val_loss: 397.2120\n",
      "Epoch 869/1000\n",
      "315/315 [==============================] - 0s 942us/step - loss: 381.6156 - val_loss: 393.6090\n",
      "Epoch 870/1000\n",
      "315/315 [==============================] - 0s 892us/step - loss: 380.1254 - val_loss: 398.2319\n",
      "Epoch 871/1000\n",
      "315/315 [==============================] - 0s 989us/step - loss: 380.4886 - val_loss: 394.7000\n",
      "Epoch 872/1000\n",
      "315/315 [==============================] - 0s 951us/step - loss: 380.4399 - val_loss: 393.9422\n",
      "Epoch 873/1000\n",
      "315/315 [==============================] - 0s 955us/step - loss: 380.6406 - val_loss: 393.4859\n",
      "Epoch 874/1000\n",
      "315/315 [==============================] - 0s 949us/step - loss: 379.8884 - val_loss: 396.9021\n",
      "Epoch 875/1000\n",
      "315/315 [==============================] - 0s 953us/step - loss: 380.0840 - val_loss: 393.6273\n",
      "Epoch 876/1000\n",
      "315/315 [==============================] - 0s 974us/step - loss: 380.5443 - val_loss: 394.4402\n",
      "Epoch 877/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.9676 - val_loss: 394.3488\n",
      "Epoch 878/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 379.8026 - val_loss: 394.2561\n",
      "Epoch 879/1000\n",
      "315/315 [==============================] - 0s 944us/step - loss: 380.8313 - val_loss: 403.4745\n",
      "Epoch 880/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 381.3826 - val_loss: 394.9694\n",
      "Epoch 881/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 379.4564 - val_loss: 397.3708\n",
      "Epoch 882/1000\n",
      "315/315 [==============================] - 0s 917us/step - loss: 382.0754 - val_loss: 393.8409\n",
      "Epoch 883/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 379.5988 - val_loss: 393.8277\n",
      "Epoch 884/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.2335 - val_loss: 395.6649\n",
      "Epoch 885/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.4742 - val_loss: 396.3878\n",
      "Epoch 886/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.5557 - val_loss: 398.3515\n",
      "Epoch 887/1000\n",
      "315/315 [==============================] - 0s 999us/step - loss: 379.8491 - val_loss: 393.4286\n",
      "Epoch 888/1000\n",
      "315/315 [==============================] - 0s 973us/step - loss: 379.9537 - val_loss: 402.9782\n",
      "Epoch 889/1000\n",
      "315/315 [==============================] - 0s 982us/step - loss: 381.3521 - val_loss: 403.4737\n",
      "Epoch 890/1000\n",
      "315/315 [==============================] - 0s 983us/step - loss: 380.6252 - val_loss: 397.5558\n",
      "Epoch 891/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 383.4016 - val_loss: 396.9173\n",
      "Epoch 892/1000\n",
      "315/315 [==============================] - 0s 995us/step - loss: 379.6965 - val_loss: 406.1321\n",
      "Epoch 893/1000\n",
      "315/315 [==============================] - 0s 898us/step - loss: 379.5403 - val_loss: 393.4402\n",
      "Epoch 894/1000\n",
      "315/315 [==============================] - 0s 905us/step - loss: 379.8109 - val_loss: 410.8210\n",
      "Epoch 895/1000\n",
      "315/315 [==============================] - 0s 931us/step - loss: 380.3076 - val_loss: 396.7566\n",
      "Epoch 896/1000\n",
      "315/315 [==============================] - 0s 956us/step - loss: 380.8923 - val_loss: 393.6411\n",
      "Epoch 897/1000\n",
      "315/315 [==============================] - 0s 884us/step - loss: 380.5901 - val_loss: 401.7958\n",
      "Epoch 898/1000\n",
      "315/315 [==============================] - 0s 961us/step - loss: 380.3629 - val_loss: 394.7653\n",
      "Epoch 899/1000\n",
      "315/315 [==============================] - 0s 980us/step - loss: 380.7780 - val_loss: 393.5748\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 887us/step - loss: 379.9522 - val_loss: 397.9109\n",
      "Epoch 901/1000\n",
      "315/315 [==============================] - 0s 909us/step - loss: 380.5001 - val_loss: 393.5387\n",
      "Epoch 902/1000\n",
      "315/315 [==============================] - 0s 911us/step - loss: 381.1636 - val_loss: 394.2971\n",
      "Epoch 903/1000\n",
      "315/315 [==============================] - 0s 899us/step - loss: 380.8484 - val_loss: 393.9597\n",
      "Epoch 904/1000\n",
      "315/315 [==============================] - 0s 946us/step - loss: 381.0553 - val_loss: 396.5442\n",
      "Epoch 905/1000\n",
      "315/315 [==============================] - 0s 873us/step - loss: 382.1824 - val_loss: 394.8016\n",
      "Epoch 906/1000\n",
      "315/315 [==============================] - 0s 914us/step - loss: 380.0180 - val_loss: 393.3888\n",
      "Epoch 907/1000\n",
      "315/315 [==============================] - 0s 941us/step - loss: 379.9915 - val_loss: 394.2185\n",
      "Epoch 908/1000\n",
      "315/315 [==============================] - 0s 897us/step - loss: 380.6626 - val_loss: 402.3841\n",
      "Epoch 909/1000\n",
      "315/315 [==============================] - 0s 853us/step - loss: 381.2598 - val_loss: 395.1913\n",
      "Epoch 910/1000\n",
      "315/315 [==============================] - 0s 902us/step - loss: 379.5601 - val_loss: 393.9374\n",
      "Epoch 911/1000\n",
      "315/315 [==============================] - 0s 901us/step - loss: 380.3573 - val_loss: 393.6045\n",
      "Epoch 912/1000\n",
      "315/315 [==============================] - 0s 936us/step - loss: 380.9326 - val_loss: 394.0140\n",
      "Epoch 913/1000\n",
      "315/315 [==============================] - 0s 914us/step - loss: 380.3831 - val_loss: 395.2539\n",
      "Epoch 914/1000\n",
      "315/315 [==============================] - 0s 908us/step - loss: 380.0069 - val_loss: 397.3119\n",
      "Epoch 915/1000\n",
      "315/315 [==============================] - 0s 890us/step - loss: 381.9071 - val_loss: 393.7122\n",
      "Epoch 916/1000\n",
      "315/315 [==============================] - 0s 915us/step - loss: 380.2375 - val_loss: 393.7442\n",
      "Epoch 917/1000\n",
      "315/315 [==============================] - 0s 948us/step - loss: 380.5240 - val_loss: 393.3988\n",
      "Epoch 918/1000\n",
      "315/315 [==============================] - 0s 852us/step - loss: 381.2487 - val_loss: 397.0182\n",
      "Epoch 919/1000\n",
      "315/315 [==============================] - 0s 893us/step - loss: 380.1727 - val_loss: 394.1724\n",
      "Epoch 920/1000\n",
      "315/315 [==============================] - 0s 981us/step - loss: 379.8953 - val_loss: 393.5630\n",
      "Epoch 921/1000\n",
      "315/315 [==============================] - 0s 943us/step - loss: 380.0080 - val_loss: 394.3055\n",
      "Epoch 922/1000\n",
      "315/315 [==============================] - 0s 864us/step - loss: 380.9826 - val_loss: 396.9279\n",
      "Epoch 923/1000\n",
      "315/315 [==============================] - 0s 923us/step - loss: 380.2924 - val_loss: 397.2993\n",
      "Epoch 924/1000\n",
      "315/315 [==============================] - 0s 842us/step - loss: 380.6923 - val_loss: 393.9251\n",
      "Epoch 925/1000\n",
      "315/315 [==============================] - 0s 999us/step - loss: 380.9211 - val_loss: 397.6190\n",
      "Epoch 926/1000\n",
      "315/315 [==============================] - 0s 943us/step - loss: 379.2514 - val_loss: 401.3606\n",
      "Epoch 927/1000\n",
      "315/315 [==============================] - 0s 924us/step - loss: 380.8014 - val_loss: 393.4280\n",
      "Epoch 928/1000\n",
      "315/315 [==============================] - 0s 952us/step - loss: 380.2557 - val_loss: 393.4552\n",
      "Epoch 929/1000\n",
      "315/315 [==============================] - 0s 999us/step - loss: 380.2360 - val_loss: 393.3898\n",
      "Epoch 930/1000\n",
      "315/315 [==============================] - 0s 891us/step - loss: 380.2628 - val_loss: 393.4019\n",
      "Epoch 931/1000\n",
      "315/315 [==============================] - 0s 888us/step - loss: 380.9001 - val_loss: 395.4498\n",
      "Epoch 932/1000\n",
      "315/315 [==============================] - 0s 918us/step - loss: 382.2144 - val_loss: 394.3032\n",
      "Epoch 933/1000\n",
      "315/315 [==============================] - 0s 964us/step - loss: 380.0977 - val_loss: 393.3985\n",
      "Epoch 934/1000\n",
      "315/315 [==============================] - 0s 901us/step - loss: 380.0633 - val_loss: 403.6570\n",
      "Epoch 935/1000\n",
      "315/315 [==============================] - 0s 872us/step - loss: 380.5685 - val_loss: 393.7032\n",
      "Epoch 936/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.2410 - val_loss: 393.5508\n",
      "Epoch 937/1000\n",
      "315/315 [==============================] - 0s 950us/step - loss: 379.9986 - val_loss: 396.4087\n",
      "Epoch 938/1000\n",
      "315/315 [==============================] - 0s 932us/step - loss: 380.9444 - val_loss: 411.5212\n",
      "Epoch 939/1000\n",
      "315/315 [==============================] - 0s 828us/step - loss: 380.1705 - val_loss: 394.1558\n",
      "Epoch 940/1000\n",
      "315/315 [==============================] - 0s 952us/step - loss: 382.1880 - val_loss: 393.5167\n",
      "Epoch 941/1000\n",
      "315/315 [==============================] - 0s 977us/step - loss: 381.1364 - val_loss: 393.4696\n",
      "Epoch 942/1000\n",
      "315/315 [==============================] - 0s 897us/step - loss: 381.3092 - val_loss: 393.8411\n",
      "Epoch 943/1000\n",
      "315/315 [==============================] - 0s 861us/step - loss: 379.5832 - val_loss: 401.5176\n",
      "Epoch 944/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.1554 - val_loss: 394.9348\n",
      "Epoch 945/1000\n",
      "315/315 [==============================] - 0s 882us/step - loss: 381.4172 - val_loss: 393.7029\n",
      "Epoch 946/1000\n",
      "315/315 [==============================] - 0s 969us/step - loss: 380.6471 - val_loss: 395.2992\n",
      "Epoch 947/1000\n",
      "315/315 [==============================] - 0s 986us/step - loss: 381.1906 - val_loss: 395.2644\n",
      "Epoch 948/1000\n",
      "315/315 [==============================] - 0s 979us/step - loss: 380.0695 - val_loss: 394.1421\n",
      "Epoch 949/1000\n",
      "315/315 [==============================] - 0s 893us/step - loss: 380.7661 - val_loss: 396.0018\n",
      "Epoch 950/1000\n",
      "315/315 [==============================] - 0s 903us/step - loss: 380.9393 - val_loss: 398.5476\n",
      "Epoch 951/1000\n",
      "315/315 [==============================] - 0s 955us/step - loss: 380.8482 - val_loss: 393.4739\n",
      "Epoch 952/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 379.8271 - val_loss: 393.4059\n",
      "Epoch 953/1000\n",
      "315/315 [==============================] - 0s 946us/step - loss: 380.2337 - val_loss: 394.2025\n",
      "Epoch 954/1000\n",
      "315/315 [==============================] - 0s 880us/step - loss: 381.3260 - val_loss: 394.7711\n",
      "Epoch 955/1000\n",
      "315/315 [==============================] - 0s 911us/step - loss: 381.5535 - val_loss: 393.6734\n",
      "Epoch 956/1000\n",
      "315/315 [==============================] - 0s 903us/step - loss: 380.6761 - val_loss: 406.6570\n",
      "Epoch 957/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 380.1966 - val_loss: 393.4418\n",
      "Epoch 958/1000\n",
      "315/315 [==============================] - 0s 867us/step - loss: 379.9466 - val_loss: 393.6110\n",
      "Epoch 959/1000\n",
      "315/315 [==============================] - 0s 915us/step - loss: 381.0427 - val_loss: 403.4009\n",
      "Epoch 960/1000\n",
      "315/315 [==============================] - 0s 895us/step - loss: 381.4669 - val_loss: 393.7379\n",
      "Epoch 961/1000\n",
      "315/315 [==============================] - 0s 958us/step - loss: 381.8111 - val_loss: 393.4200\n",
      "Epoch 962/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 380.7639 - val_loss: 400.7885\n",
      "Epoch 963/1000\n",
      "315/315 [==============================] - 0s 909us/step - loss: 380.3254 - val_loss: 398.0144\n",
      "Epoch 964/1000\n",
      "315/315 [==============================] - 0s 996us/step - loss: 379.3654 - val_loss: 393.4082\n",
      "Epoch 965/1000\n",
      "315/315 [==============================] - 0s 914us/step - loss: 381.2145 - val_loss: 393.4176\n",
      "Epoch 966/1000\n",
      "315/315 [==============================] - 0s 959us/step - loss: 381.1607 - val_loss: 402.5713\n",
      "Epoch 967/1000\n",
      "315/315 [==============================] - 0s 929us/step - loss: 380.0031 - val_loss: 398.6287\n",
      "Epoch 968/1000\n",
      "315/315 [==============================] - 0s 986us/step - loss: 379.7319 - val_loss: 395.5538\n",
      "Epoch 969/1000\n",
      "315/315 [==============================] - 0s 904us/step - loss: 380.2999 - val_loss: 393.4234\n",
      "Epoch 970/1000\n",
      "315/315 [==============================] - 0s 898us/step - loss: 380.6911 - val_loss: 394.4408\n",
      "Epoch 971/1000\n",
      "315/315 [==============================] - 0s 876us/step - loss: 381.5276 - val_loss: 396.6328\n",
      "Epoch 972/1000\n",
      "315/315 [==============================] - 0s 863us/step - loss: 380.9055 - val_loss: 394.4059\n",
      "Epoch 973/1000\n",
      "315/315 [==============================] - 0s 874us/step - loss: 379.9064 - val_loss: 393.5427\n",
      "Epoch 974/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 898us/step - loss: 379.9427 - val_loss: 402.4526\n",
      "Epoch 975/1000\n",
      "315/315 [==============================] - 0s 925us/step - loss: 381.3503 - val_loss: 402.7602\n",
      "Epoch 976/1000\n",
      "315/315 [==============================] - 0s 943us/step - loss: 380.2381 - val_loss: 399.4900\n",
      "Epoch 977/1000\n",
      "315/315 [==============================] - 0s 946us/step - loss: 379.2683 - val_loss: 396.8351\n",
      "Epoch 978/1000\n",
      "315/315 [==============================] - 0s 893us/step - loss: 380.1035 - val_loss: 393.5959\n",
      "Epoch 979/1000\n",
      "315/315 [==============================] - 0s 978us/step - loss: 381.1729 - val_loss: 398.5750\n",
      "Epoch 980/1000\n",
      "315/315 [==============================] - 0s 894us/step - loss: 382.1765 - val_loss: 393.6116\n",
      "Epoch 981/1000\n",
      "315/315 [==============================] - 0s 1ms/step - loss: 379.8884 - val_loss: 399.9914\n",
      "Epoch 982/1000\n",
      "315/315 [==============================] - 0s 865us/step - loss: 380.9037 - val_loss: 395.4620\n",
      "Epoch 983/1000\n",
      "315/315 [==============================] - 0s 889us/step - loss: 380.3370 - val_loss: 393.6027\n",
      "Epoch 984/1000\n",
      "315/315 [==============================] - 0s 891us/step - loss: 380.8192 - val_loss: 396.0332\n",
      "Epoch 985/1000\n",
      "315/315 [==============================] - 0s 857us/step - loss: 380.3324 - val_loss: 394.5371\n",
      "Epoch 986/1000\n",
      "315/315 [==============================] - 0s 930us/step - loss: 381.5299 - val_loss: 393.4001\n",
      "Epoch 987/1000\n",
      "315/315 [==============================] - 0s 969us/step - loss: 379.7558 - val_loss: 396.2097\n",
      "Epoch 988/1000\n",
      "315/315 [==============================] - 0s 819us/step - loss: 380.5298 - val_loss: 393.8185\n",
      "Epoch 989/1000\n",
      "315/315 [==============================] - 0s 924us/step - loss: 381.0905 - val_loss: 393.6643\n",
      "Epoch 990/1000\n",
      "315/315 [==============================] - 0s 899us/step - loss: 380.1988 - val_loss: 395.7222\n",
      "Epoch 991/1000\n",
      "315/315 [==============================] - 0s 991us/step - loss: 380.5020 - val_loss: 405.3292\n",
      "Epoch 992/1000\n",
      "315/315 [==============================] - 0s 947us/step - loss: 381.3355 - val_loss: 393.8067\n",
      "Epoch 993/1000\n",
      "315/315 [==============================] - 0s 818us/step - loss: 382.6810 - val_loss: 395.5147\n",
      "Epoch 994/1000\n",
      "315/315 [==============================] - 0s 892us/step - loss: 381.1406 - val_loss: 393.8622\n",
      "Epoch 995/1000\n",
      "315/315 [==============================] - 0s 934us/step - loss: 380.8788 - val_loss: 393.4593\n",
      "Epoch 996/1000\n",
      "315/315 [==============================] - 0s 931us/step - loss: 380.2537 - val_loss: 395.4275\n",
      "Epoch 997/1000\n",
      "315/315 [==============================] - 0s 871us/step - loss: 380.8386 - val_loss: 394.0401\n",
      "Epoch 998/1000\n",
      "315/315 [==============================] - 0s 940us/step - loss: 379.5848 - val_loss: 393.9639\n",
      "Epoch 999/1000\n",
      "315/315 [==============================] - 0s 933us/step - loss: 380.2570 - val_loss: 393.8805\n",
      "Epoch 1000/1000\n",
      "315/315 [==============================] - 0s 931us/step - loss: 380.2762 - val_loss: 394.5429\n",
      "34/34 [==============================] - 0s 481us/step\n",
      "1379965 successful\n"
     ]
    }
   ],
   "source": [
    "rmse_list, mape_list = [], []\n",
    "for i in range(len(latitudes)):\n",
    "    rmse, mape = cross_validation(final_df, i)\n",
    "    rmse_list.append(rmse)\n",
    "    mape_list.append(mape)\n",
    "    print(f'{device_ids[i]} successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "383f641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.168720017035618"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_rmse = np.mean(rmse_list)          \n",
    "mean_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a9f77fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.101412828338793,\n",
       " 28.11980326454524,\n",
       " 15.857607314085183,\n",
       " 21.598058026456492,\n",
       " 12.737806158141042,\n",
       " 25.56834626242732,\n",
       " 20.239426744496644,\n",
       " 13.13355844753267,\n",
       " 26.146129076490737,\n",
       " 27.185052047842035]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65808b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5616395260546081"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_mape = np.mean(mape_list)          \n",
    "mean_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "787e7a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6905492667002636,\n",
       " 0.44198048430242154,\n",
       " 0.6008417643018131,\n",
       " 0.4374656701571717,\n",
       " 0.575685004499461,\n",
       " 0.5505790877083362,\n",
       " 0.5274268689222783,\n",
       " 0.7485715150094702,\n",
       " 0.5191001726361589,\n",
       " 0.5241954263087066]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a90d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
